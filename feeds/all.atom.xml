<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Judo Salt Genius</title><link href="http://tabidots.github.io/" rel="alternate"></link><link href="http://tabidots.github.io/feeds/all.atom.xml" rel="self"></link><id>http://tabidots.github.io/</id><updated>2019-05-30T20:08:24+07:00</updated><entry><title>Introduction to Modular Arithmetic, with examples inÂ Clojure</title><link href="http://tabidots.github.io/2019/05/introduction-to-modular-arithmetic" rel="alternate"></link><published>2019-05-30T20:08:24+07:00</published><updated>2019-05-30T20:08:24+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-05-30:/2019/05/introduction-to-modular-arithmetic</id><summary type="html">&lt;p&gt;Though modular arithmetic is rather obscure, we actually use it every dayâ€”primarily when we tell time. And if youâ€™re a programmer, you have probably used the % operator before. However, there is much more to modular arithmetic, and the way it seems to turn normal math on its head is very&amp;nbsp;fascinating.&lt;/p&gt;</summary><content type="html">
&lt;p&gt;Nowadays, we take encryption on the internet for granted, but have you ever wondered how it works? Advances in cryptography since the mid-20th century have relied on an area of mathematics called &lt;strong&gt;modular arithmetic&lt;/strong&gt; to guarantee the security of everything from your WhatsApp conversations and credit cardÂ information.&lt;/p&gt;
&lt;p&gt;Though modular arithmetic is rather obscure, we actually use it every dayâ€”primarily when we tell time. And if youâ€™re a programmer, you have probably used the &lt;code class="highlight"&gt;&lt;span class="nv"&gt;%&lt;/span&gt;&lt;/code&gt; operator before. However, there is much more to modular arithmetic, and the way it seems to turn normal math on its head is veryÂ fascinating.&lt;/p&gt;
&lt;p&gt;In this post, Iâ€™ll cover the very basics of modularÂ arithmetic.&lt;/p&gt;
&lt;h1 id="counting-in-a-circle"&gt;Counting in aÂ circle&lt;/h1&gt;
&lt;p&gt;Modular arithmetic can be described as â€œcounting in a circle.â€ It is also called â€œclock arithmetic,â€ which gives a hint as to how the concept works. We all know that if you go somewhere at 2 oâ€™clock for 4 hours, it will be 6 oâ€™clock when you return, but if you go somewhere at 11 oâ€™clock for 4 hours, it will be 3 oâ€™clock when you returnâ€”&lt;em&gt;not&lt;/em&gt; 15 oâ€™clock (assuming you use the 12-hourÂ clock).&lt;/p&gt;
&lt;p&gt;This is because the numbers of the clock &lt;em&gt;wrap around&lt;/em&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ 1,2,3,4,5,6,7,8,9,10,11,12,1,2,3,4,5,6,7,8,9,10,11,12 \cdots $$&lt;/div&gt;
&lt;p&gt;We can imitate this in Clojure with the &lt;code class="highlight"&gt;cycle&lt;/code&gt; function (donâ€™t actually run this, though, because it will go on forever and lock up your &lt;span class="caps"&gt;REPL&lt;/span&gt;):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;cycle &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;;; 13 because range excludes the endpoint&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you are a musician, you can relate this to many areas of music as well: the names of the notes in the scale, such as &lt;span class="caps"&gt;ABCDEFG&lt;/span&gt;â€”or &lt;em&gt;sa re ga ma pa dha ni&lt;/em&gt;, if you likeâ€”repeat indefinitely. (That doesnâ€™t mean the notes themselves are the same; more on that later.) There is no such note as â€œJ,â€ forÂ example.&lt;/p&gt;
&lt;p&gt;In fact, it is predominantly only Western culture and music that conceptualizes music (and time) linearly. For example, Indian classical music, flamenco, and Javanese gamelan music are three forms of world music that are well-known for their explicit use of cyclic representations of form and rhythm. But thatâ€™s going beyond the scope of this postÂ ğŸ˜…&lt;/p&gt;
&lt;p&gt;Back to numbers. If we stretch the clock cycle out into a number line, you will never encounter a number greater than 12 no matter how far you go along the line. Or rather, once you go beyond 12, you find that the result is 12 less than the â€œnormalâ€Â number:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20...
1 2 3 4 5 6 7 8 9 10 11 12  1  2  3  4  5  6  7  8...
&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id="reduction-modulo-n"&gt;Reduction modulo &lt;span class="math"&gt;\(n\)&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;As the time-telling example shows, addition in modular arithmetic is similar to regular old addition, except with one extra step. If the result is greater than our upper limit (in this case 12), then we can keep subtracting the limit until we get a result that is less than theÂ limit.&lt;/p&gt;
&lt;p&gt;To be more precise, this upper limit is called the &lt;strong&gt;modulus&lt;/strong&gt;, and our final answer represents the &lt;em&gt;remainder after dividing&lt;/em&gt; the initial result by the modulus. The transformation of our initial result into the final answer is called &lt;strong&gt;reduction &lt;em&gt;modulo&lt;/em&gt;&lt;/strong&gt; &lt;span class="math"&gt;\(n\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;OrdinaryÂ arithmetic:&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{aligned}
2 + 2 &amp;amp;= 4 \\
11 + 4 &amp;amp;= 15
\end{aligned}
$$&lt;/div&gt;
&lt;p&gt;ModularÂ arithmetic:&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{aligned}
2 + 2 &amp;amp;\equiv 4 \mod 12 \\
11 + 4 &amp;amp; \textcolor{red}{\not= 15} \\
&amp;amp; \textcolor{green}{\equiv 3 \mod 12}
\end{aligned}
$$&lt;/div&gt;
&lt;p&gt;because 12 goes into 15 one time and leaves a remainder of 3. In other words, the &lt;strong&gt;quotient&lt;/strong&gt; is 1 and the remainder isÂ 3.&lt;/p&gt;
&lt;p&gt;Remainders, then, are absolutely central to modular arithmetic. Nowadays, remainders and long division are things that basically nobody bothers with after elementary school, but evidently &lt;a href="https://en.wikipedia.org/wiki/Carl_Friedrich_Gauss"&gt;Gauss&lt;/a&gt; was fascinated enough with remainders to use them as the basis for an entire mathematical treatise, the &lt;a href="Disquisitiones Arithmeticae"&gt;&lt;em&gt;Disquisitiones Arithmeticae&lt;/em&gt;&lt;/a&gt;. And thatâ€™s why we have modular arithmetic and ultimately, now, encrypted WhatsApp messagesÂ ğŸ˜„&lt;/p&gt;
&lt;p&gt;But waitâ€”whatâ€™s that &lt;span class="math"&gt;\(\equiv\)&lt;/span&gt; sign? Does that mean two things are â€œeven moreâ€ equal? No, &lt;span class="math"&gt;\(\equiv\)&lt;/span&gt; indicates &lt;strong&gt;congruence&lt;/strong&gt; and is read â€œis congruent to.â€ Two numbers are congruent to each other if they have the same remainder after division by a givenÂ modulus.&lt;/p&gt;
&lt;p&gt;Iâ€™ll come back to that in a bit. But first, someÂ code.&lt;/p&gt;
&lt;h1 id="when-is-not"&gt;When &lt;code class="highlight"&gt;&lt;span class="nv"&gt;%&lt;/span&gt;&lt;/code&gt; is not &lt;code class="highlight"&gt;&lt;span class="nv"&gt;%&lt;/span&gt;&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;If you have used the &lt;code class="highlight"&gt;&lt;span class="nv"&gt;%&lt;/span&gt;&lt;/code&gt; operator in programming before, note that the mathematical way of writing modular arithmetic statements is a little different. The math notation focuses on statements of congruence, and treats &lt;span class="math"&gt;\(\mod n\)&lt;/span&gt; as a prepositional phrase. That is, &lt;span class="math"&gt;\(a \equiv b \mod n\)&lt;/span&gt; communicates the idea that &lt;span class="math"&gt;\(a\)&lt;/span&gt; is congruent to &lt;span class="math"&gt;\(b\)&lt;/span&gt; in the â€œworldâ€ of modulo &lt;span class="math"&gt;\(n\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Programming languages, on the other hand, approach modular arithmetic with an emphasis on the operation (action) of reducing a number modulo another number, where &lt;code class="highlight"&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;/code&gt; means &lt;em&gt;reduce&lt;/em&gt; &lt;code class="highlight"&gt;a&lt;/code&gt; &lt;em&gt;(in the world of) modulo&lt;/em&gt; &lt;code class="highlight"&gt;n&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Instead of &lt;em&gt;declaring&lt;/em&gt; congruence, you would perform a Boolean test for it. In Python, &lt;span class="math"&gt;\(a \overset{?}{\equiv} b \mod n\)&lt;/span&gt; becomes &lt;code class="highlight"&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;/code&gt;, which returns &lt;code class="highlight"&gt;True&lt;/code&gt; or &lt;code class="highlight"&gt;False&lt;/code&gt;. (I am including Python here because it follows the convention of using &lt;code class="highlight"&gt;&lt;span class="nv"&gt;%&lt;/span&gt;&lt;/code&gt;, like most programmingÂ languages.)&lt;/p&gt;
&lt;p&gt;In Clojure, the symbol &lt;code class="highlight"&gt;&lt;span class="nv"&gt;%&lt;/span&gt;&lt;/code&gt; is reserved for variables in anonymous functions, so &lt;code class="highlight"&gt;mod&lt;/code&gt; is usedÂ instead.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_1_0" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt; &lt;span class="c1"&gt;# This returns the remainder after division&lt;/span&gt;
&lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;
&lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt; &lt;span class="c1"&gt;# This means integer division and returns the quotient&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="bp"&gt;True&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_1" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_1"&gt;Clojure&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mod&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mod&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;quot &lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;;; Integer division in Clojure&lt;/span&gt;
&lt;span class="nv"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mod&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nv"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="nv"&gt;true&lt;/span&gt;
&lt;span class="c1"&gt;;; Using the arrow to reorder the expressions can let you write them&lt;/span&gt;
&lt;span class="c1"&gt;;; a bit more like you'd write them in imperative languages, hence easier to read&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mod&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nv"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id="congruence"&gt;Congruence&lt;/h1&gt;
&lt;p&gt;In our example above, we saw that not only are 3 and 15 congruent with each other, but by the definition of congruence, so is every number of the form &lt;span class="math"&gt;\(12k + 3\)&lt;/span&gt;, where &lt;span class="math"&gt;\(k\)&lt;/span&gt; is an integer. Thus, all of the following areÂ congruent:&lt;/p&gt;
&lt;div class="math"&gt;$$ \cdots -21, -9, 3, 15, 27, 39, 51 \cdots $$&lt;/div&gt;
&lt;p&gt;We can see that this is true by reducing all of those numbers modÂ 12:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;map &lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mod&lt;/span&gt; &lt;span class="nv"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;-24&lt;/span&gt; &lt;span class="mi"&gt;-9&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt; &lt;span class="mi"&gt;27&lt;/span&gt; &lt;span class="mi"&gt;39&lt;/span&gt; &lt;span class="mi"&gt;51&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="nv"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The infinite set of integers that share this property is called the &lt;strong&gt;congruence class&lt;/strong&gt; of &lt;span class="math"&gt;\(3 \mod 12\)&lt;/span&gt;. An alternative name is &lt;em&gt;residue class&lt;/em&gt;, residue being synonymous withÂ remainder.&lt;/p&gt;
&lt;p&gt;(Note that negative integers are perfectly allowed in modular arithmetic, although in practice, most work is done on non-negative integers only. Negative moduli, on the other hand, are not aÂ thing.)&lt;/p&gt;
&lt;p&gt;What this means is that &lt;span class="math"&gt;\(\mathbb Z\)&lt;/span&gt;, the integers, can be sorted into different â€œboxesâ€ based on their remainder &lt;span class="math"&gt;\(\mod n\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Returning to the music analogy, all notes belong to a &lt;em&gt;pitch class&lt;/em&gt;. For example, C is a pitch class. On the piano, all notes produced by the white key just to the left of the pair of black keys belong to the pitch class C and are therefore a C, despite belonging to different octaves. The actual frequencies that result differ (by multiples of two, to be exact), but functionally, they are treated &lt;em&gt;equivalently&lt;/em&gt;. You could say that the lowest C on the piano is congruent to the highestÂ C.&lt;/p&gt;
&lt;p&gt;Similarly, for every &lt;span class="math"&gt;\(0 \le a &amp;lt; n\)&lt;/span&gt;, there is a unique congruence class &lt;span class="math"&gt;\(\bar{a}_n\)&lt;/span&gt;, also notated &lt;span class="math"&gt;\(\lbrack a \rbrack_n\)&lt;/span&gt; or &lt;span class="math"&gt;\(\bold a_n\)&lt;/span&gt; (though the latter notation could cause confusion with vectors), which can be defined in set-builder notationÂ as&lt;/p&gt;
&lt;div class="math"&gt;$$ \bar{a}_n = \{ z \in Z \space | \space z = kn + a \space \forall \space k \in \mathbb Z \} $$&lt;/div&gt;
&lt;p&gt;That is, the congruence class &lt;span class="math"&gt;\(\bar{a}_n\)&lt;/span&gt; is the set of integers &lt;span class="math"&gt;\(z\)&lt;/span&gt; given by &lt;span class="math"&gt;\(kn + a\)&lt;/span&gt; for all integers &lt;span class="math"&gt;\(k\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;While no programming language can actually process infinite sets, at least Clojure gives you a way to write them. Iâ€™m leaving this here merely to show the Clojure translation of this mathematical definition. If you try to run it, it will freeze your &lt;span class="caps"&gt;REPL&lt;/span&gt;. Youâ€™ve beenÂ warned.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_2_0" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_0"&gt;Simple&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;congruence-class-posint&lt;/span&gt;
  &lt;span class="s"&gt;"Returns an infinite sequence of the positive integers belonging to&lt;/span&gt;
&lt;span class="s"&gt;  the congruence class a mod n."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;map &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;fn &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;* &lt;/span&gt;&lt;span class="nv"&gt;k&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;range&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_2_1" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_1"&gt;Complete&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;congruence-class&lt;/span&gt;
  &lt;span class="s"&gt;"Returns an infinite sequence of all integers belonging to the congruence class a mod n."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;mapcat &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;fn &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;* &lt;/span&gt;&lt;span class="nv"&gt;k&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;* &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;- &lt;/span&gt;&lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="p"&gt;))]&lt;/span&gt; &lt;span class="c1"&gt;;; We need negative k values as well!&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;range&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id="mathbbz_n"&gt;&lt;span class="math"&gt;\(\mathbb{Z}_n\)&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;Actually, the whole congruence class notation is just a mathematical formality. In practice, any single member of a given congruence class can stand in for the entireÂ class.&lt;/p&gt;
&lt;p&gt;Bearing in mind that &lt;span class="math"&gt;\(n \equiv 0 \mod n\)&lt;/span&gt;, this effectively means that in the â€œworldâ€ of modulo &lt;span class="math"&gt;\(n\)&lt;/span&gt;, we only have to consider the integers from &lt;span class="math"&gt;\(0\)&lt;/span&gt; to &lt;span class="math"&gt;\(n - 1\)&lt;/span&gt;. (The clock analogy breaks down a little bit here because in real life, we use 1 through 12 rather than 0 through 11, but it is still a good startingÂ point.)&lt;/p&gt;
&lt;p&gt;Since this is just an introduction, Iâ€™ll skip the bit about residue systems and leave the discussion of ring theory for anotherÂ post.&lt;/p&gt;
&lt;p&gt;We can use the symbol &lt;span class="math"&gt;\(\mathbb{Z}_n\)&lt;/span&gt; to denote this subset of the integers. In code, itâ€™s equallyÂ simple:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now, what do we &lt;em&gt;do&lt;/em&gt; with theseÂ numbers?&lt;/p&gt;
&lt;h2 id="addition-subtraction-and-negative-numbers"&gt;Addition, subtraction, and negativeÂ numbers&lt;/h2&gt;
&lt;p&gt;Addition, as we have already seen, is basically the same as in normal arithmetic, except the numbers wrap around. Outside the context of telling time, you might be surprised to get a â€œsumâ€ that is smaller than the numbers you addedÂ together.&lt;/p&gt;
&lt;p&gt;The same is true forÂ subtraction:&lt;/p&gt;
&lt;div class="math"&gt;$$ 5 - 8 = -3 \equiv 9 \mod 12$$&lt;/div&gt;
&lt;p&gt;The â€œdifferenceâ€ we obtained is &lt;em&gt;greater&lt;/em&gt; than the terms we startedÂ with.&lt;/p&gt;
&lt;p&gt;Also note that negative numbers now denote counting down from &lt;span class="math"&gt;\(n\)&lt;/span&gt; rather than &lt;span class="math"&gt;\(0\)&lt;/span&gt;. If you are familiar with Python, this should make intuitive sense to you, since you can access the last &lt;code class="highlight"&gt;n&lt;/code&gt;th item in a list by writing &lt;code class="highlight"&gt;&lt;span class="n"&gt;my_list&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id="multiplication-and-efficiency"&gt;Multiplication andÂ efficiency&lt;/h2&gt;
&lt;p&gt;Multiplication also works the same as in normal arithmetic, although again, it can be surprising to obtain a product that is smaller than what you startedÂ with.&lt;/p&gt;
&lt;p&gt;Normally, when dealing with even somewhat large numbers, products can â€explodeâ€ fairly quickly. That is, it doesnâ€™t take much for multiplication to quickly result in really large numbers that can slow down computation, even for aÂ computer.&lt;/p&gt;
&lt;p&gt;If you are working in a more bare-bones language such as C++ or JavaScript, you might find it need to implement a tried-and-true modular multiplication algorithm such as &lt;a href="https://en.wikipedia.org/wiki/Montgomery_modular_multiplication"&gt;Montgomery multiplication&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;However, I have found that higher-level languages like Python and Clojure come â€œbatteries includedâ€ in this respect, so I wonâ€™t go into detail about the low-level implementation. You might want to write a helper function to make modular multiplication more convenient to write,Â though.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;mod-mul&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;b&lt;/span&gt; &lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mod&lt;/span&gt; &lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
  &lt;span class="c1"&gt;;; the ' means avoid integer overflow by using bigintegers if necessary&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mod-mul&lt;/span&gt; &lt;span class="mi"&gt;78&lt;/span&gt; &lt;span class="mi"&gt;99&lt;/span&gt; &lt;span class="mi"&gt;123&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;96&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="order-of-operations"&gt;Order ofÂ operations&lt;/h2&gt;
&lt;p&gt;Because each integer in &lt;span class="math"&gt;\(\mathbb{Z}_n\)&lt;/span&gt; is a representative of its entire congruence class, this means that in an expression like &lt;span class="math"&gt;\(a + b \mod n\)&lt;/span&gt;, either &lt;span class="math"&gt;\(a\)&lt;/span&gt; and &lt;span class="math"&gt;\(b\)&lt;/span&gt; (or both) can be reduced before adding if it makes the calculationÂ easier.&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{gathered}
\textcolor{teal}{12309} + \textcolor{maroon}{235301} \equiv \space ? \mod 12 \\
\textcolor{teal}{12309} \equiv \textcolor{skyblue}{9} \mod 12 \qquad \textcolor{maroon}{235301} \equiv \textcolor{mediumpurple}{5} \mod 12 \\
\textcolor{skyblue}{9} + \textcolor{mediumpurple}{5} = 14 \equiv \textcolor{orange}{2} \mod 12
\end{gathered}
$$&lt;/div&gt;
&lt;p&gt;AndÂ indeed,&lt;/p&gt;
&lt;div class="math"&gt;$$ \textcolor{teal}{12309} + \textcolor{maroon}{235301} = 247610 \equiv \textcolor{orange}{2} \mod 12 $$&lt;/div&gt;
&lt;p&gt;This isnâ€™t really that useful for addition and subtraction, but for iterative processes like multiplication (which is just repeated addition) and exponentiation (which is just repeated multiplication), reducing the result after each iteration can speed up computation dramatically, because computers prefer working with smallerÂ numbers.&lt;/p&gt;
&lt;p&gt;Specifically, in Java (on which Clojure is based), the maximum value for an &lt;code class="highlight"&gt;int&lt;/code&gt;eger  is &lt;code class="highlight"&gt;2147483647&lt;/code&gt; and the maximum value for a &lt;code class="highlight"&gt;long&lt;/code&gt; integer is &lt;code class="highlight"&gt;9223372036854775807&lt;/code&gt;. These are the two so-called primitive data types for integers, which yield optimal computationalÂ performance.&lt;/p&gt;
&lt;p&gt;If you want a bigger number, you need to use either Clojureâ€™s &lt;code class="highlight"&gt;bigint&lt;/code&gt; type (or use the auto-promoting &lt;code class="highlight"&gt;+' -' *' inc' dec'&lt;/code&gt; to safeguard against overflow) or Javaâ€™s &lt;code class="highlight"&gt;BigInteger&lt;/code&gt; type. However, computers treat &lt;code class="highlight"&gt;biginteger&lt;/code&gt;s as objects rather than numbers, so they have to work a bit harder (or use more memory) to manipulateÂ them.&lt;/p&gt;
&lt;p&gt;(Side note: To coerce a number to &lt;code class="highlight"&gt;BigInteger&lt;/code&gt;, use the native Clojure function &lt;code class="highlight"&gt;biginteger&lt;/code&gt;. Camel-cased &lt;code class="highlight"&gt;BigInteger.&lt;/code&gt; with a period, is a Java invocation you can use to &lt;em&gt;create&lt;/em&gt; an instance of a &lt;code class="highlight"&gt;BigInteger&lt;/code&gt; object. This opens the doors to other features unavailable in the Clojure standard library, such as generating a random integer that is larger than the maximum &lt;code class="highlight"&gt;long&lt;/code&gt; value. More on this in upcomingÂ posts.)&lt;/p&gt;
&lt;h1 id="going-beyond"&gt;GoingÂ beyond&lt;/h1&gt;
&lt;p&gt;Of course, there is more to arithmetic than just addition, subtraction, and multiplication. What about the rest of the primitiveÂ operations?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Division&lt;/strong&gt;: So far, you may notice that I have left out division. Thatâ€™s because unlike addition, subtraction, and multiplication, there is no â€divisionâ€ in modular arithmetic, at least not in the everyday sense. I will leave that for the nextÂ post.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Exponentiation&lt;/strong&gt;: I also hinted at modular exponentiation. Since it is merely repeated multiplication, the mechanics of it are not hard to understand. However, it opens the door to a whole host of interesting larger mathematical concepts that are worth at least a couple moreÂ posts.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Roots&lt;/strong&gt;: On the other hand, â€œundoingâ€ exponentiation by taking a root &lt;span class="math"&gt;\(\mod n\)&lt;/span&gt; is much, much more involved than you would expect, given how simple exponentiation is. This works quite differently than roots in regularÂ arithmetic.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Logarithms&lt;/strong&gt;: Going one step further, logarithms in modular arithmetic, also called &lt;em&gt;discrete logarithms&lt;/em&gt;, are even more different and difficult than their normal counterparts, although the underlying concept remains the same. However, it is precisely this difficulty that ensures the security of modern math-based encryptionÂ schemes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Stay tuned for upcoming posts in thisÂ series!&lt;/p&gt;</content><category term="modular arithmetic"></category></entry><entry><title>Number Theory in Clojure: AKS primalityÂ test</title><link href="http://tabidots.github.io/2019/04/number-theory-in-clojure-aks-primality-test" rel="alternate"></link><published>2019-04-08T22:34:04+07:00</published><updated>2019-04-08T22:34:04+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-04-08:/2019/04/number-theory-in-clojure-aks-primality-test</id><summary type="html">&lt;p&gt;The &lt;span class="caps"&gt;AKS&lt;/span&gt; test is an award-winning algorithm for proving whether an integer is prime, though I realized too late that it is too slow to be of any practical use. Writing the code itself was useful,&amp;nbsp;though.&lt;/p&gt;</summary><content type="html">
&lt;p&gt;After my &lt;a href="/2019/03/fundamental-theorem-arithmetic"&gt;previous post on the fundamental theorem of arithmetic&lt;/a&gt;, I had intended to move on to modular arithmetic, but I ended up getting pulled down a primality-testing rabbit hole. That ended up involving a return to &lt;a href="/2019/01/polynomial-long-division"&gt;polynomial long division&lt;/a&gt;, except this time inÂ Clojure.&lt;/p&gt;
&lt;h1 id="the-aks-primality-test"&gt;The &lt;span class="caps"&gt;AKS&lt;/span&gt; primalityÂ test&lt;/h1&gt;
&lt;p&gt;In the quest to discover a better method for testing the primality of very large numbers, I came across the &lt;a href="https://en.wikipedia.org/wiki/AKS_primality_test"&gt;&lt;span class="caps"&gt;AKS&lt;/span&gt; primality test&lt;/a&gt;, which is relatively new and has won manyÂ awards.&lt;/p&gt;
&lt;p&gt;This â€œunconditional deterministic polynomial-time algorithm that determines whether
an input number is prime or compositeâ€ is of great theoretical significance and the algorithm has â€œonlyâ€ 5 steps, so I thought it would be worth trying to implement. Plus, when I saw the phrase &lt;em&gt;multiplicative order&lt;/em&gt;, I thought, â€œHey, I know what that isâ€ and gotÂ excited.&lt;/p&gt;
&lt;p&gt;The original paper has a pretty bold, simple title: &lt;a href="https://www.cse.iitk.ac.in/users/manindra/algebra/primality_v6.pdf"&gt;&lt;em&gt;&lt;span class="caps"&gt;PRIMES&lt;/span&gt; is in P&lt;/em&gt;&lt;/a&gt;, but good luck understanding theÂ contents.&lt;/p&gt;
&lt;p&gt;The essence of the algorithmâ€”which I have &lt;em&gt;absolutely zero intuition for&lt;/em&gt;â€”is as follows. Given an integer &lt;span class="math"&gt;\(n &amp;gt; 1\)&lt;/span&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;If &lt;span class="math"&gt;\(n\)&lt;/span&gt; is a perfect power (i.e., &lt;span class="math"&gt;\(n = a^b\)&lt;/span&gt; for any &lt;span class="math"&gt;\(a, b \in â„¤\)&lt;/span&gt;), return &lt;strong&gt;composite&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Find the smallest &lt;span class="math"&gt;\(r\)&lt;/span&gt; coprime to &lt;span class="math"&gt;\(n\)&lt;/span&gt; such that &lt;span class="math"&gt;\(\textrm{ord}_r(n) &amp;gt; (\log_2 n)^2\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;If &lt;span class="math"&gt;\(n\)&lt;/span&gt; is divisible by &lt;span class="math"&gt;\(a\)&lt;/span&gt; for any &lt;span class="math"&gt;\(2 \leq a \leq \min (r, n - 1)\)&lt;/span&gt;, return &lt;strong&gt;composite&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;If &lt;span class="math"&gt;\(n \leq r\)&lt;/span&gt;, return &lt;strong&gt;prime&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;If &lt;span class="math"&gt;\((X + a)^n \not= X^n + a \mod (X^r - 1, n)\)&lt;/span&gt; for any &lt;span class="math"&gt;\(1 \leq a \leq \lfloor \sqrt{\varphi(r)} \log_2(n) \rfloor\)&lt;/span&gt;, return &lt;strong&gt;composite&lt;/strong&gt;. Else return &lt;strong&gt;prime&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="perfect-powers"&gt;PerfectÂ powers&lt;/h1&gt;
&lt;p&gt;I knew I was in for a bit of a slog when I tried to implement the first step of theÂ algorithm.&lt;/p&gt;
&lt;p&gt;What is the best way to determine if a number &lt;span class="math"&gt;\(n = a^b\)&lt;/span&gt; for some &lt;span class="math"&gt;\(a, b \in â„¤\)&lt;/span&gt;? You &lt;em&gt;could&lt;/em&gt; brute-force it, sure. But primality tests are usually concerned with really large numbers, so trying every possible combination of &lt;span class="math"&gt;\(a, b\)&lt;/span&gt; might take a lifetime orÂ two.&lt;/p&gt;
&lt;p&gt;I decided to try a technique I learned from doing many, many Project Euler problems: flip the problem on its side and solve &lt;em&gt;that&lt;/em&gt; problemÂ instead.&lt;/p&gt;
&lt;p&gt;Since we donâ€™t need to know the &lt;em&gt;value&lt;/em&gt; of &lt;span class="math"&gt;\(a\)&lt;/span&gt; and are only concerned with whether or not &lt;span class="math"&gt;\(a \in â„¤\)&lt;/span&gt; (i.e., it is a whole number), we can test the &lt;span class="math"&gt;\(b\)&lt;/span&gt;th roots of &lt;span class="math"&gt;\(n\)&lt;/span&gt; up to some upperÂ bound.&lt;/p&gt;
&lt;h2 id="highest-possible-power"&gt;Highest possibleÂ power?&lt;/h2&gt;
&lt;p&gt;First problem: How do you determine the upper bound? The answer is surprisinglyÂ simple.&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(a \in â„¤\)&lt;/span&gt;, but &lt;span class="math"&gt;\(a\)&lt;/span&gt; cannot be &lt;span class="math"&gt;\(1\)&lt;/span&gt; because &lt;span class="math"&gt;\(1^k = 1\)&lt;/span&gt; for any &lt;span class="math"&gt;\(k\)&lt;/span&gt;. So &lt;span class="math"&gt;\(2\)&lt;/span&gt; is the lower bound for &lt;span class="math"&gt;\(a\)&lt;/span&gt;, and will necessarily have the highest possible &lt;span class="math"&gt;\(b\)&lt;/span&gt;, because if &lt;span class="math"&gt;\(2^b = n\)&lt;/span&gt;, then &lt;span class="math"&gt;\(3^b &amp;gt; n\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We can thus find the highest possible &lt;span class="math"&gt;\(b\)&lt;/span&gt; by solving &lt;span class="math"&gt;\(2^b = n\)&lt;/span&gt; for &lt;span class="math"&gt;\(b\)&lt;/span&gt;, or in other words, &lt;span class="math"&gt;\(\log_2(n)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Since all composite powers can be broken down into prime powers, we only need to look at prime powers up to and including &lt;span class="math"&gt;\(b\)&lt;/span&gt;. Of course, since this is in the context of a primality-testing algorithm, it would be silly to use a prime sieve here. Testing &lt;span class="math"&gt;\(2\)&lt;/span&gt; and then all odd &lt;span class="math"&gt;\(b\)&lt;/span&gt; up to &lt;span class="math"&gt;\(\log_2(n)\)&lt;/span&gt; isÂ sufficient.&lt;/p&gt;
&lt;h2 id="floating-point-fun"&gt;Floating-pointÂ fun&lt;/h2&gt;
&lt;p&gt;Second problem: When dealing with large numbers, floating-point errors can trick the computer into thinking a number is an integer when it shouldnâ€™t be. For example, despite the obvious fact that &lt;span class="math"&gt;\(\sqrt{n}^2 = n\)&lt;/span&gt;, the following returns &lt;code class="highlight"&gt;false&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;923849028343489238498324908928349028490829058&lt;/span&gt;&lt;span class="nv"&gt;N&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/pow&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/sqrt&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="c1"&gt;;; false&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This is because Javaâ€™s built-in math functions return &lt;code class="highlight"&gt;Double&lt;/code&gt;s. What we need here is a way to determine the &lt;span class="math"&gt;\(n\)&lt;/span&gt;th root of a number to an arbitrary degree ofÂ precision.&lt;/p&gt;
&lt;p&gt;I wrote about the Babylonian square root algorithm &lt;a href="/2019/01/squarest-root-in-babylon"&gt;previously&lt;/a&gt;, and it can be adapted to compute &lt;span class="math"&gt;\(n\)&lt;/span&gt;th roots without too much trouble. The square root algorithm &lt;span class="math"&gt;\(t := \frac{t + \frac{x}{t}}{2}\)&lt;/span&gt; isÂ actually:&lt;/p&gt;
&lt;div class="math"&gt;$$ t := \frac{(\textcolor{red}{2} - 1)t + \frac{x}{t^{\textcolor{red}{2} - 1}}}{\textcolor{red}{2}} $$&lt;/div&gt;
&lt;p&gt;So the &lt;span class="math"&gt;\(n\)&lt;/span&gt;th root algorithmÂ is:&lt;/p&gt;
&lt;div class="math"&gt;$$ t := \frac{(n - 1)t + \frac{x}{t^{n - 1}}}{n} $$&lt;/div&gt;
&lt;p&gt;To maintain a little more control over the intermediate values, we can use &lt;code class="highlight"&gt;reduce&lt;/code&gt;d multiplication (&lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce * &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;repeat &lt;/span&gt;&lt;span class="nv"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;base&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/code&gt;) instead of &lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/pow&lt;/span&gt; &lt;span class="nv"&gt;base&lt;/span&gt; &lt;span class="nv"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/code&gt;, and &lt;code class="highlight"&gt;reduce&lt;/code&gt;d addition instead ofÂ multiplication.&lt;/p&gt;
&lt;p&gt;The result of that looks likeÂ this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;naive-bab-nth-root&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;root&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;loop &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;t&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="nv"&gt;iters&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;gt;= &lt;/span&gt;&lt;span class="nv"&gt;iters&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;ts&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;repeat &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;- root &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce * &lt;/span&gt;&lt;span class="nv"&gt;ts&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce + &lt;/span&gt;&lt;span class="nv"&gt;ts&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;root&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
               &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;inc &lt;/span&gt;&lt;span class="nv"&gt;iters&lt;/span&gt;&lt;span class="p"&gt;))))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;However, the sticking point is the type, which is set by the initial approximation &lt;code class="highlight"&gt;t&lt;/code&gt;. Roots of integers are generally either integers or irrational numbers, so you canâ€™t just slap an &lt;code class="highlight"&gt;M&lt;/code&gt; on it (coerce it to &lt;code class="highlight"&gt;BigDecimal&lt;/code&gt;) and call it aÂ day:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Execution error (ArithmeticException) at java.math.BigDecimal/divide (BigDecimal.java:1690).
Non-terminating decimal expansion; no exact representable decimal result.
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You have to specify some level of precision (decimalÂ places).&lt;/p&gt;
&lt;p&gt;Letâ€™s think about this a bit more. This algorithm returns increasingly accurate values with each successive iteration. But due to &lt;strong&gt;&lt;a href="/2019/01/from-zero-to-ero"&gt;floating-point rounding errors&lt;/a&gt;&lt;/strong&gt;, the algorithm might never converge on a true wholeÂ number.&lt;/p&gt;
&lt;p&gt;This means that replacing the current stopping condition (based on iterations, &lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;gt;= &lt;/span&gt;&lt;span class="nv"&gt;iters&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/code&gt;) with one based on a simple heuristic like &lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/floor&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/code&gt; or &lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;bigint&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/code&gt; will produce lots of false negatives (for small inputs) and false positives (for large inputs). NoÂ bueno.&lt;/p&gt;
&lt;h2 id="epsilon-to-the-rescue"&gt;Epsilon to theÂ rescue&lt;/h2&gt;
&lt;p&gt;My first encounter with floating-point rounding errors happened in the context of training a machine learning algorithm (detailed in the link above). Can we apply the same logicÂ here?&lt;/p&gt;
&lt;p&gt;If we define an error threshold &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt;, then we can use that in our stopping condition. Letâ€™s start with using a ridiculously small &lt;code class="highlight"&gt;BigDecimal&lt;/code&gt; value for our threshold. This should surely give us a whole number when the answer &lt;span class="math"&gt;\(\sqrt[b]{n} = a\)&lt;/span&gt; is actually a whole numberâ€”or at least enough zeroes after the decimal point that we can declare with confidence that it is a wholeÂ number.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_1_0" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_0"&gt;1. Fast but bad&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;more-precise-bab-nth-root&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;root&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="hll"&gt;  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;eps&lt;/span&gt; &lt;span class="mf"&gt;0.000000000000000000000000000000000000000001&lt;/span&gt;&lt;span class="nv"&gt;M&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/span&gt;    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;loop &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;t&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="nv"&gt;M&lt;/span&gt; &lt;span class="nv"&gt;iters&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;ts&lt;/span&gt;  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;repeat &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;- root &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="hll"&gt;            &lt;span class="nv"&gt;nxt&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;with-precision&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="nv"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;ts&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/span&gt;                                        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="nv"&gt;+&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;ts&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                                        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;root&lt;/span&gt;&lt;span class="p"&gt;)))]&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;or &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;gt;= &lt;/span&gt;&lt;span class="nv"&gt;iters&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="hll"&gt;                &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;lt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;.abs&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;- &lt;/span&gt;&lt;span class="nv"&gt;nxt&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="nv"&gt;eps&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;
&lt;/span&gt;          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="nv"&gt;nxt&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;inc &lt;/span&gt;&lt;span class="nv"&gt;iters&lt;/span&gt;&lt;span class="p"&gt;)))))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_1" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_1"&gt;2. Better but slow&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;naive-bigdec-nth-root&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;root&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="hll"&gt;  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;eps&lt;/span&gt; &lt;span class="mf"&gt;0.000000000000000000000000000000000000000001&lt;/span&gt;&lt;span class="nv"&gt;M&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;loop &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;t&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="nv"&gt;M&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/span&gt;      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;ts&lt;/span&gt;  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;repeat &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;- root &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="nv"&gt;nxt&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;with-precision&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="nv"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;ts&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                                        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="nv"&gt;+&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;ts&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                                        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;root&lt;/span&gt;&lt;span class="p"&gt;)))]&lt;/span&gt;
&lt;span class="hll"&gt;        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;lt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;.abs&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;- &lt;/span&gt;&lt;span class="nv"&gt;nxt&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="nv"&gt;eps&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;
&lt;/span&gt;          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="nv"&gt;nxt&lt;/span&gt;&lt;span class="p"&gt;))))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_2" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_2"&gt;3. Best&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;require&lt;/span&gt; &lt;span class="o"&gt;'&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;clojure.numeric-tower&lt;/span&gt; &lt;span class="ss"&gt;:as&lt;/span&gt; &lt;span class="nv"&gt;tower&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;babylonian-root&lt;/span&gt;
  &lt;span class="s"&gt;"High-precision BigDecimal nth-root using the Babylonian algorithm,&lt;/span&gt;
&lt;span class="s"&gt;  with a close initial approximation for ridiculously fast convergence."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;root&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;eps&lt;/span&gt; &lt;span class="mf"&gt;0.000000000000000000000000000000000000000001&lt;/span&gt;&lt;span class="nv"&gt;M&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="hll"&gt;    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;loop &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;t&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;bigdec&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;tower/expt&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;root&lt;/span&gt;&lt;span class="p"&gt;)))]&lt;/span&gt; &lt;span class="c1"&gt;;; rough initial approx&lt;/span&gt;
&lt;/span&gt;      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;ts&lt;/span&gt;  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;repeat &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;- root &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="nv"&gt;nxt&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;with-precision&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="nv"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;ts&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                                        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="nv"&gt;+&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;ts&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                                        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;root&lt;/span&gt;&lt;span class="p"&gt;)))]&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;lt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;.abs&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;- &lt;/span&gt;&lt;span class="nv"&gt;nxt&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="nv"&gt;eps&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="nv"&gt;nxt&lt;/span&gt;&lt;span class="p"&gt;))))))&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;babylonian-root&lt;/span&gt; &lt;span class="mi"&gt;92709463147897837085761925410587&lt;/span&gt; &lt;span class="mi"&gt;67&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;;; 3.000000000000000000000000000000000000000000000000000000000034073599999999794044017777778109595749154M&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;(Note, the apostrophes in &lt;code class="highlight"&gt;*'&lt;/code&gt; and &lt;code class="highlight"&gt;+'&lt;/code&gt; allow values to silently overflow from &lt;code class="highlight"&gt;long&lt;/code&gt; to &lt;code class="highlight"&gt;BigInteger&lt;/code&gt; ifÂ necessary.)&lt;/p&gt;
&lt;p&gt;In &lt;em&gt;1. Fast but bad&lt;/em&gt;, I used both iterations and epsilon as stopping conditions, thinking that a perfect power would stop the loop early and speed up computation. It did, but at the expense of accuracy. Even-numbered roots returned &lt;em&gt;really&lt;/em&gt; strange outputs (unrealistically large numbers). This is similar to gradient descent overshooting the minimum of the cost function in training a neural network because the learning rate is tooÂ high.&lt;/p&gt;
&lt;p&gt;That means that in some cases, more than 100 iterations were required for the algorithm to converge. So my next attempt was &lt;em&gt;2. Better but slow&lt;/em&gt;, in which I removed the iterations as a stopping condition, and let the algorithm run until the difference fell under the errorÂ threshold.&lt;/p&gt;
&lt;p&gt;That worked, but it was &lt;em&gt;slow&lt;/em&gt;. Try using it to calculate &lt;span class="math"&gt;\(\sqrt[67]{92709463147897837085761925410587}\)&lt;/span&gt;â€”itâ€™s not very fast. Since this is just part of step one of a very complex algorithm, it should ideally happen in anÂ instant.&lt;/p&gt;
&lt;p&gt;Then it occurred to me that the algorithm should not take so many iterations to converge. To be exact, the number of iterations required is a direct consequence of how accurate the initial approximation is. This matters less for small inputs, but makes a colossal difference with largeÂ inputs.&lt;/p&gt;
&lt;p&gt;There is probably a formula to determine a good initial guess without resorting to floating-point arithmetic, but doing so turned out to be a very fast and good enough solution nonetheless. Simply express &lt;span class="math"&gt;\(\sqrt[b]{n}\)&lt;/span&gt; as &lt;span class="math"&gt;\(n^{\frac{1}{b}}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In Clojure, that looks like &lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;tower/expt&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;root&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/code&gt;. (I prefer using &lt;code class="highlight"&gt;tower/expt&lt;/code&gt;, but you could certainly use built-in Java interop to do this with &lt;code class="highlight"&gt;Math/pow&lt;/code&gt; instead.) And voilÃ ! We have arrived at &lt;em&gt;3. Best&lt;/em&gt;. It converges instantly and returns a highly accurateÂ result.&lt;/p&gt;
&lt;h2 id="testing-wholeness"&gt;TestingÂ wholeness&lt;/h2&gt;
&lt;p&gt;As we intended, the values returned by &lt;code class="highlight"&gt;babylonian-root&lt;/code&gt; have a ridiculous amount of decimal places, and we can safely assume that a resultÂ like&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;(scroll right ======&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;)
3.000000000000000000000000000000000000000000000000000000000034073599999999794044017777778109595749154M
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;is, with 99.9% certainty, a whole number. But there are still non-zero digits after the decimal point &lt;em&gt;at some point&lt;/em&gt;, which means simply using &lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/floor&lt;/span&gt; &lt;span class="nv"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/code&gt; wonâ€™t work hereÂ either.&lt;/p&gt;
&lt;p&gt;The best way to be sure if our &lt;span class="math"&gt;\(n\)&lt;/span&gt;th root is an integer is to &lt;code class="highlight"&gt;Math/floor&lt;/code&gt; it, then raise it to the &lt;span class="math"&gt;\(n\)&lt;/span&gt;th power and see if it equals our input value. Both values must be coerced to the same type in order to test equality, and coercing to &lt;code class="highlight"&gt;bigint&lt;/code&gt; ensures that small and large values will be accommodated equally well. (Using &lt;code class="highlight"&gt;*'&lt;/code&gt; will only cause values to overflow to &lt;code class="highlight"&gt;bigint&lt;/code&gt; if they are largeÂ enough.)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;nth-root-is-integer?&lt;/span&gt;
  &lt;span class="s"&gt;"Tests if the nth root of x is an integer in the mathematical&lt;/span&gt;
&lt;span class="s"&gt;  (not programming) senseâ€”i.e., if it is a whole number.)."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;floor&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;bigint&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/floor&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;babylonian-root&lt;/span&gt; &lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
        &lt;span class="nv"&gt;exp&lt;/span&gt;   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;bigint&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="nv"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;repeat &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;floor&lt;/span&gt;&lt;span class="p"&gt;)))]&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="nv"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="testing-perfect-power-ness"&gt;Testing perfectÂ power-ness&lt;/h2&gt;
&lt;p&gt;Finally, weâ€™re ready to bring it all together. To test for a perfect power, we iterate through all possible &lt;span class="math"&gt;\(b\)&lt;/span&gt; up to the upper bound we established earlier and return &lt;code class="highlight"&gt;true&lt;/code&gt;, terminating early, if any &lt;span class="math"&gt;\(\sqrt[b]{n} = \lfloor \sqrt[b]{n} \rfloor\)&lt;/span&gt;. Otherwise, return &lt;code class="highlight"&gt;false.&lt;/code&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;perfect-power?&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;max-power&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/log&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/log&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="nv"&gt;powers&lt;/span&gt;    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;cons &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="nv"&gt;odd?&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;inc &lt;/span&gt;&lt;span class="nv"&gt;max-power&lt;/span&gt;&lt;span class="p"&gt;))))]&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;some &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;partial &lt;/span&gt;&lt;span class="nv"&gt;nth-root-is-integer?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;powers&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In Clojure, it is more idiomatic to use &lt;code class="highlight"&gt;some&lt;/code&gt;, although this will technically return the first non-&lt;code class="highlight"&gt;nil&lt;/code&gt; value rather than &lt;code class="highlight"&gt;true&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Phew! That was a lot of work just for a minor part of the algorithm. Letâ€™s moveÂ on.&lt;/p&gt;
&lt;h1 id="r-u-ready"&gt;&lt;span class="math"&gt;\(r\)&lt;/span&gt; uÂ ready?&lt;/h1&gt;
&lt;p&gt;The next few steps of the algorithm revolve around some number &lt;span class="math"&gt;\(r\)&lt;/span&gt; that satisfies certainÂ criteria.&lt;/p&gt;
&lt;p&gt;The first step draws on a concept called &lt;em&gt;multiplicative order&lt;/em&gt;, which comes from modular arithmetic. I donâ€™t want to cover it in full detail here, as Iâ€™m planning to write future posts on modular arithmetic in this series, so I will present just the functions and a simple explanationÂ here.&lt;/p&gt;
&lt;p&gt;After we find &lt;span class="math"&gt;\(r\)&lt;/span&gt;, the next steps are prettyÂ straightforward.&lt;/p&gt;
&lt;h2 id="multiplicative-order-in-brief"&gt;Multiplicative order (inÂ brief)&lt;/h2&gt;
&lt;p&gt;Itâ€™s similar to the concept of &lt;em&gt;multiplicative inverse&lt;/em&gt;, which &lt;a href="/2019/01/mod-squad"&gt;I have covered before&lt;/a&gt;, although instead of looking for a number that is congruent to &lt;span class="math"&gt;\(1\)&lt;/span&gt; after multiplication, we are looking for a number that is congruent to &lt;span class="math"&gt;\(1\)&lt;/span&gt; afterÂ exponentiation.&lt;/p&gt;
&lt;p&gt;Implementing a multiplicative order function in code takes a few steps. If I were to explain them in full here, this blog post would become overwhelming, so I am just going to leave the code here and revisit modular arithmetic more thoroughly in future posts. Iâ€™ll provide a link here when those posts areÂ ready.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;mod-pow&lt;/span&gt;
  &lt;span class="c1"&gt;;; Adapted from https://en.wikipedia.org/wiki/Modular_exponentiation&lt;/span&gt;
  &lt;span class="s"&gt;"Quickly calculates a ^ b % m. Useful when a and b are very large integers."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;base&lt;/span&gt; &lt;span class="nv"&gt;exp&lt;/span&gt; &lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;or &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="nv"&gt;m&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="nv"&gt;base&lt;/span&gt; &lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;loop &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;base&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mod&lt;/span&gt; &lt;span class="nv"&gt;base&lt;/span&gt; &lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;e&lt;/span&gt; &lt;span class="nv"&gt;exp&lt;/span&gt; &lt;span class="nv"&gt;res&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zero? &lt;/span&gt;&lt;span class="nv"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;res&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;base&lt;/span&gt; &lt;span class="nv"&gt;base&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mod&lt;/span&gt; &lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
               &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;bit-shift-right &lt;/span&gt;&lt;span class="nv"&gt;e&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
               &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;odd?&lt;/span&gt; &lt;span class="nv"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;res&lt;/span&gt; &lt;span class="nv"&gt;base&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mod&lt;/span&gt; &lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                 &lt;span class="nv"&gt;res&lt;/span&gt;&lt;span class="p"&gt;))))))&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;powers-of-a-mod-n&lt;/span&gt;
  &lt;span class="s"&gt;"a^k (mod n) for all 0 â‰¦ k &amp;lt; n, where k âˆˆ â„¤."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;map &lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mod-pow&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;%&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;multiplicative-order&lt;/span&gt;
  &lt;span class="s"&gt;"ord_n(a), the smallest positive integer k such that a^k â‰¡ 1 (mod n) where&lt;/span&gt;
&lt;span class="s"&gt;  a is coprime to n. a^0 â‰¡ 1 (mod n) for any n, so the quick way to find k&lt;/span&gt;
&lt;span class="s"&gt;  is to count the distinct powers of a (mod n)."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;when &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;coprime?&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;count &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;distinct &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;powers-of-a-mod-n&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\textrm{ord}_r(n)\)&lt;/span&gt; is read â€œthe multiplicative order of &lt;span class="math"&gt;\(n \pmod r\)&lt;/span&gt;â€. In the math notation, the modulus comes first, but when you read it aloud, the modulus comes last, so I have written the function with the arguments in the latterÂ order.&lt;/p&gt;
&lt;h2 id="eulers-totient-varphi-phi-function"&gt;Eulerâ€™s totient (&lt;span class="math"&gt;\(\varphi\)&lt;/span&gt; phi)Â function&lt;/h2&gt;
&lt;p&gt;The (very complicated) last step of the algorithm requires first calculating &lt;span class="math"&gt;\(\varphi(r)\)&lt;/span&gt;, which is the number of integers less than &lt;span class="math"&gt;\(r\)&lt;/span&gt; that are coprime to it. That is, their greatest common divisor is &lt;span class="math"&gt;\(1\)&lt;/span&gt; (&lt;span class="math"&gt;\(4\)&lt;/span&gt; and &lt;span class="math"&gt;\(9\)&lt;/span&gt; are coprime to each other, forÂ example.)&lt;/p&gt;
&lt;p&gt;For any prime number &lt;span class="math"&gt;\(p\)&lt;/span&gt;, &lt;span class="math"&gt;\(\varphi(p)\)&lt;/span&gt; is &lt;span class="math"&gt;\(p - 1\)&lt;/span&gt;. Of course, since we donâ€™t know if our target number is prime, that doesnâ€™t help us much in thisÂ case.&lt;/p&gt;
&lt;p&gt;There is another way to optimize the totient function using Eulerâ€™s product rule, but because that requires factorizing the number, that is also of little helpÂ here.&lt;/p&gt;
&lt;p&gt;So, letâ€™s proceed with the most naÃ¯ve, simplistic version of theÂ function.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;naive-phi&lt;/span&gt;
  &lt;span class="s"&gt;"Naive version of Euler's totient function that only uses gcd, since&lt;/span&gt;
&lt;span class="s"&gt;  the optimized version requires factoring n first."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;count &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;tower/gcd&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;%&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id="the-crazy-polynomial-part"&gt;The crazy polynomialÂ part&lt;/h1&gt;
&lt;p&gt;Now we come to the most formidable part of the algorithm. It took a while to even understand the notation at first. We have toÂ find&lt;/p&gt;
&lt;div class="math"&gt;$$\textcolor{#1f77b4}{(X + a)^n} \stackrel{?}{=} \textcolor{#e377c2}{X^n + a} \mod (\textcolor{mediumpurple}{X^r - 1}, \textcolor{orange}{n}), 1 \leq a \leq \lfloor \sqrt{\varphi(r)} \log_2(n) \rfloor$$&lt;/div&gt;
&lt;p&gt;The capital letter &lt;span class="math"&gt;\(X\)&lt;/span&gt; is apparently a convention from abstract algebra. This way of notating polynomials reflects the fact that we are not concerned with actually filling in the value of &lt;span class="math"&gt;\(x\)&lt;/span&gt; in a given polynomial, as if it were a function; it is just aÂ symbol.&lt;/p&gt;
&lt;p&gt;When I first saw this, the â€œdouble modulusâ€ was the part I found most confusing. Iâ€™m still not sure of the correct terminology for what is going on here, but essentially, this is what we need toÂ compare:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Left-hand side: Take the remainder of &lt;span class="math"&gt;\(\frac{\textcolor{#1f77b4}{(X + a)^n}}{\textcolor{mediumpurple}{X^r - 1}}\)&lt;/span&gt;, then reduce all coefficients &lt;span class="math"&gt;\(\mod \textcolor{orange}{n}\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Right-hand side: Take the remainder of &lt;span class="math"&gt;\(\frac{\textcolor{#e377c2}{X^n + a}}{\textcolor{mediumpurple}{X^r - 1}}\)&lt;/span&gt;, then reduce all coefficients &lt;span class="math"&gt;\(\mod \textcolor{orange}{n}\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This requires polynomial long division. BraceÂ yourself.&lt;/p&gt;
&lt;h2 id="polynomials-in-clojure"&gt;Polynomials inÂ Clojure&lt;/h2&gt;
&lt;p&gt;Thanks to &lt;em&gt;A Programmerâ€™s Introduction to Mathematics&lt;/em&gt;, I was already familiar with the convention of representing polynomials in code as an array of coefficients, where the index of a coefficient represents the power of its associated term. For example, &lt;span class="math"&gt;\(x^3 - 2x^2 + 17\)&lt;/span&gt; would be &lt;code class="highlight"&gt;[17, 0, -2, 1]&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Trying to port this exact representation from Python (or Java, or some other C-type language) to Clojure got a bit messy as soon as I tried to implement an addition function, because Clojure does not have a built-in &lt;code class="highlight"&gt;map-longest&lt;/code&gt; function, or a clean way of writing one. Some helpful folks on the awesome &lt;a href="https://clojurians.slack.com"&gt;Clojurians Slack group&lt;/a&gt; advised me to try representing polynomials as a map instead, with the powers as keywords: &lt;code class="highlight"&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;17&lt;/span&gt;, &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;-2&lt;/span&gt;, &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In addition to being easier to manipulate in Clojure, this way of organizing the data has the added bonus of being order-agnostic and not being sensitive to omitted zeroÂ coefficients.&lt;/p&gt;
&lt;p&gt;Well, in order to &lt;em&gt;ensure&lt;/em&gt; that the zero coefficients donâ€™t matter way or the other, we should write a â€œtrimâ€ function to save us from possibly pulling out ourÂ hair:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;poly-trim-&lt;/span&gt;
  &lt;span class="s"&gt;"Removes terms with zero coefficients from a polynomial."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;pnml&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;-&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zero? &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;get &lt;/span&gt;&lt;span class="nv"&gt;pnml&lt;/span&gt; &lt;span class="nv"&gt;%&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;keys &lt;/span&gt;&lt;span class="nv"&gt;pnml&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
       &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;dissoc &lt;/span&gt;&lt;span class="nv"&gt;%1&lt;/span&gt; &lt;span class="nv"&gt;%2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;pnml&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Itâ€™s an intuitively simple idea that requires a slightly roundabout functional implementation. Get the keys of the map (powers of the polynomial) whose coefficient is zero, then successively &lt;code class="highlight"&gt;dissoc&lt;/code&gt; (remove) those key-val pairs from theÂ map.&lt;/p&gt;
&lt;h2 id="low-hanging-fruit"&gt;Low-hangingÂ fruit&lt;/h2&gt;
&lt;p&gt;Letâ€™s nail the low-hanging fruit first. Reducing the coefficients of a polynomial &lt;span class="math"&gt;\(\mod n\)&lt;/span&gt; is prettyÂ easy:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;poly-mod&lt;/span&gt;
  &lt;span class="s"&gt;"Reduces the terms of a given polynomial mod n."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;pnml&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zipmap &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;keys &lt;/span&gt;&lt;span class="nv"&gt;pnml&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;map &lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mod&lt;/span&gt; &lt;span class="nv"&gt;%&lt;/span&gt; &lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;vals &lt;/span&gt;&lt;span class="nv"&gt;pnml&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Next, the right-hand-side term: &lt;span class="math"&gt;\(\textcolor{#e377c2}{X^n + a}\)&lt;/span&gt;. Since &lt;code class="highlight"&gt;n&lt;/code&gt; is the initial input to the algorithm and &lt;code class="highlight"&gt;a&lt;/code&gt; will be taken from a range, we can treat them as constants. We can thus write this as &lt;code class="highlight"&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;, &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Then, the polynomial modulus: &lt;span class="math"&gt;\(\textcolor{mediumpurple}{X^r - 1}\)&lt;/span&gt;. &lt;code class="highlight"&gt;r&lt;/code&gt; will have been defined in a previous step, so we can treat it as a constant. We can thus write this as &lt;code class="highlight"&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nv"&gt;r&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;, &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;That leaves two (rather tedious) things: Expanding &lt;span class="math"&gt;\(\textcolor{#1f77b4}{(X + a)^n}\)&lt;/span&gt;, which should be done using modular exponentiation to prevent the coefficients from exploding; and implementing polynomial longÂ division.&lt;/p&gt;
&lt;h2 id="modular-exponentiation-of-polynomials"&gt;Modular exponentiation ofÂ polynomials&lt;/h2&gt;
&lt;p&gt;Exponentiation requires multiplication, which requiresÂ addition.&lt;/p&gt;
&lt;p&gt;Representing polynomials as hash-maps allows us to add polynomials extremely concisely using &lt;code class="highlight"&gt;merge-with&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;add&lt;/span&gt;
  &lt;span class="s"&gt;"Adds two polynomials."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;p1&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;poly-trim-&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;merge-with + &lt;/span&gt;&lt;span class="nv"&gt;p1&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To multiply polynomials, we take every pair of terms with non-zero coefficients, add their powers, and multiply their coefficients to obtain the new terms. If there are multiple terms with the same power, add thoseÂ coefficients.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;mul&lt;/span&gt;
  &lt;span class="s"&gt;"Multiplies two polynomials."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;p1&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;-&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;for &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;powers1&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;keys &lt;/span&gt;&lt;span class="nv"&gt;p1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;powers2&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;keys &lt;/span&gt;&lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
         &lt;span class="p"&gt;{(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="nv"&gt;powers1&lt;/span&gt; &lt;span class="nv"&gt;powers2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;* &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;get &lt;/span&gt;&lt;span class="nv"&gt;p1&lt;/span&gt; &lt;span class="nv"&gt;powers1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;get &lt;/span&gt;&lt;span class="nv"&gt;p2&lt;/span&gt; &lt;span class="nv"&gt;powers2&lt;/span&gt;&lt;span class="p"&gt;))})&lt;/span&gt;
       &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;merge-with + &lt;/span&gt;&lt;span class="nv"&gt;%1&lt;/span&gt; &lt;span class="nv"&gt;%2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{})&lt;/span&gt;
       &lt;span class="nv"&gt;poly-trim-&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To exponentiate polynomials, just &lt;code class="highlight"&gt;reduce&lt;/code&gt;!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;exp&lt;/span&gt;
  &lt;span class="s"&gt;"Exponentiation of a polynomial, [p(x)]^e."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;pnml&lt;/span&gt; &lt;span class="nv"&gt;e&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="nv"&gt;mul&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;repeat &lt;/span&gt;&lt;span class="nv"&gt;e&lt;/span&gt; &lt;span class="nv"&gt;pnml&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;However, in this case, we need to exponentiate our polynomial &lt;span class="math"&gt;\(\mod n\)&lt;/span&gt;, so in order to keep the coefficients from exploding (because the values will quickly become astronomical, especially when testing very large numbers), letâ€™s reduce the coefficients &lt;span class="math"&gt;\(\mod n\)&lt;/span&gt; after everyÂ multiplication.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;mod-exp&lt;/span&gt;
  &lt;span class="s"&gt;"Slightly faster version of [p(x)]^e (mod m), where p(x) is a polynomial.&lt;/span&gt;
&lt;span class="s"&gt;  Reduces the result of each multiplication mod m with every iteration, rather&lt;/span&gt;
&lt;span class="s"&gt;  than only once at the end, in order to keep the intermediate coefficients&lt;/span&gt;
&lt;span class="s"&gt;  from exploding."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;pnml&lt;/span&gt; &lt;span class="nv"&gt;e&lt;/span&gt; &lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;poly-mod&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mul&lt;/span&gt; &lt;span class="nv"&gt;%1&lt;/span&gt; &lt;span class="nv"&gt;%2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;repeat &lt;/span&gt;&lt;span class="nv"&gt;e&lt;/span&gt; &lt;span class="nv"&gt;pnml&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="polynomial-remainder-shortcut"&gt;Polynomial remainderÂ (shortcut)&lt;/h2&gt;
&lt;p&gt;Interestingly, the particular polynomial divisor &lt;span class="math"&gt;\(\textcolor{mediumpurple}{X^r - 1}\)&lt;/span&gt; used in this algorithm seems to have some kind of special property related to &lt;em&gt;cyclotomic polynomials&lt;/em&gt;. I have no idea what those are, but someone who implemented the algorithm in JavaScript has found &lt;a href="https://medium.com/@sibu.it13/aks-primality-test-f184cf6365a1"&gt;an interesting shortcut&lt;/a&gt; to finding the remainder after dividing any polynomial by thatÂ divisor.&lt;/p&gt;
&lt;p&gt;I donâ€™t know &lt;em&gt;why&lt;/em&gt; it works, but I was able to implement it pretty quickly in Clojure. Check out the Medium post linked above for an explanation of &lt;em&gt;how&lt;/em&gt; itÂ works.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;quick-poly-rem&lt;/span&gt;
  &lt;span class="s"&gt;"Shortcut to finding the remainder of p(x) / (x^r - 1)."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;pnml&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;poly-trim-&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;reduce-kv&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;fn &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;res&lt;/span&gt; &lt;span class="nv"&gt;power&lt;/span&gt; &lt;span class="nv"&gt;coeff&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                           &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;merge-with + &lt;/span&gt;&lt;span class="nv"&gt;res&lt;/span&gt; &lt;span class="p"&gt;{(&lt;/span&gt;&lt;span class="nf"&gt;mod&lt;/span&gt; &lt;span class="nv"&gt;power&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;coeff&lt;/span&gt;&lt;span class="p"&gt;}))&lt;/span&gt;
                         &lt;span class="p"&gt;{}&lt;/span&gt; &lt;span class="nv"&gt;pnml&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="polynomial-long-division"&gt;Polynomial longÂ division&lt;/h2&gt;
&lt;p&gt;However, I tend not to be satisfied with these hand-wavy magic tricks (or at least, it &lt;em&gt;seems&lt;/em&gt; hand-wavy because the author of that article didnâ€™t provide the source of the â€œtrickâ€). So I decided to roll up my sleeves and implement polynomial long division from scratchÂ (ugh).&lt;/p&gt;
&lt;p&gt;Having done it once in Python, I was not looking forward to doing itÂ again.&lt;/p&gt;
&lt;p&gt;First, we need to implement subtraction, because otherwise the intermediate steps of the division will get messy (because of the &lt;span class="caps"&gt;LISP&lt;/span&gt; syntax). We have multiplication already, so this is easy. Just multiply the polynomial by &lt;code class="highlight"&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;/code&gt;, a constant of &lt;span class="math"&gt;\(-1\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;sub&lt;/span&gt;
  &lt;span class="s"&gt;"Subtracts polynomial p2(x) from polynomial p1(x)."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;p1&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;neg-p2&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mul&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;})]&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;poly-trim-&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;add&lt;/span&gt; &lt;span class="nv"&gt;p1&lt;/span&gt; &lt;span class="nv"&gt;neg-p2&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;From there, itâ€™s just a matter of translating the algorithm into Clojure. I found it easier to read and translate &lt;a href="http://www.math.ucla.edu/~radko/circles/lib/data/Handout-358-436.pdf"&gt;the long-hand procedure from English prose&lt;/a&gt; than translating pre-cooked implementations in other programmingÂ languages.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;degree&lt;/span&gt;
  &lt;span class="s"&gt;"Finds the degree (power of highest-power term) of a polynomial."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;pnml&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;apply max &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;keys &lt;/span&gt;&lt;span class="nv"&gt;pnml&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;lc&lt;/span&gt;
  &lt;span class="s"&gt;"Leading coefficient (coefficient of highest-power term) of a polynomial."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;pnml&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;get &lt;/span&gt;&lt;span class="nv"&gt;pnml&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;degree&lt;/span&gt; &lt;span class="nv"&gt;pnml&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;poly-quot-&lt;/span&gt;
  &lt;span class="s"&gt;"The quotient of a polynomial p1(x) divided by another p2(x).&lt;/span&gt;
&lt;span class="s"&gt;  Returns nil if p2 is of a higher degree than p1."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;p1&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;d1&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;degree&lt;/span&gt; &lt;span class="nv"&gt;p1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;d2&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;degree&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;when &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;gt;= &lt;/span&gt;&lt;span class="nv"&gt;d1&lt;/span&gt; &lt;span class="nv"&gt;d2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;{(&lt;/span&gt;&lt;span class="nb"&gt;- &lt;/span&gt;&lt;span class="nv"&gt;d1&lt;/span&gt; &lt;span class="nv"&gt;d2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                &lt;span class="c1"&gt;;; power = difference in degree&lt;/span&gt;
       &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;lc&lt;/span&gt; &lt;span class="nv"&gt;p1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;lc&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;))})))&lt;/span&gt;  &lt;span class="c1"&gt;;; coeff = quotient of lc's&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;div&lt;/span&gt;
  &lt;span class="s"&gt;"Polynomial long division of p1(x) / p2(x).&lt;/span&gt;
&lt;span class="s"&gt;  Returns nil if p2 is of a higher degree than p1."&lt;/span&gt;
  &lt;span class="c1"&gt;;; http://www.math.ucla.edu/~radko/circles/lib/data/Handout-358-436.pdf&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;p1&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;when-let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;q&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;poly-quot-&lt;/span&gt; &lt;span class="nv"&gt;p1&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;               &lt;span class="c1"&gt;;; sanity check&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;loop &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;qs&lt;/span&gt; &lt;span class="nv"&gt;q&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;-&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="nv"&gt;q&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mul&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;sub&lt;/span&gt; &lt;span class="nv"&gt;p1&lt;/span&gt;&lt;span class="p"&gt;))]&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;empty?&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="ss"&gt;:quotient&lt;/span&gt; &lt;span class="nv"&gt;qs&lt;/span&gt; &lt;span class="ss"&gt;:remainder&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="c1"&gt;;; divides evenly&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;if-let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;new-q&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;poly-quot-&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;conj &lt;/span&gt;&lt;span class="nv"&gt;qs&lt;/span&gt; &lt;span class="nv"&gt;new-q&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                 &lt;span class="c1"&gt;;; divides with remainder&lt;/span&gt;
                 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;-&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="nv"&gt;new-q&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mul&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;sub&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
          &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="ss"&gt;:quotient&lt;/span&gt; &lt;span class="nv"&gt;qs&lt;/span&gt; &lt;span class="ss"&gt;:remainder&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;})))))&lt;/span&gt;       &lt;span class="c1"&gt;;; can't divide anymore&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;poly-rem&lt;/span&gt;
  &lt;span class="s"&gt;"Remainder after dividing two polynomials, p1(x) / p2(x)."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;p1&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;:remainder&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;div&lt;/span&gt; &lt;span class="nv"&gt;p1&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id="prime-time"&gt;PrimeÂ time&lt;/h1&gt;
&lt;p&gt;Finally, itâ€™s time to combine all of the above into an implementation of the &lt;span class="caps"&gt;AKS&lt;/span&gt; algorithm. To reiterate, the algorithm is asÂ follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;If &lt;span class="math"&gt;\(n\)&lt;/span&gt; is a perfect power (i.e., &lt;span class="math"&gt;\(n = a^b\)&lt;/span&gt; for any &lt;span class="math"&gt;\(a, b \in â„¤\)&lt;/span&gt;), return &lt;strong&gt;composite&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Find the smallest &lt;span class="math"&gt;\(r\)&lt;/span&gt; coprime to &lt;span class="math"&gt;\(n\)&lt;/span&gt; such that &lt;span class="math"&gt;\(\textrm{ord}_r(n) &amp;gt; (\log_2 n)^2\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;If &lt;span class="math"&gt;\(n\)&lt;/span&gt; is divisible by &lt;span class="math"&gt;\(a\)&lt;/span&gt; for any &lt;span class="math"&gt;\(2 \leq a \leq \min (r, n - 1)\)&lt;/span&gt;, return &lt;strong&gt;composite&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;If &lt;span class="math"&gt;\(n \leq r\)&lt;/span&gt;, return &lt;strong&gt;prime&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;If &lt;span class="math"&gt;\((X + a)^n \not= X^n + a \mod (X^r - 1, n)\)&lt;/span&gt; for any &lt;span class="math"&gt;\(1 \leq a \leq \lfloor \sqrt{\varphi(r)} \log_2(n) \rfloor\)&lt;/span&gt;, return &lt;strong&gt;composite&lt;/strong&gt;. Else return &lt;strong&gt;prime&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Taking advantage of Clojureâ€™s &lt;code class="highlight"&gt;when&lt;/code&gt; to keep things concise, here is my implementation, which returns &lt;code class="highlight"&gt;true&lt;/code&gt; if the input is prime, &lt;code class="highlight"&gt;nil&lt;/code&gt; if the input is proven composite before the final step, and &lt;code class="highlight"&gt;false&lt;/code&gt; if the input is proven composite in the lastÂ step.&lt;/p&gt;
&lt;p&gt;On my local version of this code, Iâ€™ve split the modular arithmetic and polynomial functions into different namespaces to keep things tidy. &lt;code class="highlight"&gt;tower&lt;/code&gt;, &lt;code class="highlight"&gt;ma&lt;/code&gt;, &lt;code class="highlight"&gt;h&lt;/code&gt;, and &lt;code class="highlight"&gt;p&lt;/code&gt; denote the namespaces &lt;code class="highlight"&gt;numeric-tower&lt;/code&gt;, &lt;code class="highlight"&gt;modular-arithmetic&lt;/code&gt;, &lt;code class="highlight"&gt;helpers&lt;/code&gt;, and &lt;code class="highlight"&gt;polynomial&lt;/code&gt; respectively.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;aks-prime?&lt;/span&gt;
  &lt;span class="s"&gt;"Uses the Agrawalâ€“Kayalâ€“Saxena primality test to determine if an integer n&lt;/span&gt;
&lt;span class="s"&gt;  is prime. Returns true if prime, nil or false otherwise."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="c1"&gt;;; 1. Check if n is a perfect power&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;when-not &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;perfect-power?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;;; 2. Find the smallest r such that ord_r(n) &amp;gt; (log_2 n)^2.&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;log&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/log&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/log&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;tower/expt&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
          &lt;span class="nv"&gt;r&lt;/span&gt;   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;first &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;keep&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;fn &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;when-let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;ord&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;ma/multiplicative-order&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
                                     &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;when &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;gt; &lt;/span&gt;&lt;span class="nv"&gt;ord&lt;/span&gt; &lt;span class="nv"&gt;log&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
                           &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;range&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
          &lt;span class="nv"&gt;lim&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;min &lt;/span&gt;&lt;span class="nv"&gt;r&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;- &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))]&lt;/span&gt;
      &lt;span class="c1"&gt;;; 3. For all 2 â‰¤ a â‰¤ min(r, nâˆ’1), check that a does not divide n&lt;/span&gt;
      &lt;span class="c1"&gt;;; (composite if so)&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;when &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;not-any? &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;partial &lt;/span&gt;&lt;span class="nv"&gt;h/divisible?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;inc &lt;/span&gt;&lt;span class="nv"&gt;lim&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
        &lt;span class="c1"&gt;;; 4. If n â‰¤ r, output prime.&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;lt;= &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;true&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;log2n&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/log&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/log&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                &lt;span class="nv"&gt;lim&lt;/span&gt;   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;-&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;tower/sqrt&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;naive-phi&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;* &lt;/span&gt;&lt;span class="nv"&gt;log2n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;bigint&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="nv"&gt;lhs&lt;/span&gt;   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;fn &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;p/poly-rem&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;p/mod-exp&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;, &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                                          &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nv"&gt;r&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;, &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;}))&lt;/span&gt;
                &lt;span class="nv"&gt;rhs&lt;/span&gt;   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;fn &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;p/poly-rem&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;, &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
                                          &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nv"&gt;r&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;, &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;}))]&lt;/span&gt;
            &lt;span class="c1"&gt;;; 5. If (X+a)^n != (X^n)+a (mod X^r âˆ’ 1,n) for ANY a from 1 to lim,&lt;/span&gt;
            &lt;span class="c1"&gt;;; n is composite.&lt;/span&gt;
            &lt;span class="c1"&gt;;; In other words, prime? = true iff (X+a)^n = (X^n)+a (mod X^r âˆ’ 1,n)&lt;/span&gt;
            &lt;span class="c1"&gt;;; for ALL a from 1 to lim&lt;/span&gt;
            &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;every? &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;fn &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;lhs&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;rhs&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="nv"&gt;lim&lt;/span&gt;&lt;span class="p"&gt;))))))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id="gotcha"&gt;Gotcha!&lt;/h1&gt;
&lt;p&gt;Congrats! You made it thisÂ far.&lt;/p&gt;
&lt;p&gt;If you test this function, though, you might be a bit disappointed with the results. Namely, itâ€™s very slow, even for small inputs. The lag becomes apparent even with prime number inputs as small as &lt;span class="math"&gt;\(n = 37\)&lt;/span&gt;, and skyrockets exponentially as the size of &lt;span class="math"&gt;\(n\)&lt;/span&gt;Â increases.&lt;/p&gt;
&lt;p&gt;Indeed, despite all the groundbreaking features of the algorithm, &lt;a href="https://cs.stackexchange.com/questions/23260/when-is-the-aks-primality-test-actually-faster-than-other-tests/23360#23360"&gt;speed and practicality are not among them&lt;/a&gt;. Ordinarily, I would be inclined to call coding all of this a waste of time and curse myself for not having bothered to research this earlier, but since I learned a fair bit of Clojure and math in the process, I canâ€™t quite call it aÂ waste.&lt;/p&gt;
&lt;p&gt;However, it does mean I need to study up on ellipticÂ curves!&lt;/p&gt;
&lt;h1 id="references"&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/AKS_primality_test"&gt;&lt;span class="caps"&gt;AKS&lt;/span&gt; primality test&lt;/a&gt;,Â Wikipedia&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/@sibu.it13/aks-primality-test-f184cf6365a1"&gt;&lt;span class="caps"&gt;AKS&lt;/span&gt; Primality Test (Primes is in P)&lt;/a&gt;, SibaprasadÂ Maiti&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.math.ucla.edu/~radko/circles/lib/data/Handout-358-436.pdf"&gt;Long division of polynomials&lt;/a&gt;, Olga Radko, &lt;span class="caps"&gt;UCLA&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cs.stackexchange.com/questions/23260/when-is-the-aks-primality-test-actually-faster-than-other-tests/23360#23360"&gt;When is the &lt;span class="caps"&gt;AKS&lt;/span&gt; primality test actually faster than other tests?&lt;/a&gt;, &lt;span class="caps"&gt;CS&lt;/span&gt; StackÂ Exchange&lt;/li&gt;
&lt;/ul&gt;</content><category term="number theory"></category><category term="clojure"></category><category term="algorithms"></category></entry><entry><title>Number Theory in Clojure: The Fundamental Theorem ofÂ Arithmetic</title><link href="http://tabidots.github.io/2019/03/fundamental-theorem-arithmetic" rel="alternate"></link><published>2019-03-31T19:47:21+07:00</published><updated>2019-03-31T19:47:21+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-03-31:/2019/03/fundamental-theorem-arithmetic</id><summary type="html">&lt;p&gt;The first post in a new series exploring number theory in Clojure, starting with a discussion of primality testing and prime&amp;nbsp;factorization.&lt;/p&gt;</summary><content type="html">
&lt;p&gt;Iâ€™ve had to hit the pause button on the blog for a bit because life got in the way, but I havenâ€™t stopped my mathematical explorations. Actually, I got turned on to &lt;a href="https://projecteuler.net"&gt;Project Euler&lt;/a&gt; in the meantime, which became something of an addiction. Most people solve the problems in C/C++ or Python, but I decided to take the opportunity to sharpen my skills in Clojure (which is, letâ€™s face it, the best-designed programming language out thereÂ ğŸ˜‰).&lt;/p&gt;
&lt;p&gt;In the beginning, the â€œmathematical discovery factorâ€ increased with the difficulty, but after solving about 90 problems, those returns have plateaued and are now declining in relation to the diffficulty. So now itâ€™s time to start posting about some of the cool things Iâ€™ve discovered along the way, and use this blog to explore those topicsÂ further.&lt;/p&gt;
&lt;h1 id="prime-time"&gt;PrimeÂ time&lt;/h1&gt;
&lt;p&gt;Thanks to Chapter 1 of &lt;a href="https://pimbook.org"&gt;A Programmerâ€™s Introduction to Mathematics&lt;/a&gt;, I had already developed an interest in number theory and cryptography. This interest was further ignited by Project Euler, in whose problems number theory factors heavily (punÂ intended).&lt;/p&gt;
&lt;p&gt;Number theory is basically the study of the integers, &lt;span class="math"&gt;\(â„¤\)&lt;/span&gt;. This in turn shines the spotlight on prime numbers, a very special category of the integers due to their many interestingÂ properties.&lt;/p&gt;
&lt;p&gt;In order to do anything interesting in number theory, we need to find a way to &lt;strong&gt;test the primality&lt;/strong&gt; of a number and to &lt;strong&gt;generate a sequence of prime numbers&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In imperative languages, itâ€™s typical to separate these two tasks, and approach the latter by implementing what is called a â€œprime sieve,â€ such as the &lt;a href="https://en.wikipedia.org/wiki/Sieve_of_Eratosthenes"&gt;Sieve of Eratosthenes&lt;/a&gt;, which walks up an infinite sequence of numbers and crosses off more and more composite numbers with each iteration. You might start with an enormous array of &lt;code class="highlight"&gt;True&lt;/code&gt;s and switch the indices of composite numbers to &lt;code class="highlight"&gt;False&lt;/code&gt; as you goÂ along.&lt;/p&gt;
&lt;p&gt;Clojure, on the other hand, is a functional language, in which mutating sequences in-place is neither idiomatic nor clean. &lt;a href="http://clj-me.cgrand.net/2009/07/30/everybody-loves-the-sieve-of-eratosthenes/"&gt;Lazy (lazily evaluated) infinite sequences are the way to go&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As the above link shows, it is possible to implement a Sieve of Eratosthenes in Clojure, but itâ€™s quite difficult to read, and in any less than expert hands, &lt;a href="http://www.learningclojure.com/2009/11/sieve-of-eratosthenes.html"&gt;quite ugly&lt;/a&gt; as well. Meanwhile, Iâ€™ve found that itâ€™s simpler to &lt;code class="highlight"&gt;filter&lt;/code&gt; primes in Clojure than sieving them, which also conveniently integrates the task of testing primality asÂ well.&lt;/p&gt;
&lt;p&gt;This approach is highly readable and, when memoized, its performance does not catastrophically degrade until you start needing primes greater than 1 million or so. Obviously, actual cryptographic applications would require a more industrial-strength implementation, as real-world cryptography deals with integers that could be as large as 256 bits (hundreds of digits long), but for armchair explorations of number theory, this approach willÂ suffice.&lt;/p&gt;
&lt;h2 id="primes-on-trial"&gt;Primes onÂ trial&lt;/h2&gt;
&lt;p&gt;This method is called â€œtrial division,â€ since it involves dividing &lt;span class="math"&gt;\(n\)&lt;/span&gt; by numbers in a range to test for divisibility. First, we have to define divisibility. A dividend &lt;span class="math"&gt;\(n\)&lt;/span&gt; is divisible by a divisor &lt;span class="math"&gt;\(d\)&lt;/span&gt; if no remainder is left after the division, or in other words, if &lt;span class="math"&gt;\(n\)&lt;/span&gt; is a multiple of &lt;span class="math"&gt;\(d\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In terms of modular arithmetic, this is conveniently expressed as a &lt;em&gt;congruence&lt;/em&gt;: &lt;span class="math"&gt;\(n \equiv 0 \mod d\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;divisible?&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;d&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zero? &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mod&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The most naÃ¯ve, brute-force approach is to literally divide &lt;span class="math"&gt;\(n\)&lt;/span&gt; by all numbers in &lt;span class="math"&gt;\([1, n)\)&lt;/span&gt; and return &lt;code class="highlight"&gt;true&lt;/code&gt; (&lt;span class="math"&gt;\(n\)&lt;/span&gt; is prime) if &lt;span class="math"&gt;\(n\)&lt;/span&gt; is divisible by &lt;em&gt;none&lt;/em&gt; of thoseÂ numbers:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;brute-force-prime?&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;not-any? &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;partial &lt;/span&gt;&lt;span class="nv"&gt;divisible?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This is extremely slow, though. For a number like &lt;span class="math"&gt;\(45565962173\)&lt;/span&gt;, this is completely intractable, but even  generating primes up to &lt;span class="math"&gt;\(100000\)&lt;/span&gt; is impractical with thisÂ method.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;time &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;doall &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="nv"&gt;brute-force-prime?&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;100000&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;span class="c1"&gt;;; Elapsed time: 67653.900002 msecs&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;A smarter way to do this starts with noticing that only potential divisors up to &lt;span class="math"&gt;\(\sqrt{n}\)&lt;/span&gt; need to be tried, because any divisor less than that will have a complementary divisor on the other side of &lt;span class="math"&gt;\(\sqrt{n}\)&lt;/span&gt;. For example, &lt;span class="math"&gt;\(\sqrt{28} \approx 5.3\)&lt;/span&gt;. &lt;span class="math"&gt;\(28\)&lt;/span&gt; is divisible by &lt;span class="math"&gt;\(2\)&lt;/span&gt;, and this division yields the complementary divisor &lt;span class="math"&gt;\(14\)&lt;/span&gt;. Likewise, &lt;span class="math"&gt;\(4\)&lt;/span&gt; yields &lt;span class="math"&gt;\(7\)&lt;/span&gt;.&lt;/p&gt;
&lt;h2 id="integer-square-root"&gt;Integer squareÂ root&lt;/h2&gt;
&lt;p&gt;An &lt;a href="https://en.wikipedia.org/wiki/Integer_square_root"&gt;upper integer bound &lt;span class="math"&gt;\(\lfloor \sqrt{n} \rfloor\)&lt;/span&gt;&lt;/a&gt; capable of handling fairly large numbers can be implemented quite simply as &lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;bigint&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/sqrt&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/code&gt;, taking advantage of JavaÂ interop.&lt;/p&gt;
&lt;p&gt;This has been effective for all of the Project Euler problems Iâ€™ve solved so far, though it is true that a proper arithmetical solution would not involve floating-point numbers. For sufficiently large &lt;span class="math"&gt;\(n\)&lt;/span&gt;, rounding errors would yield an upper bound that is too low to find all possible factors, especially in the worst case (where a very large &lt;span class="math"&gt;\(n\)&lt;/span&gt; is the product of two very large primes that are similar but not equal inÂ value).&lt;/p&gt;
&lt;p&gt;I use the &lt;a href="https://github.com/clojure/math.numeric-tower"&gt;clojure.math.numeric-tower&lt;/a&gt; library here as
using Java interop for exponentiation (&lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/pow&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/code&gt;) similarly introduces floating-point numbers, and &lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;tower/expt&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/code&gt; is ever-so-slightly faster than &lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="nv"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;repeat &lt;/span&gt;&lt;span class="nv"&gt;e&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Here is a bulletproof integer square root function, which uses the simpler, faster method for &lt;span class="math"&gt;\(n &amp;lt; 10^24\)&lt;/span&gt; and a &lt;a href="https://cs.stackexchange.com/a/30383"&gt;more sophisticated algorithm&lt;/a&gt; (which I donâ€™t really understand) for largerÂ numbers.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;require&lt;/span&gt; &lt;span class="o"&gt;'&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;clojure.math.numeric-tower&lt;/span&gt; &lt;span class="ss"&gt;:as&lt;/span&gt; &lt;span class="nv"&gt;tower&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;isqrt&lt;/span&gt;
  &lt;span class="s"&gt;"floor(âˆšn). When incremented, provides an upper bound for factorization."&lt;/span&gt;
  &lt;span class="c1"&gt;;; Java interop is super fast but not accurate for n &amp;gt; 1E24 (approx) due to&lt;/span&gt;
  &lt;span class="c1"&gt;;; floating-point rounding. Uses a slightly slower but pinpoint-precise method for n &amp;gt; 1E24.&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;lt; &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="nv"&gt;E24&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/sqrt&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;bigint&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;;; https://cs.stackexchange.com/a/30383&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;half-bit-length&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;quot &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;.bitLength&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;bigint&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;loop &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;tower/expt&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="nv"&gt;half-bit-length&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
             &lt;span class="nv"&gt;b&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt;
             &lt;span class="nv"&gt;c&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;cond&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zero? &lt;/span&gt;&lt;span class="nv"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;gt; &lt;/span&gt;&lt;span class="nv"&gt;c&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;-&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;quot &lt;/span&gt;&lt;span class="nv"&gt;b&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="nv"&gt;c&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="mi"&gt;-2&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;b&lt;/span&gt; &lt;span class="nv"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
          &lt;span class="ss"&gt;:else&lt;/span&gt;     &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;+&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;quot &lt;/span&gt;&lt;span class="nv"&gt;b&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="nv"&gt;c&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;b&lt;/span&gt; &lt;span class="nv"&gt;b&lt;/span&gt;&lt;span class="p"&gt;))))))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="testing-primality"&gt;TestingÂ primality&lt;/h2&gt;
&lt;p&gt;Next, letâ€™s implement some basic checks to eliminate the need to do any calculations in the majority of cases. When testing for primality, we generally only consider &lt;span class="math"&gt;\(â„¤\)&lt;/span&gt;, the positive integers. Furthermore, &lt;span class="math"&gt;\(1\)&lt;/span&gt; is &lt;em&gt;not&lt;/em&gt; considered prime. So &lt;span class="math"&gt;\(n \leq 1\)&lt;/span&gt; is &lt;code class="highlight"&gt;false&lt;/code&gt; right off the bat. Next, all primes are odd except &lt;span class="math"&gt;\(2\)&lt;/span&gt;, so make an exception for &lt;span class="math"&gt;\(2\)&lt;/span&gt; and return &lt;code class="highlight"&gt;false&lt;/code&gt; for all &lt;code class="highlight"&gt;even?&lt;/code&gt; numbers.&lt;/p&gt;
&lt;p&gt;Clojureâ€™s built-in &lt;code class="highlight"&gt;even?&lt;/code&gt; function has the added bonus of throwing an exception for &lt;code class="highlight"&gt;Ratio&lt;/code&gt;s and &lt;code class="highlight"&gt;float&lt;/code&gt;s.&lt;/p&gt;
&lt;p&gt;This leaves all odd numbers &lt;span class="math"&gt;\(\geq 3\)&lt;/span&gt;. Weeding out all even numbers means that there is no need to check for even divisors (odd numbers only have oddÂ divisors).&lt;/p&gt;
&lt;p&gt;The most idiomatic way to write this wouldÂ be:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;cond&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;lt;= &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="nv"&gt;false&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="nv"&gt;true&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;even?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;false&lt;/span&gt; &lt;span class="c1"&gt;;; Will also weed out non-integers&lt;/span&gt;
  &lt;span class="ss"&gt;:else&lt;/span&gt;     &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;not-any? &lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;divisible?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;%&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;inc &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;isqrt&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;but this is actually about 1.5x as slow as a more verbose translation using &lt;code class="highlight"&gt;loop&lt;/code&gt;/&lt;code class="highlight"&gt;recur&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;naive-prime?&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;cond&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;lt;= &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="nv"&gt;false&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="nv"&gt;true&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;even?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;false&lt;/span&gt; &lt;span class="c1"&gt;;; Will also weed out non-integers&lt;/span&gt;
    &lt;span class="ss"&gt;:else&lt;/span&gt;     &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;lim&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;int-root&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
                &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;loop &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;i&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;cond&lt;/span&gt;
                    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;gt;= &lt;/span&gt;&lt;span class="nv"&gt;i&lt;/span&gt; &lt;span class="nv"&gt;lim&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;       &lt;span class="nv"&gt;true&lt;/span&gt;
                    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;divisible?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;false&lt;/span&gt;
                    &lt;span class="ss"&gt;:else&lt;/span&gt;            &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="nv"&gt;i&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)))))))&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;def &lt;/span&gt;&lt;span class="nv"&gt;prime?&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;memoize&lt;/span&gt; &lt;span class="nv"&gt;naive-prime?&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;whose performance, non-memoized and memoized, is leaps and bounds above the original brute-force trial divisionÂ function:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;require&lt;/span&gt; &lt;span class="o"&gt;'&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;criterium.core&lt;/span&gt; &lt;span class="ss"&gt;:as&lt;/span&gt; &lt;span class="nv"&gt;c&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;c/quick-bench&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;naive-prime?&lt;/span&gt; &lt;span class="mi"&gt;45565962173&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="c1"&gt;;; Execution time mean : 16.516873 ms&lt;/span&gt;
&lt;span class="c1"&gt;;; Execution time std-deviation : 1.053979 ms&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;c/quick-bench&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;prime?&lt;/span&gt; &lt;span class="mi"&gt;45565962173&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="c1"&gt;;; Execution time mean : 340.284934 ns&lt;/span&gt;
&lt;span class="c1"&gt;;; Execution time std-deviation : 10.658400 ns&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="leveraging-the-primality-test"&gt;Leveraging the primalityÂ test&lt;/h2&gt;
&lt;p&gt;This may not exactly be an industrial-strength method, but for my current purposes, it arguably allows more idiomatic and readable ways to accomplish tasks such as &lt;code class="highlight"&gt;filter&lt;/code&gt;, &lt;code class="highlight"&gt;take&lt;/code&gt;, and &lt;code class="highlight"&gt;nth&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;c/quick-bench&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;doall &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="nv"&gt;naive-prime?&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;100000&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;span class="c1"&gt;;; Execution time mean : 265.236965 ms&lt;/span&gt;
&lt;span class="c1"&gt;;; Execution time std-deviation : 6.784358 ms&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;c/quick-bench&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;doall &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="nv"&gt;prime?&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;100000&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;span class="c1"&gt;;; Execution time mean : 83.140024 ms&lt;/span&gt;
&lt;span class="c1"&gt;;; Execution time std-deviation : 1.655784 ms&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;c/quick-bench&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;take &lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="nv"&gt;prime?&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;range&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;span class="c1"&gt;;; Execution time mean : 88.645751 ns&lt;/span&gt;
&lt;span class="c1"&gt;;; Execution time std-deviation : 27.586353 ns&lt;/span&gt;

&lt;span class="c1"&gt;;; (dec n) gets the nth prime, because the sequence is zero-indexed&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;c/quick-bench&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;nth &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="nv"&gt;prime?&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;range&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;dec &lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="c1"&gt;;; Execution time mean : 2.473162 ms&lt;/span&gt;
&lt;span class="c1"&gt;;; Execution time std-deviation : 123.136771 Âµs&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id="prime-factorization"&gt;PrimeÂ factorization&lt;/h1&gt;
&lt;p&gt;With that out of the way, we come to the cornerstone of numberÂ theory:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;All integers greater than 1 are either a prime number or can be expressed as a unique product of primeÂ numbers.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The algorithm to find the prime factors of an integer &lt;span class="math"&gt;\(n\)&lt;/span&gt; is surprisingly simple to implement. Start with an empty list of factors and an infinite list of primes. Begin with the first prime (that is, &lt;span class="math"&gt;\(2\)&lt;/span&gt;) and divide &lt;span class="math"&gt;\(n\)&lt;/span&gt; by &lt;span class="math"&gt;\(2\)&lt;/span&gt; until you canâ€™t anymore. Each time you divide, add a &lt;span class="math"&gt;\(2\)&lt;/span&gt; to your list ofÂ factors.&lt;/p&gt;
&lt;p&gt;Then, proceed to the next prime (&lt;span class="math"&gt;\(3\)&lt;/span&gt;) and repeat up the list, adding factors, until the result of your division is &lt;span class="math"&gt;\(1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Letâ€™s try &lt;span class="math"&gt;\(168 = 2 \times 2 \times 2 \times 3 \times 7\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;loop &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;       &lt;span class="mi"&gt;168&lt;/span&gt;
       &lt;span class="nv"&gt;primes&lt;/span&gt;  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="nv"&gt;prime?&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;range&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
       &lt;span class="nv"&gt;factors&lt;/span&gt; &lt;span class="p"&gt;[]]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;k&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;first &lt;/span&gt;&lt;span class="nv"&gt;primes&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;cond&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;          &lt;span class="nv"&gt;factors&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;divisible?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;primes&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;conj &lt;/span&gt;&lt;span class="nv"&gt;factors&lt;/span&gt; &lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
      &lt;span class="ss"&gt;:else&lt;/span&gt;            &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;rest &lt;/span&gt;&lt;span class="nv"&gt;primes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;factors&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;

&lt;span class="c1"&gt;;; [2 2 2 3 7]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Checks out. You can try a bunch of random numbers and youâ€™ll instantly get its prime factorization, which is something like a fingerprint, since itâ€™s unique for every number. PrettyÂ cool!&lt;/p&gt;
&lt;p&gt;But again, a ridiculously large number like &lt;span class="math"&gt;\(245454537724879\)&lt;/span&gt; is too much for a simple algorithm. Actually, itâ€™s not so much that the number is too large, but that it has very large prime factors, so it takes a very long time to iterate that far up the list ofÂ primes.&lt;/p&gt;
&lt;p&gt;This can be worked around &lt;em&gt;somewhat&lt;/em&gt; if we find the factors of &lt;span class="math"&gt;\(n\)&lt;/span&gt; first, then &lt;code class="highlight"&gt;filter&lt;/code&gt; the &lt;code class="highlight"&gt;prime?&lt;/code&gt; ones.&lt;/p&gt;
&lt;h2 id="regular-factorization"&gt;RegularÂ factorization&lt;/h2&gt;
&lt;p&gt;This will look a bit like our initial foray into primality testing. Rather than checking if &lt;span class="math"&gt;\(n\)&lt;/span&gt; has no (that is, &lt;code class="highlight"&gt;not-any?&lt;/code&gt;) divisors &lt;span class="math"&gt;\(1 &amp;lt; d &amp;lt; n\)&lt;/span&gt;, we just filter all divisors &lt;span class="math"&gt;\(1 \leq d &amp;lt; n\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;brute-force-factors&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;partial &lt;/span&gt;&lt;span class="nv"&gt;divisible?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As you can imagine, since this is running through every possible number, this will take way too long for large &lt;span class="math"&gt;\(n\)&lt;/span&gt;. We can use the same upper bound as before, although that means that for every positive result, we have to add not only &lt;span class="math"&gt;\(d\)&lt;/span&gt;, but &lt;span class="math"&gt;\(\frac{n}{d}\)&lt;/span&gt; asÂ well.&lt;/p&gt;
&lt;p&gt;Here is a clean way of doingÂ that:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;factors&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;-&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;inc &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;isqrt&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
       &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;divisible?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;%&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
       &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;mapcat &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;fn &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;d&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;d&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)]))&lt;/span&gt;
       &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;into &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;sorted-set&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="more-optimized-prime-factorization"&gt;More optimized primeÂ factorization&lt;/h2&gt;
&lt;p&gt;With this, we can now improve the performance of our prime factorization function by checking the size of the number first. If &lt;span class="math"&gt;\(n\)&lt;/span&gt; is smaller than some threshold (letâ€™s say 1 million), then iterate up an infinite list of primes as before. If &lt;span class="math"&gt;\(n\)&lt;/span&gt; is larger than the threshold, though, then &lt;code class="highlight"&gt;filter&lt;/code&gt; the &lt;code class="highlight"&gt;prime?&lt;/code&gt; &lt;code class="highlight"&gt;factors&lt;/code&gt; first, and iterate up &lt;em&gt;that&lt;/em&gt; listÂ instead.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;prime-factorization&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="s"&gt;"Returns the prime factorization of an integer, e.g., 168 -&amp;gt; [2 2 2 3 7]."&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;when &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;and &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;integer?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;pos? &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;   &lt;span class="c1"&gt;;; Sanity check&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;loop &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;       &lt;span class="nv"&gt;n&lt;/span&gt;
           &lt;span class="nv"&gt;primes&lt;/span&gt;  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;gt; &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;1000000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                     &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="nv"&gt;prime?&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;factors&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                     &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="nv"&gt;prime?&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;range&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
           &lt;span class="nv"&gt;factors&lt;/span&gt; &lt;span class="p"&gt;[]]&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;k&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;first &lt;/span&gt;&lt;span class="nv"&gt;primes&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;cond&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;          &lt;span class="nv"&gt;factors&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;divisible?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;primes&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;conj &lt;/span&gt;&lt;span class="nv"&gt;factors&lt;/span&gt; &lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
          &lt;span class="ss"&gt;:else&lt;/span&gt;            &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;rest &lt;/span&gt;&lt;span class="nv"&gt;primes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;factors&lt;/span&gt;&lt;span class="p"&gt;))))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This isnâ€™t a perfect heuristic, as large numbers do not necessarily have large prime factors. For example, 12 bazillion-gajillion (&lt;span class="math"&gt;\(12 \times 10^{??}\)&lt;/span&gt;) still has only &lt;span class="math"&gt;\((2, 3, 5)\)&lt;/span&gt; as prime factors, just like &lt;span class="math"&gt;\(120\)&lt;/span&gt;. But at least it can reduce the time required for difficult cases, such as &lt;span class="math"&gt;\(n = 23897538974893789\)&lt;/span&gt;, and make themÂ tractable.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;time &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;prime-factorization&lt;/span&gt; &lt;span class="mi"&gt;23897538974893789&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="c1"&gt;;; Elapsed time: 30579.928312 msecs&lt;/span&gt;
&lt;span class="c1"&gt;;; [211 23357 4849016507]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;(The brute-force version didnâ€™t finish even after 5 minutes, so I abandonedÂ it.)&lt;/p&gt;
&lt;h2 id="prime-omega-functions"&gt;Prime omegaÂ functions&lt;/h2&gt;
&lt;p&gt;There are a couple arithmetic that look and sound really impressive but are trivial to implement in code once you can factor an integer intoÂ primes.&lt;/p&gt;
&lt;p&gt;One is the little omega function &lt;span class="math"&gt;\(\omega(n)\)&lt;/span&gt;, which counts the number of distinct prime factors of &lt;span class="math"&gt;\(n\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;count &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;distinct &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;prime-factorization&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The other is the big omega function &lt;span class="math"&gt;\(\Omega(n)\)&lt;/span&gt;, which counts the number of prime factors of &lt;span class="math"&gt;\(n\)&lt;/span&gt; with multiplicity (i.e., if &lt;span class="math"&gt;\(2\)&lt;/span&gt; appears more than once, count bothÂ instances).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;count &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;prime-factorization&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id="prime-power-representation"&gt;Prime powerÂ representation&lt;/h1&gt;
&lt;p&gt;Given the prime factorization of a number, we can use this information to formulate its unique representation as a product of primeÂ powers.&lt;/p&gt;
&lt;div class="math"&gt;$$ n = p_{1}^{e_{1}}p_{2}^{e_{2}}\cdots p_{k}^{e_{k}}
     = \prod_{i=1}^{k}p_{i}^{e_{i}} $$&lt;/div&gt;
&lt;p&gt;Returning to our simple example &lt;span class="math"&gt;\(168 = 2 \times 2 \times 2 \times 3 \times 7\)&lt;/span&gt; above, this can be written more succinctlyÂ as&lt;/p&gt;
&lt;div class="math"&gt;$$ 168 = 2^3 \times 3 \times 7 $$&lt;/div&gt;
&lt;p&gt;which is also called its &lt;strong&gt;canonical representation&lt;/strong&gt; or &lt;strong&gt;standard form&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;If we fill in the missing primes above with &lt;span class="math"&gt;\(p_{i}^{0}\)&lt;/span&gt;, which doesnâ€™t affect the final product, then the sequence of &lt;span class="math"&gt;\(e_1 \cdots e_k\)&lt;/span&gt; in the above notation can also be extracted from the prime factorization, which gives us an &lt;strong&gt;exponent vector&lt;/strong&gt; (or &lt;em&gt;unique prime signature&lt;/em&gt;). For &lt;span class="math"&gt;\(168\)&lt;/span&gt;, this wouldÂ be&lt;/p&gt;
&lt;div class="math"&gt;$$ 168 = 2^{\color{red}{3}} \times 3^{\color{red}{1}} \times 5^{\color{red}{0}} \times 7^{\color{red}{1}}
       = \begin{bmatrix}3 &amp;amp; 1 &amp;amp; 0 &amp;amp; 1\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;Hereâ€™s a simple way to implementÂ that:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;prime-powers-integer&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="s"&gt;"Returns the exponent vector for the prime power representation of an integer,&lt;/span&gt;
&lt;span class="s"&gt;  e.g., 168 = 2*2*2*3*7 = 2^3 * 3^1 * 5^0 * 7^1 -&amp;gt; (3 1 0 1)"&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;when &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;and &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;integer?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;pos? &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;pf&lt;/span&gt;      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;prime-factorization&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="nv"&gt;primes&lt;/span&gt;  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="nv"&gt;prime?&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;inc &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;peek &lt;/span&gt;&lt;span class="nv"&gt;pf&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
            &lt;span class="nv"&gt;freqs&lt;/span&gt;   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;frequencies&lt;/span&gt; &lt;span class="nv"&gt;pf&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="nv"&gt;get-exp&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;fn &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;p&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;if-let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;exp&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;get &lt;/span&gt;&lt;span class="nv"&gt;freqs&lt;/span&gt; &lt;span class="nv"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
                              &lt;span class="nv"&gt;exp&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))]&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;map &lt;/span&gt;&lt;span class="nv"&gt;get-exp&lt;/span&gt; &lt;span class="nv"&gt;primes&lt;/span&gt;&lt;span class="p"&gt;)))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For &lt;span class="math"&gt;\(n = 168\)&lt;/span&gt;, the procedure works likeÂ this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;pf&lt;/span&gt; &lt;span class="nv"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;primes&lt;/span&gt; &lt;span class="nv"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;;; one of each prime up to the last prime in pf&lt;/span&gt;
&lt;span class="nv"&gt;freqs&lt;/span&gt; &lt;span class="nv"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;, &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;, &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;map &lt;/span&gt;&lt;span class="nv"&gt;get-exp&lt;/span&gt; &lt;span class="nv"&gt;primes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;map &lt;/span&gt;&lt;span class="nv"&gt;get-exp&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="nv"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This works fine when the prime factors are small, but it isnâ€™t the cleanest approach. Namely, one list of primes may already be generated by &lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;prime-factorization&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/code&gt;, so generating another (for the purpose of determining that &lt;span class="math"&gt;\(87\)&lt;/span&gt; is the &lt;span class="math"&gt;\(i\)&lt;/span&gt;th prime, for example) is not very efficient. If we limited the &lt;code class="highlight"&gt;prime-factorization&lt;/code&gt; function to the iterative approach, we could generate a map containing &lt;code class="highlight"&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="ss"&gt;:i&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="ss"&gt;:p&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="ss"&gt;:e&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;/code&gt; for each prime, which is a starting point for generating both the canonical representation and the exponentÂ vector.&lt;/p&gt;
&lt;p&gt;However, since this is mostly for curiosityâ€™s sake than actual applications, Iâ€™m leaving it at that. For cryptographic applications, what is more important than generating exponent vectorsÂ are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Finding the factors (prime or otherwise) of an integer themselves,Â and&lt;/li&gt;
&lt;li&gt;Specialized techniques for factoring specific types of numbers, such asÂ semiprimes.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now, for completenessâ€™ sake, letâ€™s write a function to convert an exponent vector back to anÂ integer.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;prime-powers-&amp;gt;num&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;pp&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;primes&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="nv"&gt;prime?&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;range&lt;/span&gt;&lt;span class="p"&gt;))]&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="nv"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;map &lt;/span&gt;&lt;span class="nv"&gt;tower/expt&lt;/span&gt; &lt;span class="nv"&gt;primes&lt;/span&gt; &lt;span class="nv"&gt;pp&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;prime-powers-&amp;gt;num&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="c1"&gt;;; 168&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="negative-exponents-too"&gt;Negative exponentsÂ too?&lt;/h2&gt;
&lt;p&gt;While writing this, I learned that allowing negative exponents in prime factorizations enables you to represent not only all the integers (&lt;span class="math"&gt;\(n \in â„¤\)&lt;/span&gt;), but all the rationals (&lt;span class="math"&gt;\(n \in â„š\)&lt;/span&gt;) asÂ well.&lt;/p&gt;
&lt;p&gt;For some rational number &lt;span class="math"&gt;\(q = \frac{a}{b}\)&lt;/span&gt;, let &lt;span class="math"&gt;\(\vec a, \vec b\)&lt;/span&gt; be the exponent vectors for the integers &lt;span class="math"&gt;\(a, b\)&lt;/span&gt;. The exponent vector for &lt;span class="math"&gt;\(q\)&lt;/span&gt; is then &lt;span class="math"&gt;\(\vec q = \vec a - \vec b\)&lt;/span&gt;. ForÂ example,&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{gathered}
q = \frac{171}{98} \\[0.8em]
\begin{aligned}
a = 171 &amp;amp;= 3^2 \times 19^1 \\
b = 98 &amp;amp;= 2^1 \times 7^2 \\[0.8em]
\end{aligned} \\
\begin{aligned}
\vec a &amp;amp;= \begin{bmatrix}\; \; \; 0 &amp;amp; 2 &amp;amp; 0 &amp;amp; \; \; \; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\end{bmatrix} \\
\vec b &amp;amp;= \begin{bmatrix}\; \; \; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; \; \; \; 2 &amp;amp; \textcolor{#bbb}{0} &amp;amp; \textcolor{#bbb}{0} &amp;amp; \textcolor{#bbb}{0} &amp;amp; \textcolor{#bbb}{0}\end{bmatrix} \\
\vec q &amp;amp;= \begin{bmatrix}-1 &amp;amp; 2 &amp;amp; 0 &amp;amp; -2 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\end{bmatrix} \\[0.8em]
\end{aligned} \\
\begin{aligned}
q &amp;amp;= 2^{-1} \times 3^2 \times 7^{-2} \times 19^1 \\
  &amp;amp;= \frac{1}{2} \times 9 \times \frac{1}{49} \times 19
\end{aligned}
\end{gathered}$$&lt;/div&gt;
&lt;p&gt;The following code is something I scratched up quickly as Clojure does not have a simple way to implement something like &lt;code class="highlight"&gt;map-longest&lt;/code&gt;. That is, a way to map over multiple collections, filling in dummy values to make each collection the same size as the largestâ€”in this case, the light gray &lt;span class="math"&gt;\(\textcolor{#bbb}{0}\)&lt;/span&gt; in &lt;span class="math"&gt;\(\vec b\)&lt;/span&gt;Â above.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;prime-powers-rational&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;q&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;r&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;rationalize&lt;/span&gt; &lt;span class="nv"&gt;q&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="c1"&gt;;; Sanity check to accept decimal representations of rational numbers&lt;/span&gt;
    &lt;span class="c1"&gt;;; while still rejecting irrational numbers&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;when &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;or &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;ratio?&lt;/span&gt; &lt;span class="nv"&gt;q&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;double &lt;/span&gt;&lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;double &lt;/span&gt;&lt;span class="nv"&gt;q&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;prime-powers-integer&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;numerator&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="nv"&gt;d&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;prime-powers-integer&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;denominator&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="nv"&gt;pn&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;concat &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;repeat &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;count &lt;/span&gt;&lt;span class="nv"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="nv"&gt;pd&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;concat &lt;/span&gt;&lt;span class="nv"&gt;d&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;repeat &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;count &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))]&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;-&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;map - &lt;/span&gt;&lt;span class="nv"&gt;pn&lt;/span&gt; &lt;span class="nv"&gt;pd&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
             &lt;span class="nv"&gt;reverse&lt;/span&gt;
             &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;drop-while &lt;/span&gt;&lt;span class="nv"&gt;zero?&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;;; truncate zeros from the end&lt;/span&gt;
             &lt;span class="nv"&gt;reverse&lt;/span&gt;&lt;span class="p"&gt;)))))&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;prime-powers-rational&lt;/span&gt; &lt;span class="mi"&gt;171&lt;/span&gt;&lt;span class="nv"&gt;/98&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;;; (-1 2 0 -2 0 0 0 1)&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;prime-powers-&amp;gt;num&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;-1&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;-2&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="c1"&gt;;; 171/98&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;PrettyÂ cool!&lt;/p&gt;
&lt;p&gt;While the rational version doesnâ€™t reside strictly within the confines of number theory, as it goes beyond the integers, it is still mathematically interesting and can be wrapped up neatly in a bulletproof &lt;code class="highlight"&gt;prime-powers&lt;/code&gt; function that can handle both integer and rationalÂ inputs.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;prime-powers&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;when &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;pos? &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;integer?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;prime-powers-integer&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;prime-powers-rational&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Apparently, this can be &lt;a href="https://math.stackexchange.com/questions/873455/factorization-of-rational-powers-of-rational-numbers"&gt;extended to rational powers of rational numbers&lt;/a&gt; as well, which would seem to allow irrational numbers to be represented as well, though that is starting to get a little deep for meÂ ğŸ˜…&lt;/p&gt;
&lt;p&gt;Thatâ€™s all for now. Stay tuned for more posts in thisÂ series!&lt;/p&gt;
&lt;h1 id="references"&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Fundamental_theorem_of_arithmetic"&gt;Fundamental theorem of arithmetic&lt;/a&gt;,Â Wikipedia&lt;/li&gt;
&lt;li&gt;&lt;a href="https://oeis.org/wiki/Prime_factorization"&gt;Prime factorization&lt;/a&gt;, &lt;span class="caps"&gt;OEIS&lt;/span&gt;Â Wiki&lt;/li&gt;
&lt;/ul&gt;</content><category term="number theory"></category><category term="math"></category><category term="clojure"></category></entry><entry><title>djdw on the 0s andÂ 1s</title><link href="http://tabidots.github.io/2019/02/backpropagation" rel="alternate"></link><published>2019-02-05T09:25:20+07:00</published><updated>2019-02-05T09:25:20+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-02-05:/2019/02/backpropagation</id><summary type="html">&lt;p&gt;After my previous fail trying to use autograd with pandas, I decided to set simple linear regression aside and attempt training a neural network. Here, Iâ€™ve adapted the network in the Welch Labs tutorial to accommodate an arbitrary number of layers. (However, floating-point arithmetic &lt;em&gt;doesnâ€™t&lt;/em&gt; follow suit quite so&amp;nbsp;easily!)&lt;/p&gt;</summary><content type="html">
&lt;p&gt;I got frustrated with not being able to go farther with using &lt;code class="highlight"&gt;autodiff&lt;/code&gt; for my simple toy linear regression model, so I decided it was time to actually try training a toy neural network for the firstÂ time.&lt;/p&gt;
&lt;p&gt;For this, I followed Stephen Welchâ€™s excellent &lt;a href="https://www.youtube.com/watch?v=bxe2T-V8XRs"&gt;Neural Networks Demystified&lt;/a&gt; series. I had actually encountered the series a few years ago, which I recall gave me my initial intuitive understanding of neural networks, but I was not at all into math at that time and did not think I could grok the relevantÂ code.&lt;/p&gt;
&lt;p&gt;The tutorial is pretty short and the end result is not &lt;em&gt;that&lt;/em&gt; excitingâ€”at least for me, anyway. So I knew I wouldnâ€™t get much out of writing a post solely about theÂ tutorial.&lt;/p&gt;
&lt;p&gt;However, in &lt;a href="https://www.youtube.com/watch?v=GlcnxUlrtek"&gt;Video #4&lt;/a&gt;, he breezes through backpropagationâ€”the heart of neural networksâ€”and while the tutorial gives enough of an understanding of the math to build similar neural networks to the ones in the video, with one hidden layer, I wanted to see if there was a tidy way to generalize his code to an arbitrary number of hiddenÂ layers.&lt;/p&gt;
&lt;p&gt;So thatâ€™s what this post will be about, although it does skip a few intermediate steps from the last linear regression post,Â math-wise.&lt;/p&gt;
&lt;h1 id="forward-propagation"&gt;ForwardÂ propagation&lt;/h1&gt;
&lt;h2 id="linear-regression-on-steroids"&gt;Linear regression onÂ steroids&lt;/h2&gt;
&lt;p&gt;Before you can do backpropagation, you need to do forward propagation. That is, you feed your inputs forward through each successive layer of the network until you get to the last layer, which is yourÂ output.&lt;/p&gt;
&lt;p&gt;In the toy linear regression model from before, this was the process of getting an estimate &lt;span class="math"&gt;\(\hat y\)&lt;/span&gt; by initially setting the weights vector &lt;span class="math"&gt;\(\vec \theta\)&lt;/span&gt; to all zeros (or random values), and multiplying it by the input. The weights vector would then be updated and the input would be fed forward again on every iteration of gradientÂ descent.&lt;/p&gt;
&lt;p&gt;In a neural network, itâ€™s basically the same, just more complex. The linear regression model consisted of &lt;span class="math"&gt;\(j\)&lt;/span&gt; features contributing to one output; a neural network, meanwhile could have arbitrary layers of an arbitrary number ofÂ features.&lt;/p&gt;
&lt;p&gt;What was a single weights vector &lt;span class="math"&gt;\(\vec \theta\)&lt;/span&gt; is now one of several weights matrices &lt;span class="math"&gt;\(\textbf w\)&lt;/span&gt;. &lt;a href="https://medium.com/@erikhallstrm/backpropagation-from-the-beginning-77356edf427d"&gt;Erik HallstrÃ¶mâ€™s post&lt;/a&gt; has some pretty clear graphics toÂ illustrate:&lt;/p&gt;
&lt;p&gt;&lt;img src="../../images/backprop/weights_matrix.png" width="300"/&gt;&lt;/p&gt;
&lt;p&gt;The &lt;span class="math"&gt;\(j\)&lt;/span&gt;th row of the matrix is the weights (influence) of the six neurons (features) of the preceding layer on the &lt;span class="math"&gt;\(j\)&lt;/span&gt;th neuron (feature) of the nextÂ layer.&lt;/p&gt;
&lt;p&gt;Forward propagation is simply multiplying your input matrix by the first weight matrix, applying an activation function to the result. This result is the next input, which you multiply by the next weight matrix, and soÂ on.&lt;/p&gt;
&lt;h2 id="sigmoid-sounds-like-steroid-but-isnt"&gt;Sigmoid (sounds like steroid, butÂ isnâ€™t)&lt;/h2&gt;
&lt;p&gt;Here, we are going to use the &lt;strong&gt;sigmoid function&lt;/strong&gt;, &lt;span class="math"&gt;\(\sigma(z)\)&lt;/span&gt;, as our activation function. This is pretty standard in basic neural networkÂ implementations.&lt;/p&gt;
&lt;div class="math"&gt;$$ \sigma(z) = \frac{1}{1 + e^{-z}} $$&lt;/div&gt;
&lt;p&gt;Or, inÂ Python:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;sigmoid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src="../../images/backprop/sigmoid.png" width="300"/&gt;&lt;/p&gt;
&lt;p&gt;Neat.&lt;/p&gt;
&lt;h2 id="mathing-it-out"&gt;Mathing itÂ out&lt;/h2&gt;
&lt;p&gt;So then, given an input matrix &lt;span class="math"&gt;\(\textbf X\)&lt;/span&gt;, this is what a basic forward propagation sequence looksÂ like:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\textbf z_1 &amp;amp;:= \textbf X \textbf w_0 &amp;amp;\to \textbf a_1 &amp;amp;:= \sigma(\textbf z_1) \\
&amp;amp; &amp;amp; \textbf z_2 &amp;amp;:= \textbf a_1 \textbf w_1 &amp;amp;\to \textbf a_2 &amp;amp;:= \sigma(\textbf z_2) \\
&amp;amp; &amp;amp; &amp;amp; &amp;amp; \hat y &amp;amp;:= \textbf a_2
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(\textbf z_n\)&lt;/span&gt; are the â€œuncookedâ€ products of inputs and weights at layer &lt;span class="math"&gt;\(n\)&lt;/span&gt; and &lt;span class="math"&gt;\(\textbf a_n\)&lt;/span&gt; are the â€œcookedâ€ versions (activated values) of thoseÂ products.&lt;/p&gt;
&lt;p&gt;You could write this as a single nested function, but like a programming one-liner, itâ€™s unreadable. I have chosen to write it this way to highlight its recursive nature (&lt;em&gt;ahem&lt;/em&gt; &lt;code class="highlight"&gt;reduce&lt;/code&gt; &lt;em&gt;ahem&lt;/em&gt;).&lt;/p&gt;
&lt;h2 id="implementing-it-recursively"&gt;Implementing itÂ recursively&lt;/h2&gt;
&lt;p&gt;If we conceive of our networkâ€™s weights matrices as a list of matrices &lt;code class="highlight"&gt;w&lt;/code&gt; &lt;span class="math"&gt;\(= [\textbf w_0, \textbf w_1, \cdots, \textbf w_{k-2}]\)&lt;/span&gt; where &lt;span class="math"&gt;\(k\)&lt;/span&gt; is the number of layers in our network, we can then use &lt;code class="highlight"&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;/code&gt; to refer to the weights between layers 0 and 1, and soÂ on.&lt;/p&gt;
&lt;p&gt;(Notation such as &lt;span class="math"&gt;\(W_{jk}\)&lt;/span&gt; is common, but Iâ€™m using a single index to reduceÂ clutter.)&lt;/p&gt;
&lt;p&gt;With that in mind, letâ€™s rewrite &lt;code class="highlight"&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;NeuralNetwork&lt;/span&gt;&lt;/code&gt; to take a list of layer dimensions, such that
we can recreate the Welch Labs 2-3-1 network with the list &lt;code class="highlight"&gt;[2,3,1]&lt;/code&gt; and &lt;a href="https://www.youtube.com/watch?v=Ilg3gGewQ5U&amp;amp;index=4&amp;amp;list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&amp;amp;t=0s"&gt;3blue1brownâ€™s number-recognition network&lt;/a&gt; with the list &lt;code class="highlight"&gt;[784,16,16,10]&lt;/code&gt;.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_1_0" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_0"&gt;Flexible&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;layer_dims&lt;/span&gt;
        &lt;span class="c1"&gt;# Initialize n-1 matrices containing random weights&lt;/span&gt;
        &lt;span class="c1"&gt;# Weight matrices must have rows like the prev layer&lt;/span&gt;
        &lt;span class="c1"&gt;# and columns like the next layer (otherwise you must transpose)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                                 &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
                  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_1" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_1"&gt;Hard-coded&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;# Hyperparameters&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;input_layer_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hidden_layer_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;output_layer_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

        &lt;span class="c1"&gt;# Weights&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;W1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;input_layer_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hidden_layer_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;W2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hidden_layer_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;output_layer_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;With this flexible setup, forward propagation is just a matter of &lt;code class="highlight"&gt;reduce&lt;/code&gt;, as I alluded toÂ above:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_2_0" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_0"&gt;Flexible&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;functools&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nb"&gt;reduce&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;y_hat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;reduce&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;prv&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nex&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;prv&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;nex&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;initial_input&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_2_1" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_1"&gt;Hard-coded&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
          &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;W1&lt;/span&gt;
          &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sigmoid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
          &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a2&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;W2&lt;/span&gt;
          &lt;span class="n"&gt;y_hat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sigmoid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
          &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;y_hat&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Look how concise thatÂ is!&lt;/p&gt;
&lt;p&gt;However, thinking ahead, we will need to keep the intermediate values for when we do backpropagation, so letâ€™s flesh this out aÂ bit.&lt;/p&gt;
&lt;p&gt;Similar to our &lt;code class="highlight"&gt;w&lt;/code&gt; list, we should instantiate an &lt;code class="highlight"&gt;a&lt;/code&gt; list &lt;span class="math"&gt;\(= [\textbf a_0, \textbf a_1, \cdots, \textbf a_k]\)&lt;/span&gt; and a &lt;code class="highlight"&gt;z&lt;/code&gt; list &lt;span class="math"&gt;\(= [\textbf z_0, \textbf z_1, \cdots, \textbf z_k]\)&lt;/span&gt; when we run theÂ function.&lt;/p&gt;
&lt;p&gt;To make bookkeeping a little easier, letâ€™s add the necessary padding so that &lt;code class="highlight"&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;/code&gt; and &lt;code class="highlight"&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;/code&gt; refer to &lt;span class="math"&gt;\(\textbf z\)&lt;/span&gt; and &lt;span class="math"&gt;\(\textbf a\)&lt;/span&gt; at layer &lt;span class="math"&gt;\(n\)&lt;/span&gt; (starting from zero). There is no â€œuncookedâ€ input, so &lt;code class="highlight"&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Meanwhile &lt;code class="highlight"&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;/code&gt; is technically the initial input matrix and &lt;code class="highlight"&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;/code&gt; is the output &lt;span class="math"&gt;\(\hat y\)&lt;/span&gt;.&lt;/p&gt;
&lt;h2 id="testing-it-out"&gt;Testing itÂ out&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;activate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;inputs&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sigmoid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;initial_input&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;initial_input&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;# consider X as a_0&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;          &lt;span class="c1"&gt;# keep the indexes of z and a aligned&lt;/span&gt;
        &lt;span class="n"&gt;y_hat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;reduce&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;activate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;initial_input&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;y_hat&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can test this out with the Welch Labs toyÂ data:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_3_0" name="__tabs_3" type="radio"/&gt;
&lt;label for="__tab_3_0"&gt;Input&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(([&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;],[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],[&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(([&lt;/span&gt;&lt;span class="mi"&gt;75&lt;/span&gt;&lt;span class="p"&gt;],[&lt;/span&gt;&lt;span class="mi"&gt;82&lt;/span&gt;&lt;span class="p"&gt;],[&lt;/span&gt;&lt;span class="mi"&gt;93&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# normalize data&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;amax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;

&lt;span class="n"&gt;NN&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;NN&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_3_1" name="__tabs_3" type="radio"/&gt;
&lt;label for="__tab_3_1"&gt;Output&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;array([[0.58313228],
       [0.5781811 ],
       [0.59692924]])
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The codeÂ works!&lt;/p&gt;
&lt;h1 id="backpropagation"&gt;Backpropagation&lt;/h1&gt;
&lt;p&gt;Now that weâ€™ve fed our input &lt;em&gt;forward&lt;/em&gt; through the network, we now need to take its output and propagate the error (discrepancy between the output and truth) &lt;em&gt;backward&lt;/em&gt; through the network, to figure out how much to adjust the weightsÂ by.&lt;/p&gt;
&lt;p&gt;This is where the calculus becomes quite messy compared to the toy linear regression model. Each successive layer in the network introduces a new layer of functions that must be chain-ruled through in order toÂ differentiate.&lt;/p&gt;
&lt;p&gt;I am not really the best candidate to explain the nitty-gritty details of backpropagation. What follows will be  mainly my notes, which were enough to help me understand how to generalize the code to any number ofÂ layers.&lt;/p&gt;
&lt;h2 id="sigmoid-prime-brother-of-modulus-prime"&gt;Sigmoid Prime (brother of ModulusÂ Prime)&lt;/h2&gt;
&lt;p&gt;If, as a high school student, I had known advanced math would turn into a cast of Transformers characters, I might have stuck with itÂ ğŸ˜‚&lt;/p&gt;
&lt;p&gt;Anyway, before we go further, we have to define &lt;span class="math"&gt;\(\sigma'(z)\)&lt;/span&gt;, the derivative of our sigmoidÂ function.&lt;/p&gt;
&lt;div class="math"&gt;$$ \sigma'(z) = \frac{e^{-z}}{(1 + e^{-z})^2} $$&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;sigmoid_prime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src="../../images/backprop/sigmoid_prime.png" width="300"/&gt;&lt;/p&gt;
&lt;p&gt;Nice.&lt;/p&gt;
&lt;h2 id="fracpartial-textbf-jpartial-textbf-w-on-the-turntable-or-something"&gt;&lt;span class="math"&gt;\(\frac{\partial \textbf J}{\partial \textbf w}\)&lt;/span&gt; on the turntableâ€¦ orÂ something&lt;/h2&gt;
&lt;p&gt;In the toy linear regression model, gradient descent required finding &lt;span class="math"&gt;\(\frac{\partial J}{\partial \theta}\)&lt;/span&gt;. In our neural network, gradient descent is going to require finding &lt;span class="math"&gt;\(\frac{\partial \textbf J}{\partial \textbf w}\)&lt;/span&gt; for all &lt;span class="math"&gt;\(\textbf w\)&lt;/span&gt; in our list &lt;code class="highlight"&gt;w&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The tricky thing is that because the neural network is essentially functions layered on top of each other, the farther you go back toward the beginning of the network, the more complicated the derivativesÂ become.&lt;/p&gt;
&lt;p&gt;You could think of this in the following way: Values farther toward the beginning of the network have a subtler effect on the final output, while values farther toward the output have a more direct effect on the final output, despite the fact that we cannot manipulate themÂ directly.&lt;/p&gt;
&lt;p&gt;Here are the equations from the Welch Labs example, with the indices adjusted to reflect our zero-basedÂ setup.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\textrm{error} &amp;amp;= (\hat y - y) \\
\delta_2 &amp;amp;= (\hat y - y) \sigma'(\textbf z_2) &amp;amp;\to
\frac{\partial \textbf J}{\partial \textbf w_1} &amp;amp;= \textbf a_2^T \delta_2 \\[0.8em]
\delta_1 &amp;amp;= \delta_2 \textbf w_1^T \sigma'(\textbf z_1) &amp;amp;\to
\frac{\partial \textbf J}{\partial \textbf w_0} &amp;amp;= \textbf X^T \delta_1
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;Small delta &lt;span class="math"&gt;\(\delta\)&lt;/span&gt; (also a matrix), is referred to as the &lt;strong&gt;error signal&lt;/strong&gt;. &lt;span class="math"&gt;\(\delta_n\)&lt;/span&gt; indicates how much the output changes when &lt;span class="math"&gt;\(\textbf z_n\)&lt;/span&gt;, the â€œuncookedâ€ values of layer &lt;span class="math"&gt;\(n\)&lt;/span&gt;,Â change.&lt;/p&gt;
&lt;p&gt;My main question here was: Given that these two gradients are not exactly the same, what would they look like in a neural network with moreÂ layers?&lt;/p&gt;
&lt;h2 id="chain-rule-forever-and-ever-and-ever-and"&gt;Chain rule forever and ever and everÂ andâ€¦&lt;/h2&gt;
&lt;p&gt;This looks really scary, but it was the only way I could figure out theÂ pattern.&lt;/p&gt;
&lt;p&gt;Suppose we have a neural network with four layers (like the 3blue1brownÂ network).&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\frac{\partial \textbf J}{\partial \textbf w_2} &amp;amp;=
\textcolor{#1f77b4}{(\hat y - y) \frac{\partial \hat y (=\textbf a_3)}{\partial \textbf z_3}}
\frac{\partial \textbf z_3}{\partial \textbf w_2} \\[0.8em]
&amp;amp;= \textcolor{#1f77b4}{\overbrace{(\hat y - y) \sigma'(\textbf z_3)}^{\delta_3}}
\frac{\partial \textbf z_3}{\partial \textbf w_2} \\[0.8em]
&amp;amp;= \textcolor{#1f77b4}{\delta_3} \frac{\partial \textbf z_3}{\partial \textbf w_2} \\[0.8em]
&amp;amp;= \textbf a_2^T \color{#1f77b4}{\delta_3} \\[1.2em]
\frac{\partial \textbf J}{\partial \textbf w_1} &amp;amp;=
\textcolor{#1f77b4}{(\hat y - y) \frac{\partial \textbf a_3}{\partial \textbf z_3}}
\textcolor{#e377c2}{\frac{\partial \textbf z_3}{\partial \textbf a_2}
\frac{\partial \textbf a_2}{\partial \textbf z_2}} \frac{\partial \textbf z_2}{\partial \textbf w_1} \\[0.8em]
&amp;amp;= \textcolor{#e377c2}{\overbrace{\textcolor{#1f77b4}{\overbrace{(\hat y - y) \sigma'(\textbf z_3)}^{\delta_3}} \frac{\partial \textbf z_3}{\partial \textbf a_2}
\sigma'(\textbf z_2)}^{\delta_2}} \frac{\partial \textbf z_2}{\partial \textbf w_1} \\[0.8em]
&amp;amp;= \textcolor{#e377c2}{\overbrace{\delta_3 \textbf w_2^T
\sigma'(\textbf z_2)}^{\delta_2}} \frac{\partial \textbf z_2}{\partial \textbf w_1} \\[0.8em]
&amp;amp;= \textcolor{#e377c2}{\delta_2} \frac{\partial \textbf z_2}{\partial \textbf w_1} \\[0.8em]
&amp;amp;= \textbf a_1^T \textcolor{#e377c2}{\delta_2} \\[1.2em]
\frac{\partial \textbf J}{\partial \textbf w_0} &amp;amp;=
\textcolor{#1f77b4}{(\hat y - y) \frac{\partial \textbf a_3}{\partial \textbf z_3}} \textcolor{#e377c2}{\frac{\partial \textbf z_3}{\partial \textbf a_2}
\frac{\partial \textbf a_2}{\partial \textbf z_2}} \textcolor{mediumpurple}{\frac{\partial \textbf z_2}{\partial \textbf a_1}
\frac{\partial \textbf a_1}{\partial \textbf z_1}} \frac{\partial \textbf z_1}{\partial \textbf w_0} \\[0.8em]
&amp;amp;= \textcolor{mediumpurple}{\overbrace{\textcolor{#e377c2}{\overbrace{\textcolor{#1f77b4}{\delta_3} \textbf w_2^T
\sigma'(\textbf z_2)}^{\delta_2}} \frac{\partial \textbf z_2}{\partial \textbf a_1}
\sigma'(\textbf z_1)}^{\delta_1}} \frac{\partial \textbf z_1}{\partial \textbf w_0} \\[0.8em]
&amp;amp;= \textcolor{mediumpurple}{\overbrace{\delta_2 \textbf w_1^T
\sigma'(\textbf z_1)}^{\delta_1}} \frac{\partial \textbf z_1}{\partial \textbf w_0} \\[0.8em]
&amp;amp;= \textcolor{mediumpurple}{\delta_1} \frac{\partial \textbf z_1}{\partial \textbf w_0} \\[0.8em]
&amp;amp;= \textbf a_0^T \textcolor{mediumpurple}{\delta_1} = \textbf X^T \textcolor{mediumpurple}{\delta_1}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;This reveals a fewÂ generalities.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\frac{\partial \textbf a_n}{\partial \textbf z_n}\)&lt;/span&gt;, or how much the â€œcookedâ€ values of a layer change in relation to the â€œuncookedâ€ values, is simply the derivative of the sigmoid function, since going from â€œuncookedâ€ to â€œcookedâ€ only involved the sigmoid function.
&lt;div class="math"&gt;$$ \frac{\partial \textbf a_n}{\partial \textbf z_n} = \sigma'(\textbf z_n) $$&lt;/div&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\frac{\partial \textbf z_{n+1}}{\partial \textbf a_n}\)&lt;/span&gt;, or how much a layerâ€™s â€œcookedâ€ values change the â€œuncookedâ€ values of the next layer, is simply the weights between the two layers. Makes sense, right? The weights matrix does have to be transposed for the multiplication to work, though.
&lt;div class="math"&gt;$$ \frac{\partial \textbf z_{n+1}}{\partial \textbf a_n} = \textbf w_n^T $$&lt;/div&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The first error signal, &lt;span class="math"&gt;\(\textcolor{#1f77b4}{\delta_3}\)&lt;/span&gt;, is different, but after that, you can find the error signal of any layer, &lt;span class="math"&gt;\(\delta_n\)&lt;/span&gt;, by piling on more of the above two partial derivatives:
&lt;div class="math"&gt;$$ \delta_n = \delta_{n+1}
\frac{\partial \textbf z_{n+1}}{\partial \textbf a_n}
\frac{\partial \textbf a_n}{\partial \textbf z_n}
= \delta_{n+1} \textbf w_n^T \sigma'(\textbf z_n) $$&lt;/div&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Finally, if we save all the error signals in a list &lt;code class="highlight"&gt;deltas&lt;/code&gt; &lt;span class="math"&gt;\(= [\delta_k-1, \delta_2, \cdots, \delta_1]\)&lt;/span&gt; (note that this will be the same length as &lt;code class="highlight"&gt;w&lt;/code&gt;, one shorter than &lt;code class="highlight"&gt;a&lt;/code&gt;, and &lt;code class="highlight"&gt;z&lt;/code&gt;), then obtaining &lt;span class="math"&gt;\(\frac{\partial \textbf J}{\partial \textbf w_n}\)&lt;/span&gt; is just a matter of reversing &lt;code class="highlight"&gt;deltas&lt;/code&gt; and &lt;code class="highlight"&gt;zip&lt;/code&gt;ping it with &lt;code class="highlight"&gt;w&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="recursion-to-the-rescue"&gt;Recursion to theÂ rescue&lt;/h2&gt;
&lt;p&gt;In the four-layer example, &lt;code class="highlight"&gt;deltas[0]&lt;/code&gt; &lt;span class="math"&gt;\(= \textcolor{#1f77b4}{\delta_3}\)&lt;/span&gt;, so we can start offÂ defining&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;backward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;initial_error&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
        &lt;span class="n"&gt;deltas&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;initial_error&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sigmoid_prime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;From there, we need to walk backwards through the lists &lt;code class="highlight"&gt;w&lt;/code&gt; and &lt;code class="highlight"&gt;z&lt;/code&gt;, starting from the second-to-last value of each, to get the values weÂ need.&lt;/p&gt;
&lt;p&gt;Since we are reusing the newest &lt;span class="math"&gt;\(\delta_n\)&lt;/span&gt; result (i.e., &lt;code class="highlight"&gt;&lt;span class="n"&gt;deltas&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;/code&gt;) in each iteration, the loop goes roughly likeÂ this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;?&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;delta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;deltas&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="err"&gt;?&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sigmoid_prime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="err"&gt;?&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;deltas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;delta&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, once we have populated &lt;code class="highlight"&gt;deltas&lt;/code&gt;, then populating a list &lt;code class="highlight"&gt;djdw&lt;/code&gt; of all &lt;span class="math"&gt;\(\frac{\partial \textbf J}{\partial \textbf w_n}\)&lt;/span&gt; can be done in oneÂ line:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;djdw&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;reversed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;deltas&lt;/span&gt;&lt;span class="p"&gt;))]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This works out perfectly,Â because&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code class="highlight"&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;/code&gt; is the input &lt;span class="math"&gt;\(\textbf X\)&lt;/span&gt;,Â and&lt;/li&gt;
&lt;li&gt;even though &lt;code class="highlight"&gt;a&lt;/code&gt; is one longer than &lt;code class="highlight"&gt;deltas&lt;/code&gt;, &lt;code class="highlight"&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;/code&gt; is not used in these calculations and so &lt;code class="highlight"&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;/code&gt; will disregardÂ it.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code class="highlight"&gt;djdw&lt;/code&gt; thus contains &lt;span class="math"&gt;\([\textbf X^T \delta_1, \textbf a_1^T \delta_2, \textbf a_2^T \delta_3] = [\frac{\partial \textbf J}{\partial \textbf w_0}, \frac{\partial \textbf J}{\partial \textbf w_1}, \frac{\partial \textbf J}{\partial \textbf w_2}]\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;That gives us our final backpropagation function. Iâ€™ve condensed it a little here just to highlight the comparison with the hard-coded version, but the full version with comments is posted at theÂ bottom.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_4_0" name="__tabs_4" type="radio"/&gt;
&lt;label for="__tab_4_0"&gt;Flexible&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;backward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;initial_error&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
        &lt;span class="n"&gt;deltas&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;initial_error&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sigmoid_prime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
        &lt;span class="n"&gt;ll&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ll&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;delta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;deltas&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;ll&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sigmoid_prime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;ll&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="n"&gt;deltas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;delta&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;reversed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;deltas&lt;/span&gt;&lt;span class="p"&gt;))]&lt;/span&gt;        

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;djdw&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;djdw&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;NN&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;backward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_4_1" name="__tabs_4" type="radio"/&gt;
&lt;label for="__tab_4_1"&gt;Hard-coded&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cost_prime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y_hat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;delta3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y_hat&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sigmoid_prime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;delta3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;delta3&lt;/span&gt;
        &lt;span class="n"&gt;dJdW2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;delta3&lt;/span&gt;
        &lt;span class="n"&gt;delta2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;delta3&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;W2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sigmoid_prime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;dJdW1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;delta2&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;dJdW1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dJdW2&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;dJdW1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dJdW2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cost_prime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;dJdW1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;dJdW2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Nice andÂ compact!&lt;/p&gt;
&lt;h2 id="testing-it-out_1"&gt;Testing itÂ out&lt;/h2&gt;
&lt;p&gt;Letâ€™s generate a random dataset and network similar to the 3blue1brown one. That is, there should be input layer with 784 neurons, followed by 2 hidden layers and 1 output layer. His network is &lt;code class="highlight"&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;784&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;/code&gt; but why not spice things up a bit and change the numbers around aÂ little?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sklearn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;make_regression&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;784&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;NN&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;784&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;NN&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# 26048&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Awesome! It works. And there are a whopping &lt;strong&gt;26,048 weights&lt;/strong&gt; in this behemoth neural network.Â Wow.&lt;/p&gt;
&lt;p&gt;With some minor adjustments to the &lt;code class="highlight"&gt;get_params&lt;/code&gt; and &lt;code class="highlight"&gt;set_params&lt;/code&gt; methods in the original class, we should be able to drop this right into the Welch Labs &lt;code class="highlight"&gt;Trainer&lt;/code&gt; as-is.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_5_0" name="__tabs_5" type="radio"/&gt;
&lt;label for="__tab_5_0"&gt;Flexible&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;weight&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;weight&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;set_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;num_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;num_weights&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                                   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
            &lt;span class="n"&gt;params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;num_weights&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_5_1" name="__tabs_5" type="radio"/&gt;
&lt;label for="__tab_5_1"&gt;Hard-coded&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;#Get W1 and W2 unrolled into vector:&lt;/span&gt;
        &lt;span class="n"&gt;params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;W1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;W2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;set_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;#Set W1 and W2 using single paramater vector.&lt;/span&gt;
        &lt;span class="n"&gt;W1_start&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="n"&gt;W1_end&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hidden_layer_size&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;input_layer_size&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;W1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;W1_start&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;W1_end&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;input_layer_size&lt;/span&gt; &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hidden_layer_size&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="n"&gt;W2_end&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;W1_end&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hidden_layer_size&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;output_layer_size&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;W2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;W1_end&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;W2_end&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hidden_layer_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;output_layer_size&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Letâ€™s train it (See &lt;code class="highlight"&gt;Trainer&lt;/code&gt; tab in â€œSummaryâ€Â below.)!&lt;/p&gt;
&lt;p&gt;Well, being a newbie at this, it wasnâ€™t quite so obvious to me, but it wasnâ€™t feasible to train such a gigantic neural network with non-industrial-strength tools. Even with smaller networks, unnormalized data easily caused overflowÂ errors.&lt;/p&gt;
&lt;p&gt;This post is already quite long and complicated, and I donâ€™t want to stray from the topic of backpropagation by getting into numerical stability, so I decided to pare things down a bitÂ instead.&lt;/p&gt;
&lt;p&gt;Still, the following network has five layers, which is reasonably complex and a further test of the mathÂ involved.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sklearn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;make_regression&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;
&lt;span class="n"&gt;NN&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Trainer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;NN&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src="../../images/backprop/nn_train.png"/&gt;&lt;/p&gt;
&lt;p&gt;Hooray! ItÂ works.&lt;/p&gt;
&lt;h1 id="summary"&gt;Summary&lt;/h1&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_6_0" name="__tabs_6" type="radio"/&gt;
&lt;label for="__tab_6_0"&gt;setup&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt;

&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sklearn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;make_regression&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;
&lt;span class="n"&gt;NN&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Trainer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;NN&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;sigmoid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;sigmoid_prime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_6_1" name="__tabs_6" type="radio"/&gt;
&lt;label for="__tab_6_1"&gt;NeuralNetwork&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;functools&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nb"&gt;reduce&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;layer_dims&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                                  &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
                  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;activate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;inputs&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sigmoid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;initial_input&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;initial_input&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;# consider X as a_0&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;          &lt;span class="c1"&gt;# keep the indexes of z and a aligned&lt;/span&gt;
        &lt;span class="n"&gt;y_hat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;reduce&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;activate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;initial_input&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;y_hat&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;backward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;initial_error&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
        &lt;span class="c1"&gt;# Accumulate Î´'s in reverse order&lt;/span&gt;
        &lt;span class="n"&gt;deltas&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;initial_error&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sigmoid_prime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
        &lt;span class="n"&gt;ll&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ll&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;delta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;deltas&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;ll&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sigmoid_prime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;ll&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="n"&gt;deltas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;delta&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="c1"&gt;# get djdws by multiplying the transpose of each activation by each delta&lt;/span&gt;
        &lt;span class="c1"&gt;# X.T @ Î´_1, a_1.T @ Î´_2, a_2.T @ Î´_3... (note that deltas[0] is Î´_1)&lt;/span&gt;
        &lt;span class="n"&gt;djdw&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;reversed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;deltas&lt;/span&gt;&lt;span class="p"&gt;))]&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;djdw&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;djdw&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;djdw&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;NN&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;backward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y_hat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;J&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y_hat&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;J&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;weight&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;weight&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;set_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;num_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;num_weights&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                                   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
            &lt;span class="n"&gt;params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;num_weights&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_6_2" name="__tabs_6" type="radio"/&gt;
&lt;label for="__tab_6_2"&gt;Trainer&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;scipy&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;optimize&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Trainer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="c1"&gt;# unedited from Welch labs version&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cost_wrapper&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;grad&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;grad&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;callback_f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;J&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;train&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;J&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="n"&gt;params0&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_params&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;options&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'maxiter'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'disp'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="n"&gt;_res&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;optimize&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;minimize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cost_wrapper&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;params0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;jac&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                 &lt;span class="n"&gt;method&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'BFGS'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;options&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;options&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;callback&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;callback_f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id="references"&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=bxe2T-V8XRs"&gt;Neural Networks Demystified&lt;/a&gt;, WelchÂ Labs&lt;/li&gt;
&lt;li&gt;&lt;a href="https://towardsdatascience.com/multi-layer-neural-networks-with-sigmoid-function-deep-learning-for-rookies-2-bf464f09eb7f"&gt;Multi-Layer Neural Networks with Sigmoid Functionâ€” Deep Learning for Rookies (2)&lt;/a&gt;, NahuaÂ Kang&lt;/li&gt;
&lt;/ul&gt;</content><category term="machine learning"></category><category term="neural networks"></category><category term="backpropagation"></category></entry><entry><title>Linear Regression, Part 1.9999: AutogradÂ Fail</title><link href="http://tabidots.github.io/2019/02/deeper-into-linear-regression" rel="alternate"></link><published>2019-02-02T16:04:26+07:00</published><updated>2019-02-02T16:04:26+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-02-02:/2019/02/deeper-into-linear-regression</id><summary type="html">&lt;p&gt;I got halfway through this post only to be thwarted by the limits of the autograd module. The issue I opened on their GitHub repo has so far fallen on deaf ears, so I lost interest in linear regression for the time&amp;nbsp;being.&lt;/p&gt;</summary><content type="html">
&lt;p&gt;In &lt;a href="/squarest-root-in-babylon"&gt;the previous post&lt;/a&gt;, we looked at using automatic differentiation to simplify our linear regression model and make it moreÂ readable.&lt;/p&gt;
&lt;p&gt;Just to recap how far weâ€™ve come with our implementation of linearÂ regression:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Multiple regression&lt;/strong&gt;: Generalize the model to accept any number of features (&lt;span class="math"&gt;\(x_1, x_2, \cdots, x_n\)&lt;/span&gt;)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Vectorization&lt;/strong&gt;: Eliminate computationally-costly &lt;code class="highlight"&gt;for&lt;/code&gt;-loops with vector and matrixÂ operations&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Error threshold&lt;/strong&gt;: Modify our &lt;code class="highlight"&gt;train_model()&lt;/code&gt; function to use an &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; error threshold rather than a set number ofÂ iterations&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Automatic differentiation&lt;/strong&gt;: Outsource the computation of the gradient to a library such as &lt;code class="highlight"&gt;autograd&lt;/code&gt;, which can do it faster, more simply, and moreÂ accurately&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Thatâ€™s a lot, and there are still many things left to explore! Thankfully, the mathematical heavy lifting is done for now. Now we can concentrate on the coding and data science side ofÂ things!&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Do data science&lt;/strong&gt;: Use &lt;code class="highlight"&gt;pandas&lt;/code&gt; instead of &lt;code class="highlight"&gt;numpy&lt;/code&gt;; use a publicly available dataset instead of randomly generating toy data every time, and preprocess itÂ appropriately&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;span class="caps"&gt;OOP&lt;/span&gt;&lt;/strong&gt;: Encapsulate the linear regression model into aÂ class&lt;/li&gt;
&lt;li&gt;Fine-tune the hyperparameters and evaluate theÂ results&lt;/li&gt;
&lt;li&gt;Create similar models in Julia, R, and Clojure (the last one is a littleÂ ambitious)&lt;/li&gt;
&lt;li&gt;Compare our results to out-of-the-box linear regressionÂ models&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="public-data-preprocessing"&gt;Public data &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt;Â preprocessing&lt;/h1&gt;
&lt;p&gt;We were generating toy datasets with random numbers before, but that is only good for testing that the code works. If we are going to evaluate models and hyperparameters, we need to use the same single dataset forÂ consistency.&lt;/p&gt;
&lt;p&gt;I currently live in &lt;span class="caps"&gt;SE&lt;/span&gt; Asia and air pollution is a big issue here, so the &lt;a href="https://archive.ics.uci.edu/ml/datasets/PM2.5+Data+of+Five+Chinese+Cities"&gt;&lt;span class="caps"&gt;PM2&lt;/span&gt;.5 Data of Five Chinese Cities Data Set&lt;/a&gt; caught my eye as I was scrolling through the &lt;span class="caps"&gt;UCI&lt;/span&gt; Machine Learning RepositoryÂ website.&lt;/p&gt;
&lt;p&gt;Letâ€™s use &lt;code class="highlight"&gt;pandas&lt;/code&gt; to read in the Beijing data and generate a &lt;code class="highlight"&gt;DataFrame&lt;/code&gt; for us, which is a more sophisticated version of a NumPy &lt;code class="highlight"&gt;ndarray&lt;/code&gt;.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_1_0" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="c1"&gt;# You may have to change os.getcwd() and os.chdir() to tell Python where to look&lt;/span&gt;
&lt;span class="n"&gt;raw_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'FiveCitiePMData/BeijingPM20100101_20151231.csv'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;raw_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;info&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="c1"&gt;# https://datascience.stackexchange.com/questions/12645/how-to-count-the-number-of-missing-values-in-each-row-in-pandas-dataframe&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_1" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_1"&gt;Output&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;lt;class 'pandas.core.frame.DataFrame'&amp;gt;
RangeIndex: 52584 entries, 0 to 52583
Data columns (total 18 columns):
No                 52584 non-null int64
year               52584 non-null int64
month              52584 non-null int64
day                52584 non-null int64
hour               52584 non-null int64
season             52584 non-null int64
PM_Dongsi          25052 non-null float64
PM_Dongsihuan      20508 non-null float64
PM_Nongzhanguan    24931 non-null float64
PM_US Post         50387 non-null float64
DEWP               52579 non-null float64
HUMI               52245 non-null float64
PRES               52245 non-null float64
TEMP               52579 non-null float64
cbwd               52579 non-null object
Iws                52579 non-null float64
precipitation      52100 non-null float64
Iprec              52100 non-null float64
dtypes: float64(11), int64(6), object(1)
memory usage: 7.2+ MB
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Our &lt;code class="highlight"&gt;DataFrame&lt;/code&gt; has 52,584 entries (hourly snapshots of air pollution) and 18 columns, and there are a lot of â€œholesâ€ in the data (as noted on theÂ webpage).&lt;/p&gt;
&lt;p&gt;Thereâ€™s also a lot of data we donâ€™t really need. Iâ€™m not a meteorologist, and Iâ€™m not experienced enough with statistics to use this data to find out &lt;em&gt;which features&lt;/em&gt; correlate with airÂ pollution.&lt;/p&gt;
&lt;p&gt;So, the objective of our model will be to find out &lt;em&gt;how&lt;/em&gt; the salient features correlate with air pollution, and use that to predict future &lt;span class="caps"&gt;PM2&lt;/span&gt;.5Â readings.&lt;/p&gt;
&lt;p&gt;A quick-and-dirty Google search reveals that &lt;strong&gt;humidity&lt;/strong&gt; and &lt;strong&gt;air temperature&lt;/strong&gt; are the most influential factors on &lt;span class="caps"&gt;PM2&lt;/span&gt;.5 readings. So, letâ€™s trim our data down to humidity (&lt;code class="highlight"&gt;HUMI&lt;/code&gt;), air temperature (&lt;code class="highlight"&gt;TEMP&lt;/code&gt;) and the &lt;span class="caps"&gt;PM2&lt;/span&gt;.5Â reading.&lt;/p&gt;
&lt;p&gt;Note that there are several &lt;span class="caps"&gt;PM2&lt;/span&gt;.5 readings, but the &lt;code class="highlight"&gt;PM_US Post&lt;/code&gt; has the fewest holes (non-null values). So letâ€™s ignore theÂ others.&lt;/p&gt;
&lt;p&gt;Another consideration is the nature of each feature. Humidity and air temperature are both &lt;em&gt;continuous&lt;/em&gt; values, so weâ€™re in the clear, but if we cared about the time of day or wind direction, we would have to deal with those &lt;em&gt;discrete&lt;/em&gt; values in a slightly differentÂ way.&lt;/p&gt;
&lt;h2 id="cleaning-the-data"&gt;Cleaning theÂ data&lt;/h2&gt;
&lt;p&gt;Since we only need a few columns out of this entire table, letâ€™s just create a whole new &lt;code class="highlight"&gt;DataFrame&lt;/code&gt;, using &lt;code class="highlight"&gt;filter&lt;/code&gt; to &lt;a href="https://stackoverflow.com/a/34683105"&gt;select our target columns&lt;/a&gt; and &lt;code class="highlight"&gt;dropna&lt;/code&gt; to remove the rows where any of those values are &lt;code class="highlight"&gt;NaN&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;raw_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s1"&gt;'HUMI'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s1"&gt;'TEMP'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'PM_US Post'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropna&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;That wasÂ easy!&lt;/p&gt;
&lt;p&gt;Weâ€™ve gotten rid of incomplete entries, but we might still have some bad values that, err, pollute our results. Letâ€™sÂ check:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_2_0" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;describe&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_2_1" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_1"&gt;Output&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;               HUMI          TEMP    PM_US Post
count  50048.000000  50048.000000  50048.000000
mean      54.580363     12.599504     95.773258
std       25.996814     12.107097     91.731446
min        2.000000    -19.000000      1.000000
25%       31.000000      2.000000     27.000000
50%       55.000000     14.000000     69.000000
75%       78.000000     23.000000    132.000000
max      100.000000     42.000000    994.000000
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Keep in mind that &lt;code class="highlight"&gt;HUMI&lt;/code&gt; is % and &lt;code class="highlight"&gt;TEMP&lt;/code&gt; is in degrees Celsius. Everything seems okayÂ there.&lt;/p&gt;
&lt;p&gt;How about those pollution readings, though? The &lt;code class="highlight"&gt;max&lt;/code&gt; value seems a little off. I mean, I have heard of readings in the 300 range (which is still dangerous), but 994 seems like anÂ outlier.&lt;/p&gt;
&lt;p&gt;How many readings were more than 3 standard deviations above theÂ mean?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Source: https://stackoverflow.com/questions/23833763/pandas-count-number-of-elements-in-each-column-less-than-x&lt;/span&gt;
&lt;span class="n"&gt;high_pm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'PM_US Post'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'PM_US Post'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="n"&gt;high_readings&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'PM_US Post'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;high_pm&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count_nonzero&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;high_readings&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;1.86%. Iâ€™m tempted to remove them from the data, but a Google search turned up &lt;a href="https://www.telegraph.co.uk/news/worldnews/asia/china/11983156/Air-quality-plummets-as-heavy-smog-blankets-large-swaths-of-China.html"&gt;an article that suggests that such readings are not beyond the realm of possibility&lt;/a&gt;,Â sadly.&lt;/p&gt;
&lt;h2 id="feature-scaling"&gt;FeatureÂ scaling&lt;/h2&gt;
&lt;p&gt;One thing we didnâ€™t do with the randomly generated datasets is &lt;strong&gt;feature scaling&lt;/strong&gt;, which refers to the process of either normalizing or standardizing the values to facilitate faster and more accurate computations during gradient descent (or otherÂ algorithms).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Min-max scaling&lt;/strong&gt;: Make all values fit within a certain range (between 0 and 1 or some otherÂ value)&lt;/p&gt;
&lt;div class="math"&gt;$$ X_{\textrm{norm}} = \frac{X - X_{\textrm{min}}}{X_{\textrm{max}} - X_{\textrm{min}}} $$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Standardization&lt;/strong&gt;: Coerce columns to have a mean (&lt;span class="math"&gt;\(\mu\)&lt;/span&gt;) of 0 and a standard deviation (&lt;span class="math"&gt;\(\sigma\)&lt;/span&gt;) of 1 by computing a &lt;span class="math"&gt;\(z\)&lt;/span&gt;-score from the values. This is something I vaguely remember from collegeÂ stats.&lt;/p&gt;
&lt;div class="math"&gt;$$ z_i = \frac{x_i - \mu}{\sigma} $$&lt;/div&gt;
&lt;p&gt;Which isÂ better?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;When in doubt, just standardize the data, it shouldnâ€™t hurt. (&lt;a href="https://sebastianraschka.com/Articles/2014_about_feature_scaling.html#about-standardization"&gt;Source&lt;/a&gt;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Fair enough. &lt;code class="highlight"&gt;scikit-learn&lt;/code&gt; has built-in feature scaling methods, but one thing that did cross my mind is that if you train a model on normalized data, how can you make predictions from new data without the &lt;code class="highlight"&gt;min&lt;/code&gt; and &lt;code class="highlight"&gt;max&lt;/code&gt; (or &lt;code class="highlight"&gt;mean&lt;/code&gt; and &lt;code class="highlight"&gt;std&lt;/code&gt;) from everyÂ column?&lt;/p&gt;
&lt;p&gt;For now, Iâ€™ll proceed working with this dataset without doing feature scaling, but Iâ€™ll come back to this point ifÂ necessary.&lt;/p&gt;
&lt;h2 id="segregating-the-data"&gt;Segregating theÂ data&lt;/h2&gt;
&lt;p&gt;Typically, for machine learning, you randomize the data and split it into three sets for training, validation, and testing. Training is for the model to learn the weights, validation is to fine-tune the hyperparameters (learning rate, convergence threshold, etc.), and testing is for evaluating the finalizedÂ model.&lt;/p&gt;
&lt;p&gt;The following code performs a 60:20:20 split on the data. You could also doÂ 80:10:10.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Source: https://stackoverflow.com/questions/38250710/how-to-split-data-into-3-sets-train-validation-and-test&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;autograd.numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# guarantee same result every time&lt;/span&gt;
&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;permutation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;frac&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                                 &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;))])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Done!&lt;/p&gt;
&lt;h1 id="a-class-act"&gt;A classÂ act&lt;/h1&gt;
&lt;p&gt;Now, we can move on to tightening up the code a little bit. Before we encapsulate it into a class, though, we should consider the fact that we are working with &lt;code class="highlight"&gt;pandas&lt;/code&gt; now, and not &lt;code class="highlight"&gt;numpy&lt;/code&gt;, which will affect a coupleÂ things.&lt;/p&gt;
&lt;p&gt;To add a column of ones (dummy features), the &lt;span class="math"&gt;\(x_0\)&lt;/span&gt; in our linear regressionÂ matrix:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_3_0" name="__tabs_3" type="radio"/&gt;
&lt;label for="__tab_3_0"&gt;NumPy&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hstack&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_3_1" name="__tabs_3" type="radio"/&gt;
&lt;label for="__tab_3_1"&gt;Pandas&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;insert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'dummy'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;To create a column vector of zeros (our initial weights), we can use a Pandas &lt;code class="highlight"&gt;Series&lt;/code&gt;:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_4_0" name="__tabs_4" type="radio"/&gt;
&lt;label for="__tab_4_0"&gt;NumPy&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;num_weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_4_1" name="__tabs_4" type="radio"/&gt;
&lt;label for="__tab_4_1"&gt;Pandas&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Series&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataframe_minus_truth&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The &lt;code class="highlight"&gt;list(dataframe_minus_truth)&lt;/code&gt; isnâ€™t quite so transparent. I found that when doing matrix multiplication between a matrix and either a vector or a matrix in &lt;code class="highlight"&gt;pandas&lt;/code&gt;, not only must the number of columns in the matrix match the number of rows in the other object, but &lt;a href="https://stackoverflow.com/questions/16472729/matrix-multiplication-in-pandas/16473007"&gt;the column &lt;em&gt;names&lt;/em&gt; must match, too&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This is actually pretty smart, because it makes sure that your features donâ€™t get messed up. But itâ€™s still kind of a gotcha for the uninitiatedÂ (me).&lt;/p&gt;
&lt;p&gt;So, to fix that, &lt;code class="highlight"&gt;list(df)&lt;/code&gt; is a &lt;a href="https://stackoverflow.com/questions/19482970/get-list-from-pandas-dataframe-column-headers"&gt;quick way to get a list of your column names&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;With those translations in mind, letâ€™s rewrite our linear regression model as aÂ class.&lt;/p&gt;
&lt;p&gt;Our old &lt;code class="highlight"&gt;train_model&lt;/code&gt; function took separate &lt;code class="highlight"&gt;X&lt;/code&gt; and &lt;code class="highlight"&gt;y&lt;/code&gt; inputs, but we should make it more user-friendly by spliting the features from truth behind the scenes (weâ€™ll assume that the last column isÂ truth).&lt;/p&gt;
&lt;p&gt;Letâ€™s flesh out the class with some extra methods, &lt;code class="highlight"&gt;test_on(dataset)&lt;/code&gt; and &lt;code class="highlight"&gt;predict()&lt;/code&gt;. For &lt;code class="highlight"&gt;test_on(dataset)&lt;/code&gt;, letâ€™s have it return the mean error (easier to interpret) rather than the mean squaredÂ error.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;autograd&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;elementwise_grad&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;egrad&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;LinRegModel&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[:,:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;  &lt;span class="c1"&gt;# all but last column&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;insert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'dummy'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;         &lt;span class="c1"&gt;# padding (w_0)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;   &lt;span class="c1"&gt;# last column&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Series&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__cost__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;info&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'Model underwent {self.epochs} epochs of training.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Model weights:'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;train&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.001&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="c1"&gt;# just to know the value; not critical for training&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Series&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="n"&gt;grad_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;egrad&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__cost__&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;last_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;grad_cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;grad_cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;this_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__cost__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;this_cost&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;this_cost&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;last_cost&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;break&lt;/span&gt;
            &lt;span class="n"&gt;last_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;this_cost&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;info&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;test_on&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_set&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;test_X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[:,:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;   &lt;span class="c1"&gt;# all but last column&lt;/span&gt;
        &lt;span class="n"&gt;test_X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;insert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'dummy'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;          &lt;span class="c1"&gt;# padding (w_0)&lt;/span&gt;
        &lt;span class="n"&gt;test_y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;    &lt;span class="c1"&gt;# last column&lt;/span&gt;
        &lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;new_samples&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_samples&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;"list"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;new_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_samples&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;new_samples&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
            &lt;span class="k"&gt;pass&lt;/span&gt;
        &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;new_samples&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;new_samples&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;insert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'dummy'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Number of features does not match the model's dataset"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id="fail"&gt;Fail!&lt;/h1&gt;
&lt;p&gt;While &lt;code class="highlight"&gt;autograd&lt;/code&gt; can handle NumPy data types, it appears that it canâ€™t deal with Pandas data types such as &lt;code class="highlight"&gt;Series&lt;/code&gt; and &lt;code class="highlight"&gt;DataFrames&lt;/code&gt;! This defeats the whole purpose of trying to convert the old code from NumPy toÂ Pandas.&lt;/p&gt;
&lt;p&gt;I &lt;a href="https://github.com/HIPS/autograd/issues/469"&gt;opened an issue&lt;/a&gt; on the GitHub repo, but still have not received a response after a week. In the meantime, I lost interest in this topic (manual linear regression) for the time being, and will end this postÂ here.&lt;/p&gt;
&lt;h1 id="references"&gt;References&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://sebastianraschka.com/Articles/2014_about_feature_scaling.html"&gt;About Feature Scaling and Normalization&lt;/a&gt;, SebastianÂ Raschka&lt;/p&gt;</content><category term="pandas"></category><category term="automatic differentiation"></category></entry><entry><title>The mod(ular arithmetic)Â squad</title><link href="http://tabidots.github.io/2019/02/mod-squad" rel="alternate"></link><published>2019-02-01T07:35:36+07:00</published><updated>2019-02-01T07:35:36+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-02-01:/2019/02/mod-squad</id><summary type="html">&lt;p&gt;Modular arithmetic is weird, cool, and generates some trippy&amp;nbsp;polynomials!&lt;/p&gt;</summary><content type="html">
&lt;p&gt;Finally, Iâ€™m on the last of the exercises from Chapter 2 of &lt;em&gt;A Programmerâ€™s Introduction to Mathematics&lt;/em&gt;. The exercise prompts are deceptively terse, and their connection to the material presented in the chapter is not always immediately obvious. Working through them can take entire days (for me,Â anyway).&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Write a web app that implements the distribution and reconstruction of the secret sharing protocol using the polynomial interpolation algorithm presented in this chapter, using modular arithmetic modulo and a 32-bit modulus &lt;span class="math"&gt;\(p\)&lt;/span&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To be honest, it took many hours before I could even understand what I was actually being asked to do. IÂ understood&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;part of the &lt;em&gt;what&lt;/em&gt;: the concept of modulo,Â and&lt;/li&gt;
&lt;li&gt;the &lt;em&gt;why&lt;/em&gt;: modular arithmetic avoids floating-point rounding errors that emerge in the &lt;span class="math"&gt;\(\frac{x - x_j}{x_i - x_j}\)&lt;/span&gt; operation of interpolatingÂ polynomials&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But I was clueless about theÂ restâ€”namely&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;how modular arithmetic relates to polynomials; do you perform &lt;span class="math"&gt;\(\mod n\)&lt;/span&gt; on all theÂ coefficients?&lt;/li&gt;
&lt;li&gt;how does division (fractional quantities) even work in modularÂ arithmetic?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At first, I spent way too much time going down fruitless dead-ends. I tried adding in &lt;code class="highlight"&gt;mod&lt;/code&gt; in random places, but I still got floating-point roundingÂ errors.&lt;/p&gt;
&lt;h1 id="multiplicative-inverse"&gt;MultiplicativeÂ inverse&lt;/h1&gt;
&lt;p&gt;Eventually, I found my way to &lt;a href="https://math.stackexchange.com/a/2924485"&gt;the key insight that got things moving&lt;/a&gt;: There is no â€œdivisionâ€ as such in modular arithmetic. Instead, there is the &lt;em&gt;multiplicative inverse&lt;/em&gt;, which is analogous in a somewhat non-obvious way to regularÂ division.&lt;/p&gt;
&lt;p&gt;In normal arithmetic, the inverse of a number (letâ€™s say &lt;span class="math"&gt;\(b\)&lt;/span&gt;) is the entity that, when multiplied by &lt;span class="math"&gt;\(b\)&lt;/span&gt;, gives &lt;span class="math"&gt;\(1\)&lt;/span&gt;. That will be the reciprocal, and if &lt;span class="math"&gt;\(b\)&lt;/span&gt; is a whole number, then the inverse of &lt;span class="math"&gt;\(b\)&lt;/span&gt; can be written &lt;span class="math"&gt;\(b^{-1}\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
b \cdot \textrm{inv} &amp;amp;= 1 \\
\textrm{inv} &amp;amp;= \frac{1}{b} \\
&amp;amp;= b^{-1}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;In modular arithmetic, the multiplicative inverse of a number &lt;span class="math"&gt;\(b\)&lt;/span&gt; in &lt;span class="math"&gt;\(\mod n\)&lt;/span&gt; is also written &lt;span class="math"&gt;\(b^{-1}\)&lt;/span&gt;, and it is the integer that, when multiplied by &lt;span class="math"&gt;\(b\)&lt;/span&gt;, gives &lt;span class="math"&gt;\(1 \mod n\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ b \cdot b^{-1} \equiv 1 \mod n $$&lt;/div&gt;
&lt;p&gt;Now, finding the inverse is not exactly straightforward. There is an algorithm, but letâ€™s first explore some examples. The StackExchange answer linked above enumerates the multiplicative inverses of numbers in &lt;span class="math"&gt;\(\mod 11\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
1^{-1} &amp;amp;= 1 &amp;amp; 1 \cdot \textcolor{red}{1} &amp;amp;= 1 &amp;amp;\equiv 1 \mod 11 \\
2^{-1} &amp;amp;= 6 &amp;amp; 2 \cdot \textcolor{red}{6} &amp;amp;= 12 &amp;amp;\equiv 1 \mod 11 \\
3^{-1} &amp;amp;= 4 &amp;amp; 3 \cdot \textcolor{red}{4} &amp;amp;= 12 &amp;amp;\equiv 1 \mod 11 \\
4^{-1} &amp;amp;= 3 &amp;amp; 4 \cdot \textcolor{red}{3} &amp;amp;= 12 &amp;amp;\equiv 1 \mod 11 \\
5^{-1} &amp;amp;= 9 &amp;amp; 5 \cdot \textcolor{red}{9} &amp;amp;= 45 &amp;amp;\equiv 1 \mod 11 \\
6^{-1} &amp;amp;= 2 &amp;amp; 6 \cdot \textcolor{red}{2} &amp;amp;= 12 &amp;amp;\equiv 1 \mod 11 \\
7^{-1} &amp;amp;= 8 &amp;amp; 7 \cdot \textcolor{red}{8} &amp;amp;= 56 &amp;amp;\equiv 1 \mod 11 \\
8^{-1} &amp;amp;= 7 &amp;amp; 8 \cdot \textcolor{red}{7} &amp;amp;= 56 &amp;amp;\equiv 1 \mod 11 \\
9^{-1} &amp;amp;= 5 &amp;amp; 9 \cdot \textcolor{red}{5} &amp;amp;= 45  &amp;amp;\equiv 1 \mod 11 \\
10^{-1} &amp;amp;= 10 &amp;amp; 10 \cdot \textcolor{red}{10} &amp;amp;= 100 &amp;amp;\equiv 1 \mod 11
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;Back to division. In normal arithmetic, we can use the property of the inverse to rewrite fractions in a slightly awkward way: &lt;span class="math"&gt;\(\frac{a}{b} = a \cdot \frac{1}{b} = a \cdot b^{-1}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;By this logic, â€œdivisionâ€ can be performed in modular arithmetic by multiplying &lt;span class="math"&gt;\(a \cdot b^{-1} \mod n\)&lt;/span&gt; and reducing the answer you get &lt;span class="math"&gt;\(\mod n\)&lt;/span&gt;. For example, &lt;span class="math"&gt;\(\frac{7}{6}\)&lt;/span&gt; would be obtained in &lt;span class="math"&gt;\(\mod 11\)&lt;/span&gt;Â by:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
7 \cdot 6^{-1} &amp;amp;= 7 \cdot 2 \\ &amp;amp;= 14 \\ &amp;amp;\equiv 3 \mod 11
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;Interestingly, for prime moduli, there is &lt;a href="https://stackoverflow.com/a/4798776/4210855"&gt;a very quick and easy way to do it natively in Python&lt;/a&gt;, which is much faster and simpler than the full algorithm for arbitraryÂ moduli:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;mod_inv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mod&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;pow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mod&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mod&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# Same as x ** mod-2 % mod&lt;/span&gt;

&lt;span class="n"&gt;mod_inv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# 2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I donâ€™t really understand the &lt;code class="highlight"&gt;-2&lt;/code&gt; part, but it seems that in &lt;span class="math"&gt;\(\mod 11\)&lt;/span&gt;, any number raised to the &lt;em&gt;ninth power&lt;/em&gt; will produce a number that is one more than a multiple ofÂ 11.&lt;/p&gt;
&lt;h1 id="polynomial-interpolation-modularly"&gt;Polynomial interpolation,Â modularly&lt;/h1&gt;
&lt;p&gt;Now, to apply this finding to polynomial interpolation. This was the original, non-modular, non-coolÂ version:&lt;/p&gt;
&lt;div class="math"&gt;$$ f(x) = \sum_{i=0}^n y_i \Bigg(\prod_{j \not= i} \frac{x - x_j}{x_i - x_j}\Bigg) $$&lt;/div&gt;
&lt;p&gt;To make it modular and cool, we doÂ this:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
f(x) &amp;amp;= \sum_{i=0}^n y_i \Bigg(\prod_{j \not= i} \textcolor{teal}{\frac{1}{x_i - x_j}}x + \textcolor{orange}{\frac{-x_j}{x_i - x_j}}\Bigg) \\
&amp;amp;= \sum_{i=0}^n y_i \Bigg(\prod_{j \not= i} \textcolor{lightgray}{1 \cdot }\textcolor{teal}{(x_i - x_j)^{-1}} \cdot x + \textcolor{orange}{-x_j \cdot (x_i - x_j)^{-1}} \Bigg) \mod n
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;Keeping in mind that the equivlent of modular &lt;code class="highlight"&gt;a / b&lt;/code&gt; in Python is &lt;code class="highlight"&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;mod_inv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mod&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;mod&lt;/span&gt;&lt;/code&gt;, this is surprisingly easy to implement in the authorâ€™s &lt;code class="highlight"&gt;single_term&lt;/code&gt; function (original code is &lt;a href="https://github.com/pim-book/programmers-introduction-to-mathematics/blob/master/secret-sharing/interpolate.py"&gt;here&lt;/a&gt;). Letâ€™s assume a global variable &lt;code class="highlight"&gt;MOD&lt;/code&gt; that weâ€™ll createÂ later.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_1_0" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_0"&gt;Broke&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;theTerm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;theTerm&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;xj&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xi&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;xj&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                                &lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xi&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;xj&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_1" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_1"&gt;Woke&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;theTerm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;theTerm&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;xj&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;mod_inv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xi&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;xj&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;MOD&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;MOD&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                &lt;span class="n"&gt;mod_inv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xi&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;xj&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;MOD&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;MOD&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The coefficients of the polynomial generated by the &lt;code class="highlight"&gt;interpolate&lt;/code&gt; function must also be reduced. Code-wise, thatâ€™s prettyÂ easy:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_2_0" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_0"&gt;Broke&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;terms&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ZERO&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_2_1" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_1"&gt;Woke&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;terms&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ZERO&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;MOD&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Except for one thingâ€”the original class made no provision for the &lt;code class="highlight"&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;/code&gt; operator. So we have to add that to the class (original code is &lt;a href="https://github.com/pim-book/programmers-introduction-to-mathematics/blob/master/secret-sharing/polynomial.py"&gt;here&lt;/a&gt;):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__mod__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coefficients&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coefficients&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, the value returned by &lt;code class="highlight"&gt;evaluateAt&lt;/code&gt; must also be reduced &lt;span class="math"&gt;\(\mod n\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_3_0" name="__tabs_3" type="radio"/&gt;
&lt;label for="__tab_3_0"&gt;Broke&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;theSum&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_3_1" name="__tabs_3" type="radio"/&gt;
&lt;label for="__tab_3_1"&gt;Woke&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;theSum&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;MOD&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;For some reason, the &lt;code class="highlight"&gt;ZERO&lt;/code&gt; polynomial has to be changedÂ slightly:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_4_0" name="__tabs_4" type="radio"/&gt;
&lt;label for="__tab_4_0"&gt;Broke&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ZERO&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;([])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_4_1" name="__tabs_4" type="radio"/&gt;
&lt;label for="__tab_4_1"&gt;Woke&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ZERO&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id="making-floating-points-sink"&gt;Making floating pointsÂ sink&lt;/h1&gt;
&lt;p&gt;Modular arithmetic only deals with integers, or &lt;code class="highlight"&gt;int&lt;/code&gt;, so care must be taken to avoid any accidental coercion to &lt;code class="highlight"&gt;float&lt;/code&gt;s in the course of the code. Otherwise, that defeats the purpose of going through all this trouble to avoid floating-point roundingÂ errors.&lt;/p&gt;
&lt;p&gt;The initial value of each single term in the &lt;code class="highlight"&gt;single_term&lt;/code&gt; function is a &lt;code class="highlight"&gt;float&lt;/code&gt;, so letâ€™s changeÂ that:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_5_0" name="__tabs_5" type="radio"/&gt;
&lt;label for="__tab_5_0"&gt;Broke&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;theTerm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_5_1" name="__tabs_5" type="radio"/&gt;
&lt;label for="__tab_5_1"&gt;Woke&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;theTerm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Summing a list of &lt;code class="highlight"&gt;Polynomial&lt;/code&gt;s (or even just adding two together) produced floating-point values even when the original coefficients were integers. It turns out that the author explicitly coerced the value in the function &lt;code class="highlight"&gt;add&lt;/code&gt; of the &lt;code class="highlight"&gt;Polynomial&lt;/code&gt; class (which was loaded into the operator via &lt;code class="highlight"&gt;__add__&lt;/code&gt;). Another easyÂ fix:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_6_0" name="__tabs_6" type="radio"/&gt;
&lt;label for="__tab_6_0"&gt;Broke&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;zip_longest&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fillvalue&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_6_1" name="__tabs_6" type="radio"/&gt;
&lt;label for="__tab_6_1"&gt;Woke&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;zip_longest&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fillvalue&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id="modulus-prime"&gt;ModulusÂ Prime&lt;/h1&gt;
&lt;p&gt;Man, the word &lt;em&gt;modulus&lt;/em&gt; is such a cool word. Anyway, we need to createÂ one.&lt;/p&gt;
&lt;p&gt;The prompt in the book specifies the use of a 32-bit number. It just so happens that Python has a handy random number generator, &lt;code class="highlight"&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getrandbits&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/code&gt;, that takes &lt;code class="highlight"&gt;x&lt;/code&gt; bits as anÂ argument.&lt;/p&gt;
&lt;p&gt;Since our simplified algorithm for modular exponentiation assumes that the modulus is prime, we also have to find some way to check for primality. &lt;code class="highlight"&gt;sympy&lt;/code&gt; has one such function; no need to reinvent the wheel. (While I am finding number theory very fascinating, I also donâ€™t have 5 years to spend on one chapter of thisÂ book!)&lt;/p&gt;
&lt;p&gt;So, with that information, it should be pretty easy to come up with a random 32-bit primeÂ modulus:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;random&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sympy.ntheory.primetest&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;isprime&lt;/span&gt;

&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;big_prime&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getrandbits&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# a random 32-bit number&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;isprime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;break&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;

&lt;span class="n"&gt;MOD&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;big_prime&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This instantly gives us gigantic numbers like &lt;code class="highlight"&gt;3898342621&lt;/code&gt; that automatically satisfy two conditions: (1) Occupy 32 bits and (2) Be prime.Â Perfect!&lt;/p&gt;
&lt;h1 id="the-proof-is-in-the-polynomials"&gt;The proof is in theÂ polynomials&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;MOD&lt;/span&gt; &lt;span class="c1"&gt;# 2606193617&lt;/span&gt;
&lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;interpolate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# 347492486 + 2084954895 x^1 + 173746241 x^2&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xi&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;yi&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;# [5, 6, 7]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It works! Our interpolated polynomialÂ is&lt;/p&gt;
&lt;div class="math"&gt;$$ f(x) = 173746241 x^2 + 2084954895 x + 347492486 \mod 2606193617 $$&lt;/div&gt;
&lt;p&gt;and despite the enormous coefficients, it does actually pass through the points IÂ specified.&lt;/p&gt;
&lt;p&gt;It should be noted that this code &lt;em&gt;does not&lt;/em&gt; work for negative numbers, as someone commented in response to the quick-and-dirty modular exponentation function I found on Stack Exchange. You can make modular arithmetic work with negative numbers, but it takes a little moreÂ fiddling.&lt;/p&gt;
&lt;p&gt;You could also just take the lazy route and not use negative &lt;span class="math"&gt;\(y\)&lt;/span&gt; values when implementing this forÂ secret-sharing.&lt;/p&gt;
&lt;p&gt;Just out of curiosity, what does this modular polynomial look like, compared to the non-modularÂ one?&lt;/p&gt;
&lt;p&gt;&lt;img alt="polynomial interpolation" src="../../images/polynomial_interp.png"/&gt;&lt;/p&gt;
&lt;p&gt;The modular polynomial has an interesting shape! Note that the scale on the vertical axis is &lt;code class="highlight"&gt;1e9&lt;/code&gt;, or &lt;em&gt;one billion&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;I find it so bizarre and fascinating that the floating-point coefficients are off by such a small amount, yet result in an inaccuracy that would make the result completely useless for cryptography, while the modular coefficients are so gigantic (along with the fluctuations in the graph) yet do create a polynomial that passes through the givenÂ points.&lt;/p&gt;
&lt;p&gt;To illustrate just how small the floating-point errors are, here is a comparison between the floating-point and decimal version of the hand-interpolatedÂ polynomial:&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{gathered}
-0.1\overline{3} x^2 + 1.4 x + 3.7\overline{3}  \\
-0.13333333333333358 x^2 + 1.3999999999999995 x + 3.733333333333336
\end{gathered}$$&lt;/div&gt;
&lt;p&gt;Thatâ€™s enough for this post. Iâ€™ll get on implementing this into an actual toy-cryptography web appÂ soon!&lt;/p&gt;
&lt;h1 id="references"&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://math.stackexchange.com/questions/2922433/how-to-compute-prod-i-1ny-i-left-prod-genfrac01j-not-ij-1"&gt;How to compute &lt;span class="math"&gt;\(\prod_{i=1}^n y'{_i}^{\big(\prod_{j \not=i, j=1}^n \frac{x_j}{x_j-x_i}\big)}\)&lt;/span&gt; with modular arithmetic for Lagrange&lt;/a&gt;, Stack ExchangeÂ Mathematics&lt;/li&gt;
&lt;li&gt;&lt;a href="https://stackoverflow.com/a/4798776/4210855"&gt;Modular multiplicative inverse function in Python&lt;/a&gt;, StackÂ Overflow&lt;/li&gt;
&lt;/ul&gt;</content><category term="modular arithmetic"></category></entry><entry><title>Polynomial long division &amp; GCD</title><link href="http://tabidots.github.io/2019/01/polynomial-long-division" rel="alternate"></link><published>2019-01-28T20:28:55+07:00</published><updated>2019-01-28T20:28:55+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-01-28:/2019/01/polynomial-long-division</id><summary type="html">&lt;p&gt;Exercise 2.11 in A Programmerâ€™s Introduction to&amp;nbsp;Mathematics.&lt;/p&gt;</summary><content type="html">
&lt;p&gt;This is my go at Exercise 2.11 in &lt;em&gt;A Programmerâ€™s Introduction to Mathematics&lt;/em&gt;. The task was to write an implementation of the extended Euclidean algorithm to find the greatest common divisor of twoÂ polynomials.&lt;/p&gt;
&lt;p&gt;This took me way longer than it maybe should have. Implementing polynomial long division with reference to the â€œlong divisionâ€ notation was not very straightforward, and required constant checking of the intermediate output, especially because I wanted to use &lt;code class="highlight"&gt;while&lt;/code&gt; loops instead of keeping track of theÂ iterations.&lt;/p&gt;
&lt;p&gt;I hope this is somewhere in the ballpark of an elegant solutionÂ ğŸ˜…&lt;/p&gt;
&lt;h1 id="polynomial-long-division"&gt;Polynomial longÂ division&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;typing&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;poly_longdiv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dividend&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;divisor&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="sd"&gt;'''This function assumes the arguments are the author's implementation of&lt;/span&gt;
&lt;span class="sd"&gt;    Polynomials in `Programmer's Intro to Mathematics`, which orders the terms&lt;/span&gt;
&lt;span class="sd"&gt;    ascending by degree.&lt;/span&gt;
&lt;span class="sd"&gt;    '''&lt;/span&gt;
    &lt;span class="n"&gt;dividend&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reversed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dividend&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coefficients&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;divisor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reversed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;divisor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coefficients&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;remainder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dividend&lt;/span&gt;
    &lt;span class="n"&gt;quotient&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;quo&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;remainder&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;divisor&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;quotient&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;quo&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;bottom&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;quo&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;term&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;term&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;divisor&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;remainder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;bot&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;top&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bot&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;remainder&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bottom&lt;/span&gt;&lt;span class="p"&gt;)][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;remainder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dividend&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;quotient&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;divisor&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="k"&gt;except&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ne"&gt;IndexError&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"quotient"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reversed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;quotient&lt;/span&gt;&lt;span class="p"&gt;))),&lt;/span&gt;
                    &lt;span class="s2"&gt;"remainder"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reversed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;remainder&lt;/span&gt;&lt;span class="p"&gt;)))}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;See &lt;a href="https://github.com/pim-book/programmers-introduction-to-mathematics/blob/master/secret-sharing/polynomial.py"&gt;here&lt;/a&gt; for the authorâ€™s implementation of the &lt;code class="highlight"&gt;Polynomial&lt;/code&gt; class.&lt;/p&gt;
&lt;h1 id="polynomial-greatest-common-divisor"&gt;Polynomial greatest commonÂ divisor&lt;/h1&gt;
&lt;p&gt;Meanwhile, this was pretty straightforward once I found &lt;a href="http://www.math.ucla.edu/~radko/circles/lib/data/Handout-358-436.pdf"&gt;this super-concise explanation&lt;/a&gt;. The Wikipedia article wasÂ incomprehensible.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;poly_gcd&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="sd"&gt;'''Find the GCD of two polynomials using the Extended Euclidean algorithm.&lt;/span&gt;
&lt;span class="sd"&gt;    '''&lt;/span&gt;
    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;small&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;big&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;division&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;big&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;small&lt;/span&gt;
    &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;division&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"quotient"&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;division&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"remainder"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;big&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;small&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;small&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;
        &lt;span class="n"&gt;division&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;big&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;small&lt;/span&gt;
        &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;division&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"quotient"&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;division&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"remainder"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;small&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Update: And just for completeness, regular &lt;span class="caps"&gt;GCD&lt;/span&gt; with integers (copied from &lt;a href="https://www.geeksforgeeks.org/gcd-in-python/"&gt;Geeks for Geeks&lt;/a&gt;):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;gcd&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="sd"&gt;'''Find the GCD of two integers using the Extended Euclidean algorithm.&lt;/span&gt;
&lt;span class="sd"&gt;    '''&lt;/span&gt;
    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;small&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;big&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;small&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;big&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;small&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;small&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;big&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;small&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;big&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Rewriting myÂ answer:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;poly_gcd&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="sd"&gt;'''Find the GCD of two polynomials using the Extended Euclidean algorithm.&lt;/span&gt;
&lt;span class="sd"&gt;    '''&lt;/span&gt;
    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;small&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;big&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;small&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;big&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;small&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;small&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;big&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;small&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="s2"&gt;"remainder"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;big&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="polynomials"></category></entry><entry><title>Real control points have curves (or something likeÂ that)</title><link href="http://tabidots.github.io/2019/01/real-control-points-have-curves" rel="alternate"></link><published>2019-01-27T11:42:28+07:00</published><updated>2019-01-27T11:42:28+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-01-27:/2019/01/real-control-points-have-curves</id><summary type="html">&lt;p&gt;In which I generate BÃ©zier curves and learn how to use matplotlib the hard&amp;nbsp;way.&lt;/p&gt;</summary><content type="html">
&lt;p&gt;This is my go at Exercise 2.8 in &lt;em&gt;A Programmerâ€™s Introduction to Mathematics&lt;/em&gt;. The task is to write a program that computes and animates a BÃ©zierÂ curve.&lt;/p&gt;
&lt;p&gt;The code is quite long, and I wrote more sophisticated versions as I went along, so I will include them all here in a tabbed block, and continue with the textÂ below.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_1_0" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_0"&gt;Setup&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;matplotlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;animation&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rc&lt;/span&gt;
&lt;span class="n"&gt;rc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'animation'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'html5'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_1" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_1"&gt;4. Final code&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;bezier_curve_plots&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;static_t&lt;/span&gt;&lt;span class="o"&gt;=.&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# input validation&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Need at least 2 points to generate a BÃ©zier curve.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# a vector of 200 evenly spaced values from 0 to 1&lt;/span&gt;
    &lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;# facilitate vector multiplication&lt;/span&gt;
    &lt;span class="n"&gt;static_points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;6.75&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;ncols&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nrows&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ctrl_ys&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;the_axes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="n"&gt;original_lines&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'o-'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'o-'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'o-'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'C7o'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;initial_ctrl&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'ko'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'ko'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'ko'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'ko'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;end_ctrl&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'ko'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'ko'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'ko'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'ko'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;t_text1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'$t = {static_t}$'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;transform&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transAxes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;t_text2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;''&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;transform&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transAxes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;t_text3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;''&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;transform&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transAxes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;style&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xytext&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;textcoords&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'offset pixels'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'left'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;#############&lt;/span&gt;
    &lt;span class="c1"&gt;# SUBPLOT 3 (mostly)&lt;/span&gt;
    &lt;span class="c1"&gt;#############&lt;/span&gt;
    &lt;span class="c1"&gt;# Create a plotting space for each iteration of de Casteljau&lt;/span&gt;
    &lt;span class="n"&gt;plotting_spaces&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;([],&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="s1"&gt;'o-'&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="c1"&gt;# Initial annotations for Subplots 3 and 4&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;annotate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'$P_{{{i}}}$'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;original_lines&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_color&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;style&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;annotate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'$P_{{{i}}}$'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;original_lines&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_color&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;style&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;annotate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'$P_{{{i}}}$'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;original_lines&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_color&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;style&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;annotate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'$P_{{{i}}}$'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;original_lines&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_color&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;style&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;annotations&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;point_sets&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;find_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
        &lt;span class="n"&gt;point_sets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;annotations&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;annotate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;''&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;style&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;
        &lt;span class="n"&gt;static_points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;find_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;static_points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;static_points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;static_t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                         &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;static_points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
        &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;static_points&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="s1"&gt;'o-'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;#############&lt;/span&gt;
    &lt;span class="c1"&gt;# SUBPLOT 4 #&lt;/span&gt;
    &lt;span class="c1"&gt;#############&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="c1"&gt;# Create a plot for line and final split point&lt;/span&gt;
    &lt;span class="n"&gt;curve&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;final_point&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;([],&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="s1"&gt;'C6-'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                          &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;([],&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="s1"&gt;'C6o'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lw&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;init&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="n"&gt;t_text2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;''&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;([],&lt;/span&gt; &lt;span class="p"&gt;[])&lt;/span&gt;

        &lt;span class="n"&gt;t_text3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;''&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;curve&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;([],&lt;/span&gt; &lt;span class="p"&gt;[])&lt;/span&gt;
        &lt;span class="n"&gt;final_point&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;([],&lt;/span&gt; &lt;span class="p"&gt;[])&lt;/span&gt;

        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;plotting_spaces&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;  &lt;span class="c1"&gt;# value of `num` is advanced by the animation function&lt;/span&gt;
        &lt;span class="n"&gt;t_text2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'$t = {round(num / len(t), 2)}$'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;t_text3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'$t = {round(num / len(t), 2)}$'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="c1"&gt;# SUBPLOT 3&lt;/span&gt;
            &lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;point_sets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt;
                                        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;point_sets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
            &lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;the_axes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;annotations&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
                &lt;span class="n"&gt;annotations&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'$P_{{{j}}}^{{{i + 1}}}$'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;annotations&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_color&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_color&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
                &lt;span class="n"&gt;annotations&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;point_sets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                                        &lt;span class="n"&gt;point_sets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;   &lt;span class="c1"&gt;# Make the final point bigger&lt;/span&gt;
                &lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_markersize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="c1"&gt;# SUBPLOT 4&lt;/span&gt;
        &lt;span class="n"&gt;curve&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="n"&gt;curve&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;the_axes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;final_point&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;plotting_spaces&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;animation&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;FuncAnimation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;fargs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[],&lt;/span&gt;
                                   &lt;span class="n"&gt;init_func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;init&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;interval&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;blit&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;random_points&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
   &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hstack&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_2" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_2"&gt;1. Brute force&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;make_bezier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

    &lt;span class="n"&gt;P&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# a vector of 100 evenly spaced values from 0 to 1&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Need at least 2 points"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; \
              &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; \
              &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Cubic curve. Come back later"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"too many points"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Reference to https://stackoverflow.com/questions/28074461/animating-growing-line-plot-in-python-matplotlib&lt;/span&gt;
    &lt;span class="c1"&gt;# Set up the graph&lt;/span&gt;
    &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'k'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Plot the static points&lt;/span&gt;
    &lt;span class="n"&gt;pts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pts&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;pts&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'ro'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# This function runs repeatedly for len(t) times as specified below&lt;/span&gt;
    &lt;span class="c1"&gt;# x and y are a list of values, computed once for each value in t&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pts&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pts&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pts&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pts&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;animation&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;FuncAnimation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;fargs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;interval&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;blit&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;linear_anim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;make_bezier&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;span class="n"&gt;quadratic_anim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;make_bezier&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],[&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;],[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;span class="c1"&gt;# linear_anim.save('./content/images/bezier/linear_bezier.gif', writer='imagemagick', fps=24)&lt;/span&gt;
&lt;span class="c1"&gt;# quadratic_anim.save('./content/images/bezier/quadratic_bezier.gif', writer='imagemagick', fps=24)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_3" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_3"&gt;2. Animate splits&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;find_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;this_point&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;next_point&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;this_point&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;next_point&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;animate_splits&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# input validation&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Need at least 2 points to generate a BÃ©zier curve.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# a vector of 200 evenly spaced values from 0 to 1&lt;/span&gt;
    &lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;# facilitate vector multiplication&lt;/span&gt;

    &lt;span class="c1"&gt;# Set up the graph, layout, and static elements&lt;/span&gt;
    &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ctrl_ys&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;the_axes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'o-'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                              &lt;span class="c1"&gt;# Lines between all control points&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'ko'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;     &lt;span class="c1"&gt;# Initial control point&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'ko'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c1"&gt;# End control point&lt;/span&gt;

    &lt;span class="c1"&gt;# Need to create a plotting space for each iteration of de Casteljau&lt;/span&gt;
    &lt;span class="n"&gt;plotting_spaces&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;([],&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="s1"&gt;'o-'&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;init&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;([],&lt;/span&gt; &lt;span class="p"&gt;[])&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;plotting_spaces&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;  &lt;span class="c1"&gt;# value of `num` is advanced by the animation function&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

            &lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;find_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
            &lt;span class="c1"&gt;# `points` consists of all split points in the current iteration&lt;/span&gt;
            &lt;span class="c1"&gt;# each point consists of an x list and a y list, each with t number of coordinates&lt;/span&gt;

            &lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;  &lt;span class="c1"&gt;# list of xs&lt;/span&gt;
                                        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;  &lt;span class="c1"&gt;# list of ys&lt;/span&gt;
            &lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;the_axes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;   &lt;span class="c1"&gt;# Make the final point bigger&lt;/span&gt;
                &lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_markersize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;plotting_spaces&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;animation&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;FuncAnimation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;fargs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                                   &lt;span class="n"&gt;init_func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;init&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;interval&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;blit&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;fivepts_anim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;animate_splits&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                                 
&lt;span class="c1"&gt;# fivepts_anim.save('./content/images/bezier/fivept_bezier.mp4', extra_args=['-vcodec', 'libx264'], fps=60)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_4" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_4"&gt;3. Trace curve&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;trace_curve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# input validation&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Need at least 2 points to generate a BÃ©zier curve.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# a vector of 200 evenly spaced values from 0 to 1&lt;/span&gt;
    &lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;# facilitate vector multiplication&lt;/span&gt;

    &lt;span class="c1"&gt;# Set up the graph, layout, and static elements&lt;/span&gt;
    &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ctrl_ys&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;the_axes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'C7o'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                             &lt;span class="c1"&gt;# Intermediate control points&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'ko'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;     &lt;span class="c1"&gt;# Initial control point&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'ko'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c1"&gt;# End control point&lt;/span&gt;

    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;find_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="c1"&gt;# Create a plot for line and final split point&lt;/span&gt;
    &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;final_point&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;([],&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="s1"&gt;'C6-'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                         &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;([],&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="s1"&gt;'C6o'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lw&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;t_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;''&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;transform&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transAxes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;init&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;([],&lt;/span&gt; &lt;span class="p"&gt;[])&lt;/span&gt;
        &lt;span class="n"&gt;final_point&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;([],&lt;/span&gt; &lt;span class="p"&gt;[])&lt;/span&gt;
        &lt;span class="n"&gt;t_text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;''&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;final_point&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t_text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;the_axes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;final_point&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="n"&gt;t_text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'$t = {round(num / len(t), 2)}$'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;final_point&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t_text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;animation&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;FuncAnimation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;init_func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;init&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;interval&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;blit&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;bezier_curve&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;trace_curve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;      
&lt;span class="c1"&gt;# bezier_curve.save('./content/images/bezier/bezier_curve_trace.mp4', extra_args=['-vcodec', 'libx264'], fps=60)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id="sample-results"&gt;SampleÂ results&lt;/h1&gt;
&lt;p&gt;Input:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;multi_plots&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;bezier_curve_plots&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Output:&lt;/p&gt;
&lt;p&gt;&lt;span class="videobox"&gt;
&lt;video controls="" height="350" poster="http://www.judosaltgenius.com/images/bezier/bezier_curve_plots_preview.png" preload="none" width="680"&gt;&lt;source src="/../images/bezier/bezier_curve_plots.mp4" type='video/mp4; codecs="avc1.42E01E, mp4a.40.2"'/&gt;&lt;/video&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;I was already well-acquainted with &lt;em&gt;manipulating&lt;/em&gt; BÃ©zier curves from working with the Pen tool in Photoshop andÂ Illustrator.&lt;/p&gt;
&lt;p&gt;&lt;img alt="bezier curve with handles" src="../../images/bezier/bezier.gif" title="Bezier curve with handles, source: http://guity-novin.blogspot.com/2013/04/chapter-66-bezier-curves-for-digital.html"/&gt;&lt;/p&gt;
&lt;p&gt;In graphics programs, you can create BÃ©zier curves of arbitrary complexity by defining a start point, end point, and any number of &lt;em&gt;control points&lt;/em&gt; in between. The curve passes through all the control points and the shape of the curve can be further manipulated using â€œhandlesâ€ on the controlÂ points.&lt;/p&gt;
&lt;p&gt;However, this is a top-down, end-user way of looking at control points that abstracts away the process of mathematically generating the curve. At first glance, my searches for understandable explanations of the math turned upÂ short.&lt;/p&gt;
&lt;p&gt;So, since the problem also said to look up the definition of quadratic and cubic BÃ©zier curves, I started out by brute-forcing it. That still took a lot of time because &lt;code class="highlight"&gt;matplotlib&lt;/code&gt; is quite complicated and getting animations working for the first time was not soÂ straightforward.&lt;/p&gt;
&lt;h1 id="brute-force"&gt;BruteÂ force&lt;/h1&gt;
&lt;p&gt;A cursory read through the Wikipedia definition turned up a lot of rather opaque equations. Finally I managed to find some basic definitions &lt;a href="http://luthuli.cs.uiuc.edu/~daf/courses/cs-419/Week-12/Interpolation-2013.pdf"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Bold &lt;span class="math"&gt;\(\textbf B\)&lt;/span&gt; and &lt;span class="math"&gt;\(\textbf P_n\)&lt;/span&gt; are 2D coordinates that are treated as vectors in these equations. These functions run over the range &lt;span class="math"&gt;\(0 \leq t \leq 1\)&lt;/span&gt; and output a set of points &lt;span class="math"&gt;\(\textbf B\)&lt;/span&gt; that generate a BÃ©zier curve that fits the givenÂ constraints.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\textbf B_{\textrm{linear}}(t) &amp;amp;= (1 - t)\textbf P_0 + t \textbf P_1 \\
\textbf B_{\textrm{quadratic}}(t) &amp;amp;= (1 - t)^2 \textbf P_0 + 2t (1 - t) \textbf P_1 + t^2 \textbf P_2 \\
\textbf B_{\textrm{cubic}}(t) &amp;amp;= (1 - t)^3\textbf P_0 + 3(1 -t)^2 t \textbf P_1 + 3(1 - t)t^2 \textbf P_2 + t^3 \textbf P_3
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;That got me thisÂ far:&lt;/p&gt;
&lt;p&gt;&lt;img alt="linear bezier" src="../../images/bezier/linear_bezier.gif" title="Linear bezier curve animation"/&gt;
&lt;img alt="quadratic bezier" src="../../images/bezier/quadratic_bezier.gif" title="Quadratic bezier curve animation"/&gt;&lt;/p&gt;
&lt;p&gt;Iâ€™m basically a &lt;code class="highlight"&gt;matplotlib&lt;/code&gt; Picasso!Â ğŸ˜…&lt;/p&gt;
&lt;p&gt;However, I canâ€™t exactly say I fully understood what I wasÂ doing.&lt;/p&gt;
&lt;p&gt;I could see some pattern to the equationsâ€”some Pascalâ€™s triangle action happening with the coefficients of those polynomialsâ€”but I couldnâ€™t really understand how to generate the polynomialsÂ themselves.&lt;/p&gt;
&lt;p&gt;I also noticed that the quadratic curve didnâ€™t actually pass through the second point I had specified, which means that the mathetmatical control points of BÃ©zier curves are a little different than the â€œend-userâ€ control points Iâ€™m used to working with inÂ Illustrator.&lt;/p&gt;
&lt;p&gt;When I tried to dig deeper, I found some crazy stuff with what looked like Einstein notation (&lt;span class="math"&gt;\(\textbf P^2_0\)&lt;/span&gt;), which really threw me for a loop. What does this have to do withÂ matrices?&lt;/p&gt;
&lt;p&gt;&lt;img alt="de Casteljau splitting lines" src="../../images/bezier/de_casteljau.png"/&gt;&lt;/p&gt;
&lt;h1 id="dividing-lines"&gt;DividingÂ lines&lt;/h1&gt;
&lt;p&gt;It took me a while to figure out what the notationÂ meant.&lt;/p&gt;
&lt;p&gt;Maybe I should have just searched on YouTubeÂ first:&lt;/p&gt;
&lt;p&gt;&lt;span class="videobox"&gt;
&lt;iframe allowfullscreen="" frameborder="0" height="480" mozallowfullscreen="" src="https://www.youtube.com/embed/7-Q9Ue_qKTE" webkitallowfullscreen="" width="640"&gt;
&lt;/iframe&gt;
&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;(I ended up finding &lt;a href="https://www.jasondavies.com/animated-bezier/"&gt;this amazing JavaScript [D3] visualization&lt;/a&gt;Â later.)&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(t\)&lt;/span&gt; runs over the range &lt;span class="math"&gt;\([0,1]\)&lt;/span&gt;, right? So that means any intermediate value of &lt;span class="math"&gt;\(t\)&lt;/span&gt; is aÂ fraction.&lt;/p&gt;
&lt;p&gt;However, since weâ€™re looking at &lt;span class="math"&gt;\(t\)&lt;/span&gt; &lt;em&gt;and&lt;/em&gt; &lt;span class="math"&gt;\(1 - t\)&lt;/span&gt;, we can look at &lt;span class="math"&gt;\(t\)&lt;/span&gt; as a split point. For example, when &lt;span class="math"&gt;\(t = 0.7\)&lt;/span&gt;, then &lt;span class="math"&gt;\(1 - t = 0.3\)&lt;/span&gt;, producing a 70/30Â split.&lt;/p&gt;
&lt;p&gt;Using the illustration above as reference, the points &lt;span class="math"&gt;\(b\)&lt;/span&gt; with &lt;em&gt;only&lt;/em&gt; subscripts (&lt;span class="math"&gt;\(b_0, b_1, b_2\)&lt;/span&gt;) are the original user-specified control points. Between these three control points, two connecting lines can beÂ drawn.&lt;/p&gt;
&lt;p&gt;Let &lt;span class="math"&gt;\(t\)&lt;/span&gt; be a split point to split each of those lines in two. Since &lt;span class="math"&gt;\(t\)&lt;/span&gt; varies between &lt;span class="math"&gt;\([0,1]\)&lt;/span&gt;, you can imagine the lines as â€œrollersâ€ that the points run across. When &lt;span class="math"&gt;\(t = 0\)&lt;/span&gt;, the split points are at the initial end of each line; when &lt;span class="math"&gt;\(t = 1\)&lt;/span&gt;, the split points are at the final end of eachÂ line.&lt;/p&gt;
&lt;p&gt;Now draw a line between the two split points, and split &lt;em&gt;that&lt;/em&gt; line at &lt;span class="math"&gt;\(t\)&lt;/span&gt;. That is the final split point, which traces the curve as &lt;span class="math"&gt;\(t\)&lt;/span&gt; runs over the range &lt;span class="math"&gt;\([0,1]\)&lt;/span&gt;.&lt;/p&gt;
&lt;h1 id="de-casteljaus-algorithm"&gt;de Casteljauâ€™sÂ algorithm&lt;/h1&gt;
&lt;p&gt;This can be done recursively to find the curve given any number of control points. You repeat the process until you end up with one line, and thus one splitÂ point.&lt;/p&gt;
&lt;p&gt;The Einstein-looking notation above thusÂ means:&lt;/p&gt;
&lt;div class="math"&gt;$$ \textbf P^{r \textrm{ th iteration}}_{i \textrm{ th point}} $$&lt;/div&gt;
&lt;p&gt;For the 0th iteration (control points), the superscript &lt;span class="math"&gt;\(0\)&lt;/span&gt; is usually omitted, itÂ seems.&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(n\)&lt;/span&gt; control points require &lt;span class="math"&gt;\(n - 1\)&lt;/span&gt; iterations to find the final split point, so the task is to find the point &lt;span class="math"&gt;\(\textbf P^{n - 1}_0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Letâ€™s try working this out from the simplest building block. The split point between any two pointsÂ is&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{bmatrix} x \\ y \end{bmatrix}_{\textrm{split}} =  
(1 - t)\begin{bmatrix} x \\ y \end{bmatrix}_{\textrm{beginning}} +
t \begin{bmatrix} x \\ y \end{bmatrix}_{\textrm{end}}
$$&lt;/div&gt;
&lt;p&gt;Weâ€™ll use NumPy &lt;code class="highlight"&gt;array&lt;/code&gt;s to represent vectors forÂ this.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;split_point&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;this_point&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;next_point&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now, we need to loop through the initial control points in the following way. &lt;span class="math"&gt;\(n\)&lt;/span&gt; number of points results in &lt;span class="math"&gt;\(n-1\)&lt;/span&gt; number of splitÂ points.&lt;/p&gt;
&lt;p&gt;Assume we input our points as a list of lists. Each iteration, then, should give us a list that is one smaller than the last iteration. And when the length of the list is 1, we know weâ€™ve found ourÂ point.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;find_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;this_point&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;next_point&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;this_point&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;next_point&lt;/span&gt;

&lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt; &lt;span class="c1"&gt;# random number&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="s1"&gt;'o-'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;find_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="s1"&gt;'o-'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# plt.savefig('./split_points2.png')&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img alt="BÃ©zier split points" src="../../images/bezier/split_points.png"/&gt;&lt;/p&gt;
&lt;p&gt;Doing this with an arbitrary of random points can be kindaÂ fun:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img alt="crazy BÃ©zier split points" src="../../images/bezier/split_points2.png"/&gt;&lt;/p&gt;
&lt;h1 id="some-intermediate-results"&gt;Some intermediateÂ results&lt;/h1&gt;
&lt;p&gt;Animating the intermediateÂ lines:&lt;/p&gt;
&lt;p&gt;&lt;span class="videobox"&gt;
&lt;video controls="" height="360" poster="http://www.judosaltgenius.com/images/bezier/fivept_bezier_preview.png" preload="none" width="480"&gt;&lt;source src="/../images/bezier/fivept_bezier.mp4" type='video/mp4; codecs="avc1.42E01E, mp4a.40.2"'/&gt;&lt;/video&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Tracing theÂ curve:&lt;/p&gt;
&lt;p&gt;&lt;span class="videobox"&gt;
&lt;video controls="" height="360" poster="http://www.judosaltgenius.com/images/bezier/bezier_curve_trace_preview.png" preload="none" width="480"&gt;&lt;source src="/../images/bezier/bezier_curve_trace.mp4" type='video/mp4; codecs="avc1.42E01E, mp4a.40.2"'/&gt;&lt;/video&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Crazy curve andÂ annotations:&lt;/p&gt;
&lt;p&gt;&lt;span class="videobox"&gt;
&lt;video controls="" height="350" poster="http://www.judosaltgenius.com/images/bezier/crazy_bezier_preview.png" preload="none" width="680"&gt;&lt;source src="/../images/bezier/crazy_bezier_curve_lines.mp4" type='video/mp4; codecs="avc1.42E01E, mp4a.40.2"'/&gt;&lt;/video&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h1 id="references"&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://louistiao.me/posts/notebooks/save-matplotlib-animations-as-gifs/"&gt;Save Matplotlib Animations as GIFs&lt;/a&gt;, LouisÂ Tiao&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jakevdp.github.io/blog/2012/08/18/matplotlib-animation-tutorial/"&gt;Matplotlib Animation Tutorial&lt;/a&gt;, JakeÂ VanderPlas&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jakevdp.github.io/PythonDataScienceHandbook/04.09-text-and-annotation.html"&gt;Text and Annotation&lt;/a&gt;, JakeÂ VanderPlas&lt;/li&gt;
&lt;li&gt;&lt;a href="http://luthuli.cs.uiuc.edu/~daf/courses/cs-419/Week-12/Interpolation-2013.pdf"&gt;Interpolating Curves&lt;/a&gt;, &lt;span class="caps"&gt;CS&lt;/span&gt; 419, &lt;span class="caps"&gt;UIUC&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cs.huji.ac.il/course/2005/cg/lectures/08-CurvesSurfaces.pdf"&gt;Curves and Surfaces&lt;/a&gt;, Computer Graphics, Benin School of ComputerÂ Science&lt;/li&gt;
&lt;/ul&gt;</content><category term="matplotlib"></category><category term="bÃ©zier curves"></category></entry><entry><title>PIM notes, Chapter 2:Â Exercises</title><link href="http://tabidots.github.io/2019/01/pim-notes-chapter-2-exercises" rel="alternate"></link><published>2019-01-25T16:55:04+07:00</published><updated>2019-01-25T16:55:04+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-01-25:/2019/01/pim-notes-chapter-2-exercises</id><summary type="html">&lt;p&gt;Exercises from Chapter 2 of &lt;span class="caps"&gt;PIM&lt;/span&gt;, minus the coding&amp;nbsp;projects.&lt;/p&gt;</summary><content type="html">
&lt;p&gt;These exercises exclude the coding projects, which I will write about later and post onÂ GitHub.&lt;/p&gt;
&lt;p&gt;Answering these has been very tedious. The first few were easy, but they quickly ballooned in difficulty / time required and so they got put on the back burner for a bit. I hope this book becomes moreÂ enjoyable.&lt;/p&gt;
&lt;h1 id="21"&gt;2.1&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The highest-degree term in &lt;span class="math"&gt;\(f\)&lt;/span&gt; is &lt;span class="math"&gt;\(x^2\)&lt;/span&gt;; the highest-degree term in &lt;span class="math"&gt;\(g\)&lt;/span&gt; is &lt;span class="math"&gt;\(x\)&lt;/span&gt;. The highest possible power of &lt;span class="math"&gt;\(x\)&lt;/span&gt; that can occur in &lt;span class="math"&gt;\(f \cdot g\)&lt;/span&gt; is &lt;span class="math"&gt;\(x^2 \cdot x\)&lt;/span&gt;, or &lt;span class="math"&gt;\(x^3\)&lt;/span&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The highest-degree term in &lt;span class="math"&gt;\(f\)&lt;/span&gt; is &lt;span class="math"&gt;\(x^n\)&lt;/span&gt;; the highest-degree term in &lt;span class="math"&gt;\(g\)&lt;/span&gt; is &lt;span class="math"&gt;\(m\)&lt;/span&gt;. The highest possible power of &lt;span class="math"&gt;\(x\)&lt;/span&gt; that can occur in &lt;span class="math"&gt;\(f \cdot g\)&lt;/span&gt; is &lt;span class="math"&gt;\(x^n \cdot x^m = x^{n + m}\)&lt;/span&gt;, resulting in a polynomial of degree &lt;span class="math"&gt;\(n+m\)&lt;/span&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;This does not hold when &lt;span class="math"&gt;\(f\)&lt;/span&gt; or &lt;span class="math"&gt;\(g\)&lt;/span&gt; are the zero polynomial. The generalization could be changed to say that &lt;span class="math"&gt;\(f\)&lt;/span&gt; and &lt;span class="math"&gt;\(g\)&lt;/span&gt; are polynomials with degrees &lt;span class="math"&gt;\(n\)&lt;/span&gt; and &lt;span class="math"&gt;\(m\)&lt;/span&gt; where &lt;span class="math"&gt;\(n \geq 0\)&lt;/span&gt; and &lt;span class="math"&gt;\(m \geq 0\)&lt;/span&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="22"&gt;2.2&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If &lt;span class="math"&gt;\(n = 24\)&lt;/span&gt;, then the relative prime numbers of &lt;span class="math"&gt;\(n\)&lt;/span&gt; are &lt;span class="math"&gt;\(5, 7, 11, 13, 17, 19, 23\)&lt;/span&gt;, which means &lt;span class="math"&gt;\(\phi(n) = 8\)&lt;/span&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;One example of a monic polynomial is &lt;span class="math"&gt;\(f(x) = x^5 + 3x^4 + 12x^3 + x + 7\)&lt;/span&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If &lt;span class="math"&gt;\(f(x) = 6x^3 + 18x^2 - 3x\)&lt;/span&gt;, a &lt;span class="math"&gt;\(3x\)&lt;/span&gt; can be factored out of each term, leaving the factors &lt;span class="math"&gt;\(g(x) = 2x^3 + 6x^2 - 1\)&lt;/span&gt; and &lt;span class="math"&gt;\(h(x) = 3x\)&lt;/span&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span class="math"&gt;\(f(x) = 17x^3 - 2\)&lt;/span&gt; and &lt;span class="math"&gt;\(g(x) = 6x^2\)&lt;/span&gt; are relatively prime polynomials. &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; is also irreducible. For the functions &lt;span class="math"&gt;\(f(x) = 2x^2 + 4\)&lt;/span&gt; and &lt;span class="math"&gt;\(g(x) = 4x^2 + 8\)&lt;/span&gt;, their greatest common divisor, since it must be monic, is &lt;span class="math"&gt;\((j)x = x^2 + 4\)&lt;/span&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="23"&gt;2.3&lt;/h1&gt;
&lt;p&gt;According to Eulerâ€™s theorem, &lt;span class="math"&gt;\(a^{\varphi(n)}\over{n}\)&lt;/span&gt; has remainder &lt;span class="math"&gt;\(1\)&lt;/span&gt; (or &lt;span class="math"&gt;\(a^{\varphi(n)}\)&lt;/span&gt; &lt;code class="highlight"&gt;mod&lt;/code&gt; &lt;span class="math"&gt;\(n = 1\)&lt;/span&gt;). This meansÂ that
    &lt;/p&gt;
&lt;div class="math"&gt;$$\begin{aligned}
    a^{\varphi(n)} \bmod n &amp;amp;= 1 \\
    \frac{a^{\varphi(n)}}{n} &amp;amp;= c + \frac{1}{n} \\
    a^{\varphi(n)} &amp;amp;= cn + 1 \\
    \end{aligned}$$&lt;/div&gt;
&lt;p&gt;
&lt;span class="math"&gt;\(c\)&lt;/span&gt; must be a nonnegative integer, which means that &lt;span class="math"&gt;\(\frac{a^{\varphi(n)} - 1}{n}\)&lt;/span&gt; must be a nonnegative integer. Using the numbers from the previous example (&lt;span class="math"&gt;\(n = 24\)&lt;/span&gt;, &lt;span class="math"&gt;\(\varphi(n) = 8\)&lt;/span&gt;), we can let &lt;span class="math"&gt;\(a = 5\)&lt;/span&gt;.
    &lt;/p&gt;
&lt;div class="math"&gt;$$\begin{aligned}
    \frac{5^{8}}{24} &amp;amp;= c + \frac{1}{24} \\
    5^{8} &amp;amp;= 24c + 1 \\
    390625 - 1 &amp;amp;= 24c \\
    c &amp;amp;= 16276
    \end{aligned}$$&lt;/div&gt;
&lt;p&gt;
  Indeed, &lt;span class="math"&gt;\(\frac{390625 - 1}{24}\)&lt;/span&gt; is a nonnegativeÂ integer.&lt;/p&gt;
&lt;h1 id="24"&gt;2.4&lt;/h1&gt;
&lt;p&gt;Based on the definition, a number &lt;span class="math"&gt;\(z\)&lt;/span&gt; is algebraic if there is some polynomial function &lt;span class="math"&gt;\(f(x) = a_0 + a_1x + \cdots + a_nx^n\)&lt;/span&gt;, where all &lt;span class="math"&gt;\(a_i\)&lt;/span&gt; are rational, such that &lt;span class="math"&gt;\(f(z) = 0\)&lt;/span&gt;. &lt;span class="math"&gt;\(\sqrt 2\)&lt;/span&gt; is algebraic because it is the root of &lt;span class="math"&gt;\(x^2 - 2\)&lt;/span&gt;, which has the rational coefficients &lt;span class="math"&gt;\(a_0 = -2\)&lt;/span&gt;, &lt;span class="math"&gt;\(a_1 = 0\)&lt;/span&gt;, and &lt;span class="math"&gt;\(a_2 = 1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;You can find this by trying to get to &lt;span class="math"&gt;\(z\)&lt;/span&gt; from 0, then going backwards through that order of operations starting with &lt;span class="math"&gt;\(x\)&lt;/span&gt;. I find this easier to visualize by writing inÂ Clojure:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;sqrt&lt;/span&gt;         &lt;span class="c1"&gt;; x^2&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;    &lt;span class="c1"&gt;; - 2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;What about &lt;span class="math"&gt;\(\phi = \frac{1 + \sqrt 5}{2}\)&lt;/span&gt;?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;              &lt;span class="c1"&gt;; 2x&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;            &lt;span class="c1"&gt;; - 1&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;sqrt&lt;/span&gt;         &lt;span class="c1"&gt;; all of that ^2&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;  &lt;span class="c1"&gt;; - 5&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Thus,&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
f(x) &amp;amp;= (2x - 1)^2 - 5 \\
&amp;amp;= 2x^2 - 4x + 1 - 5 \\
&amp;amp;= 2x^2 - 4x - 4
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;So, we have a polynomial. Since we started from 0 and worked in reverse to come up with this polynomial, that should mean &lt;span class="math"&gt;\(\phi\)&lt;/span&gt; is algebraic. Letâ€™sÂ check:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
f(\phi) &amp;amp;= \Big(\cancel{2}(\frac{1 + \sqrt 5}{\cancel{2}}) - 1\Big)^2 - 5 \\
&amp;amp;= (\cancel{1} + \sqrt 5 - \cancel{1})^2 - 5 \\
&amp;amp;= (\sqrt 5)^2 - 5 \\
&amp;amp;= 0
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;And &lt;span class="math"&gt;\(\phi\)&lt;/span&gt; is its root, so yes, &lt;span class="math"&gt;\(\phi\)&lt;/span&gt; is an algebraic number. Now, how about &lt;span class="math"&gt;\(\sqrt 2 + \sqrt 3\)&lt;/span&gt;? At first I tried to work it out with Clojure and I got the wrong answer. But there is definitely a way to make &lt;span class="math"&gt;\(\sqrt 2 + \sqrt 3 = 0\)&lt;/span&gt;. I did it the old-fashioned way, filling up an entire sheet of paper withÂ algebra.&lt;/p&gt;
&lt;p&gt;You have to square the term to get rid of the square roots, but because &lt;span class="math"&gt;\((a + b)^2 = a^2 + 2ab + b^2\)&lt;/span&gt;, youâ€™ll also have to get rid of the &lt;span class="math"&gt;\(2\sqrt 2\sqrt 3\)&lt;/span&gt; that remains when you do &lt;span class="math"&gt;\((\sqrt 2 + \sqrt 3)^2\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
f(x) &amp;amp;= \Big(\frac{x^2 - 5}{2}\Big)^2 - 6 \\
&amp;amp;= \frac{1}{4}x^4 + \frac{5}{2}x^2 + \frac{25}{4} - 6 \\
&amp;amp;= \frac{1}{4}x^4 + \frac{5}{2}x^2 + \frac{1}{4}
\end{aligned} $$&lt;/div&gt;
&lt;h1 id="25"&gt;2.5&lt;/h1&gt;
&lt;h2 id="product-and-sum-of-algebraic-numbers"&gt;Product and sum of algebraicÂ numbers&lt;/h2&gt;
&lt;p&gt;A polynomial encompasses the operations of addition, multiplication, and exponentiation. To find the root of a polynomial is to perform the â€oppositeâ€ of theseÂ operations.&lt;/p&gt;
&lt;p&gt;Addition and multiplication are commutative, so their opposite is themselves; the opposite of exponentiation is to take aÂ root.&lt;/p&gt;
&lt;p&gt;It would seem from the above work that any number made from combinations of these â€œoppositeâ€ operations performed on rational numbers is the root of &lt;em&gt;some&lt;/em&gt; polynomial and is thereforeÂ algebraic.&lt;/p&gt;
&lt;p&gt;Therefore, for any two algebraic numbers, their sum and their product are both algebraic asÂ well.&lt;/p&gt;
&lt;h2 id="proof-regarding-pie-and-pi-e"&gt;Proof regarding &lt;span class="math"&gt;\(\pi+e\)&lt;/span&gt; and &lt;span class="math"&gt;\(\pi e\)&lt;/span&gt;Â &lt;/h2&gt;
&lt;p&gt;For this part, I was stuck, so I got some help from the authorÂ himself:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For the &lt;span class="math"&gt;\(\pi+e\)&lt;/span&gt; and &lt;span class="math"&gt;\(\pi e\)&lt;/span&gt; part, there are two steps: (1) prove that a number which is the root of a polynomial whose coefficients are algebraic is also algebraic, and (2) construct a polynomial whose roots are &lt;span class="math"&gt;\(\pi\)&lt;/span&gt; and &lt;span class="math"&gt;\(e\)&lt;/span&gt;, and whose coefficients can be expressed in terms of &lt;span class="math"&gt;\(\pi+e\)&lt;/span&gt; and &lt;span class="math"&gt;\(\pi e\)&lt;/span&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The author said the second part was easy. It is, but itâ€™s not obvious. Apparently you can create a polynomial from a series of roots by just &lt;a href="https://www.purplemath.com/modules/fromzero2.htm"&gt;subtracting them from &lt;span class="math"&gt;\(x\)&lt;/span&gt; and multiplying them together&lt;/a&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ (x-r_1)(x-r_2) $$&lt;/div&gt;
&lt;p&gt;Since we want a polynomial with roots &lt;span class="math"&gt;\(\pi\)&lt;/span&gt; and &lt;span class="math"&gt;\(e\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
f(x) &amp;amp;= (x-\pi)(x-e) \\
&amp;amp;= x^2 - ex - \pi x + \pi e \\
&amp;amp;= x^2 - (\textcolor{teal}{\pi + e})x + \textcolor{orange}{\pi e}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;Done!&lt;/p&gt;
&lt;p&gt;Now, back to the first part. In a more general form, the statement about the roots of a polynomial would lookÂ like&lt;/p&gt;
&lt;div class="math"&gt;$$ f(x) = \prod_{i=1}^n (x-r_i) $$&lt;/div&gt;
&lt;p&gt;for a polynomial with &lt;span class="math"&gt;\(n\)&lt;/span&gt;Â roots.&lt;/p&gt;
&lt;p&gt;That means all that can ever happen to any &lt;span class="math"&gt;\(r_i\)&lt;/span&gt; is the accumulation of multiplication or additionÂ operations.&lt;/p&gt;
&lt;p&gt;As discussed above, for any two algebraic numbers, their sum and their product are both algebraic as well. So for a set of &lt;span class="math"&gt;\(r_1, \cdots, r_n\)&lt;/span&gt; that are all algebraic, &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; will also beÂ algebraic.&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\pi\)&lt;/span&gt; and &lt;span class="math"&gt;\(e\)&lt;/span&gt; are known to &lt;em&gt;not&lt;/em&gt; be algebraic, so accumulating multiplication or addition with algebraic numbers will never &lt;em&gt;make&lt;/em&gt; them algebraic. Therefore the resulting coefficients will not beÂ algebraic.&lt;/p&gt;
&lt;p&gt;Letâ€™s try making &lt;span class="math"&gt;\(\pi + e\)&lt;/span&gt; a root of a polynomial that has an &lt;em&gt;algebraic&lt;/em&gt; root asÂ well.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
g(x) &amp;amp;= \Big(x - (\pi + e)\Big)(x + 2) \\
&amp;amp;= x^2 + 2x - (\pi + e)x - 2(\pi + e) \\
&amp;amp;= x^2 + (2 - \pi - e)x - 2\pi - e
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;Nope! How about &lt;span class="math"&gt;\(\pi e\)&lt;/span&gt;?&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
h(x) &amp;amp;= (x - \pi e)(x + 2) \\
&amp;amp;= x^2 + 2x - \pi e x - 2 \pi e \\
&amp;amp;= x^2 + (2 - \pi e)x - 2 \pi e
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;Here, we cannot know for sure. If &lt;span class="math"&gt;\(\pi e\)&lt;/span&gt; is algebraic, then &lt;span class="math"&gt;\(h(x)\)&lt;/span&gt; will also be algebraic. But we donâ€™t know. So it is true that &lt;span class="math"&gt;\(\pi\)&lt;/span&gt; and &lt;span class="math"&gt;\(e\)&lt;/span&gt; are not algebraic, but &lt;span class="math"&gt;\(\pi + e\)&lt;/span&gt; and &lt;span class="math"&gt;\(\pi e\)&lt;/span&gt; cannot &lt;em&gt;both&lt;/em&gt; beÂ algebraic.&lt;/p&gt;
&lt;h1 id="26"&gt;2.6&lt;/h1&gt;
&lt;p&gt;I donâ€™t know how to prove Vietaâ€™s formulas other than working through them. The product is easier than the sum and can be done without substituting actual numbers. Letâ€™s try a polynomial of degree 3 (&lt;span class="math"&gt;\(n=3\)&lt;/span&gt;):&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{gathered}
(x - r_3)(x - r_2)(x - r_1) \\
(x^2 - r_2x - r_3x + \textcolor{red}{r_2r_3})(x - r_1) \\
x^3 - r_2x^2 - r_3x^2 + r_2r_3x - (r_1x^2 + r_1r_2x + r_1r_3x - \textcolor{red}{r_1r_2r_3}) \\
x^3 \textcolor{teal}{- r_2x^2 - r_3x^2} + \textcolor{orange}{r_2r_3x} - \textcolor{teal}{r_1x^2} \textcolor{orange}{- r_1r_2x - r_1r_3x} + \textcolor{red}{r_1r_2r_3} \\
{\underbrace{\textcolor{lightgray}{1}}_{a_3}} x^3 + {\underbrace{(\textcolor{teal}{-r_1 - r_2- r_3}}_{a_2})} x^2 + {\underbrace{(\textcolor{orange}{-r_1r_2 - r_1r_3 + r_2r_3})}_{a_1}} x + \underbrace{\textcolor{red}{r_1r_2r_3}}_{a_0}
\end{gathered} $$&lt;/div&gt;
&lt;p&gt;According to Vietaâ€™s formula, the following should beÂ true:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\prod_{i=1}^n r_i &amp;amp;= (-1)^n \frac{a_0}{a_n} \\
r_1r_2r_3 &amp;amp;\overset{?}{=} (-1)^3 \frac{r_1r_2r_3}{1} \end{aligned} $$&lt;/div&gt;
&lt;p&gt;Indeed it is! And if you look at the term I went back and highlighted in red above, you can seeÂ why:&lt;/p&gt;
&lt;p&gt;As you keep multiplying binomials, the final coefficient (the one without a variable) is always going to be the cumulative product of the roots (the term in the binomials without a variable), with the sign switching for each binomial youÂ multiply.&lt;/p&gt;
&lt;p&gt;But what about the sum of theÂ roots?&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\sum_{i=1}^n r_i &amp;amp;= -\frac{a_{n-1}}{a_n} \\
r_1 + r_2 + r_3 &amp;amp;\overset{?}{=} -\frac{a_2}{a_3} \\
&amp;amp;\overset{?}{=} -\frac{-r_1 - r_2 - r_3}{1} \\
&amp;amp;= r_1 + r_2 + r_3
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;I canâ€™t explain why this is the case, but I can see that it doesÂ work.&lt;/p&gt;
&lt;p&gt;So Vietaâ€™s formulas are basically saying that for any degree &lt;span class="math"&gt;\(n\)&lt;/span&gt; polynomial &lt;span class="math"&gt;\(a_n \prod_{i=1}^n (x - r_i)\)&lt;/span&gt; with roots &lt;span class="math"&gt;\(r_1, ..., r_n\)&lt;/span&gt;, where &lt;span class="math"&gt;\(a_n\)&lt;/span&gt; acts to â€œscaleâ€ the polynomial,Â then&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class="math"&gt;\(a_0\)&lt;/span&gt; (the coefficient without a variable) is the de-scaled product of all the roots (flipping its sign for each iteration),Â and&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(a_{n-1}\)&lt;/span&gt;, the coefficient of the second highest term, is the flipped-sign de-scaled sum of all theÂ roots.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="29"&gt;2.9&lt;/h1&gt;
&lt;p&gt;Wilkinsonâ€™s polynomial has a very precise shape because it was created from multiplying very simple binomials. It is â€œinfinitelyâ€ steep near its roots (almost a straight line) and because the terms are of such a high order, altering the coefficients slightly turns what was a very â€œsimpleâ€ function (the product of simple binomials) into an extremely complicatedÂ one.&lt;/p&gt;
&lt;h1 id="212"&gt;2.12&lt;/h1&gt;
&lt;p&gt;As far as I found, fields of math involved in different proofs of the Fundamental Theorem of Algebra include: Complex analysis, real analysis, topology, and Riemannian differential geometry. Pretty scaryÂ stuff.&lt;/p&gt;</content></entry><entry><title>The squarest root in Babylon and automaticÂ differentiation</title><link href="http://tabidots.github.io/2019/01/squarest-root-in-babylon" rel="alternate"></link><published>2019-01-22T15:47:33+07:00</published><updated>2019-01-22T15:47:33+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-01-22:/2019/01/squarest-root-in-babylon</id><summary type="html">&lt;p&gt;If you thought 1 + Ïµ = 1 was weird, wait till you see what ÏµÂ² equates&amp;nbsp;to.&lt;/p&gt;</summary><content type="html">
&lt;p&gt;In my previous post on &lt;a href="/2019/01/from-zero-to-ero"&gt;&lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; (epsilon)&lt;/a&gt;, I wrote about thisÂ statement:&lt;/p&gt;
&lt;div class="math"&gt;$$ 1 + \epsilon = 1 $$&lt;/div&gt;
&lt;p&gt;which seemed like it came from a planet that had fallen out of orbit or something. Well, try this one on forÂ size:&lt;/p&gt;
&lt;div class="math"&gt;$$ \epsilon^2 = 0 $$&lt;/div&gt;
&lt;p&gt;Another math koan! &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; is still a stand-in for the same concept hereâ€”an infinitesimal valueâ€”but its function is a little different. This post will be about &lt;strong&gt;dual numbers&lt;/strong&gt; and what you can do withÂ them.&lt;/p&gt;
&lt;p&gt;But first, letâ€™s start with another devilishly complex (har har) number: &lt;span class="math"&gt;\(i\)&lt;/span&gt;.&lt;/p&gt;
&lt;h1 id="same-same-but-different"&gt;Same same butÂ different&lt;/h1&gt;
&lt;p&gt;You might remember imaginary and complex numbers from high school trigonometry. There is a number &lt;span class="math"&gt;\(i\)&lt;/span&gt; suchÂ that&lt;/p&gt;
&lt;div class="math"&gt;$$ i^2 = -1 $$&lt;/div&gt;
&lt;p&gt;which really tempts you to find the value of just plain &lt;span class="math"&gt;\(i\)&lt;/span&gt;. Since it doesnâ€™t really exist, we just have to treat it like an &lt;span class="math"&gt;\(x\)&lt;/span&gt;: &lt;span class="math"&gt;\(2 + 3i\)&lt;/span&gt; (a complex number),Â etc.&lt;/p&gt;
&lt;p&gt;But the kicker is that the point of &lt;span class="math"&gt;\(i\)&lt;/span&gt; is not its value but &lt;em&gt;what it lets us do&lt;/em&gt;. The point is that this property of &lt;span class="math"&gt;\(i\)&lt;/span&gt; makes it possible for us to reason about rotation around a circle, because its sign changes as you keep multiplying it byÂ itself.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I may or may not have learned that last point in high school, but if youâ€™re anything like me, it is helpful to have a refresher that is more lucid and engaging than any high school math class: &lt;a href="https://www.youtube.com/watch?v=spUNpyF58BY"&gt;3blue1brown&lt;/a&gt; / &lt;a href="https://betterexplained.com/articles/a-visual-intuitive-guide-to-imaginary-numbers/"&gt;BetterExplained&lt;/a&gt; / &lt;a href="https://www.youtube.com/watch?v=65wYmy8Pf-Y"&gt;WelchÂ Labs&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id="coding-with-i"&gt;Cod&lt;span class="math"&gt;\(i\)&lt;/span&gt;ng with &lt;span class="math"&gt;\(i\)&lt;/span&gt;?&lt;/h1&gt;
&lt;p&gt;While weâ€™re on the subject of complex numbers, letâ€™s play with them a bit. I was a bit surprised to discover that built-in &lt;code class="highlight"&gt;complex&lt;/code&gt; data types are not rare among modern programming languages. Itâ€™s not a surprise that Julia has them natively, but so do R, Python, and even Ruby. (Sadly, Clojure doesÂ not.)&lt;/p&gt;
&lt;p&gt;Of course, there is some variation in coolness ofÂ implementation:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_1_0" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_0"&gt;Julia&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;# You can use `im` to implicitly denote the imaginary part of a complex number&lt;/span&gt;
&lt;span class="c"&gt;# Not much different than typing LaTeX. Pretty slick!&lt;/span&gt;
&lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="nb"&gt;im&lt;/span&gt;
&lt;span class="n"&gt;typeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                     &lt;span class="c"&gt;# Complex{Int64}&lt;/span&gt;
&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;                            &lt;span class="c"&gt;# 6 + 8im&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="nb"&gt;im&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;                       &lt;span class="c"&gt;# -1 + 0im. Don't need to declare 0 real part&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="nb"&gt;im&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="nb"&gt;im&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;         &lt;span class="c"&gt;# 5 + 7im&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="nb"&gt;im&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="nb"&gt;im&lt;/span&gt;                     &lt;span class="c"&gt;# 0 + 0im&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="nb"&gt;im&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="nb"&gt;im&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;         &lt;span class="c"&gt;# 5 + 5im&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_1" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_1"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Python follows the electrical engineering convention of using j for i&lt;/span&gt;
&lt;span class="c1"&gt;# because i means current in that field (pun intended)&lt;/span&gt;
&lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;complex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;             &lt;span class="c1"&gt;# (3+4j)&lt;/span&gt;
&lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                       &lt;span class="c1"&gt;# complex&lt;/span&gt;
&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;z&lt;/span&gt;                         &lt;span class="c1"&gt;# (6+8j)&lt;/span&gt;
&lt;span class="nb"&gt;complex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;            &lt;span class="c1"&gt;# (-1+0j)&lt;/span&gt;
&lt;span class="nb"&gt;complex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;complex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# (5+7j)&lt;/span&gt;
&lt;span class="nb"&gt;complex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nb"&gt;complex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# 0j. interesting output&lt;/span&gt;
&lt;span class="nb"&gt;complex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nb"&gt;complex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# (5+5j)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_2" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_2"&gt;R&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Syntax is a bit cumbersome&lt;/span&gt;
&lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;complex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;imaginary&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;    &lt;span class="c1"&gt;# 3 + 4i&lt;/span&gt;
&lt;span class="nf"&gt;typeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                                &lt;span class="c1"&gt;# complex&lt;/span&gt;
&lt;span class="nf"&gt;complex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;imaginary&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;    &lt;span class="c1"&gt;# -1 + 0i&lt;/span&gt;
&lt;span class="nf"&gt;complex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;imaginary&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nf"&gt;complex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;imaginary&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# 5 + 7i&lt;/span&gt;

&lt;span class="c1"&gt;# Sorry R, but I can't be bothered to type so much&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Okay, that was fun. Now letâ€™s return to &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt;.&lt;/p&gt;
&lt;h1 id="dual-numbers"&gt;DualÂ numbers&lt;/h1&gt;
&lt;p&gt;Dual numbers are pretty similar to complex numbers, except with &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; instead of &lt;span class="math"&gt;\(i\)&lt;/span&gt;. &lt;span class="math"&gt;\(2 + 3\epsilon\)&lt;/span&gt; is a dual number, forÂ example.&lt;/p&gt;
&lt;p&gt;We could say that it still represents an infinitesimal here, a value so small that when you square it, it is effectively zero.Â Thus,&lt;/p&gt;
&lt;div class="math"&gt;$$ \epsilon^2 = 0 $$&lt;/div&gt;
&lt;p&gt;But as with &lt;span class="math"&gt;\(i\)&lt;/span&gt;, the significance of &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; is not in the exact value, but rather the mathematical play that it opens up for us. Watch what happens to this unsuspectingÂ parabola:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
f(x) &amp;amp;= x^2 \\
f(x + \epsilon) &amp;amp;= (x + \epsilon)^2 \\
&amp;amp;= x^2 + 2x\epsilon + \epsilon^2 \\
&amp;amp;= x^2 + 2x\epsilon + \cancel{0}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;We can rewrite this further, since our original function has reappeared in theÂ result:&lt;/p&gt;
&lt;div class="math"&gt;$$ f(x + \epsilon) = f(x) + 2x\epsilon $$&lt;/div&gt;
&lt;p&gt;And what is &lt;span class="math"&gt;\(2x\)&lt;/span&gt; but the &lt;strong&gt;derivative&lt;/strong&gt; of &lt;span class="math"&gt;\(x^2\)&lt;/span&gt;?Â ğŸ¤”&lt;/p&gt;
&lt;div class="math"&gt;$$ f(x + \epsilon) \overset{?}{=} f(x) + f'(x)\epsilon $$&lt;/div&gt;
&lt;p&gt;Just to make sure this isnâ€™t a one-off, letâ€™s try it with a more complex polynomial, and scale the &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt;Â component:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
f(x) &amp;amp;= 2x^3 + 5x - 7 \\
f(x + \textcolor{magenta}{2} \epsilon) &amp;amp;= 2(x + \textcolor{magenta}{2} \epsilon)^3 + 5(x + \textcolor{magenta}{2} \epsilon) - 7 \\
&amp;amp;= 2(x^3 + 6x^2\epsilon + 12x\epsilon^2 + 8\epsilon^3) + 5(x + 2\epsilon) - 7 \\
&amp;amp;= \textcolor{teal}{2x^3} + \textcolor{orange}{12x^2\epsilon} + \textcolor{lightgray}{24x\epsilon^2} + \textcolor{orange}{16\epsilon^3} + \textcolor{teal}{5x} + \textcolor{orange}{10\epsilon} - \textcolor{teal}{7} \\
&amp;amp;= \textcolor{teal}{2x^3 + 5x - 7} + \textcolor{magenta}{2} \textcolor{orange}{(6x^2 + 5 } \textcolor{lightgray}{+ 8\epsilon^2}\textcolor{orange}{)\epsilon} \\
&amp;amp;= \textcolor{teal}{f(x)} + \textcolor{magenta}{2} \textcolor{orange}{f'(x) \epsilon}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;Indeed, we still obtain the derivative of our original function, multiplied by the dual component of our input. ğŸ˜® ThisÂ means&lt;/p&gt;
&lt;div class="math"&gt;$$ f(a + b \epsilon) = f(a) + bf'(a)\epsilon $$&lt;/div&gt;
&lt;p&gt;In other words, we found the output and a local derivative in one goâ€”automagically!â€”without having to find the derivative by hand first (that would be &lt;em&gt;symbolic differentiation&lt;/em&gt;, i.e., through manipulatingÂ symbols).&lt;/p&gt;
&lt;p&gt;It should be possibly to exploit this property of &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; with functions whose derivatives are not so straightforward toÂ find.&lt;/p&gt;
&lt;p&gt;Well, technically, you could also approximate the derivative with &lt;em&gt;finite differences&lt;/em&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img alt="derivative animation" src="../../images/derivative_animation.gif" title="source: https://sites.google.com/a/student.ashcoll.school.nz/bcashcoll/13-mac/differentiation-as-3-6-91578"/&gt;&lt;/p&gt;
&lt;p&gt;But this is tedious at best and still not perfectly accurate when done by hand, and prone to all sorts of errors when done by computer (truncation errors, rounding errors,Â etc.).&lt;/p&gt;
&lt;h1 id="diy-automatic-differentiation"&gt;&lt;span class="caps"&gt;DIY&lt;/span&gt; automaticÂ differentiation&lt;/h1&gt;
&lt;p&gt;This brings us to automatic differentiation, which is a &lt;em&gt;huge&lt;/em&gt; topic in machine learning. There are libraries to do this, but it is important to understand how they work by implementing automatic differentiation fromÂ scratch.&lt;/p&gt;
&lt;p&gt;One stumbling block, however, is that outside of machine learning, dual numbers are a pretty obscure piece of mathematics. No language comes with them built-in; you have to implement a classÂ yourself.&lt;/p&gt;
&lt;h2 id="the-squarest-root-in-babylon"&gt;The squarest root inÂ Babylon&lt;/h2&gt;
&lt;p&gt;Before we build the class, letâ€™s set aÂ goalpost.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=vAp6nUMrKYg"&gt;Alan Edelmanâ€™s demonstration of automatic differentiation in Julia&lt;/a&gt; is pretty nifty, though I think it moves pretty fast for a newcomer to automatic differentiation. So letâ€™s break down what he is trying toÂ do.&lt;/p&gt;
&lt;p&gt;He wants to find the derivative of &lt;span class="math"&gt;\(\sqrt x\)&lt;/span&gt;. With the same power rule we used for the polynomials above, thatâ€™s pretty trivial to do symbolically,Â right?&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
f(x) = \sqrt x &amp;amp;= x^{\frac{1}{2}} \\
\frac{df}{dx} = \frac{1}{2} x^{-\frac{1}{2}} &amp;amp;= \frac{1}{2\sqrt x}
 \end{aligned} $$&lt;/div&gt;
&lt;p&gt;Done. Blog postÂ over!&lt;/p&gt;
&lt;p&gt;ğŸ¤¦ğŸ»&lt;/p&gt;
&lt;p&gt;Okay, but letâ€™s say we didnâ€™t know that &lt;span class="math"&gt;\(\sqrt x = x^{\frac{1}{2}}\)&lt;/span&gt;. Now whatcha gonnaÂ do?&lt;/p&gt;
&lt;p&gt;Apparently the Babylonians knew a way to approximate the squareÂ root.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{gathered}
t := \frac{t + \frac{x}{t}}{2} \\
\textrm{Repeat until }t \textrm{ converges to } \sqrt x
\end{gathered} $$&lt;/div&gt;
&lt;p&gt;The tutorial is of course intended to show off how well-suited Julia is to the overall task, but Iâ€™d say this preliminary work is a fun task for Clojure. Let &lt;code class="highlight"&gt;n&lt;/code&gt; denote the number ofÂ iterations.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_2_0" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_0"&gt;Clojure&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;bab-sqrt&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;loop &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;t&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="nv"&gt;acc&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;gt;= &lt;/span&gt;&lt;span class="nv"&gt;acc&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
         &lt;span class="nv"&gt;t&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="nv"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
               &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;inc &lt;/span&gt;&lt;span class="nv"&gt;acc&lt;/span&gt;&lt;span class="p"&gt;)))))&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;bab-sqrt&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c1"&gt;; 1.414213562373095&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/sqrt&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;    &lt;span class="c1"&gt;; 1.4142135623730951&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_2_1" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_1"&gt;Julia&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;# the original code from Alan Edelman's notebook&lt;/span&gt;
&lt;span class="k"&gt;function&lt;/span&gt; &lt;span class="n"&gt;Babylonian&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;  &lt;span class="k"&gt;end&lt;/span&gt;    
  &lt;span class="n"&gt;t&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="n"&gt;Babylonian&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c"&gt;# 1.414213562373095&lt;/span&gt;
&lt;span class="o"&gt;âˆš&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;             &lt;span class="c"&gt;# 1.4142135623730951&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_2_2" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_2"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;bab_root&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;iters&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;iters&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;
&lt;span class="n"&gt;bab_root&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;That converged pretty quick! Not to mention, itâ€™s more than an â€œapproximationâ€â€”itâ€™s practically indistinguishable to the true value after just fiveÂ iterations.&lt;/p&gt;
&lt;p&gt;Okay, so we have our function. Since we already know the derivative of &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; through symbolic differentiation, we can compute a true value for &lt;span class="math"&gt;\(f'(x)\)&lt;/span&gt; at any point &lt;span class="math"&gt;\(x = a\)&lt;/span&gt;, against which we can validate the result of automatically differentiating &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; at &lt;span class="math"&gt;\(x = a\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The first step to differentiate the Babylonian square root function at &lt;span class="math"&gt;\(x = 2\)&lt;/span&gt; &lt;em&gt;symbolically&lt;/em&gt; using dual numbers would look likeÂ this:&lt;/p&gt;
&lt;div class="math"&gt;$$ \frac{t + \frac{2 + \epsilon}{t}}{2} $$&lt;/div&gt;
&lt;p&gt;which should yield a satisfactorily precise result after 5Â iterations.&lt;/p&gt;
&lt;p&gt;We thus need to implement our class similarly to the imaginary number classes, so that something like &lt;code class="highlight"&gt;&lt;span class="n"&gt;bab_root&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/code&gt; will give us the derivative of &lt;span class="math"&gt;\(f(x) = \sqrt x\)&lt;/span&gt; at &lt;span class="math"&gt;\(x = 5\)&lt;/span&gt; &lt;em&gt;without having to explicitly write anything about&lt;/em&gt; &lt;span class="math"&gt;\(\frac{1}{2\sqrt 5}\)&lt;/span&gt;.&lt;/p&gt;
&lt;h2 id="getting-classy"&gt;GettingÂ classy&lt;/h2&gt;
&lt;p&gt;The basic task here is to create a class that overloads the basic arithmetic operators so that dual numbers can be manipulated like normal numbers. In other words, extend the operators to follow the rules of dual number arithmetic (includedÂ below).&lt;/p&gt;
&lt;p&gt;To be honest, defining classes is above my current level of Clojure skills, Iâ€™ve never overloaded operators in Python before, and Iâ€™m almost completely new to Julia. So I will adapt the Python code from &lt;a href="http://eviatarbach.com/2013/05/13/dual-numbers-and-automatic-differentiation/"&gt;this post&lt;/a&gt; and the Julia code from &lt;a href="https://nbviewer.jupyter.org/github/alanedelman/YouTubeNotebooks/blob/master/Automatic%20Differentiation%20in%2010%20Minutes.ipynb"&gt;this notebook&lt;/a&gt;, break it down and proceed fromÂ there.&lt;/p&gt;
&lt;p&gt;The rules of dual number arithmetic are as follows. Addition and multiplication work just like with complex numbers or polynomials (&lt;span class="caps"&gt;FOIL&lt;/span&gt;):&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
(a + b\epsilon) \pm (c + d\epsilon) &amp;amp;= \textcolor{teal}{(a + c)} \pm \textcolor{orange}{(b + d)}\epsilon \\
(a + b\epsilon) (c + d\epsilon) &amp;amp;= \textcolor{teal}{(ac)} + \textcolor{orange}{(bc + ad)}\epsilon
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;Division is not so obvious, but this is the rule (&lt;a href="https://en.wikipedia.org/wiki/Dual_number#Division"&gt;from Wikipedia&lt;/a&gt;):&lt;/p&gt;
&lt;div class="math"&gt;$$ \frac{a + b\epsilon}{c + d\epsilon} = \textcolor{teal}{\frac{a}{c}} + \textcolor{orange}{\frac{bc - ad}{c^2}} \epsilon $$&lt;/div&gt;
&lt;p&gt;Our result should have the teal part as its real component and the orange part as its dual component. We can treat &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; as merely a symbol to be printed when the value needs to be displayed for us humans toÂ read.&lt;/p&gt;
&lt;p&gt;The Python code looks really long, but donâ€™t get intimidated; itâ€™s mostlyÂ boilerplate.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_3_0" name="__tabs_3" type="radio"/&gt;
&lt;label for="__tab_3_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dual&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Overload basic operators&lt;/span&gt;
    &lt;span class="c1"&gt;# Copying these to the "r" functions ensures that a mixed expression can be&lt;/span&gt;
    &lt;span class="c1"&gt;# computed regardless of the order of arguments (Real+Dual / Dual+Real)&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__add__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;isinstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="fm"&gt;__radd__&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="fm"&gt;__add__&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__sub__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;isinstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__rsub__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__mul__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;isinstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="fm"&gt;__rmul__&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="fm"&gt;__mul__&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__truediv__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;isinstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__rtruediv__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__truediv__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__pow__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="c1"&gt;# For human-readable representation&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__repr__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;repr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s1"&gt;' + '&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;repr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s1"&gt;'Ïµ'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_3_1" name="__tabs_3" type="radio"/&gt;
&lt;label for="__tab_3_1"&gt;Julia&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;# taken from Alan's notebook&lt;/span&gt;
&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Base&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;convert&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;promote_rule&lt;/span&gt;

&lt;span class="n"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;:&lt;/span&gt; &lt;span class="kt"&gt;Number&lt;/span&gt;  &lt;span class="c"&gt;# D is a function-derivative pair&lt;/span&gt;
    &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;Tuple&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="kt"&gt;Float64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="kt"&gt;Float64&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;

&lt;span class="c"&gt;# Overload basic operators&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;.+&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;.-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])))&lt;/span&gt;
&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c"&gt;# Convert(D, 3)&lt;/span&gt;
&lt;span class="n"&gt;convert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;Type&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;Real&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;zero&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="c"&gt;# Operations with a dual number and a real number return a dual value&lt;/span&gt;
&lt;span class="n"&gt;promote_rule&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;Type&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt; &lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;Type&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;:&lt;/span&gt;&lt;span class="kt"&gt;Number&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;
&lt;span class="c"&gt;# For human-readable representation&lt;/span&gt;
&lt;span class="n"&gt;Base&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;io&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;IO&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;io&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="s"&gt;" + "&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="s"&gt;"Ïµ"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;I think itâ€™s noteworthy how short the Julia code is, even beyond Alanâ€™s use of single-letter variables, for accomplishing the same thing (with the exception of accepting &lt;code class="highlight"&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/code&gt; and returning &lt;code class="highlight"&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/code&gt;, which Iâ€™m sure is also possible). Itâ€™s almost like halfway between Python and Clojure! (And it almost makes Python look like JavaÂ ğŸ˜†)&lt;/p&gt;
&lt;p&gt;Letâ€™s play around aÂ bit.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_4_0" name="__tabs_4" type="radio"/&gt;
&lt;label for="__tab_4_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Complete input&lt;/span&gt;
&lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                &lt;span class="c1"&gt;# 3.0 + 5.0Ïµ&lt;/span&gt;
&lt;span class="c1"&gt;# Real-only input&lt;/span&gt;
&lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                   &lt;span class="c1"&gt;# 3.0 + 0.0Ïµ&lt;/span&gt;
&lt;span class="c1"&gt;# Confirming the characteristic property of Ïµ&lt;/span&gt;
&lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;           &lt;span class="c1"&gt;# 0.0 + 0.0Ïµ&lt;/span&gt;
&lt;span class="c1"&gt;# Random arithmetic&lt;/span&gt;
&lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# 12.0 + 64.0Ïµ&lt;/span&gt;
&lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;            &lt;span class="c1"&gt;# 5.0 + 2.0Ïµ&lt;/span&gt;
&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;           &lt;span class="c1"&gt;# 1.4 + -8.4Ïµ  &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_4_1" name="__tabs_4" type="radio"/&gt;
&lt;label for="__tab_4_1"&gt;Julia&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;# Complete input&lt;/span&gt;
&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;                &lt;span class="c"&gt;# 3.0 + 5.0Ïµ&lt;/span&gt;
&lt;span class="c"&gt;# Convert real numbers to dual numbers&lt;/span&gt;
&lt;span class="n"&gt;convert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c"&gt;# Confirming the characteristic property of Ïµ&lt;/span&gt;
&lt;span class="c"&gt;# Note that Julia doesn't require ^ to be explicitly defined!&lt;/span&gt;
&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;           &lt;span class="c"&gt;# 0.0 + 0.0Ïµ&lt;/span&gt;
&lt;span class="c"&gt;# Random arithmetic&lt;/span&gt;
&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  &lt;span class="c"&gt;# 12.0 + 64.0Ïµ&lt;/span&gt;
&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;            &lt;span class="c"&gt;# 5.0 + 2.0Ïµ&lt;/span&gt;
&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;           &lt;span class="c"&gt;# 1.4 + -8.4Ïµ  &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id="ready-for-liftoff"&gt;Ready forÂ liftoff&lt;/h2&gt;
&lt;p&gt;This makes it quite simple to do more sophisticated things with dual numbers, because our classes work with just the salient parts: the real and dual components. The &lt;span class="math"&gt;\(+\)&lt;/span&gt; and &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; are just there forÂ decoration.&lt;/p&gt;
&lt;p&gt;What that means is when we input a &lt;code class="highlight"&gt;Dual(my_real, 1)&lt;/code&gt; into &lt;code class="highlight"&gt;my_func(x)&lt;/code&gt;, we get another &lt;code class="highlight"&gt;Dual(dual, real)&lt;/code&gt; back. The &lt;code class="highlight"&gt;real&lt;/code&gt; component of this &lt;code class="highlight"&gt;Dual&lt;/code&gt; result is the value of &lt;code class="highlight"&gt;my_func(my_real)&lt;/code&gt;. The &lt;code class="highlight"&gt;dual&lt;/code&gt; component of the result (which is just a &lt;code class="highlight"&gt;float&lt;/code&gt;, not another &lt;code class="highlight"&gt;Dual&lt;/code&gt;) is the derivative of &lt;code class="highlight"&gt;my_func(x)&lt;/code&gt; at &lt;code class="highlight"&gt;my_real&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The code is simpler than theÂ explanation:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_5_0" name="__tabs_5" type="radio"/&gt;
&lt;label for="__tab_5_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;auto_diff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_5_1" name="__tabs_5" type="radio"/&gt;
&lt;label for="__tab_5_1"&gt;Julia&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;function&lt;/span&gt; &lt;span class="n"&gt;AutoDiff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Letâ€™s start with a softball. How about &lt;span class="math"&gt;\(f'(2)\)&lt;/span&gt; if &lt;span class="math"&gt;\(f(x) = x^2\)&lt;/span&gt;?&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_6_0" name="__tabs_6" type="radio"/&gt;
&lt;label for="__tab_6_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;auto_diff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;    &lt;span class="c1"&gt;# 4.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_6_1" name="__tabs_6" type="radio"/&gt;
&lt;label for="__tab_6_1"&gt;Julia&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;AutoDiff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Not bad! How about &lt;span class="math"&gt;\(f'(10)\)&lt;/span&gt; if &lt;span class="math"&gt;\(f(x) = x^{\sqrt e} + x^{\sqrt \pi}\)&lt;/span&gt;?&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_7_0" name="__tabs_7" type="radio"/&gt;
&lt;label for="__tab_7_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;math&lt;/span&gt;
&lt;span class="n"&gt;auto_diff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pi&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# 17.839035180965308&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;And how about &lt;span class="math"&gt;\(f'(\pi)\)&lt;/span&gt; if &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; is the Babylonian square root (&lt;span class="math"&gt;\(\frac{t + \frac{x}{t}}{2}\)&lt;/span&gt;)? The wild thing is that we can actually compute the derivative with more and more precision by increasing the number of iterations of the originalÂ function.&lt;/p&gt;
&lt;p&gt;(Hmm, that sounds vaguely akin to gradient descentâ€¦Â ğŸ¤”)&lt;/p&gt;
&lt;p&gt;Letâ€™s modify &lt;code class="highlight"&gt;auto_diff&lt;/code&gt; to allow this, and then iteratively show more and more precise values for &lt;span class="math"&gt;\(f(\pi)\)&lt;/span&gt; and &lt;span class="math"&gt;\(f'(\pi)\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_8_0" name="__tabs_8" type="radio"/&gt;
&lt;label for="__tab_8_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;auto_diff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;func&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;bab_root&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;iters&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;deriv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;auto_diff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bab_root&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;iters&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"{func}, {deriv}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_8_1" name="__tabs_8" type="radio"/&gt;
&lt;label for="__tab_8_1"&gt;Julia&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;function&lt;/span&gt; &lt;span class="n"&gt;AutoDiff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt; &lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;
    &lt;span class="n"&gt;func&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Babylonian&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;Ï€&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;deriv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AutoDiff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Babylonian&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;Ï€&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;println&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"&lt;/span&gt;&lt;span class="si"&gt;$&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s"&gt;, &lt;/span&gt;&lt;span class="si"&gt;$&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;deriv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;What is impressive is that not only does this &lt;em&gt;work&lt;/em&gt;, itâ€™s also more manageable, computationally faster, and more accurate to take derivatives this way. I wonâ€™t bore you with the evidence (you can check other blogs for that) because Iâ€™m mostly interested in the math behindÂ this.&lt;/p&gt;
&lt;p&gt;Plus, I can already believe that this is a better way. The only thing is that itâ€™s a black box; you canâ€™t see the general derivative &lt;span class="math"&gt;\(f'(x)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Or canÂ you?&lt;/p&gt;
&lt;h2 id="automatic-symbolic-differentiation"&gt;Automatic symbolicÂ differentiation?&lt;/h2&gt;
&lt;p&gt;Thanks to Alanâ€™s notebook, I discovered SymPy, which can generate properly typeset &lt;span class="math"&gt;\(\LaTeX\)&lt;/span&gt; &lt;em&gt;directly from your code&lt;/em&gt; and manipulate variables like &lt;span class="math"&gt;\(x\)&lt;/span&gt; as symbols rather thanÂ values!&lt;/p&gt;
&lt;p&gt;I tried to hack SymPyâ€™s &lt;code class="highlight"&gt;ImaginaryUnit&lt;/code&gt; class to implement a symbolic version of dual numbers, but I was too unfamiliar with it to get any results (everything was coming back zero). So to demonstrate this, Iâ€™m going to jump ahead a bit and use Juliaâ€™s built-in &lt;code class="highlight"&gt;diff&lt;/code&gt; function.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;# Pkg.add("SymPy")  # if you don't already have it&lt;/span&gt;
&lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;SymPy&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;symbols&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"x"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;
    &lt;span class="n"&gt;display&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;simplify&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Babylonian&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;
    &lt;span class="n"&gt;display&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;simplify&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;diff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;simplify&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Babylonian&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Watch what happens as we do successive iterations of the function &lt;code class="highlight"&gt;Babylonian&lt;/code&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{gathered}
\frac{x}{2} + \frac{1}{2} \\[0.8em]
\frac{x + \frac{\left(x + 1\right)^{2}}{4}}{x + 1} \\[1em]
\frac{x^{4} + 28 x^{3} + 70 x^{2} + 28 x + 1}{8 \left(x^{3} + 7 x^{2} + 7 x + 1\right)} \\[1em]
\frac{x^{8} + 120 x^{7} + 1820 x^{6} + 8008 x^{5} + 12870 x^{4} + 8008 x^{3} + 1820 x^{2} + 120 x + 1}{16 \left(x^{7} + 35 x^{6} + 273 x^{5} + 715 x^{4} + 715 x^{3} + 273 x^{2} + 35 x + 1\right)}
\end{gathered} $$&lt;/div&gt;
&lt;p&gt;Watch what happens as we do successive iterations of itsÂ derivative:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{gathered}
\frac{1}{2} \\[0.8em]
\frac{x^{2} + 2 x + 5}{4 \left(x^{2} + 2 x + 1\right)} \\[1em]
\frac{x^{6} + 14 x^{5} + 147 x^{4} + 340 x^{3} + 375 x^{2} + 126 x + 21}{8 \left(x^{6} + 14 x^{5} + 63 x^{4} + 100 x^{3} + 63 x^{2} + 14 x + 1\right)}
\end{gathered} $$&lt;/div&gt;
&lt;p&gt;Once you go beyond the third iteration, the polynomial expression of the derivative of the Babylonian square root function explodes to a length that is way beyond any computer monitor (and I canâ€™t get the &lt;span class="math"&gt;\(\KaTeX\)&lt;/span&gt; renderer to do line-wrapping), so youâ€™ll have to be convinced byÂ this.&lt;/p&gt;
&lt;p&gt;It should be noted that this is &lt;em&gt;not&lt;/em&gt; what the computer is doing in order to &lt;code class="highlight"&gt;diff&lt;/code&gt; our function, but it &lt;em&gt;is&lt;/em&gt; what &lt;em&gt;we&lt;/em&gt; would have to do by handÂ if&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We wanted an exact answer,Â but&lt;/li&gt;
&lt;li&gt;Our &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; couldnâ€™t be differentiated with simple rules like the power rule,Â and&lt;/li&gt;
&lt;li&gt;Dual numbers didnâ€™tÂ exist.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Imagine!&lt;/p&gt;
&lt;h1 id="automatic-differentiation"&gt;AutomaticÂ differentiation&lt;/h1&gt;
&lt;p&gt;Itâ€™sÂ showtime.&lt;/p&gt;
&lt;h2 id="out-of-the-box-solutions"&gt;Out-of-the-boxÂ solutions&lt;/h2&gt;
&lt;p&gt;Earlier, I hinted at the relevance of automatic differentiation to gradient descent. Indeed, it is &lt;em&gt;hugely relevant&lt;/em&gt; to gradient descent, and thus to machine learning more generally. It should come as no surprise, then, that major machine learning libraries like PyTorch and Google-backed TensorFlow leverage itÂ heavily.&lt;/p&gt;
&lt;p&gt;You can go &lt;em&gt;really&lt;/em&gt; deep with this stuff, but for the purposes of this blog post (and where Iâ€™m at in my studies of all this), itâ€™s enough just to get automatic differentiation working out of the box in Python (with &lt;code class="highlight"&gt;Autograd&lt;/code&gt;) and Julia (with &lt;code class="highlight"&gt;ForwardDiff&lt;/code&gt;).&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_9_0" name="__tabs_9" type="radio"/&gt;
&lt;label for="__tab_9_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;autograd.numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;autograd&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;grad&lt;/span&gt;

&lt;span class="c1"&gt;# Our DIY version&lt;/span&gt;
&lt;span class="n"&gt;auto_diff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bab_root&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# 0.35355339059327373&lt;/span&gt;

&lt;span class="c1"&gt;# Autograd version&lt;/span&gt;
&lt;span class="n"&gt;dbab_root&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;grad&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bab_root&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;dbab_root&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;2.&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;           &lt;span class="c1"&gt;# 0.35355339059327373&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_9_1" name="__tabs_9" type="radio"/&gt;
&lt;label for="__tab_9_1"&gt;Julia&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;# Pkg.add("ForwardDiff") # if you don't have it&lt;/span&gt;
&lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;ForwardDiff&lt;/span&gt;

&lt;span class="c"&gt;# Our DIY version&lt;/span&gt;
&lt;span class="n"&gt;AutoDiff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Babylonian&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                      &lt;span class="c"&gt;# 0.3535533905932738&lt;/span&gt;

&lt;span class="c"&gt;# ForwardDiff version&lt;/span&gt;
&lt;span class="n"&gt;ForwardDiff&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;derivative&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;Babylonian&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c"&gt;# 0.35355339059327373&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Cool! It works out of the boxâ€”no fiddling with making dual number classes. Thatâ€™s been done for us (and done more comprehensively and fasterÂ too).&lt;/p&gt;
&lt;p&gt;Now, we got &lt;code class="highlight"&gt;grad&lt;/code&gt; to auto-differentiate &lt;code class="highlight"&gt;bab_root&lt;/code&gt; for us, a function &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; that accepts a scalar and returns a scalar, &lt;span class="math"&gt;\(f'(x)\)&lt;/span&gt;.&lt;/p&gt;
&lt;h2 id="epsilon-in-the-cost-function"&gt;&lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; in the costÂ function&lt;/h2&gt;
&lt;p&gt;Can &lt;code class="highlight"&gt;grad&lt;/code&gt; auto-gradiate(?) the cost function &lt;span class="math"&gt;\(J(\theta)\)&lt;/span&gt; of &lt;a href="/from-zero-to-ero#convergence-threshold"&gt;our linear regression model from before&lt;/a&gt;, finding multiple partial derivatives in oneÂ swoop?&lt;/p&gt;
&lt;p&gt;Letâ€™s first take a step back and think about what weâ€™re actually doingÂ here.&lt;/p&gt;
&lt;p&gt;Our cost function &lt;span class="math"&gt;\(J(\theta)\)&lt;/span&gt; takes a vector of weights &lt;span class="math"&gt;\(\theta\)&lt;/span&gt;. The cost function returns a vector where each value indicates how â€œoffâ€ the model is due to eachÂ weight.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
J(Î¸) &amp;amp;= \frac{1}{2m}\sum_{i=1}^m{\Big[h_Î¸(x^i) - y_i\Big]}^2 \\
&amp;amp;= \frac{1}{2m} \Big[\vec o^T (h_Î¸{\textbf X} - \vec y)\Big]^2
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;In this case, there are 6 weights (5 features + the bias), so &lt;span class="math"&gt;\(J(\theta)\)&lt;/span&gt; has 6Â components.&lt;/p&gt;
&lt;p&gt;The partial derivatives of &lt;span class="math"&gt;\(J(\theta)\)&lt;/span&gt; takes the same vector of weights and return the gradient &lt;span class="math"&gt;\(\nabla J\)&lt;/span&gt;, which is a vector where each value indicates the â€œvelocityâ€ of each misestimation due to the corresponding weight. (Returning to the coffee mug analogy, the gradient tells us the slope in each dimension &lt;span class="math"&gt;\(x, y, z\)&lt;/span&gt; at our current point on the coffeeÂ mug.)&lt;/p&gt;
&lt;div class="math"&gt;$$ \frac{\partial J(Î¸)}{\partial Î¸_j} = \frac{1}{m}\sum_{i=1}^m\Big[h_Î¸(x^i) - y_i\Big]x_j^i $$&lt;/div&gt;
&lt;p&gt;These â€œvelocitiesâ€ tell us how to change our weights so that we can get a little closer to the minimum of the function (convergence, or the bottom of theÂ mug).&lt;/p&gt;
&lt;p&gt;When we did this before, we still had to find the partial derivatives manually, even though we did use matrix operations to streamline it all aÂ bit:&lt;/p&gt;
&lt;div class="math"&gt;$$
\nabla J = \begin{bmatrix}
  \frac{1}{m} \sum_{i=1}^m x_0^i{(e_1)}^2 \\[0.5em]
  \frac{1}{m} \sum_{i=1}^m x_1^i{(e_1)}^2 \\[0.5em]
  \vdots \\[0.5em]
  \frac{1}{m} \sum_{i=1}^m x_n^i{(e_1)}^2
\end{bmatrix} $$&lt;/div&gt;
&lt;p&gt;What we are asking now is: Can we get the velocities straight from the cost function without explicitly doing any math to find partialÂ derivatives?&lt;/p&gt;
&lt;p&gt;That is, can we write code to do &lt;span class="math"&gt;\(J(\theta + \epsilon)\)&lt;/span&gt;?&lt;/p&gt;
&lt;div class="math"&gt;$$
\theta = \begin{bmatrix}
  \theta_0 \\ \theta_1 \\ \vdots \\ \theta_n
\end{bmatrix} \qquad
\theta + \epsilon = \begin{bmatrix}
  \theta_0 + \epsilon \\ \theta_1 + \epsilon \\ \vdots \\ \theta_n + \epsilon
\end{bmatrix}
$$&lt;/div&gt;
&lt;p&gt;Spoiler alert: The answer is &lt;em&gt;yes&lt;/em&gt;!&lt;/p&gt;
&lt;h2 id="making-the-loopless-loop-mathless-too"&gt;Making the loopless loop mathless,Â too?&lt;/h2&gt;
&lt;p&gt;Letâ€™s get our setup goingÂ again.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt;

&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sklearn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;make_regression&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hstack&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# padding for bias column&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# this just fixes a quirk of sklearn's output&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After much trial and error, it seems to me that &lt;code class="highlight"&gt;grad&lt;/code&gt; can only take one argument. Mathematically, this makesÂ sense.&lt;/p&gt;
&lt;p&gt;This will require re-working the code a little bit, since I originally wrote it in a way that was more modular but also required more variables (Clojure thinking pattern,Â perhaps?).&lt;/p&gt;
&lt;p&gt;Also, I learned that &lt;code class="highlight"&gt;numpy&lt;/code&gt; has a built-in &lt;code class="highlight"&gt;mean()&lt;/code&gt; method, which makes it possible to simplify the cost function by quite a bit (eliminating the need for the &lt;code class="highlight"&gt;ones&lt;/code&gt; vector and the &lt;code class="highlight"&gt;num_samples&lt;/code&gt; variables), and make it veryÂ readable.&lt;/p&gt;
&lt;p&gt;I suppose that since weâ€™re doing automatic differentiation, we donâ€™t need the &lt;code class="highlight"&gt;cost&lt;/code&gt; value to be divided by 2, since the original purpose of that was to make the symbolic differentiationÂ easier.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;/span&gt;    &lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
&lt;span class="hll"&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/span&gt;
&lt;span class="n"&gt;dummy_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dummy_weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;     &lt;span class="c1"&gt;# a big number. I got 7177.83591830956&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To take this to the next level, just &lt;em&gt;one line&lt;/em&gt; isÂ needed!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;dcost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;grad&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# returns a new function&lt;/span&gt;
&lt;span class="n"&gt;dcost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dummy_weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Returns a vector of values for each weight. I got this:&lt;/span&gt;
&lt;span class="c1"&gt;# array([[  7.68455105],&lt;/span&gt;
&lt;span class="c1"&gt;#        [-70.49488731],&lt;/span&gt;
&lt;span class="c1"&gt;#        [-77.80611382],&lt;/span&gt;
&lt;span class="c1"&gt;#        [-40.00725071],&lt;/span&gt;
&lt;span class="c1"&gt;#        [  5.90183055],&lt;/span&gt;
&lt;span class="c1"&gt;#        [ -3.48617932]])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Amazing! Now we should be able to rewrite the &lt;code class="highlight"&gt;train_model&lt;/code&gt; function aÂ bit.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;train_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.001&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;last_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="c1"&gt;# just to know the value; not critical for training&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="hll"&gt;        &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;dcost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;        &lt;span class="n"&gt;this_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;this_cost&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;last_cost&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;break&lt;/span&gt;
        &lt;span class="n"&gt;last_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;this_cost&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Completed {epochs} epochs of training."&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="hll"&gt;    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Final cost: {cost(weights)}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;

&lt;span class="n"&gt;train_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Completed 699 epochs of training.&lt;/span&gt;
&lt;span class="c1"&gt;# Final cost: 0.06114217689306121&lt;/span&gt;
&lt;span class="c1"&gt;# array([[-0.09259437],&lt;/span&gt;
&lt;span class="c1"&gt;#        [81.0788861 ],&lt;/span&gt;
&lt;span class="c1"&gt;#        [88.26630974],&lt;/span&gt;
&lt;span class="c1"&gt;#        [43.93549829],&lt;/span&gt;
&lt;span class="c1"&gt;#        [ 4.96655198],&lt;/span&gt;
&lt;span class="c1"&gt;#        [ 2.08424121]])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;ğŸ”¥ğŸ”¥ğŸ”¥&lt;/p&gt;
&lt;p&gt;And thatâ€™s it for this post. Stay tuned forÂ more!&lt;/p&gt;
&lt;h1 id="summary"&gt;Summary&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;autograd.numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt; &lt;span class="c1"&gt;# use instead of normal numpy&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;autograd&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;grad&lt;/span&gt;
&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt;

&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sklearn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;make_regression&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hstack&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# padding for bias column&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# this just fixes a quirk of sklearn's output&lt;/span&gt;

&lt;span class="hll"&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;/span&gt;    &lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
&lt;span class="hll"&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/span&gt;
&lt;span class="n"&gt;dcost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;grad&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# returns a new function&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;train_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.001&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;last_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="c1"&gt;# just to know the value; not critical for training&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="hll"&gt;        &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;dcost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;        &lt;span class="n"&gt;this_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;this_cost&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;last_cost&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;break&lt;/span&gt;
        &lt;span class="n"&gt;last_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;this_cost&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Completed {epochs} epochs of training."&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="hll"&gt;    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Final cost: {cost(weights)}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;

&lt;span class="n"&gt;train_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id="references"&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Automatic differentiation in 10 minutes with Julia (&lt;a href="https://www.youtube.com/watch?v=vAp6nUMrKYg"&gt;video&lt;/a&gt; / &lt;a href="https://nbviewer.jupyter.org/github/alanedelman/YouTubeNotebooks/blob/master/Automatic%20Differentiation%20in%2010%20Minutes.ipynb"&gt;notebook&lt;/a&gt;), AlanÂ Edelman&lt;/li&gt;
&lt;li&gt;Automatic differentiation in Ruby (&lt;a href="https://www.youtube.com/watch?v=TI7mtWB4WiA"&gt;video&lt;/a&gt; / &lt;a href="https://github.com/tomstuart/dual_number"&gt;code&lt;/a&gt;), TomÂ Stuart&lt;/li&gt;
&lt;li&gt;&lt;a href="http://eviatarbach.com/2013/05/13/dual-numbers-and-automatic-differentiation/"&gt;Dual numbers and automatic differentiation&lt;/a&gt;, EviatarÂ Bach&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/HIPS/autograd/blob/master/docs/tutorial.md"&gt;Autograd tutorial&lt;/a&gt;, AutogradÂ docs&lt;/li&gt;
&lt;/ul&gt;</content><category term="dual numbers"></category><category term="automatic differentiation"></category><category term="machine learning"></category></entry><entry><title>Model Thinker notes, Ch. 2 andÂ 3</title><link href="http://tabidots.github.io/2019/01/model-thinker-notes-chapters-2-3" rel="alternate"></link><published>2019-01-20T10:30:47+07:00</published><updated>2019-01-20T10:30:47+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-01-20:/2019/01/model-thinker-notes-chapters-2-3</id><summary type="html">&lt;p&gt;Getting reacquainted with statistics for the first time since my ill-fated stint in introductory statistics in&amp;nbsp;college.&lt;/p&gt;</summary><content type="html">
&lt;p&gt;Along with &lt;a href="http://www.pimbook.org/"&gt;&lt;em&gt;A Programmerâ€™s Introduction to Mathematics&lt;/em&gt;&lt;/a&gt;, I started reading &lt;a href="https://www.amazon.com/Model-Thinker-What-Need-Know/dp/0465094627/ref=zg_bs_13884_41?_encoding=UTF8&amp;amp;psc=1&amp;amp;refRID=ZK3QGA2250Q3CJSWR8Q2"&gt;&lt;em&gt;Model Thinker: What You Need to Know to Make Data Work for You&lt;/em&gt;&lt;/a&gt; as a sort of analogous non-statisticianâ€™s introduction toÂ statistics.&lt;/p&gt;
&lt;p&gt;Or perhaps I should say &lt;em&gt;re&lt;/em&gt;-introduction, since I had to take Intro to Stats in college. But I passed that class by the skin of my teeth and really developed an aversion to statistical analysis from that course. But itâ€™s a necessary part of data science,Â soâ€¦&lt;/p&gt;
&lt;h1 id="chapter-2"&gt;ChapterÂ 2&lt;/h1&gt;
&lt;p&gt;Chapter 2 is about what models can do and their strength inÂ numbers.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Models can take one of threeÂ approaches:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;embodiment&lt;/em&gt; approach (simplified but still realistic, like a geologicalÂ model)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;analogy&lt;/em&gt; approach (abstracted from reality: &lt;em&gt;Think of the situation as aâ€¦&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;alternative reality&lt;/em&gt;Â approach&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Models must be &lt;em&gt;communicable&lt;/em&gt; and &lt;em&gt;tractable&lt;/em&gt; (analyzable). This means that it should be possible to translate them precisely into math, code, or some other formal language. (Most models are mathematical in nature, but this is not aÂ must.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;All models are wrong in their own way, so no single model can accurately represent complex phenomena, but many, together, areÂ useful.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Models are a superhero &lt;em&gt;&lt;span class="caps"&gt;REDCAPE&lt;/span&gt;&lt;/em&gt;: Reason, explain, design, communicate, action, predict,Â explore.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Many models can be applied to the same problem (many-to-one). And with &lt;em&gt;creativity&lt;/em&gt;, one model can also be put to many uses. For example, how many applications are there for a random walk? (What a relief to know that there is a place at the table for creativity and a non-&lt;span class="caps"&gt;STEM&lt;/span&gt;Â background!)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="chapter-3"&gt;ChapterÂ 3&lt;/h1&gt;
&lt;p&gt;Chapter 3 is about how there is a Goldilocks-esque balance to be struck with regard to the diversity of models and the accuracy of any givenÂ model.&lt;/p&gt;
&lt;p&gt;More is better, until itâ€™s not; more accurate is better, until itâ€™sÂ not.&lt;/p&gt;
&lt;p&gt;The chapter uses some fancy-looking equations dressed up in terms that are specific to this context, but the equations are actually rooted in statistics and often have simpler, more intuitiveÂ explanations.&lt;/p&gt;
&lt;h2 id="diversity"&gt;Diversity&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Condorcet jury theorem&lt;/strong&gt;: If all jury members in a case have an above-average probability of choosing the correct verdict, then each successive jury member after the first increases the probability of the whole jury choosing the correct verdict. The probability approaches 1 as you keep addingÂ members.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Wisdom of the crowd&lt;/strong&gt;: The authorâ€™s &lt;em&gt;model diversity theorem&lt;/em&gt; is an adaptation of &lt;a href="https://www.archania.org/theorems/diversity/"&gt;the wisdom of the crowd theorem&lt;/a&gt;, and it uses the &lt;em&gt;error&lt;/em&gt; as we calculated in linear regression. (Actually, all of the equations in this chapter are based on a mean squared error of some sort.) The book presents it as follows:
  &lt;br/&gt;
&lt;div class="math"&gt;$$ \underbrace{(\bar{M} - V)^2}_{\textrm{Many-Model Error}} =
  \underbrace{\sum_{i=1}^N \frac{(M_i - V)^2}{N}}_{\textrm{Average-Model Error}} -
  \underbrace{\textcolor{teal}{\sum_{i=1}^N} \frac{\textcolor{teal}{(M_i - \bar{M})^2}}{N}}_{\textrm{Diversity of Model Predictions}} $$&lt;/div&gt;
&lt;br/&gt;
  where &lt;span class="math"&gt;\(M_i\)&lt;/span&gt; is the prediction of model &lt;span class="math"&gt;\(i\)&lt;/span&gt;, &lt;span class="math"&gt;\(\bar{M}\)&lt;/span&gt; is the average value of all models, and &lt;span class="math"&gt;\(V\)&lt;/span&gt; is the true value. In otherÂ words,&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;if you have only one model (&lt;span class="math"&gt;\(M_i = \bar{M}\)&lt;/span&gt;), you can never decrease the discrepancy between its prediction andÂ truth.&lt;/li&gt;
&lt;li&gt;Even if you have many models that make identical predictions (still &lt;span class="math"&gt;\(M_i = \bar{M}\)&lt;/span&gt;), they will collectively misestimate truth by as much as each one misestimatesÂ truth.&lt;/li&gt;
&lt;li&gt;However, as the modelsâ€™ predictions diverge from each other (that is, as &lt;span class="math"&gt;\(\color{teal}\sum_{i=1}^N (M_i - \bar{M})^2\)&lt;/span&gt; increases), their &lt;em&gt;collective misestimation&lt;/em&gt; goes on decreasing. This is similar to the Condorcet jury theorem, except in continuous rather than binaryÂ terms.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;However, there is a diminishing rate of returns as you &lt;em&gt;include more models&lt;/em&gt;: Accuracy seems to converge on a limit of some sort, not unlike gradient descent. Conceived in that way, you should stop adding models once the error between &lt;span class="math"&gt;\(n\)&lt;/span&gt; models and &lt;span class="math"&gt;\(n-1\)&lt;/span&gt; models is lower than some &lt;a href="/2019/01/from-zero-to-ero"&gt;&lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; threshold value&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Why is this the case? Diversity is a factor of the dataâ€™s dimensionality. Models using the same (or similar) subsets of salient features are liable to predictÂ similarly.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There is a limit to how independent (&lt;em&gt;accurate&lt;/em&gt; and &lt;em&gt;diverse&lt;/em&gt;) a given group of models can be. Accuracy may suffer as a result of artificially trying to increase diversity (categorizing a list of locations by alphabetical order, forÂ example).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="accuracy"&gt;Accuracy&lt;/h2&gt;
&lt;p&gt;Increasing the fit (and thus predictive accuracy) of a model by increasing its granularity (adding categories, features, etc.) can backfire after a certainÂ point.&lt;/p&gt;
&lt;p&gt;The rest of the chapter is a long and slightly overly complicated explanation of the what statisticians call the &lt;strong&gt;bias-variance tradeoff&lt;/strong&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The relationship between bias and variance is similar to the relationship between &lt;em&gt;precision&lt;/em&gt; and &lt;em&gt;recall&lt;/em&gt; for binary classification. Ideal B-V are both as low as possible; ideal P-R are both as high as possible. However, they have a diametrically opposing relationship, so this is not actuallyÂ feasible.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="bias"&gt;Bias&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;High &lt;strong&gt;bias&lt;/strong&gt; âŸ¶ underfitting (model is too coarse to capture the general trend of the data). &lt;img alt="underfitting" src="../../images/underfitting.png"/&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Source for this illustration and the following ones: &lt;a href="https://medium.freecodecamp.org/using-machine-learning-to-predict-the-quality-of-wines-9e2e13d7480d"&gt;FreeCodeCamp&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the context of the chapterâ€™s house price example, high bias is also called &lt;strong&gt;categorization error&lt;/strong&gt;. This is the discrepancy between the samples in each category and the mean of thatÂ category.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bias (categorization error) â†‘ if your categories are bad and donâ€™t accurately reflect any shared characteristics among the samples. This makes sense because in terms of a scatter plot, the data points in each category will be spread out randomly and have no trend. In terms of house prices, this could be like lumping real estate markets of states that begin with the same letterÂ together.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bias (categorization error) â†“ as category granularity â†‘ (gets moreÂ precise)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bias (categorization error) also â†“ as sample size â†‘, because the law of large numbers dictates that a larger number of samples in a category will tend toward the mean of that category. This makes sense because more data points should more clearly indicate a trend for the model toÂ follow.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="variance"&gt;Variance&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;High &lt;strong&gt;variance&lt;/strong&gt; âŸ¶ overfitting (model is so fine that it starts to capture noise in the data, or in other words, every little &lt;em&gt;variation&lt;/em&gt;).
&lt;img alt="overfitting" src="../../images/underfitting.png"/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the context of the chapterâ€™s house price example, high bias is also called &lt;strong&gt;valuation error&lt;/strong&gt;. This is the total discrepancy between the estimated category means and the actual categoryÂ means.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Variance (valuation error) â†“ as categories get larger, again because of the law of largeÂ numbers.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="we-all-want-what-we-cant-have"&gt;We all want what we canâ€™tÂ have&lt;/h2&gt;
&lt;p&gt;We want low variance and low bias:
&lt;img alt="good fit" src="../../images/goodfit.png"/&gt;&lt;/p&gt;
&lt;p&gt;But decreasing variance increases bias, and decreasing bias increases variance. So good luck withÂ that.&lt;/p&gt;
&lt;h2 id="a-more-intuitive-explanation-of-r2"&gt;A more intuitive explanation of &lt;span class="math"&gt;\(R^2\)&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;There are many ways to measure a modelâ€™s accuracy, and there is a sidebar mentioning &lt;span class="math"&gt;\(R^2\)&lt;/span&gt;, which quantifies the predictive accuracy of a regression model. However, it doesnâ€™t explain it anywhere near as intuitively as illustration onÂ Wikipedia:&lt;/p&gt;
&lt;p&gt;&lt;img alt="RÂ² image" src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/86/Coefficient_of_Determination.svg/640px-Coefficient_of_Determination.svg.png" title="By Orzetto - Own work, CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=11398293"/&gt;&lt;/p&gt;
&lt;p&gt;The chapterâ€™s definition of &lt;span class="math"&gt;\(R^2\)&lt;/span&gt; is a pretty common one: &lt;em&gt;The proportion of variance explained by the model&lt;/em&gt;. Thatâ€™s prettyÂ abstract.&lt;/p&gt;
&lt;p&gt;A more intuitive explanation, based on the above illustration, is: &lt;em&gt;How much better is a prediction made with your model than just taking the average of theÂ data?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;You want the total area of the blue squares (including overlaps) to be as small as possible compared to the total area of the red squares (includingÂ overlaps).&lt;/p&gt;
&lt;h2 id="model-error-decomposition-theorem"&gt;Model error decompositionÂ theorem&lt;/h2&gt;
&lt;p&gt;The problem with a score like &lt;span class="math"&gt;\(R^2\)&lt;/span&gt; is that it doesnâ€™t tell you how much of the error is due to bias and how much is due to variance. I suppose that might be helpful if you know exactly how to fine-tune one or theÂ other.&lt;/p&gt;
&lt;p&gt;The author presents the &lt;strong&gt;model error decomposition theorem&lt;/strong&gt; to solve thisÂ problem.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{gathered}
\textrm{Model Error} = \textrm{Categorization Error} + \textrm{Valuation Error} \\
\underbrace{\sum_{x \in \textbf X} \Big(M(x) - V(x) \Big)^2}_\textrm{Model Error} =
\underbrace{\sum_{i=1}^n \sum_{x \in S_i} \Big(V(x) - V_i \Big)^2}_\textrm{Categorization Error} +
\underbrace{\sum_{i=1}^n \Big(M_i - V_i \Big)^2}_\textrm{Valuation Error}
\end{gathered} $$&lt;/div&gt;
&lt;p&gt;Lotta variablesÂ here.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;Variable&lt;/th&gt;
&lt;th align="left"&gt;Meaning&lt;/th&gt;
&lt;th align="left"&gt;Variable&lt;/th&gt;
&lt;th align="left"&gt;Meaning&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;span class="math"&gt;\(x\)&lt;/span&gt;&lt;/td&gt;
&lt;td align="left"&gt;sample&lt;/td&gt;
&lt;td align="left"&gt;&lt;span class="math"&gt;\(S_i\)&lt;/span&gt;&lt;/td&gt;
&lt;td align="left"&gt;category &lt;span class="math"&gt;\(i\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;span class="math"&gt;\(\textbf X\)&lt;/span&gt;&lt;/td&gt;
&lt;td align="left"&gt;dataset&lt;/td&gt;
&lt;td align="left"&gt;&lt;span class="math"&gt;\(M_i\)&lt;/span&gt;&lt;/td&gt;
&lt;td align="left"&gt;mean of modelâ€™s predictions for category &lt;span class="math"&gt;\(i\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;span class="math"&gt;\(M(x)\)&lt;/span&gt;&lt;/td&gt;
&lt;td align="left"&gt;modelâ€™s predicition for sample &lt;span class="math"&gt;\(x\)&lt;/span&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;span class="math"&gt;\(V_i\)&lt;/span&gt;&lt;/td&gt;
&lt;td align="left"&gt;mean of true values for category &lt;span class="math"&gt;\(i\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;span class="math"&gt;\(V(x)\)&lt;/span&gt;&lt;/td&gt;
&lt;td align="left"&gt;true value for sample &lt;span class="math"&gt;\(x\)&lt;/span&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Thus,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\textrm{Model Error}\)&lt;/span&gt;: sum discrepancy between model and truth for allÂ samples&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\textrm{Categorization Error}\)&lt;/span&gt;: sum discrepancy between true values in a category and true mean of that category for allÂ categories&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\textrm{Valuation Error}\)&lt;/span&gt;: sum discrepancy between predicted mean and true mean for allÂ categories&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It seems like you could do &lt;span class="math"&gt;\(\sqrt{\textrm{Model Error}}\)&lt;/span&gt; to find a number the average amount that a prediction made with the model will be offÂ by.&lt;/p&gt;
&lt;h1 id="references"&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://medium.freecodecamp.org/using-- machine-learning-to-predict-the-quality-of-wines-9e2e13d7480d"&gt;Using Machine Learning to Predict the Quality of Wines&lt;/a&gt;,Â FreeCodeCamp&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff"&gt;Bias-variance tradeoff&lt;/a&gt;,Â Wikipedia&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Coefficient_of_determination"&gt;Coefficient of determination&lt;/a&gt;,Â Wikipedia&lt;/li&gt;
&lt;/ul&gt;</content><category term="bias"></category><category term="variance"></category><category term="model error decomposition"></category><category term="predictive accuracy"></category><category term="RÂ²"></category><category term="wisdom of the crowd"></category></entry><entry><title>From zero to â€œÎµ-roâ€: Infinitesimals, floating-point, convergence, and randomÂ error</title><link href="http://tabidots.github.io/2019/01/from-zero-to-ero" rel="alternate"></link><published>2019-01-19T17:32:22+07:00</published><updated>2019-01-19T17:32:22+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-01-19:/2019/01/from-zero-to-ero</id><summary type="html">&lt;p&gt;Who knew so much could be said about a value so small? I didnâ€™t even cover&amp;nbsp;everything!&lt;/p&gt;</summary><content type="html">
&lt;p&gt;One of the questions I left open from my blogâ€™s inaugural post on linear regression was &lt;em&gt;How do you know when youâ€™ve reachedÂ convergence?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;That led me to learning about &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; (epsilon), or I suppose re-learning, if you count high school calculus, in which I think it made a single brief appearance in the formal definition ofÂ limit.&lt;/p&gt;
&lt;p&gt;Iâ€™m going to take a rather circuitous route to explaining the role of &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; in linear regression, as I kept discovering interesting new things along theÂ way.&lt;/p&gt;
&lt;p&gt;Hopefully your attention span is larger than the value of &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; (harÂ har)!&lt;/p&gt;
&lt;h1 id="all-the-small-things"&gt;All the smallÂ things&lt;/h1&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; can be found in a variety of contexts, but it always represents an &lt;strong&gt;infinitesimal&lt;/strong&gt;: a quantity that it is infinitely small and basically zero, but not zero-y &lt;em&gt;enough&lt;/em&gt; to notÂ exist.&lt;/p&gt;
&lt;p&gt;In high school calculus, &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; is the differenceÂ between&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the value of a function, &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt;, near its limit point, &lt;span class="math"&gt;\(x \rightarrow a\)&lt;/span&gt;,Â and&lt;/li&gt;
&lt;li&gt;the hypothetical value &lt;span class="math"&gt;\(L\)&lt;/span&gt; that the function appears to tend toward at the actual limit point &lt;span class="math"&gt;\(a\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As the distance between &lt;span class="math"&gt;\(x\)&lt;/span&gt; and &lt;span class="math"&gt;\(a\)&lt;/span&gt; (which is called &lt;span class="math"&gt;\(\delta\)&lt;/span&gt;, delta) shrinks, so does &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt;, so the upper bounds of the two quantities move inÂ tandem.&lt;/p&gt;
&lt;p&gt;You can also use &lt;span class="math"&gt;\(\delta\)&lt;/span&gt; and &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; to describe derivatives; i.e., if &lt;span class="math"&gt;\(dx = \delta\)&lt;/span&gt; and &lt;span class="math"&gt;\(\frac{dy}{dx} = \epsilon\)&lt;/span&gt;, you can imagine how shrinking one shrinks the other, and more importantly, that the ideal value for both of them is &lt;em&gt;as close as you can get to zero without vanishing&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="derivative animation" src="../../images/derivative_animation.gif" title="source: https://sites.google.com/a/student.ashcoll.school.nz/bcashcoll/13-mac/differentiation-as-3-6-91578"/&gt;&lt;/p&gt;
&lt;h1 id="machine-epsilon"&gt;MachineÂ epsilon&lt;/h1&gt;
&lt;p&gt;There is also a quantity that computer scientists call &lt;strong&gt;machine epsilon&lt;/strong&gt;, which defines the smallest number that a given computing environment canÂ represent.&lt;/p&gt;
&lt;p&gt;It is the largest &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; thatÂ satisfies&lt;/p&gt;
&lt;div class="math"&gt;$$ 1 + \epsilon = 1 $$&lt;/div&gt;
&lt;p&gt;which looks like another math koan, or at least some Orwellian â€œnewmathâ€ like &lt;span class="math"&gt;\(2 + 2 = 5\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Actually, that &lt;span class="math"&gt;\(+\)&lt;/span&gt; should have a &lt;span class="math"&gt;\(\bigcirc\)&lt;/span&gt; around it: &lt;span class="math"&gt;\(\oplus\)&lt;/span&gt;, givingÂ us&lt;/p&gt;
&lt;div class="math"&gt;$$ 1 \oplus \epsilon = 1 $$&lt;/div&gt;
&lt;p&gt;The &lt;span class="math"&gt;\(\oplus\)&lt;/span&gt; means &lt;em&gt;floating-point addition&lt;/em&gt;.  &lt;/p&gt;
&lt;p&gt;Now, in my programming life, I have not had a need for significant precision until now, with my new interest in fields that require numericalÂ computing.&lt;/p&gt;
&lt;p&gt;I also started with Python (well, JavaScript if you go way back), so I never even really had to distinguish between &lt;code class="highlight"&gt;float&lt;/code&gt;s and &lt;code class="highlight"&gt;int&lt;/code&gt;s in my codeâ€”much less think about the consequences or even know the difference, really. I just knew that if you wanted a number with a decimal point, it had to be a &lt;code class="highlight"&gt;float&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Once you get into doing real math with computers, though, you canâ€™t just keep &lt;code class="highlight"&gt;float&lt;/code&gt;ing along like that, because the limitations of machines come intoÂ play.&lt;/p&gt;
&lt;h2 id="floating-point-arithmetic"&gt;Floating-pointÂ arithmetic&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Floating-point arithmetic&lt;/em&gt; was devised because computer memory, especially in machines from the very early days of computing, can only allocate a finite amount of resources toÂ data.&lt;/p&gt;
&lt;p&gt;Floating-point is basically scientific notation. Letâ€™s consider the mass of a proton in scientific notation (this post isnâ€™t about physics, but as an astoundingly small value, itâ€™s a goodÂ example):&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned} &amp;amp; 0.0000000000000000000000000016726 \space \textrm{kg} \\
&amp;amp;= \underbrace{1.6726}_{\textrm{significand}} \times \underbrace{10}_{\textrm{base}}  \!\!\!\!^{\overbrace{-27}^{\textrm{exponent}}} \space \textrm{kg}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;The goal of scientific notation is to translate numbers of extreme magnitude into more human-friendly terms. But computers donâ€™t operate like humans do. So how can we translate this number into &lt;em&gt;computer&lt;/em&gt;-friendlyÂ terms?&lt;/p&gt;
&lt;p&gt;First, computers use &lt;em&gt;binary&lt;/em&gt;, not base 10 (decimal system). Of course, we know that, but what does that actually mean? I always thought binary sequences were random collections of ones and zerosâ€”as if computer programs were like canvasses assaulted by a digital Jackson Pollock armed with buckets of bits andÂ bytes.&lt;/p&gt;
&lt;p&gt;&lt;img alt="binary counter" src="https://upload.wikimedia.org/wikipedia/commons/7/75/Binary_counter.gif" title="(source: Ephert [CC BY-SA 4.0] https://creativecommons.org/licenses/by-sa/4.0, from Wikimedia Commons)"/&gt;&lt;/p&gt;
&lt;p&gt;I am not well-versed enough in binary to explain this in words, but you can definitely see some sort of pattern in the movement of the valuesÂ here.&lt;/p&gt;
&lt;p&gt;Anyway, letâ€™s rewrite the mass of a proton in binary (scroll sideways, itâ€™s a longÂ one):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100001001000010
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And in binary scientific notation (sortÂ of):&lt;/p&gt;
&lt;div class="math"&gt;$$ 1.00001001000010_{\textrm{bin}} \times 2^{-89} $$&lt;/div&gt;
&lt;p&gt;Almost there. Letâ€™s take a look at how computers actually store floating-pointÂ numbers:&lt;/p&gt;
&lt;p&gt;&lt;img alt="64-bit floating point storage structure" src="https://upload.wikimedia.org/wikipedia/commons/a/a9/IEEE_754_Double_Floating_Point_Format.svg" title="source: Codekaizen - Own work, [CC BY-SA 4.0] https://commons.wikimedia.org/w/index.php?curid=3595583"/&gt;&lt;/p&gt;
&lt;p&gt;Every number is allocated 64 bits of memory (this can vary, but letâ€™s stick with 64). There are 52 bits for the &lt;em&gt;mantissa&lt;/em&gt; (computer science term for significand), 11 for the exponent, and 1 for the sign (positve or negative). Each bit can be 1 or 0, which is the whole reason for using binary in the firstÂ place.&lt;/p&gt;
&lt;p&gt;Storing the mantissa, then, is just a matter of finding a way to fit the relevant sequence of ones and zeros into the 52 slots allocated for it. If there are too many digits, chop them off; if there are too few (as in this case), add padding. This is where floating-point differs from scientificÂ notation.&lt;/p&gt;
&lt;div class="math"&gt;$$ 00000000 \space 00000000 \space 00000000 \space 00000000 \space
00000\textcolor{teal}{100 \space 00100100 \space 0010} \times 2^{-51} $$&lt;/div&gt;
&lt;p&gt;Looks like a lot of zeros. Incidentally, the method to obtain a base-10 number from this can be expressed mathematically in a coolÂ way:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
&amp;amp; \Bigg(\sum_{n=0}^{p-1} \textrm{bit}_n \times 2^{-n} \Bigg) \times 2^e \\
&amp;amp;= (0 \times 2^{-0} + 0 \times 2^{-1} + 0 \times 2^{-2} + \cdots + 1 \times 2^{-50} + 0 \times 2^{-51}) \times 2^{-51} \\
&amp;amp;= (1 \times 2^{-37} + 1 \times 2^{-42} + 1 \times 2^{-45} + 1 \times 2^{-50}) \times 2^{-51}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(\textrm{bit}_n\)&lt;/span&gt; is the binary value of the bit at index &lt;span class="math"&gt;\(n\)&lt;/span&gt; (from the left, starting at 0), &lt;span class="math"&gt;\(p\)&lt;/span&gt; is the precision (number of bits), and &lt;span class="math"&gt;\(e\)&lt;/span&gt; is the exponent (which just happens to be &lt;span class="math"&gt;\(-51\)&lt;/span&gt; here; it has nothing to do with the number of bits for theÂ mantissa).&lt;/p&gt;
&lt;p&gt;Okay, that was fun. NowÂ what?&lt;/p&gt;
&lt;h2 id="rounding-errors"&gt;RoundingÂ errors&lt;/h2&gt;
&lt;p&gt;&lt;img alt="xkcd comic" src="https://imgs.xkcd.com/comics/e_to_the_pi_minus_pi.png" title="XKCD #217 https://xkcd.com/217/"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If there are too many digits, chop them off&lt;/em&gt;. This opens up a big can of worms. Or an infinitesimal one, given the topic at hand (harÂ har).&lt;/p&gt;
&lt;p&gt;In exchange for the computability (read: speed and power) and storeability of floating-point numbers, we have to accept a limit to their precision. The digits of &lt;span class="math"&gt;\(\pi\)&lt;/span&gt;, for example, repeat endlessly. We canâ€™t expect a computer to handle them all, or a calculator, for thatÂ matter.&lt;/p&gt;
&lt;p&gt;Even totally pedestrian numbers like &lt;span class="math"&gt;\(\frac{1}{3}\)&lt;/span&gt; go on forever. This means that computers cannot reason about fractional quantities in the way that the human mindÂ can.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
1 + \frac{1}{3} &amp;amp;= \frac{4}{3}_{\textrm{human}} \\[0.8em]
&amp;amp;= 1.333\overline{3}_{\textrm{dec}} \\
&amp;amp;= 1.1010\overline{10}_{\textrm{bin}}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;That is, unless you are working in some baller language like Clojure that has &lt;code class="highlight"&gt;Ratio&lt;/code&gt; dataÂ types:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_1_0" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_0"&gt;Clojure&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;        &lt;span class="c1"&gt;; 1/3&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;type&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;; clojure.lang.Ratio&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  &lt;span class="c1"&gt;; 4/3&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_1" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_1"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# 1.3333333333333333&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Most languages seem to have implemented some sort of corrective mechanism that works in simple cases, but notice what happens with the following expressions inÂ Python:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="c1"&gt;# 1.0&lt;/span&gt;
&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# 1.0&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;
&lt;span class="c1"&gt;# 0.9999999999999998&lt;/span&gt;
&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;
&lt;span class="c1"&gt;# False&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Keep in mind that weâ€™re working in binary here. Unexpectedly (if you are not proficient in binary), many â€œsimpleâ€ numbers that donâ€™t repeat in decimal do inÂ binary:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\frac{1}{10} &amp;amp;= 0.1_{\textrm{dec}} \\
&amp;amp;= 0.1100\overline{1100}_{\textrm{bin}}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;All of this leads to &lt;strong&gt;floating-point rounding errors&lt;/strong&gt; that can quickly snowball into massively erroneous output over many iterations. Hereâ€™s the example from the &lt;a href="https://youtu.be/8iGzBMboA0I?t=3247"&gt;Rachel Thomas lecture&lt;/a&gt;. Start with &lt;span class="math"&gt;\(x = \frac{1}{10}\)&lt;/span&gt; and keep applying the function to the output youÂ get:&lt;/p&gt;
&lt;div class="math"&gt;$$ f(x) = \begin{cases}
2x     &amp;amp; \textrm{if } x \leq \frac{1}{2} \\
2x - 1 &amp;amp; \textrm{if } x &amp;gt; \frac{1}{2}
\end{cases} $$&lt;/div&gt;
&lt;p&gt;If you do this by hand youÂ get&lt;/p&gt;
&lt;div class="math"&gt;$$ \{\tfrac{1}{10}, \tfrac{1}{5}, \tfrac{2}{5}, \tfrac{4}{5}, \tfrac{3}{5}, \overline{\tfrac{1}{5}, \tfrac{2}{5}, \tfrac{4}{5}, \tfrac{3}{5}}, \cdots\} $$&lt;/div&gt;
&lt;p&gt;but when you try to execute this on aÂ computer:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_2_0" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;80&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_2_1" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_1"&gt;Clojure&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;use&lt;/span&gt; &lt;span class="ss"&gt;'clojure.pprint&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;f&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;lt;= &lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;* &lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;- &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;* &lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;pprint&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;take &lt;/span&gt;&lt;span class="mi"&gt;80&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;iterate &lt;/span&gt;&lt;span class="nv"&gt;f&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;it doesnâ€™t take long before the value converges on 1, which is veryÂ bizarre.&lt;/p&gt;
&lt;h2 id="granularity"&gt;Granularity&lt;/h2&gt;
&lt;p&gt;Limited storage space leads to limited precision. A related consequence of this is that floating-point numbers are discrete, not continuous like the number line we picture in our minds. (As a kid, I think I imagined a spectrum. Fun? Yes. Accurate? Not sure.) Computers are capable of pretty precise calculations, but not perfectlyÂ precise.&lt;/p&gt;
&lt;p&gt;Think of floating-point numbers like pixels. While it is true that computer displays have become less and less â€œpixelly-lookingâ€ over the years, and text rendered on a Retina screen can almost look like a printed page, we know that such output still consists ofÂ pixels.&lt;/p&gt;
&lt;p&gt;The same is true for floating-point numbers. They allow for some degree of precision, but the number line they form is more like a dotted line than a solid line. (Even stranger, the density of the line changes at different scales, but Iâ€™ll leave that one for someone else toÂ explain!)&lt;/p&gt;
&lt;p&gt;Take the binary number &lt;code class="highlight"&gt;1.0&lt;/code&gt; (regular binary, not floating-point). This is equal to the decimal number 1 as well. If we keep moving the 1 to the right and adding zeros accordingly, the value isÂ halved:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
1.0_\textrm{bin} = 1_\textrm{dec} \\
0.1_\textrm{bin} = \tfrac{1}{2}_\textrm{dec} \\
0.01_\textrm{bin} = \tfrac{1}{4}_\textrm{dec} \\
0.001_\textrm{bin} = \tfrac{1}{8}_\textrm{dec}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;It is pretty clear that with 52 slots for binary values, you are going to run out of room at some pointâ€”even with the orders-of-magnitude wiggle room that the exponentÂ provides.&lt;/p&gt;
&lt;p&gt;This means that after enough iterations, a value can no longer be halved. &lt;em&gt;That unhalvable value&lt;/em&gt; is the smallest difference that that computing environment can represent, and it is the distance between a given number and its closest possible neighbor on the floating-point numberÂ line.&lt;/p&gt;
&lt;p&gt;You could think of that as the size of a â€number pixel.â€ The whole pixel has the value of (say) its left edge, and any quantity that falls within the space of the pixel gets rounded to the edge of that pixel or the nextÂ one.&lt;/p&gt;
&lt;p&gt;Machine epsilon, then, is the &lt;em&gt;largest quantity&lt;/em&gt; that is less than the width of a number pixel. So it makes sense, then, that &lt;span class="math"&gt;\(1 \oplus \epsilon = 1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;This means that machine epsilon is the &lt;em&gt;largest possible rounding error&lt;/em&gt; of a floating-pointÂ system.&lt;/p&gt;
&lt;p&gt;It also means that on our continuous human number line, as soon as you move &lt;em&gt;rightward&lt;/em&gt; of machine epsilon, you have entered the territory of the next machine-perceptible number. That is how machine epsilon defines the smallest possible difference that the system canÂ represent.&lt;/p&gt;
&lt;h2 id="calculating-machine-epsilon"&gt;Calculating machineÂ epsilon&lt;/h2&gt;
&lt;p&gt;Before I started writing this post, I just wanted to see the code to calculate machine epsilon. But I didnâ€™t fully understand what was going on, and my dissatisfaction with that led me to go back through all the stuff I just explained. (Of course, it didnâ€™t help that I wasnâ€™t sure about the syntax of &lt;code class="highlight"&gt;loop&lt;/code&gt; in ClojureÂ ğŸ™ˆ)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;; Source: https://github.com/log0ymxm/gorilla-worksheets/blob/master/src/machine-epsilon.clj&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;loop &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;k&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="nv"&gt;s&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;or &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;lt;= &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="nv"&gt;s&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;gt; &lt;/span&gt;&lt;span class="nv"&gt;k&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="nb"&gt;dec &lt;/span&gt;&lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;, &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;* &lt;/span&gt;&lt;span class="mf"&gt;2.0&lt;/span&gt; &lt;span class="nv"&gt;s&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;inc &lt;/span&gt;&lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;* &lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt; &lt;span class="nv"&gt;s&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;span class="c1"&gt;; [53 2.220446049250313E-16]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This loop is trying to find the unhalvable value I wrote about earlier. Start with &lt;code class="highlight"&gt;s = 1.0&lt;/code&gt; and keep halving that (moving the binary 1 rightward) until &lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;lt;= &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="nv"&gt;s&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/code&gt; or &lt;span class="math"&gt;\(1 + s \leq 1\)&lt;/span&gt;. That is, until the computer no longer recognizes &lt;code class="highlight"&gt;s&lt;/code&gt; as havingÂ value.&lt;/p&gt;
&lt;p&gt;Once that happens, youâ€™ve gone too far and fallen within the bounds of a number pixel. To find the edge of the next pixelâ€”that is, the next adjacent perceptibly different numberâ€”move the binary 1 left by one place (in decimal, thatâ€™s multiplying byÂ 2).&lt;/p&gt;
&lt;p&gt;Thatâ€™s the reason for the final &lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;* &lt;/span&gt;&lt;span class="mf"&gt;2.0&lt;/span&gt; &lt;span class="nv"&gt;s&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/code&gt; once the terminating condition isÂ met.&lt;/p&gt;
&lt;p&gt;&lt;code class="highlight"&gt;k&lt;/code&gt; tells us that the 1 is in the &lt;span class="math"&gt;\(k\)&lt;/span&gt;th place after the decimal point. Here, thatâ€™s the 53rd place. Thatâ€™s no surprise; we know itâ€™s a 64-bit number. But &lt;code class="highlight"&gt;k&lt;/code&gt; could be larger or smaller depending on the precision of the floating-point system, with higher values meaning more available places and thus higherÂ precision.&lt;/p&gt;
&lt;p&gt;Julia, NumPy, and R have built-in ways to find machine epsilon (or rather, the value just a hair larger than machine epsilon). Of the three, Juliaâ€™s value is the most precise (to the same level of precision as ClojureÂ above).&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_3_0" name="__tabs_3" type="radio"/&gt;
&lt;label for="__tab_3_0"&gt;Julia&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;# source: https://docs.julialang.org/en/v1/manual/integers-and-floating-point-numbers/index.html&lt;/span&gt;
&lt;span class="n"&gt;julia&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;eps&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;         
&lt;span class="mf"&gt;2.220446049250313e-16&lt;/span&gt;
&lt;span class="n"&gt;julia&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;eps&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;Float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c"&gt;# 32-bit (single-precision) number&lt;/span&gt;
&lt;span class="mf"&gt;1.1920929f-7&lt;/span&gt;
&lt;span class="n"&gt;julia&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;eps&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="mf"&gt;1.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_3_1" name="__tabs_3" type="radio"/&gt;
&lt;label for="__tab_3_1"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# source: https://stackoverflow.com/questions/19141432/python-numpy-machine-epsilon&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;finfo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eps&lt;/span&gt;        
&lt;span class="mf"&gt;2.22044604925e-16&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;finfo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eps&lt;/span&gt; &lt;span class="c1"&gt;# 32-bit (single-precision) number&lt;/span&gt;
&lt;span class="mf"&gt;1.19209e-07&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;finfo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eps&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="mf"&gt;1.0&lt;/span&gt;
 &lt;span class="sb"&gt;``&lt;/span&gt;&lt;span class="err"&gt;`&lt;/span&gt;

&lt;span class="sb"&gt;``&lt;/span&gt;&lt;span class="err"&gt;`&lt;/span&gt;&lt;span class="n"&gt;R&lt;/span&gt; &lt;span class="n"&gt;tab&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;
&lt;span class="c1"&gt;# source: https://stackoverflow.com/questions/2619543/how-do-i-obtain-the-machine-epsilon-in-r&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Machine&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;double&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eps&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="mf"&gt;2.220446e-16&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Machine&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;double&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eps&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Just for completeness, this is that value in mathÂ notation:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\epsilon_{\textrm{mach}} &amp;amp;= 2.220446049250313 \times 10^{-16} \\
&amp;amp;= 0.000 \space 000 \space 000 \space 000 \space 000 \space 000 \space 000 \space
222 \space 044 \space 604 \space 9250
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;So, even though I donâ€™t immediately see myself caring about the specific &lt;em&gt;value&lt;/em&gt; of machine epsilon (as opposed to its &lt;em&gt;implications&lt;/em&gt;), thatâ€™s prettyÂ neat.&lt;/p&gt;
&lt;p&gt;Speaking of the implications of &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt;â€”of the machine and non-machine varietyâ€”I have to bring the discussion back to what brought me to &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; in the first place: convergence in linearÂ regression.&lt;/p&gt;
&lt;h1 id="linear-regression"&gt;LinearÂ regression&lt;/h1&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; has &lt;em&gt;two&lt;/em&gt; meanings in linear regression depending on whether you are creating the model or using theÂ model.&lt;/p&gt;
&lt;h2 id="convergence-threshold"&gt;ConvergenceÂ threshold&lt;/h2&gt;
&lt;p&gt;&lt;a href="/2019/01/loopless-loop"&gt;Previously&lt;/a&gt;, we performed stochastic gradient descent in a way that we could see the cost decreasing with every iteration, but we still had to adjust the number of iterations manually and judge convergence by looking through the output to find the point where the next iteration wasnâ€™t really worthÂ it.&lt;/p&gt;
&lt;p&gt;Itâ€™s conceptually very simple to have the computer do this for you. On each iteration, just keep track of the cost obtained after the previous iteration and compare it to the current cost. If the difference is below a certain threshold value, stopÂ iterating.&lt;/p&gt;
&lt;div class="math"&gt;$$ | J(\theta_{\textrm{current}}) - J(\theta_{\textrm{previous}}) | &amp;lt; \epsilon $$&lt;/div&gt;
&lt;p&gt;In this context, the threshold value is called &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt;. Something like &lt;span class="math"&gt;\(0.0001\)&lt;/span&gt; might beÂ adequate.&lt;/p&gt;
&lt;p&gt;Letâ€™s take first part of the code from the lastÂ post:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt;

&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sklearn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;make_regression&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hstack&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# padding for bias column&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# this just fixes a quirk of sklearn's output&lt;/span&gt;

&lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;num_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;o&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;num_samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
    &lt;span class="n"&gt;cost_array&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;num_samples&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;cost_array&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and modify our &lt;code class="highlight"&gt;train_model&lt;/code&gt; function to show us the difference between the current and the last cost on every 50th iteration, and train for 1500Â epochs.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;train_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;num_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="hll"&gt;    &lt;span class="n"&gt;last_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;/span&gt;    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
        &lt;span class="n"&gt;step_distance&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;num_samples&lt;/span&gt;
        &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;step_distance&lt;/span&gt;
&lt;span class="hll"&gt;        &lt;span class="n"&gt;this_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;            &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;this_cost&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;last_cost&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;        &lt;span class="n"&gt;last_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;this_cost&lt;/span&gt;
&lt;/span&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;

&lt;span class="n"&gt;train_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1500&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;At 600 epochs, the difference falls to about &lt;code class="highlight"&gt;0.001&lt;/code&gt; and at 700 epochs, it falls to about &lt;code class="highlight"&gt;0.0001&lt;/code&gt;. Considering the difference between the initial 20 iterations was in the hundreds, I think &lt;code class="highlight"&gt;0.001&lt;/code&gt; is a sufficiently good &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Letâ€™s rewrite the function to stop training based on a value of &lt;code class="highlight"&gt;epsilon&lt;/code&gt; rather than a number &lt;code class="highlight"&gt;epochs&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;train_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.001&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;/span&gt;    &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;num_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;last_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="hll"&gt;    &lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="c1"&gt;# just to know the value; not critical for training&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;        &lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;/span&gt;        &lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
        &lt;span class="n"&gt;step_distance&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;num_samples&lt;/span&gt;
        &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;step_distance&lt;/span&gt;
        &lt;span class="n"&gt;this_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="hll"&gt;        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;this_cost&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;last_cost&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;            &lt;span class="k"&gt;break&lt;/span&gt;
&lt;/span&gt;        &lt;span class="n"&gt;last_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;this_cost&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Completed {epochs} epochs of training."&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Final cost: {cost(X, y, weights)}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;

&lt;span class="n"&gt;train_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Completed 612 epochs of training.&lt;/span&gt;
&lt;span class="c1"&gt;# Final cost: 0.05001815274191081&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Nice!&lt;/p&gt;
&lt;h2 id="random-error"&gt;RandomÂ error&lt;/h2&gt;
&lt;p&gt;I sort of lied when I said linear regressionÂ is&lt;/p&gt;
&lt;div class="math"&gt;$$ h_{\theta}(x) = \theta_0x_0 + \theta_1x_1 + \cdots + \theta_nx_n $$&lt;/div&gt;
&lt;p&gt;I mean, it is. But that function gives the idealized, &lt;em&gt;predicted&lt;/em&gt; value, the &lt;span class="math"&gt;\(\hat y\)&lt;/span&gt;. The &lt;em&gt;real&lt;/em&gt; valueÂ is&lt;/p&gt;
&lt;div class="math"&gt;$$ y = \theta_0x_0 + \theta_1x_1 + \cdots + \theta_nx_n + \textcolor{magenta}{\epsilon} $$&lt;/div&gt;
&lt;p&gt;(And in statistics they use &lt;span class="math"&gt;\(\beta\)&lt;/span&gt; rather than &lt;span class="math"&gt;\(\theta\)&lt;/span&gt;, just to keep you on yourÂ toes.)&lt;/p&gt;
&lt;p&gt;This &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; is called the &lt;strong&gt;random error&lt;/strong&gt;, which sounds like the consequence of a really sloppy programmer, but is simply a way of dealing with the unavoidable fact that no model can beÂ perfect.&lt;/p&gt;
&lt;p&gt;Remember how we used the &lt;em&gt;actual&lt;/em&gt; error (&lt;span class="math"&gt;\(\hatY - Y\)&lt;/span&gt;) to compute the distance between our hypothetical line of best fit and each data point? The random error is basically sayingÂ that&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The regression line is the line that best fitsâ€”not &lt;em&gt;perfectly&lt;/em&gt; fitsâ€”the data used to create it,Â and&lt;/li&gt;
&lt;li&gt;Because of that, predictions made with the model are not likely to fall directly &lt;em&gt;on&lt;/em&gt; theÂ line.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That doesnâ€™t mean they &lt;em&gt;wonâ€™t&lt;/em&gt;, but we canâ€™t know for sure, and itâ€™s not likely. This uncertainty is captured by &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; (which we should hope is a small value, if not infinitesimal ğŸ˜…). &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; is considered to be takenÂ from&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;a normally distributed (bell curve) set ofÂ values&lt;/li&gt;
&lt;li&gt;with a mean ofÂ 0&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The second property makes sense; our line is the best-fitting line, so its underestimates should equal its overestimates). The first property is arbitraryâ€”you could choose any kind of probability distribution, but a bell curve is apparently the simplest one that is correct enough frequentlyÂ enough.&lt;/p&gt;
&lt;p&gt;This is more of a theoretical shim than anything that concerns atually coding a model, but itâ€™s still an importantÂ variable.&lt;/p&gt;
&lt;p&gt;In a future post, I will talk about a topic that takes &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; to the next level. StayÂ tuned!&lt;/p&gt;
&lt;h1 id="references"&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikibooks.org/wiki/Floating_Point/Epsilon"&gt;Floating Point/Epsilon&lt;/a&gt;,Â Wikibooks&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Floating-point_arithmetic"&gt;Floating-point arithmetic&lt;/a&gt;,Â Wikipedia&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www0.gsb.columbia.edu/faculty/pglasserman/B6014/Regression.pdf"&gt;B6014 Managerial Statistics: Linear Regression&lt;/a&gt;, Columbia BusinessÂ School&lt;/li&gt;
&lt;li&gt;&lt;a href="https://math.stackexchange.com/questions/1051863/assumption-of-a-random-error-term-in-a-regression"&gt;Assumption of a Random error term in a regression&lt;/a&gt;, StackExchangeÂ Mathematics&lt;/li&gt;
&lt;/ul&gt;</content><category term="convergence"></category><category term="floating-point"></category><category term="error"></category><category term="epsilon"></category></entry><entry><title>PIM notes, Chapter 2Â (Polynomials)</title><link href="http://tabidots.github.io/2019/01/pim-notes-chapter-2" rel="alternate"></link><published>2019-01-17T12:54:19+07:00</published><updated>2019-01-17T12:54:19+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-01-17:/2019/01/pim-notes-chapter-2</id><summary type="html">&lt;p&gt;My first experience with something that resembles a math textbook in many years, but this time with â€œbig kid math.â€ Itâ€™s&amp;nbsp;hard!&lt;/p&gt;</summary><content type="html">
&lt;p&gt;I started reading Jeremy Kunâ€™s &lt;em&gt;&lt;a href="https://pimbook.org/"&gt;A Programmerâ€™s Introduction to Mathematics&lt;/a&gt;&lt;/em&gt;. This is just a collection of my notes from Chapter 2, or code/math that I felt like writing/typesetting as an exercise while working through theÂ chapter.&lt;/p&gt;
&lt;p&gt;I activated the SuperFences Markdown plugin in the blogâ€™s settings, so itâ€™s really cool to write code for the same thing in different languages side-by-side. (The Java lexer is a little off,Â though.)&lt;/p&gt;
&lt;p&gt;Note: The chapter is divided into the â€œmain material,â€ an implementation of something that uses the relevant math, and exercises. I had actually gotten through the material and code part of the chapter last week, before I wrote about Markov matrices, and thought Iâ€™d be able to publish the complete notes in oneÂ go.&lt;/p&gt;
&lt;p&gt;However, the exercises are time-consuming and quickly get very difficult, so my impatience compels me to split this post in two, since itâ€™d be strange to be writing about &lt;span class="math"&gt;\(\Pi\)&lt;/span&gt; notation after covering way more advanced material! Iâ€™ll publish my answers to the exercises anotherÂ week.&lt;/p&gt;
&lt;h1 id="sum-summation"&gt;&lt;span class="math"&gt;\(\sum\)&lt;/span&gt;Â (Summation)&lt;/h1&gt;
&lt;p&gt;Summation notation wasnâ€™t new to me (I learned it the hard way trying to make sense of the linear regression stuff), nor was the Python equivalent. However, since it was presented in Java, I thought it was good opportunity to see the correspondence between Python and Java. When I first started learning to code (beyond web development), I ran away from Java with my tail between my legs, but now it makes a lot more sense. Itâ€™s just terribly verbose andÂ inefficient.&lt;/p&gt;
&lt;p&gt;Also, I wanted to use an easy example to get reacquainted with Clojure, my other favorite language, and pick up some R and Julia along the wayÂ too.&lt;/p&gt;
&lt;div class="math"&gt;$$ f(x) = \sum_{i=0}^x i $$&lt;/div&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_1_0" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;sum_to&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;sum_to&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;list_comp_sum_to&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_1" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_1"&gt;Clojure&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;sum-to&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="nv"&gt;+&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;

&lt;span class="nv"&gt;user=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;sum-to&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;6&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_2" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_2"&gt;Java&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;main&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
  &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;sumTo&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;mySum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
      &lt;span class="n"&gt;mySum&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;mySum&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
  &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;

&lt;span class="n"&gt;jshell&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;sumTo&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;$9&lt;/span&gt; &lt;span class="o"&gt;==&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;55&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_3" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_3"&gt;Julia&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;function&lt;/span&gt; &lt;span class="n"&gt;sum_to&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;
        &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;
    &lt;span class="k"&gt;end&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;

&lt;span class="n"&gt;julia&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;sum_to&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;6&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_4" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_4"&gt;R&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sum_to&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;
  &lt;span class="nf"&gt;for &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="n"&gt;result&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;sum_to&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;[1]&lt;/span&gt; &lt;span class="m"&gt;4&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id="prod-pi-product"&gt;&lt;span class="math"&gt;\(\prod\)&lt;/span&gt;Â (Pi-product)&lt;/h1&gt;
&lt;p&gt;This was new to me, and so was the existence of the &lt;code class="highlight"&gt;*=&lt;/code&gt; operator, which I guess I had never had a needÂ for.&lt;/p&gt;
&lt;div class="math"&gt;$$ g(x) = \prod_{j=1}^x i $$&lt;/div&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_2_0" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;mult_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;*=&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;mult_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="mi"&gt;120&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_2_1" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_1"&gt;Clojure&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;mult-all&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="nv"&gt;*&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;

&lt;span class="nv"&gt;user=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mult-all&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;120&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_2_2" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_2"&gt;Java&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;main&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
  &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;multAll&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;myProd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
      &lt;span class="n"&gt;myProd&lt;/span&gt; &lt;span class="o"&gt;*=&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;myProd&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
  &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;

&lt;span class="n"&gt;jshell&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;multAll&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;$10&lt;/span&gt; &lt;span class="o"&gt;==&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;120&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_2_3" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_3"&gt;Julia&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;function&lt;/span&gt; &lt;span class="n"&gt;mult_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;
        &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;*=&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;
    &lt;span class="k"&gt;end&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;

&lt;span class="n"&gt;julia&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;mult_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;120&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_2_4" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_4"&gt;R&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;mult_all&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;
  &lt;span class="nf"&gt;for &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="n"&gt;result&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;mult_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;[1]&lt;/span&gt; &lt;span class="m"&gt;120&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id="sumprod-nested-product-in-sum"&gt;&lt;span class="math"&gt;\(\sum\prod\)&lt;/span&gt; (Nested product inÂ sum)&lt;/h1&gt;
&lt;p&gt;Pretty wild. I tried really hard to translate this into Clojure, but I couldnâ€™tÂ as-is.&lt;/p&gt;
&lt;div class="math"&gt;$$ f(x) = \sum_{i=0}^n \textrm{bar}(i) \Bigg(\prod_{j \not = i} \textrm{foo}(i, j)\Bigg) $$&lt;/div&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_3_0" name="__tabs_3" type="radio"/&gt;
&lt;label for="__tab_3_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;inner&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;continue&lt;/span&gt;
        &lt;span class="n"&gt;inner&lt;/span&gt; &lt;span class="o"&gt;*=&lt;/span&gt; &lt;span class="n"&gt;foo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;bar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;inner&lt;/span&gt;
&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_3_1" name="__tabs_3" type="radio"/&gt;
&lt;label for="__tab_3_1"&gt;Java&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;innerProd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="o"&gt;++)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
      &lt;span class="n"&gt;innerProd&lt;/span&gt; &lt;span class="o"&gt;*=&lt;/span&gt; &lt;span class="n"&gt;foo&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
  &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;bar&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;inner&lt;/span&gt;
  &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id="horners-method"&gt;Hornerâ€™sÂ Method&lt;/h1&gt;
&lt;p&gt;I had never heard of this until I encountered it in the code for the authorâ€™s &lt;code class="highlight"&gt;Polynomial&lt;/code&gt; class. It is definitely easier to understand how it works in Python than it is to understand why it worksÂ mathematically!&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned} \sum_{i=0}^{n-1} a_i x^i &amp;amp;= a_0 + a_1 x + a_2 x^2 + \cdots + a_{n-1} x^{n-1} \\
&amp;amp;= a_0 + x(a_1 + x(a_2 + \cdots + x\,a_{n-1})) \end{aligned} $$&lt;/div&gt;
&lt;p&gt;Cooler still, the recursion evident in the Python code means that it can be implemented as a &lt;code class="highlight"&gt;reduce&lt;/code&gt; in functional programming, making it extremely concise andÂ loopless.&lt;/p&gt;
&lt;p&gt;If &lt;span class="math"&gt;\(f(x) = 2x^3 + 4x + 3\)&lt;/span&gt;, letâ€™s find &lt;span class="math"&gt;\(f(2)\)&lt;/span&gt; with Hornerâ€™sÂ method.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_4_0" name="__tabs_4" type="radio"/&gt;
&lt;label for="__tab_4_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;horners_method&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coefficients&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;reversed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coefficients&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;horners_method&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="mi"&gt;27&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_4_1" name="__tabs_4" type="radio"/&gt;
&lt;label for="__tab_4_1"&gt;Clojure&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;horners-method&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;coefs&lt;/span&gt; &lt;span class="nv"&gt;x&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="nv"&gt;%2&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;* &lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="nv"&gt;%1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reverse &lt;/span&gt;&lt;span class="nv"&gt;coefs&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

&lt;span class="nv"&gt;user=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;horners-method&lt;/span&gt; &lt;span class="nv"&gt;coefs&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;27&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_4_2" name="__tabs_4" type="radio"/&gt;
&lt;label for="__tab_4_2"&gt;Java&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;main&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
  &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="nf"&gt;hornersMethod&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;coefficients&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;coefficients&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;length&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;--)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
      &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;coefficients&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;];&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
  &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;

&lt;span class="n"&gt;jshell&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;hornersMethod&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;[]&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;},&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;$32&lt;/span&gt; &lt;span class="o"&gt;==&amp;gt;&lt;/span&gt; &lt;span class="mf"&gt;27.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id="nested-polynomials"&gt;NestedÂ polynomials&lt;/h1&gt;
&lt;p&gt;Speaking of nested polynomials, in the section on interpolating polynomials (normal ones), I was stuck on this line in the function &lt;code class="highlight"&gt;single_term()&lt;/code&gt; for aÂ bit:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;single_term&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;theTerm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;xi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;yi&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;continue&lt;/span&gt;

        &lt;span class="n"&gt;xj&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="hll"&gt;        &lt;span class="n"&gt;theTerm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;theTerm&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;xj&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xi&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;xj&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xi&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;xj&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;
&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;theTerm&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;yi&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This function is supposed to get us the term of the polynomial for point &lt;span class="math"&gt;\(i\)&lt;/span&gt; of the points we feed it. Itâ€™s this, without theÂ summation:&lt;/p&gt;
&lt;div class="math"&gt;$$ f(x) = \sum_{i=0}^n y_i \Bigg(\prod_{j \not= i} \frac{x - x_j}{x_i - x_j}\Bigg) $$&lt;/div&gt;
&lt;p&gt;How does the fraction &lt;span class="math"&gt;\(\frac{x - x_j}{x_i - x_j}\)&lt;/span&gt; get broken down into &lt;code class="highlight"&gt;Polynomial(&lt;/code&gt;&lt;span class="math"&gt;\(\frac{-x_j}{x_i - x_j}, \frac{1}{x_i - x_j}\)&lt;/span&gt;&lt;code class="highlight"&gt;)&lt;/code&gt;?&lt;/p&gt;
&lt;p&gt;&lt;code class="highlight"&gt;&lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;/code&gt; produces a polynomial &lt;span class="math"&gt;\(a\textcolor{lightgray}{x^0} + b\textcolor{orange}x\textcolor{lightgray}{^1} + c\textcolor{orange}{x^2}\)&lt;/span&gt;, so &lt;code class="highlight"&gt;&lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;xj&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xi&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;xj&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xi&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;xj&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;&lt;/code&gt; yields&lt;/p&gt;
&lt;div class="math"&gt;$$\frac{-\textcolor{maroon}{x_j}}{\textcolor{teal}{x_i} - \textcolor{maroon}{x_j}} + \frac{1}{\textcolor{teal}{x_i} - \textcolor{maroon}{x_j}}\textcolor{orange}x = \frac{\textcolor{orange}x - \textcolor{maroon}{x_j}}{\textcolor{teal}{x_i} - \textcolor{maroon}{x_j}}$$&lt;/div&gt;
&lt;p&gt;Ah, makes sense. Itâ€˜s easy to miss (for me, anyway), but the function &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; isnâ€™t the only polynomial hereâ€”the term within the &lt;span class="math"&gt;\(\prod\)&lt;/span&gt; is itself also aÂ polynomial.&lt;/p&gt;
&lt;p&gt;At first, I thought it was just a clever trick, but the reason for factoring out the &lt;span class="math"&gt;\(x\)&lt;/span&gt; without a subscript is basically that unlike everything else in the entire function, that &lt;span class="math"&gt;\(x\)&lt;/span&gt; is &lt;em&gt;not&lt;/em&gt; being iterated over by either the &lt;span class="math"&gt;\(\prod\)&lt;/span&gt; (iterator &lt;span class="math"&gt;\(j\)&lt;/span&gt;) or &lt;span class="math"&gt;\(\sum\)&lt;/span&gt; (iterator &lt;span class="math"&gt;\(i\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;Itâ€™s the general indeterminate quantity &lt;span class="math"&gt;\(\textcolor{orange}x\)&lt;/span&gt;, and not &lt;span class="math"&gt;\(\textcolor{teal}{x_i}\)&lt;/span&gt; or &lt;span class="math"&gt;\(\textcolor{maroon}{x_j}\)&lt;/span&gt; (i.e., the x-coordinate of one of the &lt;span class="math"&gt;\(n\)&lt;/span&gt; points that we provided to the function), which are actually part of the coefficients here. Incidentally, separating the static &lt;code class="highlight"&gt;x&lt;/code&gt; from the dynamic &lt;code class="highlight"&gt;x&lt;/code&gt;s was a stumbling block for me as I imagined how to tackleÂ this.&lt;/p&gt;</content><category term="pimbook"></category></entry><entry><title>Zen Coding: A Markov chain inÂ Clojure</title><link href="http://tabidots.github.io/2019/01/markov-chain-in-clojure" rel="alternate"></link><published>2019-01-16T21:06:57+07:00</published><updated>2019-01-16T21:06:57+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-01-16:/2019/01/markov-chain-in-clojure</id><summary type="html">&lt;p&gt;Clojure is so terse and Zen-like. I love it. This is the Clojure translation of the Markov chain implementation I wrote in Python&amp;nbsp;yesterday.&lt;/p&gt;</summary><content type="html">
&lt;p&gt;Iâ€™m currently in the middle of, among learning many new things, getting back into Clojure. I never really could imagine deploying production-grade Clojure programs, but writing code in a functional paradigm is always a fascinating, challenging, and rewardingÂ exercise.&lt;/p&gt;
&lt;p&gt;Plus, any Lisp looks pretty cool syntactically, and such languages are always extremelyÂ terse.&lt;/p&gt;
&lt;p&gt;Hereâ€™s a Clojure adaptation of the &lt;span class="caps"&gt;HIV&lt;/span&gt;/&lt;span class="caps"&gt;AIDS&lt;/span&gt; Markov chain scenario model that I wrote about and implemented in Python yesterday. Look at how short itÂ is!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;require&lt;/span&gt; &lt;span class="o"&gt;'&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;clojupyter.misc.helper&lt;/span&gt; &lt;span class="ss"&gt;:as&lt;/span&gt; &lt;span class="nv"&gt;helper&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;helper/add-dependencies&lt;/span&gt; &lt;span class="o"&gt;'&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;net.mikera/core.matrix&lt;/span&gt; &lt;span class="s"&gt;"0.62.0"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;use&lt;/span&gt; &lt;span class="o"&gt;'&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;clojure.core.matrix&lt;/span&gt; &lt;span class="ss"&gt;:as&lt;/span&gt; &lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;def &lt;/span&gt;&lt;span class="nv"&gt;hiv&lt;/span&gt; &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mf"&gt;0.9&lt;/span&gt; &lt;span class="mf"&gt;0.07&lt;/span&gt; &lt;span class="mf"&gt;0.02&lt;/span&gt; &lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mf"&gt;0.93&lt;/span&gt; &lt;span class="mf"&gt;0.05&lt;/span&gt; &lt;span class="mf"&gt;0.02&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mf"&gt;0.85&lt;/span&gt; &lt;span class="mf"&gt;0.15&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;def &lt;/span&gt;&lt;span class="nv"&gt;p-0&lt;/span&gt; &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mf"&gt;0.85&lt;/span&gt;, &lt;span class="mf"&gt;0.1&lt;/span&gt;, &lt;span class="mf"&gt;0.05&lt;/span&gt;, &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;evolutions&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;p-matrix&lt;/span&gt; &lt;span class="nv"&gt;initial&lt;/span&gt; &lt;span class="nv"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;reductions&lt;/span&gt; &lt;span class="nv"&gt;m/mmul&lt;/span&gt;
              &lt;span class="nv"&gt;initial&lt;/span&gt;
              &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;repeat &lt;/span&gt;&lt;span class="nv"&gt;steps&lt;/span&gt; &lt;span class="nv"&gt;p-matrix&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;future-distribution&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;p-matrix&lt;/span&gt; &lt;span class="nv"&gt;initial&lt;/span&gt; &lt;span class="nv"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;last&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;evolutions&lt;/span&gt; &lt;span class="nv"&gt;p-matrix&lt;/span&gt;
                &lt;span class="nv"&gt;initial&lt;/span&gt;
                &lt;span class="nv"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;watch-evolve&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;column&lt;/span&gt; &lt;span class="nv"&gt;p-matrix&lt;/span&gt; &lt;span class="nv"&gt;initial&lt;/span&gt; &lt;span class="nv"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;evolutions&lt;/span&gt; &lt;span class="nv"&gt;p-matrix&lt;/span&gt;
                  &lt;span class="nv"&gt;initial&lt;/span&gt;
                  &lt;span class="nv"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;get-column&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;get-column&lt;/span&gt; &lt;span class="nv"&gt;column&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: Itâ€™s written in a way that works in &lt;a href="https://blog.nteract.io/hydrogen-interactive-computing-in-atom-89d291bcc4dd"&gt;Hydrogen&lt;/a&gt; for Atom (i.e., via a hidden Jupyter Notebook). Iâ€™m not sure how youâ€™d go about importing &lt;a href="https://github.com/mikera/core.matrix/"&gt;core.matrix&lt;/a&gt; in a one-off &lt;span class="caps"&gt;REPL&lt;/span&gt; session (not a Leiningen project), but now that Iâ€™ve discovered Hydrogen, I doubt there will be many terminal &lt;span class="caps"&gt;REPL&lt;/span&gt; sessions in myÂ future!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Coding in Clojure means non-object-oriented and no mutable state. You can write a function to compute the probability distribution at time &lt;span class="math"&gt;\(t\)&lt;/span&gt;, but the system wonâ€™t stay in thatÂ state.&lt;/p&gt;
&lt;p&gt;In fact, there &lt;em&gt;is&lt;/em&gt; no systemâ€”&lt;strong&gt;only evolution&lt;/strong&gt;. In that sense, you quite literally end up with a &lt;em&gt;memoryless&lt;/em&gt; Markov chain. The design philosophy of Clojure is all about impermanence, which is very Zen, when you think about it. (Would that make each program aÂ koan?)&lt;/p&gt;
&lt;p&gt;Letâ€™s take a quick tour of theÂ functions.&lt;/p&gt;
&lt;p&gt;First, there is &lt;code class="highlight"&gt;evolutions [p-matrix initial steps]&lt;/code&gt;. Thatâ€™s a base function that works as a building block for the other functions. In pseudo-math, it would look likeÂ this:&lt;/p&gt;
&lt;div class="math"&gt;$$ E(P, \pi^{(0)}, t) = {\pi^{(1)}, \cdots, \pi^{(t)}} $$&lt;/div&gt;
&lt;p&gt;Itâ€™s easy to see that computing some &lt;span class="math"&gt;\(\pi^{(n)}\)&lt;/span&gt;, the probability distribution (state of the system) at a given time, can be accomplished with a single &lt;code class="highlight"&gt;reduce&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;But Clojure has an interesting function &lt;code class="highlight"&gt;reductions&lt;/code&gt; (&lt;a href="https://clojuredocs.org/clojure.core/reductions"&gt;docs&lt;/a&gt;), which stores all of the intermediate outputs in a list, with the expected output of &lt;code class="highlight"&gt;reduce&lt;/code&gt; as the last entry. So it makes sense to write two functionsÂ here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;one, &lt;code class="highlight"&gt;evolutions&lt;/code&gt;, that gives us &lt;em&gt;all&lt;/em&gt; &lt;span class="math"&gt;\(\{\pi^{(1)}, \cdots, \pi^{(t)}\}\)&lt;/span&gt;,Â and&lt;/li&gt;
&lt;li&gt;another, &lt;code class="highlight"&gt;future-distribution&lt;/code&gt;, that takes the same inputs and outputs only the &lt;code class="highlight"&gt;last&lt;/code&gt; evolution.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;InÂ pseudo-math:&lt;/p&gt;
&lt;div class="math"&gt;$$ F(P, \pi^{(0)}, t) = \pi^{(t)} $$&lt;/div&gt;
&lt;p&gt;InÂ action:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;future-distribution&lt;/span&gt; &lt;span class="nv"&gt;hiv&lt;/span&gt; &lt;span class="nv"&gt;p-0&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;; =&amp;gt; [[0.10334015640198398 0.24687062185910383 0.12037223090781371 0.5294169908310989]]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;What else can we do with the output of &lt;code class="highlight"&gt;evolutions&lt;/code&gt;? Well, we can choose one state of the system and watch its distribution evolve over time by picking out the &lt;span class="math"&gt;\(k\)&lt;/span&gt;-th item of each evolution (a rowÂ vector).&lt;/p&gt;
&lt;p&gt;In this case, we can observe how the proportion of a segment of the population (asymptomatic, symptomatic, has &lt;span class="caps"&gt;AIDS&lt;/span&gt;, dead) changes over &lt;span class="math"&gt;\(t\)&lt;/span&gt;Â time-steps.&lt;/p&gt;
&lt;p&gt;InÂ pseudo-math:&lt;/p&gt;
&lt;div class="math"&gt;$$ W(s, P, \pi^{(0)}, t) = \Big\{ P(s_0), P(s_1 | s_0), \cdots, P(s_t | s_{t-1}) \Big\} $$&lt;/div&gt;
&lt;p&gt;InÂ action:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;watch-evolve&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;hiv&lt;/span&gt; &lt;span class="nv"&gt;p-0&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;; =&amp;gt; [0.85 0.765 0.6885 0.61965 0.5576850000000001 0.5019165000000001]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;What a coolÂ language.&lt;/p&gt;</content><category term="clojure"></category><category term="recursion"></category><category term="markov chain"></category></entry><entry><title>Outer State Space Race: Markov chains andÂ matrices</title><link href="http://tabidots.github.io/2019/01/outer-state-space-race" rel="alternate"></link><published>2019-01-16T02:10:30+07:00</published><updated>2019-01-16T02:10:30+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-01-16:/2019/01/outer-state-space-race</id><summary type="html">&lt;p&gt;â€State spaceâ€ is the coolest term Iâ€™ve learned in a while. Also, I implemented a simple Markov chain, from scratch, as a Python&amp;nbsp;class.&lt;/p&gt;</summary><content type="html">
&lt;p&gt;I had heard of Markov chains before, but because my perspective had always been tightly focused on language, I never felt they were reallyÂ useful.&lt;/p&gt;
&lt;p&gt;To review, a Markov chain basically describes a scenario or system where one event leads to other events (and so on, perhaps in a cycle) with varying probabilities, but &lt;em&gt;the probability of any one event leading to another given event is completely independent of all other probabilities&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;In &lt;a href="https://www.youtube.com/watch?v=0Il-y_WLTo4"&gt;the &lt;span class="caps"&gt;HIV&lt;/span&gt;/&lt;span class="caps"&gt;AIDS&lt;/span&gt; scenario model&lt;/a&gt; that originally got me interested in learning about Markov chains, the chances of your next â€œstepâ€â€”future health outcomeâ€”depend &lt;em&gt;only&lt;/em&gt; on your presentÂ status.&lt;/p&gt;
&lt;p&gt;This is called the &lt;strong&gt;Markov property&lt;/strong&gt;. Itâ€™s like the opposite of the Monty Hall problem I wrote about previously. The probability of there being a car behind Door 2 &lt;em&gt;changes&lt;/em&gt; after Monty opens Door 3. Meanwhile, in a Markov chain, every probability is independent of theÂ others.&lt;/p&gt;
&lt;p&gt;Markov chains, as far as I know, have limited usefulness in natural language processing, because sequences of language dataâ€”letters, words, sentences, paragraphsâ€”are highly dependent on not only the previous item, but to some extent &lt;em&gt;all&lt;/em&gt; previousÂ items.&lt;/p&gt;
&lt;p&gt;You can see the implications of this in Markov text generators, based on everything from Shakespeare to Eminem, that struggle to produce anything meaningful. Or in the case of part-of-speech tagging, it is simply inaccurate that a &lt;span class="caps"&gt;POS&lt;/span&gt; of a word could depend &lt;em&gt;only&lt;/em&gt; on the &lt;span class="caps"&gt;POS&lt;/span&gt; of the previousÂ word.&lt;/p&gt;
&lt;p&gt;(Even human brains falter in processing so-called &lt;em&gt;garden path sentences&lt;/em&gt;, such as â€œThe horse raced past the barn fell,â€ where you expect perhaps an adverb of some sort after the wordÂ â€œbarn.â€)&lt;/p&gt;
&lt;h1 id="matrix-izing-a-markov-chain"&gt;Matrix-izing a MarkovÂ chain&lt;/h1&gt;
&lt;p&gt;The simplest representation of a Markov chain is called a &lt;em&gt;transition diagram&lt;/em&gt;, which basically looks like a flowchart (although it could be cyclical) with arrows going between different states and probability values attached to thoseÂ arrows.&lt;/p&gt;
&lt;p&gt;Now, what recently got me interested in Markov chains, as I &lt;a href="2019/01/monty-hall-beginner"&gt;wrote previously&lt;/a&gt;, is the fact that they can also be represented by matrices, and manipulated with the tools of linearÂ algebra.&lt;/p&gt;
&lt;p&gt;The following is a Markov chain as a matrix, also known as a &lt;strong&gt;transition matrix&lt;/strong&gt;, since the values in the matrix represent the probabilities of transitioning from one state to another. In this case, suppose our system has fiveÂ states.&lt;/p&gt;
&lt;p&gt;(Annotating a matrix is beyond my &lt;span class="math"&gt;\(\LaTeX\)&lt;/span&gt; skillsâ€”and perhaps the capabilities of the &lt;span class="math"&gt;\(\KaTeX\)&lt;/span&gt; rendererâ€”so I will use a codeÂ block.)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;                  &lt;span class="n"&gt;you&lt;/span&gt; &lt;span class="n"&gt;want&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;go&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt;
                      &lt;span class="n"&gt;A&lt;/span&gt;  &lt;span class="n"&gt;B&lt;/span&gt;  &lt;span class="n"&gt;C&lt;/span&gt;  &lt;span class="n"&gt;D&lt;/span&gt;  &lt;span class="n"&gt;E&lt;/span&gt;
                  &lt;span class="n"&gt;A&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="n"&gt;probabilities&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;sum&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;reading&lt;/span&gt; &lt;span class="n"&gt;across&lt;/span&gt;
                  &lt;span class="n"&gt;B&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="n"&gt;probabilities&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;          &lt;span class="s"&gt;""&lt;/span&gt;
&lt;span class="hll"&gt; &lt;span class="n"&gt;you&lt;/span&gt; &lt;span class="n"&gt;are&lt;/span&gt; &lt;span class="kp"&gt;in&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="n"&gt;probabilities&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;          &lt;span class="s"&gt;""&lt;/span&gt;
&lt;/span&gt;                  &lt;span class="n"&gt;D&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="n"&gt;probabilities&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;          &lt;span class="s"&gt;""&lt;/span&gt;
                  &lt;span class="n"&gt;E&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="n"&gt;probabilities&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;          &lt;span class="s"&gt;""&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The collection of &lt;em&gt;possible states&lt;/em&gt; of a system is called its &lt;strong&gt;state space&lt;/strong&gt; (what a cool term!) and notated as &lt;span class="math"&gt;\(S = \{1,2,3,\cdots,N\}\)&lt;/span&gt; in the general case. For our system, itâ€™s &lt;span class="math"&gt;\(S = \{A, B, C, D, E\}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;To give a more concrete example, for a text-generating Markov chain, the state space would include all the relevant units (letters of the alphabet plus spaces and punctuation for a character-by-character generator, words in the vocabulary for a word-by-word generator,Â etc.).&lt;/p&gt;
&lt;p&gt;In formal notation, a possible &lt;strong&gt;transition matrix&lt;/strong&gt; (a.k.a. Markov matrix, stochastic matrix) might look something likeÂ this:&lt;/p&gt;
&lt;div class="math"&gt;$$ P = \begin{bmatrix}
1\over4 &amp;amp; 1\over2 &amp;amp; 1\over4 \\[0.5em]
1\over3 &amp;amp; 0       &amp;amp; 2\over3 \\[0.5em]
1\over2 &amp;amp; 0       &amp;amp; 1\over2 \end{bmatrix} $$&lt;/div&gt;
&lt;p&gt;Capital &lt;span class="math"&gt;\(P\)&lt;/span&gt; represents the whole matrix and each small &lt;span class="math"&gt;\(p\)&lt;/span&gt; with subscripts (&lt;span class="math"&gt;\(p_{ij}\)&lt;/span&gt;, like &lt;span class="math"&gt;\(p_{DE}\)&lt;/span&gt;) represents the probability of going from state &lt;span class="math"&gt;\(i\)&lt;/span&gt; (some row) to state &lt;span class="math"&gt;\(j\)&lt;/span&gt; (some column in that row). &lt;span class="math"&gt;\(p_{ij}\)&lt;/span&gt; can also be used in a general sense to mean &lt;em&gt;all&lt;/em&gt; of the probabilities in theÂ matrix.&lt;/p&gt;
&lt;p&gt;Each row must add up to 1 because it includes every possible next step from thatÂ state.&lt;/p&gt;
&lt;p&gt;Also note that the probabilities of the state &lt;em&gt;staying the same&lt;/em&gt; from one time step to the next run along the diagonal from top left to bottom right, which means that the identity matrix would represent a static systemâ€”one that &lt;em&gt;never changes&lt;/em&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ P = \begin{bmatrix}
1 &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; 1 &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 1 \end{bmatrix} $$&lt;/div&gt;
&lt;h1 id="when-pi-is-not-pi"&gt;When &lt;span class="math"&gt;\(\pi\)&lt;/span&gt; is not &lt;span class="math"&gt;\(\pi\)&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;Now, a transition matrix by itself doesnâ€™t really have any added value compared to the transition diagram it represents, other than looking nicely organized. So letâ€™s make a simple matrix with some random values and do matrix-y stuff with it, like multiply it byÂ something.&lt;/p&gt;
&lt;p&gt;For the time being, I live in Southeast Asia and I eat mostly local food, which means that for any given meal, thereâ€™ll either be rice or noodles on my plate. (Not that Iâ€™m complainingâ€”everything is ridiculouslyÂ tasty!)&lt;/p&gt;
&lt;p&gt;Consider a system &lt;span class="math"&gt;\(X\)&lt;/span&gt; (thatâ€™s the conventional choice of letter) that describes my meals with a state space &lt;span class="math"&gt;\(S = \{N, R\}\)&lt;/span&gt;. The transition matrix &lt;span class="math"&gt;\(P\)&lt;/span&gt; isÂ then&lt;/p&gt;
&lt;div class="math"&gt;$$ P = \begin{bmatrix}
0.4 &amp;amp; 0.6 \\
0.2 &amp;amp; 0.8 \end{bmatrix} $$&lt;/div&gt;
&lt;p&gt;Again, I canâ€™t label the rows and columns of the matrix, so letâ€™s stick to alphabetical order and make &lt;span class="math"&gt;\(N\)&lt;/span&gt; first.Â Thus:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class="math"&gt;\(p_{NN}\)&lt;/span&gt;, probability of repeating noodles: &lt;span class="math"&gt;\(0.4\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(p_{NR}\)&lt;/span&gt;, probability of rice after noodles: &lt;span class="math"&gt;\(0.6\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(p_{RN}\)&lt;/span&gt;, probability of noodles after rice: &lt;span class="math"&gt;\(0.2\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(p_{RR}\)&lt;/span&gt;, probability of repeating rice: &lt;span class="math"&gt;\(0.8\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The initial state can be represented by a row vector with &lt;span class="math"&gt;\(S\)&lt;/span&gt; values (i.e., as many values as there are possible states), with a 1 in the spot corresponding to the current state and a 0 for all otherÂ states.&lt;/p&gt;
&lt;p&gt;If my first meal was a noodle dish, then I can express that initial state likeÂ this:&lt;/p&gt;
&lt;div class="math"&gt;$$ \pi^{(0)} = \begin{bmatrix}1 &amp;amp; 0\end{bmatrix} $$&lt;/div&gt;
&lt;p&gt;The math notation for this is not soÂ straightforward.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Lowercase &lt;em&gt;pi&lt;/em&gt; here represents a given state, &lt;strong&gt;not&lt;/strong&gt; the constant &lt;em&gt;pi&lt;/em&gt; that relates to circles! I donâ€™t know who came up with that idea, but I donâ€™t think it was a wiseÂ choice.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The superscript number is also not what it seems: itâ€™s not an exponent, but rather the &lt;em&gt;number of time steps from now&lt;/em&gt;. So &lt;span class="math"&gt;\(\pi^{(0)}\)&lt;/span&gt; means our state at 0 time steps from now, or in other words,Â now.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Why is this vector of the more uncommon horizontal variety (i.e., a row vector)? Thatâ€™s a more complicated question (and the reason that I got stuck on the warmup problem in the Linear Algebra for CodersÂ course).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This is the part where I turned to Python because I couldnâ€™t get any farther with the mathÂ alone.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="n"&gt;meals&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mf"&gt;0.4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.6&lt;/span&gt;&lt;span class="p"&gt;],[&lt;/span&gt;&lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.8&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;span class="n"&gt;now&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id="the-next-step-and-the-ones-thereafter"&gt;The next step (and the onesÂ thereafter)&lt;/h1&gt;
&lt;p&gt;To find the probabilities for the next meal, we can multiply this vector and the transition matrix together. If you &lt;a href="https://www.youtube.com/watch?v=kYB8IZa5AuE"&gt;imagine matrix-vector multiplication as a vector undergoing a linear transformation&lt;/a&gt;, then this sort of makesÂ sense.&lt;/p&gt;
&lt;p&gt;Thereâ€™s a catch, though. Transition matrices are set up to be read &lt;em&gt;across&lt;/em&gt;, from left to right, with each row telling us the next-step probabilities &lt;em&gt;if&lt;/em&gt; we are in thatÂ state:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;                &lt;span class="n"&gt;you&lt;/span&gt; &lt;span class="n"&gt;want&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;go&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt;
                      &lt;span class="n"&gt;N&lt;/span&gt;    &lt;span class="n"&gt;R&lt;/span&gt;
&lt;span class="hll"&gt; &lt;span class="n"&gt;you&lt;/span&gt; &lt;span class="n"&gt;are&lt;/span&gt; &lt;span class="kp"&gt;in&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="mf"&gt;0.4&lt;/span&gt;  &lt;span class="mf"&gt;0.6&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;
&lt;/span&gt;                  &lt;span class="n"&gt;R&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="mf"&gt;0.2&lt;/span&gt;  &lt;span class="mf"&gt;0.8&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So if we already &lt;em&gt;know&lt;/em&gt; that we will be in state &lt;span class="math"&gt;\(N\)&lt;/span&gt; to begin with, we can essentially filter out the other rows, leaving a singleÂ row:&lt;/p&gt;
&lt;div class="math"&gt;$$ \pi^{(1)} = \begin{bmatrix}p_{NN} &amp;amp; p_{NR}\end{bmatrix} = \begin{bmatrix}0.4 &amp;amp; 0.6\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;Now, if we suppose that our state vector is a column vector &lt;span class="math"&gt;\(\vec v\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$ \vec v = \begin{bmatrix}1 \\ 0\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;and multiply it by theÂ matrix,&lt;/p&gt;
&lt;div class="math"&gt;$$ \pi^{(1)} \stackrel{?}{=} P\vec v
= \begin{bmatrix}
0.4 &amp;amp; 0.6 \\
0.2 &amp;amp; 0.8 \end{bmatrix} \begin{bmatrix}1 \\ 0\end{bmatrix}
= \begin{bmatrix}
1\cdot0.4 + \textcolor{lightgray}{0\cdot0.6} \\
1\cdot0.2 + \textcolor{lightgray}{0\cdot0.8} \end{bmatrix}
= \begin{bmatrix} 0.4 \\ 0.2 \end{bmatrix} $$&lt;/div&gt;
&lt;p&gt;Hmm, thatâ€™s not quite right. The values donâ€™t match what we know about our system, and we want a row, not aÂ column.&lt;/p&gt;
&lt;p&gt;Since the product of a matrix and a vector is the shape of the vector, &lt;span class="math"&gt;\(\pi^{(0)}\)&lt;/span&gt; should be a row vector if we want &lt;span class="math"&gt;\(\pi^{(1)}\)&lt;/span&gt; to be a row vector. We could also transpose the matrix, but then the rows of the matrix no longer represent probabilities of transitioning from a given state. Using a row vector maintains the idea that rows describe origin states and the property that values of rows add up toÂ 1.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\pi^{(1)} = \pi^{(0)}P &amp;amp;= \begin{bmatrix}1 &amp;amp; 0\end{bmatrix} \begin{bmatrix}
0.4 &amp;amp; 0.6 \\
0.2 &amp;amp; 0.8 \end{bmatrix} \\
&amp;amp;= \begin{bmatrix}
1\cdot0.4 + \textcolor{lightgray}{0\cdot0.2} &amp;amp;
1\cdot0.6 + \textcolor{lightgray}{0\cdot0.8} \end{bmatrix} \\
&amp;amp;= \begin{bmatrix} 0.4 &amp;amp; 0.6 \end{bmatrix}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;Intuitively, you can imagine that youâ€™re â€œfeedingâ€ the collection of probabilities through the state and getting the â€œtransformedâ€Â probabilities.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;now&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;meals&lt;/span&gt;
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mf"&gt;0.4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.6&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Also, since the probabilities at time &lt;span class="math"&gt;\(t + 1\)&lt;/span&gt; only depend on the probabilities at time &lt;span class="math"&gt;\(t\)&lt;/span&gt;, we can do this recursively to find &lt;span class="math"&gt;\(\pi^{(n)}\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;p1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;now&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;meals&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;p1&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;meals&lt;/span&gt;
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mf"&gt;0.28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.72&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt; &lt;span class="c1"&gt;# this is pi^(2), or probabilities at time 2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;On a day where I had noodles for breakfast, then, I have a 40% chance of having noodles and a 60% chance of having rice for lunch, and then a 28% chance of having noodles and a 72% chance of having rice forÂ dinner.&lt;/p&gt;
&lt;h1 id="other-possibilities-for-the-state-vector"&gt;Other possibilities for the stateÂ vector&lt;/h1&gt;
&lt;p&gt;Actually, I oversimplified the above example a bit. The state vector doesnâ€™t have to be a binary thing. Since its values must sum to 1, it can also reflect an initial probability &lt;em&gt;distribution&lt;/em&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ \pi^{(0)} = \begin{bmatrix}0.45 &amp;amp; 0.55\end{bmatrix} $$&lt;/div&gt;
&lt;p&gt;As you can see, this changes the subsequentÂ probabilities:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;now&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mf"&gt;0.45&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.55&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;now&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;meals&lt;/span&gt;
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mf"&gt;0.29&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.71&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In the &lt;span class="caps"&gt;HIV&lt;/span&gt;/&lt;span class="caps"&gt;AIDS&lt;/span&gt; scenario I referred to at the beginning of this post, the initial state vector is used to represent the population (since subsets of a population can be expressed as the probability that a random person will belong to thatÂ subset).&lt;/p&gt;
&lt;p&gt;Here are the givens of that problem. The states are &lt;em&gt;&lt;span class="caps"&gt;HIV&lt;/span&gt; asymptomatic, &lt;span class="caps"&gt;HIV&lt;/span&gt; symptomatic, &lt;span class="caps"&gt;AIDS&lt;/span&gt;,&lt;/em&gt; and &lt;em&gt;death&lt;/em&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{gathered} P = \begin{bmatrix}
0.97 &amp;amp; 0.07 &amp;amp; 0.02 &amp;amp; 0.01 \\
0    &amp;amp; 0.93 &amp;amp; 0.05 &amp;amp; 0.02 \\
0    &amp;amp; 0    &amp;amp; 0.85 &amp;amp; 0.15 \\
0    &amp;amp; 0    &amp;amp; 0    &amp;amp; 1.00 \end{bmatrix} \\
\pi^{(0)} = \begin{bmatrix} 0.85 &amp;amp; 0.10 &amp;amp; 0.05 &amp;amp; 0 \end{bmatrix}
\end{gathered} $$&lt;/div&gt;
&lt;p&gt;This means that the initial population was 85% asymptomatic, 10% symptomatic, 5% &lt;span class="caps"&gt;AIDS&lt;/span&gt; patients, and 0%Â dead.&lt;/p&gt;
&lt;p&gt;If we used a vector with a single 1 and the rest 0s, then that would represent the outcomes for a homogenous population, or more likely, a singleÂ person.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;hiv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mf"&gt;0.9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.07&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.02&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;  &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.93&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.02&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;  &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.85&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.15&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;  &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;   &lt;span class="p"&gt;]])&lt;/span&gt;
&lt;span class="n"&gt;population&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mf"&gt;0.85&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;33&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;population&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;hiv&lt;/span&gt;
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;33&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mf"&gt;0.765&lt;/span&gt; &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.1525&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.0645&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.018&lt;/span&gt; &lt;span class="p"&gt;]])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So the outcomes after 1 year (&lt;span class="math"&gt;\(t = 1\)&lt;/span&gt;) are 76.5% asymptomatic, 15.25% symptomatic, 6.45% &lt;span class="caps"&gt;AIDS&lt;/span&gt; patients, and 1.8%Â dead.&lt;/p&gt;
&lt;h1 id="python-izing-a-markov-chain"&gt;Python-izing a MarkovÂ chain&lt;/h1&gt;
&lt;p&gt;Maybe this is kind of overkill, but we can implement our system as aÂ class.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;MarkovChain&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;init_state&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;# Validate the matrix&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ndarray&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;init_state&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ndarray&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;TypeError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'The Markov matrix and state vector must be NumPy arrays.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Markov matrices must be square.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;matrix&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;any&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;init_state&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;any&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Probabilities cannot be negative.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Each row in a Markov matrix must sum to 1.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# Validate the init_state&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;init_state&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ndarray&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;TypeError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'The initial state vector must be a NumPy array.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;init_state&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'The state vector must have a shape of 1 x {matrix.shape[1]}.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;init_state&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'The values in the state vector must sum to 1.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matrix&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;init_state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;init_state&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;

        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;probs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;init_state&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;evolve&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;evolve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;            
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;probs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;probs&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matrix&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;status&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;probs_list&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;round&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;"%"&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;probs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'At time {self.time}, the transition probabilities are'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;probs_list&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;restart&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;init_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
          &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;init_state&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
              &lt;span class="n"&gt;init_state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;init_state&lt;/span&gt;
          &lt;span class="c1"&gt;# call with no args to start over with same initial state&lt;/span&gt;
          &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;init_state&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now we can see what the population will be like after many years with just a fewÂ keystrokes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MarkovChain&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hiv&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;population&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;At&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;transition&lt;/span&gt; &lt;span class="n"&gt;probabilities&lt;/span&gt; &lt;span class="n"&gt;are&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'76.5%'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'15.25%'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'6.45%'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'1.8%'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;41&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;evolve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;At&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;transition&lt;/span&gt; &lt;span class="n"&gt;probabilities&lt;/span&gt; &lt;span class="n"&gt;are&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'26.67%'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'31.53%'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'13.58%'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'28.21%'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;evolve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;At&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt; &lt;span class="mi"&gt;21&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;transition&lt;/span&gt; &lt;span class="n"&gt;probabilities&lt;/span&gt; &lt;span class="n"&gt;are&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'9.3%'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'23.68%'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'11.67%'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'55.34%'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;43&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;evolve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;At&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt; &lt;span class="mi"&gt;31&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;transition&lt;/span&gt; &lt;span class="n"&gt;probabilities&lt;/span&gt; &lt;span class="n"&gt;are&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'3.24%'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'14.4%'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'7.71%'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'74.65%'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;75% dead after 30 yearsâ€”grim outlook, to say the least. (Though to be fair, the model takes into account that people may and do die of things other than &lt;span class="caps"&gt;HIV&lt;/span&gt;/&lt;span class="caps"&gt;AIDS&lt;/span&gt;. This is represented in the matrix by the nonzero probabilities of asymptomatic people transitioning right toÂ death.)&lt;/p&gt;
&lt;p&gt;â€¦aaaand on that note, Iâ€™ll end this post here for now. I will write about Markov chains again in the nearÂ future.&lt;/p&gt;
&lt;h1 id="references"&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=0Il-y_WLTo4"&gt;Concepts of Markov Chains&lt;/a&gt; (video), PaulÂ Harper&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.stat.auckland.ac.nz/~fewster/325/notes/ch8.pdf"&gt;Stats 325, Chapter 8: Markov Chains&lt;/a&gt;, RachelÂ Fewster&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/@balamurali_m/markov-chain-simple-example-with-python-985d33b14d19"&gt;Markov Chain: Simple example with Python&lt;/a&gt;, BalamuraliÂ M&lt;/li&gt;
&lt;/ul&gt;</content><category term="Markov chain"></category><category term="linear algebra"></category></entry><entry><title>Monty, Monte, andâ€¦ Bayes: Statistics andÂ probability</title><link href="http://tabidots.github.io/2019/01/monty-hall-beginner" rel="alternate"></link><published>2019-01-12T10:54:19+07:00</published><updated>2019-01-12T10:54:19+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-01-12:/2019/01/monty-hall-beginner</id><summary type="html">&lt;p&gt;Getting stumped by some basic probability questions led me down a rabbit hole whereupon I stumbled across Bayesâ€™&amp;nbsp;theorem.&lt;/p&gt;</summary><content type="html">
&lt;p&gt;I thought I had familiarized myself enough with the basic workings of linear algebra after Week 1 that I thought Rachel Thomasâ€™ (&lt;a href="www.fast.ai"&gt;fast.ai&lt;/a&gt;)â€™s &lt;a href="https://www.youtube.com/watch?v=8iGzBMboA0I&amp;amp;index=2&amp;amp;list=PLtmWHNX-gukIc92m1K0P6bIOnZb-mg0hY&amp;amp;t=0s"&gt;Linear algebra for coders&lt;/a&gt; course would be a good way to deepen my knowledge by applying these newly learned concepts inÂ Python.&lt;/p&gt;
&lt;p&gt;But embarrassingly, even the first warmup problem was beyond me. It required the use of a Markov matrix, which is the application of linear algebra to probability. Then I realized I had no background in probability, so I tried Brilliantâ€™s &lt;a href="https://brilliant.org/courses/probability/introduction-to-probability/"&gt;Intro to Probability&lt;/a&gt;, whereupon I roundly botched a bunch of basic probabilityÂ questions.&lt;/p&gt;
&lt;p&gt;I found it really odd that I had just learned these mathematical techniques (basic linear algebra and multivariable calculus) to solve problems in a new way, yet while these probability problems &lt;em&gt;could&lt;/em&gt; be solved computationally, they are meant to be solved â€œintuitively.â€ Of course, that seems like a cruel joke, since their counterintuitive solutions make such problems seem more like ZenÂ koans.&lt;/p&gt;
&lt;h1 id="the-monty-hall-problem"&gt;The Monty HallÂ problem&lt;/h1&gt;
&lt;p&gt;Take, for example, the &lt;a href="https://en.wikipedia.org/wiki/Monty_Hall_problem"&gt;Monty Hall problem&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Suppose youâ€™re on a game show, and youâ€™re given the choice of three doors: Behind one door is a car; behind the others,Â goats.&lt;/p&gt;
&lt;p&gt;You pick a door, say No. 1, and the host, who knows whatâ€™s behind the doors, opens another door, say No. 3, which has a goat. He then says to you, â€œDo you want to pick door No.Â 2?â€&lt;/p&gt;
&lt;p&gt;Is it to your advantage to switch yourÂ choice?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Spoiler alert&lt;/strong&gt;: The answer is that you &lt;em&gt;do&lt;/em&gt; switch, because you would then have a &lt;span class="math"&gt;\(\frac{2}{3}\)&lt;/span&gt; probability of choosing theÂ car.&lt;/p&gt;
&lt;p&gt;Wait, what? How does a single door go from having a &lt;span class="math"&gt;\(\frac{1}{3}\)&lt;/span&gt; chance that the car is behind it to a &lt;span class="math"&gt;\(\frac{2}{3}\)&lt;/span&gt; chance? It seemed to me that you would now have a 50/50 chance, since there were two doorsÂ left.&lt;/p&gt;
&lt;p&gt;People tend to explain the rationale for the solution by increasing the number of doors to 100, and the number of doors revealed to 98. But this didnâ€™t change anything for me; you still ended up with 2 doors, and thus a 50/50Â chance.&lt;/p&gt;
&lt;p&gt;No number of doors, visual explanation, or animation seemed to help me understand it. Finally, I managed to find a &lt;a href="https://www.reddit.com/r/explainlikeimfive/comments/58cdw3/eli5_the_monty_hall_problem/d8zanoq"&gt;comment&lt;/a&gt; in an old &lt;a href="https://www.reddit.com/r/explainlikeimfive"&gt;&lt;span class="caps"&gt;ELI5&lt;/span&gt;&lt;/a&gt; thread that made it click forÂ me:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;As simply as possible: Donâ€™t think of it as three doors. Think of it as your door, and Montyâ€™s doors. The odds that you picked the right door are 1 in 3, and the odds that you didnâ€™t are 2 in 3,Â right?&lt;/p&gt;
&lt;p&gt;When Monty gets rid of one bad choice, he doesnâ€™t change the odds that your door is right - itâ€™s still 1 in 3. That means heâ€™s also not changing the odds that you arenâ€™t right - itâ€™s still 2 inÂ 3.&lt;/p&gt;
&lt;p&gt;Therefore youâ€™re not picking one door - youâ€™re picking two doors at the same time and getting the best possible outcome. If either of Montyâ€™s doors was right, you win; If both of Montyâ€™s doors were bad, youÂ lose.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Explained this way, it then makes sense that there would only be a 50/50 chance if you had two doors &lt;em&gt;to begin with&lt;/em&gt;. Or, if you had fallen into â€œthe probability trap of treating non-random information as if it were random,â€ as it has been described &lt;a href="https://sites.google.com/site/psmartinsite/Home/bridge-articles/the-monty-hall-trap"&gt;elsewhere&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id="statistical-approach"&gt;StatisticalÂ approach&lt;/h1&gt;
&lt;p&gt;Letâ€™s first try to simulate the game in Python. Iâ€™ll skip over explaining whatâ€™s going on in the code here, as itâ€™s prettyÂ elementary.&lt;/p&gt;
&lt;p&gt;I just added perpetual loops to avoid the problem of bad input (if you were going to get other people to play, forÂ example).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;random&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;monty_hall&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;doors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"a"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s2"&gt;"b"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s2"&gt;"c"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;car&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;first_choice&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Choose a door (a/b/c): "&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;first_choice&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;doors&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;break&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;doors&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;car&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;first_choice&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;monty_opens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;action&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Monty opens door {monty_opens}; do you switch? (y/n) "&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;"y"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="c1"&gt;# switch doors&lt;/span&gt;
            &lt;span class="n"&gt;final_choice&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;doors&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;first_choice&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;monty_opens&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            &lt;span class="k"&gt;break&lt;/span&gt;
        &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;"n"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;final_choice&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;first_choice&lt;/span&gt;
            &lt;span class="k"&gt;break&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;continue&lt;/span&gt;

    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Your final choice is door {final_choice}."&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;final_choice&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;car&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"You win! The car is behind door {car}."&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"You lose. The car was behind door {car}."&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Next, letâ€™s automate the process so that the computer decides randomly whether or not to switch, and returns us the information we need to analyze the outcomes (&lt;em&gt;stay/switch&lt;/em&gt; and &lt;em&gt;win/lose&lt;/em&gt;).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;monty_hall&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;doors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"a"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s2"&gt;"b"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s2"&gt;"c"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;car&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;first_choice&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;doors&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;car&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;first_choice&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;monty_opens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt;

    &lt;span class="n"&gt;switch_doors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;final_choice&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;doors&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;first_choice&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;monty_opens&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;switch_doors&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="n"&gt;first_choice&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;final_choice&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;car&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"switch_doors"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;switch_doors&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"result"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;monty_hall&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'switch_doors'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'result'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Just as we can get the computer to flip a million coins for us, we can also get it to confront the Monty Hall problem a million times (if we want). This is called a &lt;strong&gt;Monte Carlo simulation&lt;/strong&gt;. I was already familiar with this concept, but to offer a quick summary here, it basically leverages the &lt;strong&gt;law of large numbers&lt;/strong&gt;: If you perform the same experiment enough times, the real result eventually converges on the theoreticalÂ result.&lt;/p&gt;
&lt;p&gt;So letâ€™s code it with a simple loop, tallying the results in two lists, and taking advantage of the truthiness of booleans in Python to quickly analyze theÂ results:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;monte_monty&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;switch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stay&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;monty_hall&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"switch_doors"&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
            &lt;span class="n"&gt;switch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"result"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;stay&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"result"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;switch&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="c1"&gt;# avoid division by zero errors if you do 1 or 2 trials&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Switching won {sum(switch)} out of {len(switch)} times; probability of {round(sum(switch)/len(switch) * 100, 2)}%."&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;stay&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Staying won {sum(stay)} out of {len(stay)} times; probability of {round(sum(stay)/len(stay) * 100, 2)}%."&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To reiterate the explanation above, &lt;em&gt;if you perform the same experiment enough times, the real result eventually converges on the theoretical result.&lt;/em&gt; Watch what happens with just 25Â simulations:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;monte_monty&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Switching&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;58.33&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;
&lt;span class="n"&gt;Staying&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;30.77&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It is already clear after just 25 simulations that the probability of switching is significantly greater than that of staying. Letâ€™s keepÂ going.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;21&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;monte_monty&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Switching&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;18&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;29&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;62.07&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;
&lt;span class="n"&gt;Staying&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;21&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;33.33&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;monte_monty&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Switching&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;51&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;62.75&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;
&lt;span class="n"&gt;Staying&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;49&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;32.65&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;monte_monty&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Switching&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;330&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;496&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;66.53&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;
&lt;span class="n"&gt;Staying&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;169&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;504&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;33.53&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;monte_monty&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Switching&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;3376&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;5053&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;66.81&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;
&lt;span class="n"&gt;Staying&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;1675&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;4947&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;33.86&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;monte_monty&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Switching&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;33289&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;49759&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;66.9&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;
&lt;span class="n"&gt;Staying&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;16789&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;50241&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;33.42&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;26&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;monte_monty&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1000000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Switching&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;333204&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;500463&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;66.58&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;
&lt;span class="n"&gt;Staying&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;166298&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;499537&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;33.29&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;27&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;monte_monty&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10000000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Switching&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;3331217&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;4998552&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;66.64&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;
&lt;span class="n"&gt;Staying&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;1666441&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;5001448&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;33.32&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After 1000 runs, we pretty much obtain the theoretical probability of &lt;span class="math"&gt;\(\frac{2}{3}\)&lt;/span&gt; chance of a winning switch and &lt;span class="math"&gt;\(\frac{1}{3}\)&lt;/span&gt; chance of a winning stay, and after 10 million runs, we come within a hairâ€™s breadth ofÂ it.&lt;/p&gt;
&lt;p&gt;In this way, the Monte Carlo method is not that different from stochastic gradientÂ descent.&lt;/p&gt;
&lt;h1 id="probabilistic-approach"&gt;ProbabilisticÂ approach&lt;/h1&gt;
&lt;p&gt;There is another, less brute-force, more theoretical way of working out this answer using &lt;strong&gt;Bayesian inference&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Letâ€™s rephrase the problem. Instead of focusing on the probability of a certain action (&lt;em&gt;stay/switch&lt;/em&gt;) winning, weâ€™ll examine the probability of a car being behind door &lt;span class="math"&gt;\(x\)&lt;/span&gt; after Monty opens door &lt;span class="math"&gt;\(y\)&lt;/span&gt;, or in the language of &lt;strong&gt;conditional probability&lt;/strong&gt;, &lt;em&gt;given&lt;/em&gt; that Monty opens door &lt;span class="math"&gt;\(y\)&lt;/span&gt;. ThatÂ is,&lt;/p&gt;
&lt;div class="math"&gt;$$ P(\textrm{car}_x | \textrm{Monty}_y) $$&lt;/div&gt;
&lt;p&gt;Letâ€™s start with the &lt;em&gt;unconditional&lt;/em&gt; probability (i.e., before the game starts) of the car being behind each of the doors, &lt;span class="math"&gt;\(P(\textrm{car}_x)\)&lt;/span&gt;. There are three doors and one car,Â so&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{gathered} P(\textrm{car}_x) = \tfrac{1}{3} \\
\therefore P(\textrm{car}_a) = P(\textrm{car}_b) = P(\textrm{car}_c) = \tfrac{1}{3} \end{gathered} $$&lt;/div&gt;
&lt;p&gt;Next, letâ€™s determine the &lt;em&gt;unconditional&lt;/em&gt; probabilities (i.e., before the game starts) of Monty choosing each of the doors. Since he cannot choose the door you will have chosen, that leaves him with twoÂ doors:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{gathered} P(\textrm{Monty}_x) = \tfrac{1}{2} \\
\therefore P(\textrm{Monty}_a) = P(\textrm{Monty}_b) = P(\textrm{Monty}_c) = \tfrac{1}{2} \end{gathered} $$&lt;/div&gt;
&lt;p&gt;Now that we have our building blocks, letâ€™s plug in what we can into theÂ theorem:&lt;/p&gt;
&lt;div class="math"&gt;$$ P(H|E) = \frac{P(E|H) P(H)}{P(E)} $$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(H\)&lt;/span&gt; is the hypothesis weâ€™re interested in and &lt;span class="math"&gt;\(E\)&lt;/span&gt; is the plot-twist, game-changingÂ event.&lt;/p&gt;
&lt;p&gt;Letâ€™s assume our first choice is door A. If we want to know the probability of the car being behind door A after Monty opens door C (i.e., we win by staying), we can fill in what weÂ know:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned} P(\textrm{car}_a|\textrm{Monty}_c) &amp;amp;= \frac{P(\textrm{Monty}_c|\textrm{car}_a) P(\textrm{car}_a)}{P(\textrm{Monty}_c)} \\
&amp;amp;= \frac{P(\textrm{Monty}_c|\textrm{car}_a) \cdot \tfrac{1}{3} }{\tfrac{1}{2}} \end{aligned} $$&lt;/div&gt;
&lt;p&gt;which leaves one last probability to calculate, &lt;span class="math"&gt;\(P(\textrm{Monty}_c|\textrm{car}_a)\)&lt;/span&gt;. That is the probability that Monty will open door C if the car is behind doorÂ A.&lt;/p&gt;
&lt;p&gt;Monty canâ€™t choose your door (A) or the door with the car (also A), leaving him two choices. He is therefore equally likely to choose door B or C, which means that &lt;span class="math"&gt;\(P(\textrm{Monty}_c|\textrm{car}_a) = \tfrac{1}{2}\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$ P(\textrm{car}_a|\textrm{Monty}_c) = \frac{P(\textrm{Monty}_c|\textrm{car}_a) P(\textrm{car}_a)}{P(\textrm{Monty}_c)} = \frac{\tfrac{1}{2} \cdot \tfrac{1}{3} }{\tfrac{1}{2}} = \frac{1}{3} $$&lt;/div&gt;
&lt;p&gt;Though the theorem is quite convoluted, this answer agrees with our intuition and the Monte CarloÂ results.&lt;/p&gt;
&lt;p&gt;What about the probability that we win by switching (i.e., the probability that the car is behind door B after Monty opens doorÂ C)?&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned} P(\textrm{car}_b|\textrm{Monty}_c) &amp;amp;= \frac{P(\textrm{Monty}_c|\textrm{car}_b) P(\textrm{car}_b)}{P(\textrm{Monty}_c)} \\
&amp;amp;= \frac{P(\textrm{Monty}_c|\textrm{car}_b) \cdot \tfrac{1}{3} }{\tfrac{1}{2}} \end{aligned} $$&lt;/div&gt;
&lt;p&gt;In the case of &lt;span class="math"&gt;\(P(\textrm{Monty}_c|\textrm{car}_b)\)&lt;/span&gt;, we have chosen door A and the car is behind door B. Monty knows this, and he also canâ€™t choose the door youâ€™ve chosen, doorÂ A.&lt;/p&gt;
&lt;p&gt;His &lt;em&gt;only&lt;/em&gt; choice, then, is to choose door C, and therefore &lt;span class="math"&gt;\(P(\textrm{Monty}_c|\textrm{car}_b) = 1\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$ P(\textrm{car}_b|\textrm{Monty}_c) = \frac{P(\textrm{Monty}_c|\textrm{car}_b) P(\textrm{car}_b)}{P(\textrm{Monty}_c)} = \frac{1 \cdot \tfrac{1}{3} }{\tfrac{1}{2}} = \frac{2}{3} $$&lt;/div&gt;
&lt;p&gt;Again, the theorem agrees with the Monte Carlo results, although whether or not it also agrees with your intuition is a differentÂ question!&lt;/p&gt;
&lt;h1 id="where-do-we-go-from-here"&gt;Where do we go fromÂ here?&lt;/h1&gt;
&lt;p&gt;I know that the Monte Carlo method can be used to make predictions about the movements of the stock market. However, Iâ€™m totally new to probability theory, so Iâ€™m not yet sure where to go after Bayesâ€™ theorem. Iâ€™ll update this section once I find out and post about more generalized and sophisticated ways to apply Monte Carlo and Bayesâ€™ theorem. StayÂ tuned!&lt;/p&gt;
&lt;h1 id="references"&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://datant.wordpress.com/2017/01/16/the-monty-hall-problem-and-3-ways-to-solve-it/"&gt;The Monty Hall problem and 3 ways to solve it&lt;/a&gt;, AnthonyÂ Oâ€™Farrell&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.countbayesie.com/blog/2015/2/18/bayes-theorem-with-lego"&gt;Bayesâ€™ Theorem with Lego&lt;/a&gt;, WillÂ Kurt&lt;/li&gt;
&lt;li&gt;&lt;a href="https://sc5.io/posts/how-to-solve-the-monty-hall-problem-using-bayesian-inference/#gref"&gt;How to solve the Monty Hall problem using Bayesian inference&lt;/a&gt;, MaxÂ Pagels&lt;/li&gt;
&lt;/ul&gt;</content><category term="Monte Carlo"></category><category term="Bayesian inference"></category></entry><entry><title>The Loopless Loop (or How I made my code run 7,000 timesÂ faster)</title><link href="http://tabidots.github.io/2019/01/loopless-loop" rel="alternate"></link><published>2019-01-10T19:00:46+07:00</published><updated>2019-01-10T19:00:46+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-01-10:/2019/01/loopless-loop</id><summary type="html">&lt;p&gt;In which I (1) discover that the purpose of linear algebra is not to just manipulate spreadsheets and move vectors around but to make your code faster and cleanerâ€”in other words, to give it a Zen uppercut; and (2) learn LaTeX and start a blog just to see syntax-highlighted code and properly typeset math on the same&amp;nbsp;page.&lt;/p&gt;</summary><content type="html">
&lt;h1 id="part-1-ugly-math-ugly-code"&gt;Part 1: Ugly math, uglyÂ code&lt;/h1&gt;
&lt;p&gt;As I embarked on my journey to learn the math side of machine learning, all of the blog posts seemed to point to linear algebra as the starting point. The problem was, nothing I read made it immediately clear &lt;em&gt;how&lt;/em&gt; linear algebra played a role in machineÂ learning.&lt;/p&gt;
&lt;p&gt;Worse yet, the whole discussion of vectors, matrices, linear combinations, and linear transformations seemed completely disconnected from my laymanâ€™s understanding of machineÂ learning.&lt;/p&gt;
&lt;p&gt;The Khan Academy videos on linear algebra are quite tedious and I didnâ€™t feel I was getting anywhere. &lt;a href="https://www.youtube.com/watch?v=fNk_zzaMoSs&amp;amp;list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab"&gt;3blue1brownâ€™s Linear Algebra series&lt;/a&gt; is much more engaging and lucid, but I was still getting bogged down in the theory without seeing theÂ application.&lt;/p&gt;
&lt;p&gt;Needless to say, it was pretty slowÂ going.&lt;/p&gt;
&lt;h2 id="my-linear-algebra-a-ha-moment"&gt;My linear algebra &lt;em&gt;a-ha&lt;/em&gt;Â moment&lt;/h2&gt;
&lt;p&gt;It wasnâ€™t until I switched gears and decided, on a whim, to tackle &lt;em&gt;linear regression&lt;/em&gt; that linear algebra really started to click for me. On a practical level, code that uses linear-algebraic methods simplifies work for the computer by orders of magnitude, making it possible to process massive datasetsâ€”and process them rapidly. This is obviously a critical requirement in the age of BigÂ Data.&lt;/p&gt;
&lt;p&gt;And on a conceptual level, it gave me my first mathematical &lt;em&gt;a-ha&lt;/em&gt;Â moment:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;By manipulating matrices and vectors, you can achieve the same outcome as a loop without explicitly loopingâ€”a loopless loop&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;That&lt;/em&gt; is why linear algebra is the cornerstone of machineÂ learning.&lt;/p&gt;
&lt;p&gt;The only thing is, no single resource I found on the internet seemed to really clarify the mathematical and programmatic aspects &lt;em&gt;at the same time&lt;/em&gt; without getting too abstract on the math side ofÂ things.&lt;/p&gt;
&lt;p&gt;As a self-taught and formerly math-phobic coder, I needed a guide that progressed from from inelegant code (which I could understand) and inelegant math to (mind-blowingly) elegant math, which would then lay the groundwork for writing extremely elegantâ€”and performantâ€”code (which is incomprehensible without understanding theÂ math).&lt;/p&gt;
&lt;p&gt;This is that guide, created from my notes from Week 1 of my machine learning journey. Iâ€™ve split it up into multiple posts, since itâ€™s quiteÂ long.&lt;/p&gt;
&lt;h2 id="how-to-make-a-computer-explode"&gt;How to make a computerÂ explode&lt;/h2&gt;
&lt;p&gt;I always thought that for-loops were simply a fact ofÂ life.&lt;/p&gt;
&lt;p&gt;While I understood the basic principle behind stochastic gradient descent, I had never implemented it myself before. If I had tried my hand at it before learning the math involved, I probably would have come up with thisÂ monster:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# DON'T TRY THIS&lt;/span&gt;

&lt;span class="n"&gt;samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;lists&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;actual&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;train_lr_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;actual&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;feature&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;samples&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="c1"&gt;# 0 to start&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weight&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;summation_part_of_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sample&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;samples&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                &lt;span class="n"&gt;sum_of_sq_errs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hypothesis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;actual&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
                &lt;span class="n"&gt;summation_part_of_cost&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;sum_of_sq_errs&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            &lt;span class="n"&gt;partial_deriv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;samples&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;summation_part_of_cost&lt;/span&gt;
            &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;partial_deriv&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;

&lt;span class="c1"&gt;# I REALLY HOPE YOU DIDN'T TRY THIS&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Okay, maybe not. (It would be pretty hard to write this without understanding the mathÂ involved.)&lt;/p&gt;
&lt;p&gt;Count those loopsâ€”&lt;em&gt;three&lt;/em&gt;, to be exact! Terrifying. Now, being handy with Python, I could probably have calculated &lt;code class="highlight"&gt;partial_deriv&lt;/code&gt; in one line with an even more terrifying list comprehension, just to showÂ off:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;partial_deriv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;samples&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hypothesis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;actual&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sample&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;samples&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;â€¦which shaves off four lines, at the expense of all readability. But bigger problemsÂ remain:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;The time complexity of this program is off the charts.&lt;/strong&gt; In &lt;a href="https://en.wikipedia.org/wiki/Time_complexity"&gt;Big-O time complexity&lt;/a&gt; terms, it is &lt;em&gt;at least&lt;/em&gt; &lt;span class="math"&gt;\(O(n^3)\)&lt;/span&gt;, if not more, which is cubic time, or (literally) &lt;em&gt;exponentially &lt;a href="http://bigocheatsheet.com/"&gt;horrible&lt;/a&gt;&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;It doesnâ€™t even work.&lt;/strong&gt; Even with a dataset of unremarkable size, youâ€™re bound to get a &lt;code class="highlight"&gt;&lt;span class="n"&gt;RuntimeWarning&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;overflow&lt;/span&gt; &lt;span class="n"&gt;encountered&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="n"&gt;square&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;/code&gt; that canâ€™t be avoided even if you set the &lt;code class="highlight"&gt;learning_rate&lt;/code&gt; to an impractically small value like &lt;code class="highlight"&gt;0.00001&lt;/code&gt;. Trust me, Iâ€™veÂ tried.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Is there any way beyond thisÂ impasse?&lt;/p&gt;
&lt;h2 id="meeting-a-zen-master-on-the-road"&gt;Meeting a Zen master on theÂ road&lt;/h2&gt;
&lt;p&gt;In Zen Buddhism, there is a famous book called &lt;em&gt;The Gateless Gate&lt;/em&gt;, which is a collection of &lt;em&gt;koans&lt;/em&gt;. A Zen &lt;em&gt;koan&lt;/em&gt; is a riddle that cannot be approached with the rational mind. ForÂ example:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Goso said: â€œWhen you meet a Zen master on the road, you cannot talk to him, but neither can you face him with silence. What are you going toÂ do?â€&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To solve it, you have to transcend the duality of &lt;em&gt;this&lt;/em&gt; and &lt;em&gt;not-this&lt;/em&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Give him an uppercut&lt;br/&gt;
And you will be called one who understands Zen.&lt;/em&gt;&lt;br/&gt;
â€”The Gateless Gate, KoanÂ #36&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As you might imagine, linear algebraâ€”&lt;strong&gt;the loopless loop&lt;/strong&gt;â€”is the Zen uppercut of coding. What, then is the target of ourÂ uppercut?&lt;/p&gt;
&lt;h2 id="linear-regression-a-basic-overview"&gt;Linear regression: A basicÂ overview&lt;/h2&gt;
&lt;p&gt;Basically, linear regression is used to make predictions about a &lt;em&gt;thing&lt;/em&gt; based on its characteristics, assumingÂ that&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;that there is some correlation among those characteristicsÂ and&lt;/li&gt;
&lt;li&gt;that you have plenty of data about other &lt;em&gt;things&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The intuition here can be explained with middle school algebra. Imagine you know the square footage and price of 200 houses and you want to estimate the price of a house with a given squareÂ footage.&lt;/p&gt;
&lt;p&gt;Obviously, this is an oversimplified correlation for the sake of example. (And for some reason, everyone seems to explain this concept using houses, so why reinvent theÂ wheel?)&lt;/p&gt;
&lt;p&gt;If you were to make a scatter plot of that data, with the area along the x-axis and the price along the y-axis, the pattern might roughly look like it follows a lineâ€”not perfectly linear, but linear &lt;em&gt;enough&lt;/em&gt; to predict the price of a house with &lt;span class="math"&gt;\(x\)&lt;/span&gt; square footage. You can use linear regression to work backward from the data to determine this line, &lt;strong&gt;the line of best fit&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In middle school algebra, lines are written in theÂ form&lt;/p&gt;
&lt;div class="math"&gt;$$ y = \textcolor{magenta}{m}\textcolor{teal}{x} + \textcolor{orange}{b} $$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(\textcolor{teal}{x}\)&lt;/span&gt; is the input, &lt;span class="math"&gt;\(\textcolor{magenta}{m}\)&lt;/span&gt; is the slope of the line, &lt;span class="math"&gt;\(\textcolor{orange}{b}\)&lt;/span&gt; moves the line up and down on the graph, and &lt;span class="math"&gt;\(y\)&lt;/span&gt; is the height of the line at point &lt;span class="math"&gt;\(\textcolor{teal}{x}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Our house problem can also be framed as a line, where &lt;span class="math"&gt;\(\textcolor{teal}{x}\)&lt;/span&gt; is the square footage, which influences the price by some value &lt;span class="math"&gt;\(\textcolor{magenta}{m}\)&lt;/span&gt;, to which we add some kind of base price to bring us to the final price, &lt;span class="math"&gt;\(y\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Well, that was easy enough,Â right?&lt;/p&gt;
&lt;h2 id="multiple-linear-regression-because-more-is-better-or-something"&gt;Multiple linear regression: Because more is better (orÂ something)&lt;/h2&gt;
&lt;p&gt;In the real world, of course, area is not the only factor that decides the price of a house. There are many others. Can we still adapt our middle school equation to this problem if each house has 3 featuresâ€”say, area, nearby property values, and age of theÂ building?&lt;/p&gt;
&lt;div class="math"&gt;$$ y = \textcolor{magenta}{m}\textcolor{teal}{x} + \textcolor{magenta}{n}\textcolor{teal}{z} + \textcolor{magenta}{o}\textcolor{teal}{a} + \textcolor{orange}{b} $$&lt;/div&gt;
&lt;p&gt;We can, but itâ€™s messy. (Itâ€™s also no longer a line, but letâ€™s ignore that for now.) First, letâ€™s rewrite that â€œbase priceâ€ as &lt;span class="math"&gt;\(b \cdot 1\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$ y = \textcolor{magenta}{m}\textcolor{teal}{x} + \textcolor{magenta}{n}\textcolor{teal}{z} + \textcolor{magenta}{o}\textcolor{teal}{a} + \textcolor{magenta}{b}\cdot\textcolor{teal}{1} $$&lt;/div&gt;
&lt;p&gt;This gives us a nice symmetry: Notice that all of the teal variables are features, which are multiplied by their degree of influence (called a &lt;em&gt;coefficient&lt;/em&gt; in statistics, or a &lt;em&gt;weight&lt;/em&gt; in machine learning). When you add all these together, you get the price of theÂ house.&lt;/p&gt;
&lt;p&gt;This is called &lt;strong&gt;multiple linear regression&lt;/strong&gt;. Most people wouldnâ€™t skip directly to multiple &lt;span class="caps"&gt;LR&lt;/span&gt; after introducing single &lt;span class="caps"&gt;LR&lt;/span&gt;, but single &lt;span class="caps"&gt;LR&lt;/span&gt; is pretty easy to digest if you can understand high school calculus (derivatives), so it didnâ€™t level up my mathÂ knowledge.&lt;/p&gt;
&lt;p&gt;Now, letâ€™s code our equation, putting all the feature values into a &lt;em&gt;list&lt;/em&gt; &lt;code class="highlight"&gt;features&lt;/code&gt; and the weights into another &lt;em&gt;list&lt;/em&gt; &lt;code class="highlight"&gt;weights&lt;/code&gt;. In Python, in increasing order of elegance, we can write theÂ following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Using completely random numbers just to show the code&lt;/span&gt;
&lt;span class="n"&gt;features&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;# 3 features; first value is the â€œdummy featureâ€&lt;/span&gt;
&lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.75&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;# Brute-force addition&lt;/span&gt;
&lt;span class="n"&gt;price&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If we use &lt;span class="math"&gt;\(x\)&lt;/span&gt;s to denote our features, &lt;span class="math"&gt;\(Î¸\)&lt;/span&gt;s to denote our weights, and subscript numbers to denote the position of each item in a list (series), then we can rewrite our equation in a slightly more organizedÂ way:&lt;/p&gt;
&lt;div class="math"&gt;$$ h_Î¸(x) = \textcolor{magenta}{Î¸_0}\textcolor{lightgray}{x_0} + \textcolor{magenta}{Î¸_1}\textcolor{teal}{x_1} + \cdots + \textcolor{magenta}{Î¸_n}\textcolor{teal}{x_n}  $$&lt;/div&gt;
&lt;p&gt;which just happens to be the &lt;strong&gt;generalized form of linear regression&lt;/strong&gt;â€”&lt;em&gt;general&lt;/em&gt; in the sense that it can accommodate any number of features, whether thatâ€™s 1 orÂ 1,000.&lt;/p&gt;
&lt;p&gt;Here, &lt;span class="math"&gt;\(x\)&lt;/span&gt; is the collection of all feature values &lt;span class="math"&gt;\(\textcolor{teal}{x_1}\)&lt;/span&gt; through &lt;span class="math"&gt;\(\textcolor{teal}{x_n}\)&lt;/span&gt;, where &lt;span class="math"&gt;\(n\)&lt;/span&gt; is the number of features. (And &lt;span class="math"&gt;\(x_{1000}\)&lt;/span&gt; actually isnâ€™t too crazy in terms of real-world datasets!) It also includes the dummy feature &lt;span class="math"&gt;\(\textcolor{lightgray}{x_0} = 1\)&lt;/span&gt;. Likewise, &lt;span class="math"&gt;\(Î¸\)&lt;/span&gt; is the collection of all weights, including &lt;span class="math"&gt;\(\textcolor{magenta}{Î¸_0}\)&lt;/span&gt;, the â€œbase priceâ€ in our example. In machine learning, this is called the &lt;em&gt;bias&lt;/em&gt;Â value.&lt;/p&gt;
&lt;p&gt;Finally, the function notation &lt;span class="math"&gt;\(h_Î¸(x)\)&lt;/span&gt; indicates that this is the &lt;strong&gt;hypothesis&lt;/strong&gt; for item (house) &lt;span class="math"&gt;\(x\)&lt;/span&gt; given the collection of weights &lt;span class="math"&gt;\(Î¸\)&lt;/span&gt;.&lt;/p&gt;
&lt;h2 id="how-to-python-in-math-lesson-1"&gt;How to Python in math (LessonÂ 1)&lt;/h2&gt;
&lt;p&gt;If you know anything about programming, you know that the last line of code above is no way to write a program. Accommodating 100 features would be a chore, and accommodating a variable number of features would be impossible. Naturally, we would use the magic ofÂ iteration:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Super-basic iteration over the lists&lt;/span&gt;
&lt;span class="n"&gt;price&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;price&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;No one actually writes the linear regression formula like this, but if you wanted to, you could express the above code in math using a &lt;em&gt;summation&lt;/em&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ h_Î¸(x) = \sum_{j=0}^n \textcolor{magenta}{Î¸_j}\textcolor{teal}{x_j} $$&lt;/div&gt;
&lt;p&gt;That Greek letter &lt;span class="math"&gt;\(\sum\)&lt;/span&gt; (sigma) means &lt;em&gt;summation&lt;/em&gt;. Basically, run a for-loop that adds the result of the following expression for each sample (house) starting at &lt;span class="math"&gt;\(j=0\)&lt;/span&gt; until &lt;span class="math"&gt;\(j=n\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;If you know Python better than you know math (as I did), then you might try further refactoring theÂ code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Functional programming version&lt;/span&gt;
&lt;span class="n"&gt;price&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;price&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt;

&lt;span class="c1"&gt;# More Pythonic version of the above&lt;/span&gt;
&lt;span class="n"&gt;price&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I didnâ€™t realize this when I wrote the first draft of this post, but even expressing the simple Python function &lt;code class="highlight"&gt;zip(x, y)&lt;/code&gt; in math requires linear algebra. Iâ€™ll get back to the non-fancy version of linear regression in just a minute, but for sake of thoroughness, if &lt;span class="math"&gt;\(x\)&lt;/span&gt; and &lt;span class="math"&gt;\(Î¸\)&lt;/span&gt; are both vectors,Â then&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\vec x = \begin{bmatrix} x_0 \\ x_1 \\ \vdots \\ x_n \end{bmatrix} &amp;amp; \qquad{}
\vec Î¸ = \begin{bmatrix} Î¸_0 \\ Î¸_1 \\ \vdots \\ Î¸_n \end{bmatrix} &amp;amp; \quad{}
z(\vec x, \vec Î¸) = \vec Î¸\vec x \end{aligned} $$&lt;/div&gt;
&lt;p&gt;Similarly, we can rewrite our equation as a function in Python, too. Letâ€™s leave vectors aside for now, but keep the &lt;code class="highlight"&gt;zip&lt;/code&gt; and encapsulate it into a function, because itâ€™s clean and easy toÂ understand.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;hypothesis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="einstein-notation-making-math-less-confusing-by-making-it-more-confusing"&gt;Einstein notation: Making math less confusing by making it moreÂ confusing&lt;/h2&gt;
&lt;p&gt;This is all great if thereâ€™s only one &lt;span class="math"&gt;\(x\)&lt;/span&gt; (house). But we will need tons of houses to make a decent prediction. Our list &lt;code class="highlight"&gt;houses&lt;/code&gt; needs to be changed into a &lt;em&gt;list of lists&lt;/em&gt;. For the sake of example, if we had three houses and three features, &lt;code class="highlight"&gt;houses&lt;/code&gt; would look like this (remember the dummyÂ feature):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;houses&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
          &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
          &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="c1"&gt;# random values&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This also allows us to refer to specific features of specific houses using two indexes, &lt;code class="highlight"&gt;houses[i][j]&lt;/code&gt;. How do we do this in math, though? Enter &lt;strong&gt;Einstein notation&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$ h_Î¸(x^i) = Î¸_0x_0^i + Î¸_1x_1^i + \cdots + Î¸_nx_n^i  $$&lt;/div&gt;
&lt;p&gt;The superscript numbers here &lt;em&gt;arenâ€™t&lt;/em&gt; exponents. You would think Einstein, of all people, could come up with something less confusing, but that is the convention, so itâ€™s important to become familiar withÂ it.&lt;/p&gt;
&lt;p&gt;Just remember that in linear regression, there are conventional choices for the variable names. &lt;span class="math"&gt;\(i\)&lt;/span&gt; denotes the &lt;span class="math"&gt;\(i\)&lt;/span&gt;th house, and &lt;span class="math"&gt;\(j\)&lt;/span&gt; the &lt;span class="math"&gt;\(j\)&lt;/span&gt;thÂ feature.&lt;/p&gt;
&lt;div class="math"&gt;$$ x^{\textcolor{orange}{i \textrm{th sample}}}_{\textcolor{blue}{j \textrm{th feature}}} $$&lt;/div&gt;
&lt;p&gt;So if we were to start describing each hypothesis for our datasetÂ individually,&lt;/p&gt;
&lt;div class="math"&gt;$$ h_Î¸(x^i) = \left\{\begin{array}{ll}
h_Î¸(x^0) = Î¸_0x_0^0 + Î¸_1x_1^0 + \cdots + Î¸_nx_n^0 \\[0.5em]
h_Î¸(x^1) = Î¸_0x_0^1 + Î¸_1x_1^1 + \cdots + Î¸_nx_n^1 \\[0.5em]
h_Î¸(x^2) = Î¸_0x_0^2 + Î¸_1x_1^2 + \cdots + Î¸_nx_n^2 \\[0.5em]
h_Î¸(x^3) = Î¸_0x_0^2 + Î¸_1x_1^2 + \cdots + Î¸_nx_n^2
\end{array}\right. $$&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;hypothesis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;hypothesis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;hypothesis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;hypothesis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;hyps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;hypothesis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;house&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;house&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="cost-function-how-accurate-are-our-predictions"&gt;Cost function: How accurate are ourÂ predictions?&lt;/h2&gt;
&lt;p&gt;Seeing as the goal of linear regression is to come up with a line that best fits the data, we need some way to evaluate a lineâ€™s &lt;strong&gt;goodness of fit&lt;/strong&gt; to the data. One measure of that is the &lt;strong&gt;mean squared error&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id="error"&gt;Error&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Error&lt;/em&gt; is how far the prediction for one sample (house) is from its actualÂ value.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\textrm{error}_i &amp;amp;= \textrm{prediction}_i - \textrm{actual}_i\\
&amp;amp;= \hat{Y}_i - Y_i
\end{aligned} $$&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Note&lt;/em&gt;: The subscript &lt;span class="math"&gt;\(i\)&lt;/span&gt; here is &lt;strong&gt;not&lt;/strong&gt; Einstein notation, because these are just lists of values, not a â€œspreadsheetâ€ of rows and columns. The Einstein notation in this discussion of linear regression only applies to &lt;span class="math"&gt;\(x\)&lt;/span&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\hat Y\)&lt;/span&gt; is read â€œY-hat,â€ which is just a statistical convention. It can be substituted with our function &lt;span class="math"&gt;\(h_Î¸(x^i)\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$ \textrm{error}_i = h_Î¸(x^i) - Y_i $$&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;actual_values&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;# 3 houses; random values&lt;/span&gt;
&lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.75&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;error&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;hypothesis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;actual_values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="squared-error"&gt;SquaredÂ error&lt;/h3&gt;
&lt;p&gt;We &lt;em&gt;square&lt;/em&gt; it so that (1) all values are positive, preventing underestimates and overestimates from canceling each other out; and (2) larger errors are considered proportionally â€œmore erroneousâ€ than smallerÂ errors.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\textrm{SE}_i &amp;amp;= \textrm{error}^2\\
&amp;amp;= (\hat{Y}_i - Y_i)^2\\
&amp;amp;= (h_Î¸(x^i) - Y_i)^2
\end{aligned} $$&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;se&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="mean-squared-error"&gt;Mean squaredÂ error&lt;/h3&gt;
&lt;p&gt;The &lt;em&gt;mean&lt;/em&gt; value of the squared error for all samples can give us an idea about our lineâ€™s goodness ofÂ fit.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\textrm{MSE} &amp;amp;= \frac{\textrm{SE}_\textcolor{red}{1} \textcolor{blue}{+ \cdots + } \textrm{ SE}_\textcolor{red}{\textrm{number of samples}}}{\textrm{number of samples}}\\
&amp;amp;= \frac{\textcolor{blue}{\sum}_{\textcolor{red}{i=1}}^{\textcolor{red}{m}} \textrm{SE}}{m}\\
&amp;amp;= \frac{\sum_{\textcolor{red}{i=1}}^{\textcolor{red}{m}} (\hat{Y}_{\textcolor{red}i} - Y_{\textcolor{red}i})^2}{m}\\
&amp;amp;= \frac{1}{m} \sum_{\textcolor{red}{i=1}}^{\textcolor{red}{m}} (\hat{Y}_{\textcolor{red}i} - Y_{\textcolor{red}i})^2\\
&amp;amp;= \frac{1}{m} \sum_{\textcolor{red}{i=1}}^{\textcolor{red}{m}} (h_Î¸(x^{\textcolor{red}i}) - Y_{\textcolor{red}i})^2
\end{aligned} $$&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;total_se&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;total_se&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;se&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;mse&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;total_se&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;

&lt;span class="c1"&gt;# More Pythonic and more similar to the actual math notation&lt;/span&gt;
&lt;span class="n"&gt;mse&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;se&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;house&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;house&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Note&lt;/em&gt;: &lt;span class="caps"&gt;MSE&lt;/span&gt; gives us an indication of goodness of fit, but itâ€™s difficult to tie that value directly to the data. You can use the &lt;span class="caps"&gt;RMSE&lt;/span&gt; (root mean squared error), which is just the square root of the &lt;span class="caps"&gt;MSE&lt;/span&gt;, to reframe the average error in terms of the data. In this case, the &lt;span class="caps"&gt;RMSE&lt;/span&gt; would tell us how much (in dollars) that our prediction line was offÂ by.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Letâ€™s use the mean squared error to rewrite this equation as a function of the collection of weights. Every time we change the weights, we will obtain a different line with a different goodness of fit (&lt;span class="caps"&gt;MSE&lt;/span&gt;), and this relationship can be illustrated by a function called the &lt;em&gt;cost function&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;se&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;house&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;house&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Well, almost. This function is conventionally named &lt;span class="math"&gt;\(J\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ J(Î¸) = \frac{1}{\textcolor{magenta}{2}m} \sum_{i=1}^m (h_Î¸(x^i) - Y_i)^2 $$&lt;/div&gt;
&lt;p&gt;Where did that &lt;span class="math"&gt;\(\textcolor{magenta}{2}\)&lt;/span&gt; come from? Again, this is just a matter of convention. The &lt;span class="math"&gt;\(\textcolor{magenta}{2}\)&lt;/span&gt; will cancel out in the the nextÂ step.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;se&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;house&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;house&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Keep in mind that &lt;span class="math"&gt;\(Î¸\)&lt;/span&gt; and &lt;span class="math"&gt;\(Y\)&lt;/span&gt; are lists and &lt;span class="math"&gt;\(x\)&lt;/span&gt; is a list of lists. What this means is that in a situation with two features (plus the dummyÂ feature),&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned} h_{Î¸_\textcolor{teal}{0}, Î¸_\textcolor{teal}{1}, Î¸_\textcolor{teal}{2}}(x) &amp;amp;= h_{Î¸_\textcolor{teal}{0}}(x_\textcolor{teal}{0}) + h_{Î¸_\textcolor{teal}{1}}(x_\textcolor{teal}{1}) + h_{Î¸_2}(x_\textcolor{teal}{2}) \\
h_{Î¸_\textcolor{teal}{0}, Î¸_\textcolor{teal}{1}, Î¸_\textcolor{teal}{2}}(x^\textcolor{red}{i}) &amp;amp;= h_{Î¸_\textcolor{teal}{0}}(x_\textcolor{teal}{0}^\textcolor{red}{i}) + h_{Î¸_\textcolor{teal}{1}}(x_\textcolor{teal}{1}^\textcolor{red}{i}) + h_{Î¸_\textcolor{teal}{2}}(x_\textcolor{teal}{2}^\textcolor{red}{i}) \\
J(Î¸_\textcolor{teal}{0}, Î¸_\textcolor{teal}{1}, Î¸_\textcolor{teal}{2}) &amp;amp;= \frac{1}{2m} \sum_{\textcolor{red}{i=1}}^\textcolor{red}{m} \Big[h_{Î¸_\textcolor{teal}{0}}(x_\textcolor{teal}{0}^\textcolor{red}{i}) + h_{Î¸_\textcolor{teal}{1}}(x_\textcolor{teal}{1}^\textcolor{red}{i}) + h_{Î¸_\textcolor{teal}{2}}(x_\textcolor{teal}{2}^\textcolor{red}{i}) - Y_{\textcolor{red}i}\Big]^2
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;Numbers in teal represent feature numbers; numbers in red represent sampleÂ numbers.&lt;/p&gt;
&lt;h2 id="multivariable-calculus-how-much-effect-does-each-weight-have"&gt;Multivariable calculus: How much effect does each weightÂ have?&lt;/h2&gt;
&lt;p&gt;Now, imagine each feature as knobs on a radio. Increasing or decreasing the weight of each feature is like turning up or down the knob for that feature. We want to â€œtuneâ€ our line to be as close to the data as possible by â€œdialingâ€ the features up and down. In order to do this, we need to determine the effect that a given combination of knob settings has on the finalÂ output.&lt;/p&gt;
&lt;p&gt;In math terms, this is akin to asking â€œHow much does &lt;span class="math"&gt;\(J\)&lt;/span&gt; change when &lt;span class="math"&gt;\(Î¸\)&lt;/span&gt; changes?â€ Sounds like derivatives from high schoolÂ calculus.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned} f(x) &amp;amp;= 5x^2 \\
\frac{df}{dx} &amp;amp;= 5\cdot2x^{2-1} \\
&amp;amp;= 10x
\end{aligned}
$$&lt;/div&gt;
&lt;p&gt;Our function &lt;span class="math"&gt;\(J\)&lt;/span&gt; is actually one function inside of another, so the chain rule applies. Bonus points if you remember that from high schoolâ€”IÂ didnâ€™t.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
J(Î¸) &amp;amp;= \textcolor{purple}{\frac{1}{2m}} \textcolor{purple}{\sum_{i=1}^m} \textcolor{purple}{\Big[} \textcolor{orange}{h_Î¸(x^i)} \textcolor{purple}{- Y_i)\Big]^2} \\
\frac{dJ(Î¸)}{dÎ¸} &amp;amp;= d_\textcolor{purple}{\textrm{outer}} \cdot d_\textcolor{orange}{\textrm{inner}}
\end{aligned} $$&lt;/div&gt;
&lt;div class="math"&gt;$$
\begin{aligned}
\textcolor{purple}{\textrm{outer}} &amp;amp;= \textcolor{purple}{\frac{1}{2m}} \textcolor{purple}{\sum_{i=1}^m} \textcolor{purple}{(} \textcolor{orange}{\textrm{inner}} \textcolor{purple}{- Y_i)^2} &amp;amp;
\textcolor{orange}{\textrm{inner}} &amp;amp;= \textcolor{magenta}{Î¸_0}\textcolor{teal}{x_0} + \textcolor{magenta}{Î¸_1}\textcolor{teal}{x_1} + \cdots + \textcolor{magenta}{Î¸_n}\textcolor{teal}{x_n} \\
d_\textcolor{purple}{\textrm{outer}} &amp;amp;= \textcolor{purple}{\frac{\cancel{2}}{\cancel{2}m}} \textcolor{purple}{\sum_{i=1}^m} \textcolor{purple}{\Big[} \textcolor{orange}{h_Î¸(x^i)} \textcolor{purple}{{- Y_i\Big]}^2} &amp;amp; d_\textcolor{orange}{\textrm{inner}} &amp;amp;= ???
\end{aligned}
$$&lt;/div&gt;
&lt;p&gt;This is where I got stuck. &lt;span class="math"&gt;\(Î¸\)&lt;/span&gt; is a collection of values, not just a single value. Each knob on our radio affects the output individually, and we have to determine the individual effect of eachÂ knob.&lt;/p&gt;
&lt;p&gt;It helps to start by breaking down what the chain rule is actuallyÂ saying.&lt;/p&gt;
&lt;div class="math"&gt;$$ \frac{d[\textcolor{purple}{\textrm{outer}}(\textcolor{orange}{\textrm{inner}}(x))]}{dx} = \frac{d_\textcolor{purple}{\textrm{outer}}}{d_\textcolor{orange}{\textrm{inner}}} \cdot \frac{d_\textcolor{orange}{inner}}{dx} $$&lt;/div&gt;
&lt;p&gt;This means our â€œouter derivativeâ€ &lt;span class="math"&gt;\(d_\textcolor{purple}{\textrm{outer}}\)&lt;/span&gt; tells us how much our cost function &lt;span class="math"&gt;\(J(Î¸)\)&lt;/span&gt; changes in response to a given change in our hypothesis &lt;span class="math"&gt;\(h(x)\)&lt;/span&gt;. We now need to find the â€œinner derivativeâ€ &lt;span class="math"&gt;\(d_{\textcolor{orange}{\textrm{inner}}}\)&lt;/span&gt;, which tells us how much our hypothesis &lt;span class="math"&gt;\(h(x)\)&lt;/span&gt; changes in response to a given change in our weights &lt;span class="math"&gt;\(Î¸\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;But since &lt;span class="math"&gt;\(Î¸\)&lt;/span&gt; is a collection of values, there isnâ€™t a single derivative, but rather several &lt;em&gt;partial derivatives&lt;/em&gt;, which indicate how much our hypothesis &lt;span class="math"&gt;\(h(x^i)\)&lt;/span&gt; for a specific sample (house) &lt;span class="math"&gt;\(x^i\)&lt;/span&gt; changes in response to a given change in &lt;em&gt;each&lt;/em&gt; of the weights &lt;span class="math"&gt;\(Î¸_j\)&lt;/span&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Note&lt;/em&gt;: Another labeling conventionâ€”just as &lt;span class="math"&gt;\(i\)&lt;/span&gt; is used to refer to, or â€œindex,â€ samples from &lt;span class="math"&gt;\(1\)&lt;/span&gt; through &lt;span class="math"&gt;\(m\)&lt;/span&gt;, the total number of samples, lowercase &lt;span class="math"&gt;\(j\)&lt;/span&gt; is used to index features from &lt;span class="math"&gt;\(0\)&lt;/span&gt; through &lt;span class="math"&gt;\(n\)&lt;/span&gt;, the total number of features. To return to our Einstein notation,
&lt;div class="math"&gt;$$ x^{1 \leq \space i^\textrm{th} \textrm{ sample} \space \leq \space m \textrm{ samples}}_{0 \space \leq \space j^\textrm{th} \textrm{ feature} \space \leq \space n \textrm{ features}} $$&lt;/div&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In math notation, this is written with a funny â€œdâ€ called a â€œdel,â€ &lt;span class="math"&gt;\(\partial\)&lt;/span&gt;, likeÂ this:&lt;/p&gt;
&lt;div class="math"&gt;$$ \frac{\partial h_Î¸(x^i)}{\partial Î¸_j} $$&lt;/div&gt;
&lt;p&gt;This looks crazy, but the process of finding these partial derivatives is really the same as finding a normal derivative, except you &lt;em&gt;treat all the other variables as constant&lt;/em&gt;, effectively ignoring them. So, for we now only have to concern ourselvesÂ with&lt;/p&gt;
&lt;div class="math"&gt;$$ h_{Î¸_j}(x^i) = \begin{cases}
\textcolor{magenta}{Î¸_0}\textcolor{teal}{x_0^i} \textcolor{lightgray}{+Î¸_1x_1^i + Î¸_2x_2^i} &amp;amp; \text{when } j=0 \\
\textcolor{lightgray}{Î¸_0x_0^i} \textcolor{lightgray}{+} \textcolor{magenta}{Î¸_1}\textcolor{teal}{x_1^i} \textcolor{lightgray}{+Î¸_2x_2^i} &amp;amp; \text{when } j=1 \\
\textcolor{lightgray}{Î¸_0x_0^i + Î¸_1x_1^i} \textcolor{lightgray}{+} \textcolor{magenta}{Î¸_2}\textcolor{teal}{x_2^i} &amp;amp; \text{when } j=2 \\
\end{cases} $$&lt;/div&gt;
&lt;p&gt;The derivative of a variable times something else is just the &lt;em&gt;something else&lt;/em&gt;. (For a line &lt;span class="math"&gt;\(y = 2x\)&lt;/span&gt;, &lt;span class="math"&gt;\(\frac{dy}{dx}\)&lt;/span&gt; is just &lt;span class="math"&gt;\(2\)&lt;/span&gt;, since its slope will be 2 at every point along the line.)Â Thus,&lt;/p&gt;
&lt;div class="math"&gt;$$ \frac{\partial h_Î¸(x)}{\partial Î¸_j} = \begin{cases}
\frac{\partial h_Î¸(x)}{\partial Î¸_0} &amp;amp;= \textcolor{lightgray}{Î¸_0} \textcolor{teal}{x_0^i} &amp;amp; \text{when } j=0 \\[0.5em]
\frac{\partial h_Î¸(x)}{\partial Î¸_1} &amp;amp;= \textcolor{lightgray}{Î¸_1} \textcolor{teal}{x_1^i} &amp;amp; \text{when } j=1 \\[0.5em]
\frac{\partial h_Î¸(x)}{\partial Î¸_2} &amp;amp;= \textcolor{lightgray}{Î¸_2} \textcolor{teal}{x_2^i} &amp;amp; \text{when } j=2
\end{cases} $$&lt;/div&gt;
&lt;p&gt;OrÂ just&lt;/p&gt;
&lt;div class="math"&gt;$$ \frac{\partial h_Î¸(x)}{\partial Î¸_j} = \left\{\begin{array}{lr}
x_0^i &amp;amp; \text{when } j=0 \\[0.5em]
x_1^i &amp;amp; \text{when } j=1 \\[0.5em]
x_2^i &amp;amp; \text{when } j=2
\end{array}\right\}
= \textcolor{red}{x_j^i} $$&lt;/div&gt;
&lt;p&gt;Thatâ€™s &lt;span class="math"&gt;\(d_{\textcolor{orange}{\textrm{inner}}}\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\frac{\partial{J(Î¸)}}{\partial{Î¸_j}} &amp;amp;= d_\textcolor{purple}{\textrm{outer}} \cdot d_\textcolor{orange}{\textrm{inner}} \\
&amp;amp;= \frac{1}{m} \sum_{i=1}^m (h_Î¸(x^i) - Y_i) \cdot \textcolor{red}{x_j^i}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;Phew! That was a lot of abstract math. Finally, we have something that can be translated intoÂ code.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;effect_of_weight&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;which_weight&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;house&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;which_weight&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;house&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="n"&gt;effect_of_all_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;effect_of_weight&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="stochastic-gradient-descent-making-regression-lines-fit-again"&gt;Stochastic gradient descent: Making regression lines fitÂ again&lt;/h2&gt;
&lt;p&gt;Strictly speaking, &lt;span class="math"&gt;\(\frac{1}{m} \sum_{i=1}^m (h_Î¸(x^i) - Y_i) \cdot x_j^i\)&lt;/span&gt; is not a derivative, but a &lt;strong&gt;gradient&lt;/strong&gt;â€”a collection of partial derivatives. In high school calculus, the derivative at a given point is visualized as the line that is tangent to the graphâ€™s curve at that point. In multivariable calculus, the gradient at a given point is visualized as the &lt;em&gt;plane&lt;/em&gt; that is tangent to the graphâ€™s surface at theÂ point.&lt;/p&gt;
&lt;p&gt;In more concrete terms, imagine running a small piece of cardboard around the sides of a coffee mug so that the cardboard follows the curvature of the mug. Every point on the surface of the mug corresponds to some combination of weights, and the closer we are to the top of the mug, the greater the value of our cost function is, and so the more inaccurate our prediction is. We want to find the bottom of the mug, where the piece of cardboard is parallel to the ground, because that is where the value of the cost function is as low asÂ possible.&lt;/p&gt;
&lt;p&gt;When that value is zero, the line would fit our data perfectly. However, thatâ€™s not possible for real-world data, so we will settle for the lowest valueâ€”that is, we want to &lt;em&gt;minimize&lt;/em&gt; the costÂ function.&lt;/p&gt;
&lt;div class="math"&gt;$$ \underset{Î¸}{\arg\min} \, J(Î¸) $$&lt;/div&gt;
&lt;p&gt;In the language of math (and neural networks), this is called &lt;strong&gt;stochastic gradient descent&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;em&gt;gradient&lt;/em&gt; is the thing weâ€™re trying toÂ minimize.&lt;/li&gt;
&lt;li&gt;This process is &lt;em&gt;stochastic&lt;/em&gt; (random) because we start with random weights (all zeros), which puts us at a random point on theÂ mug.&lt;/li&gt;
&lt;li&gt;It is a &lt;em&gt;descent&lt;/em&gt; because we want to move down to a progressively flatter region of the mug with each attempt (combination ofÂ weights).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The descent occurs in â€œsteps.â€ Imagine, for a moment, a basic parabola &lt;span class="math"&gt;\(f(x) = x^2\)&lt;/span&gt; instead of a mug. The derivative at any point &lt;span class="math"&gt;\(x\)&lt;/span&gt; is &lt;span class="math"&gt;\(2x\)&lt;/span&gt;. Positive &lt;span class="math"&gt;\(x\)&lt;/span&gt; values give us positive derivatives and negative &lt;span class="math"&gt;\(x\)&lt;/span&gt; values give us negative derivatives. If we started at some point to the right of 0 and wanted to follow the parabola to its trough, we could do that by subtracting something from &lt;span class="math"&gt;\(x\)&lt;/span&gt;. Likewise, if we started at some point to the left of 0, weâ€™d want to add something to &lt;span class="math"&gt;\(x\)&lt;/span&gt;â€”or rather, subtract a negativeÂ value.&lt;/p&gt;
&lt;p&gt;This means that if we start at any point &lt;span class="math"&gt;\(x\)&lt;/span&gt; and subtract &lt;span class="math"&gt;\(\frac{dy}{dx}\)&lt;/span&gt;, we will tend toward the trough. We donâ€™t necessarily know exactly what our new &lt;span class="math"&gt;\(x\)&lt;/span&gt; value will be, but we can assume that subtracting &lt;span class="math"&gt;\(\frac{dy}{dx}\)&lt;/span&gt; again will take us closer to the trough, although slightly less closer. Each step brings us increasingly closer but in progressively smaller steps. At some point, we will reach &lt;strong&gt;convergence&lt;/strong&gt;, or a point that is close enough toÂ minimum.&lt;/p&gt;
&lt;p&gt;The same applies to gradients. The gradient for any set of weights &lt;span class="math"&gt;\(Î¸\)&lt;/span&gt; tells us the &lt;em&gt;opposite&lt;/em&gt; direction we should go in to find the bottom of the mug. That means that if we start with some initial collection of weights &lt;span class="math"&gt;\(Î¸\)&lt;/span&gt; and keep subtracting the gradient, which is notated &lt;span class="math"&gt;\(\nabla J\)&lt;/span&gt;, we should eventually arrive at theÂ bottom.&lt;/p&gt;
&lt;div class="math"&gt;$$ \textrm{repeat } Î¸ := Î¸ - \nabla J \textrm{ until convergence} $$&lt;/div&gt;
&lt;p&gt;But try translating this intoÂ Python.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;gradient_of_cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;my_weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;effect_of_weight&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;my_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;last_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;my_weights&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="n"&gt;gradient_of_cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;last_weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# ???&lt;/span&gt;
    &lt;span class="n"&gt;last_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;my_weights&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;convergence&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="c1"&gt;# ???&lt;/span&gt;
        &lt;span class="k"&gt;break&lt;/span&gt;

&lt;span class="n"&gt;minimum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;my_weights&lt;/span&gt; &lt;span class="c1"&gt;# ???&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In doing so, a couple of questions arise (besides the suspicion that there are way too many loops andÂ functions):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How do you compare weights so that you can know which of two collections is â€œlesserâ€ and which isÂ â€œgreaterâ€?&lt;/li&gt;
&lt;li&gt;How do you know when youâ€™ve reachedÂ convergence?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Itâ€˜s clear that we have more or less come as far as we can with the level of math and coding that we have used soÂ far.&lt;/p&gt;
&lt;h1 id="part-2-crazy-math-beautiful-code"&gt;Part 2: Crazy math, beautifulÂ code&lt;/h1&gt;
&lt;p&gt;When you think about it, it almost seems a little backwards to call linear algebra the starting point of machine learning. After all, weâ€™ve come this far without it. Multivariable calculus strikes me as more fundamental, although I suppose that it might be hard to imagine the output of a two-variable function as a bowl- or mug-shaped object without the concept ofÂ vectors.&lt;/p&gt;
&lt;p&gt;In any case, itâ€™s time for that ZenÂ uppercut.&lt;/p&gt;
&lt;p&gt;I wonâ€™t go into the mechanics of vector and matrix operations here; they are too tedious to write about, and Iâ€™m certainly not the best person to explain them. What Iâ€™m more interested in is the concept of &lt;strong&gt;vectorization&lt;/strong&gt;: the â€œtranslationâ€ (pun intended) of the algebra and calculus above into linear algebra and multivariable calculus, as well as what that looks like in Python (usingÂ NumPy).&lt;/p&gt;
&lt;h2 id="vectorize-all-the-things"&gt;Vectorize all theÂ things!!!&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Ninja mode activated! (That was easy, eh?) First of all, letâ€™s convert all lists to &lt;em&gt;vectors&lt;/em&gt; and all lists of lists to &lt;em&gt;matrices&lt;/em&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\textbf X =
\begin{bmatrix}
  x_1^1 &amp;amp; x_2^1 &amp;amp; \dots  &amp;amp; x_n^1 \\[0.5em]
  x_1^2 &amp;amp; x_2^2 &amp;amp; \dots  &amp;amp; x_n^2 \\[0.5em]
  \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\[0.5em]
  x_1^m &amp;amp; x_2^m &amp;amp; \dots  &amp;amp; x_n^m
\end{bmatrix} \qquad{}
&amp;amp; \vec Î¸ = \begin{bmatrix} Î¸_0 \\ Î¸_1 \\ Î¸_2 \\ \vdots \\ Î¸_n \end{bmatrix}
&amp;amp; \vec y = \begin{bmatrix} y_0 \\ y_1 \\ \vdots \\ y_m \end{bmatrix}
\end{aligned}$$&lt;/div&gt;
&lt;p&gt;Letâ€™s use &lt;code class="highlight"&gt;scikit-learn&lt;/code&gt; to generate a suitable dataset for us. Since we wonâ€™t have to do any of the computations by hand, letâ€™s go wild with the number of features and samples. We also need a vector with our initial weights (allÂ zeros).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sklearn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;make_regression&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# as many rows as X has columns, and 1 column&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;One important thing to note is that the dummy feature &lt;span class="math"&gt;\(x_0\)&lt;/span&gt; needs to be added to the data. Also, &lt;code class="highlight"&gt;scikit-learn&lt;/code&gt; generates a &lt;code class="highlight"&gt;y&lt;/code&gt; array that doesnâ€™t have the proper dimensions of a vector for someÂ reason.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hstack&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# padding for bias column&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# this just fixes a quirk of sklearn's output&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="math"&gt;$$ \begin{aligned} \textbf X =
\begin{bmatrix}
  \textcolor{red}1 &amp;amp; x_1^1 &amp;amp; x_2^1 &amp;amp; \dots &amp;amp; x_n^1 \\[0.5em]
  \textcolor{red}1 &amp;amp; x_1^2 &amp;amp; x_2^2 &amp;amp; \dots &amp;amp; x_n^2 \\[0.5em]
  \textcolor{red}\vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\[0.5em]
  \textcolor{red}1 &amp;amp; x_1^m &amp;amp; x_2^m &amp;amp; \dots &amp;amp; x_n^m
\end{bmatrix} \qquad{}
&amp;amp; \vec Î¸ = \begin{bmatrix} Î¸_0 \\ Î¸_1 \\ Î¸_2 \\ \vdots \\ Î¸_n \end{bmatrix}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;The hypothesis function &lt;span class="math"&gt;\(h_Î¸(x^i)\)&lt;/span&gt; can now be written succinctly as the product of the â€œhousesâ€ matrix &lt;span class="math"&gt;\(\textbf X\)&lt;/span&gt; and the weights vector &lt;span class="math"&gt;\(\vec Î¸\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned} \textbf X\vec Î¸ &amp;amp;= \begin{bmatrix}
  \textcolor{teal}{x_0^1} &amp;amp; \textcolor{teal}{x_1^1} &amp;amp; \textcolor{teal}{x_2^1} &amp;amp; \dots &amp;amp; \textcolor{teal}{x_n^1} \\[0.5em]
  \textcolor{teal}{x_0^2} &amp;amp; \textcolor{teal}{x_1^2} &amp;amp; \textcolor{teal}{x_2^2} &amp;amp; \dots &amp;amp; \textcolor{teal}{x_n^2} \\[0.5em]
  \textcolor{teal}\vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\[0.5em]
  \textcolor{teal}{x_0^m} &amp;amp; \textcolor{teal}{x_1^m} &amp;amp; \textcolor{teal}{x_2^m} &amp;amp; \dots &amp;amp; \textcolor{teal}{x_n^m}
\end{bmatrix} \begin{bmatrix} \textcolor{magenta}{Î¸_0} \\ \textcolor{magenta}{Î¸_1} \\ \textcolor{magenta}{Î¸_2} \\ \vdots \\ \textcolor{magenta}{Î¸_n} \end{bmatrix} \\
&amp;amp;= \begin{bmatrix}
  \textcolor{magenta}{Î¸_0}\textcolor{teal}{x_0^1} &amp;amp; \textcolor{magenta}{Î¸_1}\textcolor{teal}{x_1^1} &amp;amp; \textcolor{magenta}{Î¸_2}\textcolor{teal}{x_2^1} &amp;amp; \dots &amp;amp; \textcolor{magenta}{Î¸_n}\textcolor{teal}{x_n^1} \\[0.5em]
  \textcolor{magenta}{Î¸_0}\textcolor{teal}{x_0^2} &amp;amp; \textcolor{magenta}{Î¸_1}\textcolor{teal}{x_1^2} &amp;amp; \textcolor{magenta}{Î¸_2}\textcolor{teal}{x_2^2} &amp;amp; \dots &amp;amp; \textcolor{magenta}{n_2}\textcolor{teal}{x_n^2} \\[0.5em]
  \vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\[0.5em]
  \textcolor{magenta}{Î¸_0}\textcolor{teal}{x_0^m} &amp;amp; \textcolor{magenta}{Î¸_1}\textcolor{teal}{x_1^m} &amp;amp; \textcolor{magenta}{Î¸_2}\textcolor{teal}{x_2^m} &amp;amp; \dots &amp;amp; \textcolor{magenta}{Î¸_n}\textcolor{teal}{x_n^m}
\end{bmatrix} \end{aligned}
$$&lt;/div&gt;
&lt;p&gt;Here is the generalized form of linear regression before and after vectorization, followed by the vectorized NumPyÂ version.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Notice how the non-vectorized version inherently refers to only one sample at a time, with the superscript &lt;span class="math"&gt;\(i\)&lt;/span&gt;. This implies the equation is true for each &lt;span class="math"&gt;\(i\)&lt;/span&gt;, but the vectorized version automatically includes every sample at the same time without us even having to know how many there are. So letâ€™s use the plural &lt;code class="highlight"&gt;hypotheses&lt;/code&gt; to name theÂ result.&lt;/li&gt;
&lt;li&gt;Look at how simple the math expression and the code become! (Of course, it does rely on a sufficient understanding of matrixÂ multiplication.)&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
h_Î¸(x^i) &amp;amp;= \textcolor{magenta}{Î¸_0}\textcolor{teal}{x_0^i} + \textcolor{magenta}{Î¸_1}\textcolor{teal}{x_1^i} + \cdots + \textcolor{magenta}{Î¸_n}\textcolor{teal}{x_n^i} \\
h_Î¸(\textbf X) &amp;amp;= \textbf X\vec Î¸
\end{aligned} $$&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;hypotheses&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;theta&lt;/span&gt; &lt;span class="c1"&gt;# @ is short for matrix multiplication&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="vectorizing-the-cost-function-so-fresh-so-clean"&gt;Vectorizing the cost function: So fresh, soÂ clean&lt;/h2&gt;
&lt;p&gt;This makes it easy to express the error as the difference between the hypothesis and the actualÂ value:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\textrm{error} &amp;amp;= \hat{Y}_i - Y_i \\
&amp;amp;= h_Î¸(x^i) - y_i \\
\vec e &amp;amp;= \textbf X\vec Î¸ - \vec y
\end{aligned} $$&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hypotheses&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Recall that the cost function involves the sum of squared errors. In linear algebra, summation can be expressed as the product of a transposed vector of ones and a vector with the values to be summed, which struck me as a very cleverÂ manipulation.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\vec o = \begin{bmatrix} 1 \\ 1 \\ \vdots \\ 1 \end{bmatrix}
&amp;amp; \quad{} \vec e = \begin{bmatrix} e_1 \\ e_2 \\ \vdots \\ e_m \end{bmatrix}
= \begin{bmatrix} h_Î¸(x^1) - y_1 \\ h_Î¸(x^2) - y_2 \\ \vdots \\ h_Î¸(x^m) - y_m \end{bmatrix}
\end{aligned} $$&lt;/div&gt;
&lt;div class="math"&gt;$$
\begin{aligned}
\vec o^T\vec e &amp;amp;= \begin{bmatrix} 1 &amp;amp; 1 &amp;amp; \cdots &amp;amp; 1 \end{bmatrix} \begin{bmatrix} e_1 \\ e_2 \\ \vdots \\ e_m \end{bmatrix} \\
&amp;amp;= \textcolor{lightgray}1 \cdot e_1 + \textcolor{lightgray}1 \cdot e_2 + \cdots + \textcolor{lightgray}1 \cdot e_m = \sum_{i=1}^m e_i
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;The cost function thenÂ becomes:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
J(Î¸) &amp;amp;= \frac{1}{2m}\sum_{i=1}^m \Big[h_Î¸(x^i) - Y_i\Big]^2 \\
&amp;amp;= \frac{1}{2m}\sum_{i=1}^m {(e_i)}^2 \\
&amp;amp;= \frac{1}{2m} \vec o^T \vec e^2
\end{aligned} $$&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;num_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;o&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;num_samples&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that the NumPy function &lt;code class="highlight"&gt;np.square(z)&lt;/code&gt; is faster than &lt;code class="highlight"&gt;z ** 2&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;rando&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;500000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="c1"&gt;# just a random big dataset for testing&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rando&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mf"&gt;1.2&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="err"&gt;Â±&lt;/span&gt; &lt;span class="mf"&gt;7.99&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt; &lt;span class="err"&gt;Â±&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="n"&gt;runs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="n"&gt;each&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="n"&gt;rando&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="mf"&gt;1.19&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="err"&gt;Â±&lt;/span&gt; &lt;span class="mf"&gt;7.01&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt; &lt;span class="err"&gt;Â±&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="n"&gt;runs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="n"&gt;each&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and &lt;code class="highlight"&gt;o.T @ np.square(z))&lt;/code&gt; (that is, &lt;span class="math"&gt;\(\vec o^T\textbf Z^2\)&lt;/span&gt;)  blows &lt;code class="highlight"&gt;sum(z ** 2)&lt;/code&gt; (that is, &lt;span class="math"&gt;\(\sum_{i=1}^m (z_i)^2\)&lt;/span&gt;) out of theÂ water:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rando&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mf"&gt;1.36&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="err"&gt;Â±&lt;/span&gt; &lt;span class="mf"&gt;16.3&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt; &lt;span class="err"&gt;Â±&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="n"&gt;runs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="n"&gt;each&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rando&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="mf"&gt;1.37&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="err"&gt;Â±&lt;/span&gt; &lt;span class="mf"&gt;12.1&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt; &lt;span class="err"&gt;Â±&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="n"&gt;runs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="n"&gt;each&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;rando&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="c1"&gt;# because rando has more than 1 column&lt;/span&gt;
&lt;span class="mf"&gt;25.1&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="err"&gt;Â±&lt;/span&gt; &lt;span class="mi"&gt;603&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt; &lt;span class="err"&gt;Â±&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="n"&gt;runs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="n"&gt;each&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;At this point, itâ€™s helpful to turn our cost function into a Python function that takes &lt;span class="math"&gt;\(\textbf X, \vec y, \vec Î¸\)&lt;/span&gt; as its inputs. This will make it easier to evaluate our modelÂ later.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;num_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;o&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;num_samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
    &lt;span class="n"&gt;cost_array&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;num_samples&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# 1x1 matrix&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;cost_array&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;# plain number&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="vectorizing-the-gradient-ninja-mode-on-overdrive"&gt;Vectorizing the gradient: Ninja mode onÂ overdrive&lt;/h2&gt;
&lt;p&gt;On to the gradient. This is where linear algebra really kicks this thing into highÂ gear.&lt;/p&gt;
&lt;p&gt;(This is also where I get to show off my LaTeXÂ chops.)&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\nabla J = \frac{\partial J(Î¸)}{\partial Î¸_j} &amp;amp;= \Bigg\{\frac{\partial J(Î¸)}{\partial Î¸_0}, \frac{\partial J(Î¸)}{\partial Î¸_1}, \cdots, \frac{\partial J(Î¸)}{\partial Î¸_n}\Bigg\} \\
&amp;amp;= \frac{1}{m} \sum_{i=1}^m \Big[h_Î¸(x^i) - Y_i\Big]^2 \cdot x_j^i \qquad{} \textrm{for } 0 \leq j \leq n \\
&amp;amp;= \frac{1}{m} \sum_{i=1}^m {(e_i)}^2 x_j^i \qquad{}\qquad{}\qquad{}\qquad{}\qquad{}  " \\
&amp;amp;= \frac{1}{m} \sum_{i=1}^m x_j^i {(e_i)}^2 \qquad{}\qquad{}\qquad{}\qquad{}\qquad{}  " \\
&amp;amp;= \Bigg\{ \textcolor{teal}{
  \frac{1}{m} \sum_{i=1}^m x_0^i {(e_i)}^2, \frac{1}{m} \sum_{i=1}^m x_1^i {(e_i)}^2, \cdots, \frac{1}{m} \sum_{i=1}^m x_n^i {(e_i)}^2
  }\Bigg\}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;Transposing &lt;span class="math"&gt;\(\textbf X\)&lt;/span&gt; and squaring &lt;span class="math"&gt;\(\vec e\)&lt;/span&gt; givesÂ us:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\textbf X^T = \begin{bmatrix}
  x_0^1 &amp;amp; x_0^2 &amp;amp; \dots &amp;amp; x_0^m \\[0.5em]
  x_1^1 &amp;amp; x_1^2 &amp;amp; \dots &amp;amp; x_1^m \\[0.5em]
  \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\[0.5em]
  x_n^1 &amp;amp; x_n^2 &amp;amp; \dots  &amp;amp; x_n^m
\end{bmatrix} &amp;amp; \quad{} \vec e^2 = \begin{bmatrix} {(e_1)}^2 \\[0.5em] {(e_2)}^2 \\[0.5em] \vdots \\[0.5em] {(e_m)}^2 \end{bmatrix}
\end{aligned} $$&lt;/div&gt;
&lt;div class="math"&gt;$$ \textbf X^T \vec e^2 = \begin{bmatrix}
  x_0^1 {(e_1)}^2 + x_0^2 {(e_2)}^2 + x_0^3 {(e_3)}^2 + \cdots + x_0^m {(e_m)}^2 \\[0.5em]
  x_1^1 {(e_1)}^2 + x_1^2 {(e_2)}^2 + x_1^3 {(e_3)}^2 + \cdots + x_1^m {(e_m)}^2 \\[0.5em]
  \vdots \\[0.5em]
  x_n^1 {(e_1)}^2 + x_n^2 {(e_2)}^2 + x_n^3 {(e_3)}^2 + \cdots + x_n^m {(e_m)}^2
\end{bmatrix} = \begin{bmatrix}
  \sum_{i=1}^m x_0^i{(e_1)}^2 \\[0.5em]
  \sum_{i=1}^m x_1^i{(e_1)}^2 \\[0.5em]
  \vdots \\[0.5em]
  \sum_{i=1}^m x_n^i{(e_1)}^2 \\
\end{bmatrix} $$&lt;/div&gt;
&lt;p&gt;Notice how multiplying this result by &lt;span class="math"&gt;\(\frac{1}{m}\)&lt;/span&gt; gives us a vector containing the same values highlighted above inÂ teal.&lt;/p&gt;
&lt;div class="math"&gt;$$ \frac{1}{m} \textbf X^T \vec e^2 = \frac{1}{m} \begin{bmatrix}
  \sum_{i=1}^m x_0^i{(e_1)}^2 \\[0.5em]
  \sum_{i=1}^m x_1^i{(e_1)}^2 \\[0.5em]
  \vdots \\[0.5em]
  \sum_{i=1}^m x_n^i{(e_1)}^2 \\
\end{bmatrix} = \begin{bmatrix}
  \textcolor{teal}{ \frac{1}{m} \sum_{i=1}^m x_0^i{(e_1)}^2 } \\[0.5em]
  \textcolor{teal}{ \frac{1}{m} \sum_{i=1}^m x_1^i{(e_1)}^2 } \\[0.5em]
  \textcolor{teal}{ \vdots } \\[0.5em]
  \textcolor{teal}{ \frac{1}{m} \sum_{i=1}^m x_n^i{(e_1)}^2 } \\
\end{bmatrix} = \begin{bmatrix}
  \frac{\partial J(Î¸)}{\partial Î¸_0} \\[0.5em]
  \frac{\partial J(Î¸)}{\partial Î¸_1} \\[0.5em]
  \vdots \\[0.5em]
  \frac{\partial J(Î¸)}{\partial Î¸_n}
\end{bmatrix} $$&lt;/div&gt;
&lt;p&gt;Astonishingly, that gigantic mess can be expressedÂ as&lt;/p&gt;
&lt;div class="math"&gt;$$ \nabla J = \frac{1}{m} \textbf X^T \vec e^2 $$&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;num_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;gradient&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;num_samples&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Finally&lt;/em&gt;, we can work out the last function, the gradient descentÂ function:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{gathered} \vec Î¸ := \vec Î¸ - Î±\frac{1}{m} \textbf X^T \vec e^2 \\
\textrm{repeat until convergence} \end{gathered} $$&lt;/div&gt;
&lt;p&gt;Hey, whereâ€™d that &lt;span class="math"&gt;\(Î±\)&lt;/span&gt; come from? Thatâ€™s the &lt;strong&gt;learning rate&lt;/strong&gt;, a small number that adjusts the size of each training step. Too large and you jump right over the minimum; too small and you never reach theÂ minimum.&lt;/p&gt;
&lt;p&gt;For now, letâ€™s choose an arbitrary value for &lt;span class="math"&gt;\(Î±\)&lt;/span&gt; and disregard the whole bit about convergence. If we wanted to perform stochastic gradient descent with 100 steps, this is how weâ€™d doÂ it:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.01&lt;/span&gt;
    &lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
    &lt;span class="n"&gt;num_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;step_distance&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;num_samples&lt;/span&gt;
    &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;step_distance&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Letâ€™s refactor this as a function &lt;code class="highlight"&gt;train_lr_model&lt;/code&gt; that takes &lt;span class="math"&gt;\(\textbf X, \vec y\)&lt;/span&gt;, and the number of steps (training epochs) as its inputs, and outputs the weights &lt;span class="math"&gt;\(\vec Î¸\)&lt;/span&gt;. Along the way, letâ€™s have it tell us the cost. If all goes well, we should see that number approach zero as trainingÂ progresses.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;train_lr_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;num_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
        &lt;span class="n"&gt;step_distance&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;num_samples&lt;/span&gt;
        &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;step_distance&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="c1"&gt;# dot products are single values, but NumPy returns them as 1x1 matrices&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;

&lt;span class="n"&gt;weights_300_epochs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_lr_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;300&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now, we can predict the output for a random set of featureÂ values.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;

&lt;span class="n"&gt;mystery_input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;mystery_input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hstack&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;mystery_input&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# dummy feature&lt;/span&gt;
&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mystery_input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights_300_epochs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I like to geek out on math notation and wrote this function to generate LaTeX for the equation of theÂ model:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;expand_model_latex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;terms&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"{round(w[0], 2)}x_{i}"&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"$$ h_Î¸(x) &lt;/span&gt;&lt;span class="se"&gt;\a&lt;/span&gt;&lt;span class="s2"&gt;pprox {' + '.join(terms)} $$"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="math"&gt;$$ h_Î¸(x) \approx -2.36x_0 + 63.26x_1 + 61.15x_2 + 88.99x_3 + 0.82x_4 + 58.95x_5 $$&lt;/div&gt;
&lt;p&gt;Weâ€™re not done with linear regression, but letâ€™s recap so that this post canÂ end.&lt;/p&gt;
&lt;h2 id="summary-so-far"&gt;Summary soÂ far&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align="center"&gt;Broke&lt;/th&gt;
&lt;th align="center"&gt;Woke&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Linear regression model&lt;/td&gt;
&lt;td align="center"&gt;
&lt;div class="math"&gt;$$h_Î¸(x) = Î¸_0x_0 + Î¸_1x_1 + \cdots + Î¸_nx_n$$&lt;/div&gt;
&lt;/td&gt;
&lt;td align="center"&gt;
&lt;div class="math"&gt;$$h_Î¸(\textbf X) = \textbf X\vec Î¸$$&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Cost function&lt;/td&gt;
&lt;td align="center"&gt;
&lt;div class="math"&gt;$$J(Î¸) = \frac{1}{2m}\sum_{i=1}^m{\Big[h_Î¸(x^i) - y_i\Big]}^2$$&lt;/div&gt;
&lt;/td&gt;
&lt;td align="center"&gt;
&lt;div class="math"&gt;$$ \begin{gathered} \vec e = h_Î¸{\textbf X} - \vec y \\ J(Î¸) = \frac{1}{2m}\vec o^T\vec e^2 \end{gathered} $$&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Gradient of cost function&lt;/td&gt;
&lt;td align="center"&gt;
&lt;div class="math"&gt;$$ \frac{\partial J(Î¸)}{\partial Î¸_j} = \frac{1}{m}\sum_{i=1}^m\Big[h_Î¸(x^i) - y_i\Big]x_j^i $$&lt;/div&gt;
&lt;/td&gt;
&lt;td align="center"&gt;
&lt;div class="math"&gt;$$ \nabla J = \frac{1}{m}\textbf X^T\vec e $$&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Gradient descent function&lt;/td&gt;
&lt;td align="center"&gt;
&lt;div class="math"&gt;$$ Î¸_j := Î¸_j - Î±\frac{\partial J(Î¸)}{\partial Î¸_j} $$&lt;/div&gt;
&lt;/td&gt;
&lt;td align="center"&gt;
&lt;div class="math"&gt;$$ \vec Î¸ := \vec Î¸ - Î±\nabla J $$&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Such complex math can be applied to a linear regression model trained in some 20 lines ofÂ Python!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt;

&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sklearn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;make_regression&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hstack&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# padding for bias column&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# this just fixes a quirk of sklearn's output&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;num_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;o&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;num_samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
    &lt;span class="n"&gt;cost_array&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;num_samples&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;cost_array&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;train_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;num_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
        &lt;span class="n"&gt;step_distance&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;num_samples&lt;/span&gt;
        &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;step_distance&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Completed {epochs} epochs of training."&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Final cost: {cost(X, y, weights)}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="comparison-of-performance"&gt;Comparison ofÂ performance&lt;/h2&gt;
&lt;p&gt;This is a contrived comparison, but it helps to illustrate very clearly the point of jumping through all of these mathematicalÂ hoops.&lt;/p&gt;
&lt;p&gt;On the 500-sample, 5-feature dataset weâ€™ve been using, the vectorized gradient descent function runs over &lt;strong&gt;7,000 times faster&lt;/strong&gt; than the terrible, monstrous, donâ€™t-say-I-didnâ€™t-warn-you procedural version from the beginning of thisÂ post.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="n"&gt;train_lr_model_procedurally&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.00001&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mf"&gt;14.2&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="err"&gt;Â±&lt;/span&gt; &lt;span class="mi"&gt;609&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt; &lt;span class="err"&gt;Â±&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="n"&gt;runs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="n"&gt;each&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="n"&gt;train_lr_model_vectorizedly&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.00001&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mf"&gt;2.28&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="err"&gt;Â±&lt;/span&gt; &lt;span class="mf"&gt;64.9&lt;/span&gt; &lt;span class="err"&gt;Âµ&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt; &lt;span class="err"&gt;Â±&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="n"&gt;runs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="n"&gt;loops&lt;/span&gt; &lt;span class="n"&gt;each&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id="remaining-questions-for-future-posts-links-will-be-included-upon-publication"&gt;Remaining questions for future posts (links will be included uponÂ publication)&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Are there any other simple techniques to speed this up? (MeanÂ normalization)&lt;/li&gt;
&lt;li&gt;&lt;a href="squarest-root-in-babylon"&gt;Are there any complex techniques to speed this up? (AutomaticÂ differentiation)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="from-zero-to-ero"&gt;How do we know when weâ€™ve reached convergence?Â (Epsilon)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;How can &lt;em&gt;linear&lt;/em&gt; (as opposed to &lt;em&gt;logistic&lt;/em&gt;) regression be applied to language tasks? (General backpropagation of neuralÂ networks)&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="references"&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=fNk_zzaMoSs&amp;amp;list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab"&gt;The Essence of Linear Algebra&lt;/a&gt; (video series), GrantÂ Sanderson&lt;/li&gt;
&lt;li&gt;&lt;a href="https://towardsdatascience.com/linear-regression-using-python-b136c91bf0a2"&gt;Linear Regression using Python&lt;/a&gt;, AnimeshÂ Agarwal&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.ritchieng.com/multi-variable-linear-regression/"&gt;Linear Regression with Multiple Variables&lt;/a&gt;, RitchieÂ Ng&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/@lachlanmiller_52885/understanding-and-calculating-the-cost-function-for-linear-regression-39b8a3519fcb"&gt;Understanding and Calculating the Cost Function for Linear Regression&lt;/a&gt;, LachlanÂ Miller&lt;/li&gt;
&lt;li&gt;&lt;a href="http://anwarruff.com/the-linear-regression-cost-function-in-matrix-form/"&gt;The Linear Regression Cost Function in Matrix Form&lt;/a&gt;, AnwarÂ Ruff&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/differentiating-vector-valued-functions/a/multivariable-chain-rule-simple-version"&gt;Multivariable chain rule, simple version&lt;/a&gt;, KhanÂ Academy&lt;/li&gt;
&lt;/ul&gt;</content><category term="koan"></category><category term="multivariable calculus"></category><category term="stochastic gradient descent"></category><category term="linear algebra"></category></entry></feed>