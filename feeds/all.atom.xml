<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Judo Salt Genius</title><link href="http://tabidots.github.io/" rel="alternate"></link><link href="http://tabidots.github.io/feeds/all.atom.xml" rel="self"></link><id>http://tabidots.github.io/</id><updated>2019-05-30T20:08:24+07:00</updated><entry><title>Introduction to Modular Arithmetic, with examples in Clojure</title><link href="http://tabidots.github.io/2019/05/introduction-to-modular-arithmetic" rel="alternate"></link><published>2019-05-30T20:08:24+07:00</published><updated>2019-05-30T20:08:24+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-05-30:/2019/05/introduction-to-modular-arithmetic</id><summary type="html">&lt;p&gt;Though modular arithmetic is rather obscure, we actually use it every day—primarily when we tell time. And if you’re a programmer, you have probably used the % operator before. However, there is much more to modular arithmetic, and the way it seems to turn normal math on its head is very&amp;nbsp;fascinating.&lt;/p&gt;</summary><content type="html">
&lt;p&gt;Nowadays, we take encryption on the internet for granted, but have you ever wondered how it works? Advances in cryptography since the mid-20th century have relied on an area of mathematics called &lt;strong&gt;modular arithmetic&lt;/strong&gt; to guarantee the security of everything from your WhatsApp conversations and credit card information.&lt;/p&gt;
&lt;p&gt;Though modular arithmetic is rather obscure, we actually use it every day—primarily when we tell time. And if you’re a programmer, you have probably used the &lt;code class="highlight"&gt;&lt;span class="nv"&gt;%&lt;/span&gt;&lt;/code&gt; operator before. However, there is much more to modular arithmetic, and the way it seems to turn normal math on its head is very fascinating.&lt;/p&gt;
&lt;p&gt;In this post, I’ll cover the very basics of modular arithmetic.&lt;/p&gt;
&lt;h1 id="counting-in-a-circle"&gt;Counting in a circle&lt;/h1&gt;
&lt;p&gt;Modular arithmetic can be described as “counting in a circle.” It is also called “clock arithmetic,” which gives a hint as to how the concept works. We all know that if you go somewhere at 2 o’clock for 4 hours, it will be 6 o’clock when you return, but if you go somewhere at 11 o’clock for 4 hours, it will be 3 o’clock when you return—&lt;em&gt;not&lt;/em&gt; 15 o’clock (assuming you use the 12-hour clock).&lt;/p&gt;
&lt;p&gt;This is because the numbers of the clock &lt;em&gt;wrap around&lt;/em&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ 1,2,3,4,5,6,7,8,9,10,11,12,1,2,3,4,5,6,7,8,9,10,11,12 \cdots $$&lt;/div&gt;
&lt;p&gt;We can imitate this in Clojure with the &lt;code class="highlight"&gt;cycle&lt;/code&gt; function (don’t actually run this, though, because it will go on forever and lock up your &lt;span class="caps"&gt;REPL&lt;/span&gt;):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;cycle &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;;; 13 because range excludes the endpoint&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you are a musician, you can relate this to many areas of music as well: the names of the notes in the scale, such as &lt;span class="caps"&gt;ABCDEFG&lt;/span&gt;—or &lt;em&gt;sa re ga ma pa dha ni&lt;/em&gt;, if you like—repeat indefinitely. (That doesn’t mean the notes themselves are the same; more on that later.) There is no such note as “J,” for example.&lt;/p&gt;
&lt;p&gt;In fact, it is predominantly only Western culture and music that conceptualizes music (and time) linearly. For example, Indian classical music, flamenco, and Javanese gamelan music are three forms of world music that are well-known for their explicit use of cyclic representations of form and rhythm. But that’s going beyond the scope of this post 😅&lt;/p&gt;
&lt;p&gt;Back to numbers. If we stretch the clock cycle out into a number line, you will never encounter a number greater than 12 no matter how far you go along the line. Or rather, once you go beyond 12, you find that the result is 12 less than the “normal” number:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20...
1 2 3 4 5 6 7 8 9 10 11 12  1  2  3  4  5  6  7  8...
&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id="reduction-modulo-n"&gt;Reduction modulo &lt;span class="math"&gt;\(n\)&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;As the time-telling example shows, addition in modular arithmetic is similar to regular old addition, except with one extra step. If the result is greater than our upper limit (in this case 12), then we can keep subtracting the limit until we get a result that is less than the limit.&lt;/p&gt;
&lt;p&gt;To be more precise, this upper limit is called the &lt;strong&gt;modulus&lt;/strong&gt;, and our final answer represents the &lt;em&gt;remainder after dividing&lt;/em&gt; the initial result by the modulus. The transformation of our initial result into the final answer is called &lt;strong&gt;reduction &lt;em&gt;modulo&lt;/em&gt;&lt;/strong&gt; &lt;span class="math"&gt;\(n\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Ordinary arithmetic:&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{aligned}
2 + 2 &amp;amp;= 4 \\
11 + 4 &amp;amp;= 15
\end{aligned}
$$&lt;/div&gt;
&lt;p&gt;Modular arithmetic:&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{aligned}
2 + 2 &amp;amp;\equiv 4 \mod 12 \\
11 + 4 &amp;amp; \textcolor{red}{\not= 15} \\
&amp;amp; \textcolor{green}{\equiv 3 \mod 12}
\end{aligned}
$$&lt;/div&gt;
&lt;p&gt;because 12 goes into 15 one time and leaves a remainder of 3. In other words, the &lt;strong&gt;quotient&lt;/strong&gt; is 1 and the remainder is 3.&lt;/p&gt;
&lt;p&gt;Remainders, then, are absolutely central to modular arithmetic. Nowadays, remainders and long division are things that basically nobody bothers with after elementary school, but evidently &lt;a href="https://en.wikipedia.org/wiki/Carl_Friedrich_Gauss"&gt;Gauss&lt;/a&gt; was fascinated enough with remainders to use them as the basis for an entire mathematical treatise, the &lt;a href="Disquisitiones Arithmeticae"&gt;&lt;em&gt;Disquisitiones Arithmeticae&lt;/em&gt;&lt;/a&gt;. And that’s why we have modular arithmetic and ultimately, now, encrypted WhatsApp messages 😄&lt;/p&gt;
&lt;p&gt;But wait—what’s that &lt;span class="math"&gt;\(\equiv\)&lt;/span&gt; sign? Does that mean two things are “even more” equal? No, &lt;span class="math"&gt;\(\equiv\)&lt;/span&gt; indicates &lt;strong&gt;congruence&lt;/strong&gt; and is read “is congruent to.” Two numbers are congruent to each other if they have the same remainder after division by a given modulus.&lt;/p&gt;
&lt;p&gt;I’ll come back to that in a bit. But first, some code.&lt;/p&gt;
&lt;h1 id="when-is-not"&gt;When &lt;code class="highlight"&gt;&lt;span class="nv"&gt;%&lt;/span&gt;&lt;/code&gt; is not &lt;code class="highlight"&gt;&lt;span class="nv"&gt;%&lt;/span&gt;&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;If you have used the &lt;code class="highlight"&gt;&lt;span class="nv"&gt;%&lt;/span&gt;&lt;/code&gt; operator in programming before, note that the mathematical way of writing modular arithmetic statements is a little different. The math notation focuses on statements of congruence, and treats &lt;span class="math"&gt;\(\mod n\)&lt;/span&gt; as a prepositional phrase. That is, &lt;span class="math"&gt;\(a \equiv b \mod n\)&lt;/span&gt; communicates the idea that &lt;span class="math"&gt;\(a\)&lt;/span&gt; is congruent to &lt;span class="math"&gt;\(b\)&lt;/span&gt; in the “world” of modulo &lt;span class="math"&gt;\(n\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Programming languages, on the other hand, approach modular arithmetic with an emphasis on the operation (action) of reducing a number modulo another number, where &lt;code class="highlight"&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;/code&gt; means &lt;em&gt;reduce&lt;/em&gt; &lt;code class="highlight"&gt;a&lt;/code&gt; &lt;em&gt;(in the world of) modulo&lt;/em&gt; &lt;code class="highlight"&gt;n&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Instead of &lt;em&gt;declaring&lt;/em&gt; congruence, you would perform a Boolean test for it. In Python, &lt;span class="math"&gt;\(a \overset{?}{\equiv} b \mod n\)&lt;/span&gt; becomes &lt;code class="highlight"&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;/code&gt;, which returns &lt;code class="highlight"&gt;True&lt;/code&gt; or &lt;code class="highlight"&gt;False&lt;/code&gt;. (I am including Python here because it follows the convention of using &lt;code class="highlight"&gt;&lt;span class="nv"&gt;%&lt;/span&gt;&lt;/code&gt;, like most programming languages.)&lt;/p&gt;
&lt;p&gt;In Clojure, the symbol &lt;code class="highlight"&gt;&lt;span class="nv"&gt;%&lt;/span&gt;&lt;/code&gt; is reserved for variables in anonymous functions, so &lt;code class="highlight"&gt;mod&lt;/code&gt; is used instead.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_1_0" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt; &lt;span class="c1"&gt;# This returns the remainder after division&lt;/span&gt;
&lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;
&lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt; &lt;span class="c1"&gt;# This means integer division and returns the quotient&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="bp"&gt;True&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_1" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_1"&gt;Clojure&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mod&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mod&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;quot &lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;;; Integer division in Clojure&lt;/span&gt;
&lt;span class="nv"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mod&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nv"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="nv"&gt;true&lt;/span&gt;
&lt;span class="c1"&gt;;; Using the arrow to reorder the expressions can let you write them&lt;/span&gt;
&lt;span class="c1"&gt;;; a bit more like you'd write them in imperative languages, hence easier to read&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mod&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nv"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id="congruence"&gt;Congruence&lt;/h1&gt;
&lt;p&gt;In our example above, we saw that not only are 3 and 15 congruent with each other, but by the definition of congruence, so is every number of the form &lt;span class="math"&gt;\(12k + 3\)&lt;/span&gt;, where &lt;span class="math"&gt;\(k\)&lt;/span&gt; is an integer. Thus, all of the following are congruent:&lt;/p&gt;
&lt;div class="math"&gt;$$ \cdots -21, -9, 3, 15, 27, 39, 51 \cdots $$&lt;/div&gt;
&lt;p&gt;We can see that this is true by reducing all of those numbers mod 12:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;map &lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mod&lt;/span&gt; &lt;span class="nv"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;-24&lt;/span&gt; &lt;span class="mi"&gt;-9&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt; &lt;span class="mi"&gt;27&lt;/span&gt; &lt;span class="mi"&gt;39&lt;/span&gt; &lt;span class="mi"&gt;51&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="nv"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The infinite set of integers that share this property is called the &lt;strong&gt;congruence class&lt;/strong&gt; of &lt;span class="math"&gt;\(3 \mod 12\)&lt;/span&gt;. An alternative name is &lt;em&gt;residue class&lt;/em&gt;, residue being synonymous with remainder.&lt;/p&gt;
&lt;p&gt;(Note that negative integers are perfectly allowed in modular arithmetic, although in practice, most work is done on non-negative integers only. Negative moduli, on the other hand, are not a thing.)&lt;/p&gt;
&lt;p&gt;What this means is that &lt;span class="math"&gt;\(\mathbb Z\)&lt;/span&gt;, the integers, can be sorted into different “boxes” based on their remainder &lt;span class="math"&gt;\(\mod n\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Returning to the music analogy, all notes belong to a &lt;em&gt;pitch class&lt;/em&gt;. For example, C is a pitch class. On the piano, all notes produced by the white key just to the left of the pair of black keys belong to the pitch class C and are therefore a C, despite belonging to different octaves. The actual frequencies that result differ (by multiples of two, to be exact), but functionally, they are treated &lt;em&gt;equivalently&lt;/em&gt;. You could say that the lowest C on the piano is congruent to the highest C.&lt;/p&gt;
&lt;p&gt;Similarly, for every &lt;span class="math"&gt;\(0 \le a &amp;lt; n\)&lt;/span&gt;, there is a unique congruence class &lt;span class="math"&gt;\(\bar{a}_n\)&lt;/span&gt;, also notated &lt;span class="math"&gt;\(\lbrack a \rbrack_n\)&lt;/span&gt; or &lt;span class="math"&gt;\(\bold a_n\)&lt;/span&gt; (though the latter notation could cause confusion with vectors), which can be defined in set-builder notation as&lt;/p&gt;
&lt;div class="math"&gt;$$ \bar{a}_n = \{ z \in Z \space | \space z = kn + a \space \forall \space k \in \mathbb Z \} $$&lt;/div&gt;
&lt;p&gt;That is, the congruence class &lt;span class="math"&gt;\(\bar{a}_n\)&lt;/span&gt; is the set of integers &lt;span class="math"&gt;\(z\)&lt;/span&gt; given by &lt;span class="math"&gt;\(kn + a\)&lt;/span&gt; for all integers &lt;span class="math"&gt;\(k\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;While no programming language can actually process infinite sets, at least Clojure gives you a way to write them. I’m leaving this here merely to show the Clojure translation of this mathematical definition. If you try to run it, it will freeze your &lt;span class="caps"&gt;REPL&lt;/span&gt;. You’ve been warned.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_2_0" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_0"&gt;Simple&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;congruence-class-posint&lt;/span&gt;
  &lt;span class="s"&gt;"Returns an infinite sequence of the positive integers belonging to&lt;/span&gt;
&lt;span class="s"&gt;  the congruence class a mod n."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;map &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;fn &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;* &lt;/span&gt;&lt;span class="nv"&gt;k&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;range&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_2_1" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_1"&gt;Complete&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;congruence-class&lt;/span&gt;
  &lt;span class="s"&gt;"Returns an infinite sequence of all integers belonging to the congruence class a mod n."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;mapcat &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;fn &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;* &lt;/span&gt;&lt;span class="nv"&gt;k&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;* &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;- &lt;/span&gt;&lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="p"&gt;))]&lt;/span&gt; &lt;span class="c1"&gt;;; We need negative k values as well!&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;range&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id="mathbbz_n"&gt;&lt;span class="math"&gt;\(\mathbb{Z}_n\)&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;Actually, the whole congruence class notation is just a mathematical formality. In practice, any single member of a given congruence class can stand in for the entire class.&lt;/p&gt;
&lt;p&gt;Bearing in mind that &lt;span class="math"&gt;\(n \equiv 0 \mod n\)&lt;/span&gt;, this effectively means that in the “world” of modulo &lt;span class="math"&gt;\(n\)&lt;/span&gt;, we only have to consider the integers from &lt;span class="math"&gt;\(0\)&lt;/span&gt; to &lt;span class="math"&gt;\(n - 1\)&lt;/span&gt;. (The clock analogy breaks down a little bit here because in real life, we use 1 through 12 rather than 0 through 11, but it is still a good starting point.)&lt;/p&gt;
&lt;p&gt;Since this is just an introduction, I’ll skip the bit about residue systems and leave the discussion of ring theory for another post.&lt;/p&gt;
&lt;p&gt;We can use the symbol &lt;span class="math"&gt;\(\mathbb{Z}_n\)&lt;/span&gt; to denote this subset of the integers. In code, it’s equally simple:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now, what do we &lt;em&gt;do&lt;/em&gt; with these numbers?&lt;/p&gt;
&lt;h2 id="addition-subtraction-and-negative-numbers"&gt;Addition, subtraction, and negative numbers&lt;/h2&gt;
&lt;p&gt;Addition, as we have already seen, is basically the same as in normal arithmetic, except the numbers wrap around. Outside the context of telling time, you might be surprised to get a “sum” that is smaller than the numbers you added together.&lt;/p&gt;
&lt;p&gt;The same is true for subtraction:&lt;/p&gt;
&lt;div class="math"&gt;$$ 5 - 8 = -3 \equiv 9 \mod 12$$&lt;/div&gt;
&lt;p&gt;The “difference” we obtained is &lt;em&gt;greater&lt;/em&gt; than the terms we started with.&lt;/p&gt;
&lt;p&gt;Also note that negative numbers now denote counting down from &lt;span class="math"&gt;\(n\)&lt;/span&gt; rather than &lt;span class="math"&gt;\(0\)&lt;/span&gt;. If you are familiar with Python, this should make intuitive sense to you, since you can access the last &lt;code class="highlight"&gt;n&lt;/code&gt;th item in a list by writing &lt;code class="highlight"&gt;&lt;span class="n"&gt;my_list&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id="multiplication-and-efficiency"&gt;Multiplication and efficiency&lt;/h2&gt;
&lt;p&gt;Multiplication also works the same as in normal arithmetic, although again, it can be surprising to obtain a product that is smaller than what you started with.&lt;/p&gt;
&lt;p&gt;Normally, when dealing with even somewhat large numbers, products can ”explode” fairly quickly. That is, it doesn’t take much for multiplication to quickly result in really large numbers that can slow down computation, even for a computer.&lt;/p&gt;
&lt;p&gt;If you are working in a more bare-bones language such as C++ or JavaScript, you might find it need to implement a tried-and-true modular multiplication algorithm such as &lt;a href="https://en.wikipedia.org/wiki/Montgomery_modular_multiplication"&gt;Montgomery multiplication&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;However, I have found that higher-level languages like Python and Clojure come “batteries included” in this respect, so I won’t go into detail about the low-level implementation. You might want to write a helper function to make modular multiplication more convenient to write, though.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;mod-mul&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;b&lt;/span&gt; &lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mod&lt;/span&gt; &lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
  &lt;span class="c1"&gt;;; the ' means avoid integer overflow by using bigintegers if necessary&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mod-mul&lt;/span&gt; &lt;span class="mi"&gt;78&lt;/span&gt; &lt;span class="mi"&gt;99&lt;/span&gt; &lt;span class="mi"&gt;123&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;96&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="order-of-operations"&gt;Order of operations&lt;/h2&gt;
&lt;p&gt;Because each integer in &lt;span class="math"&gt;\(\mathbb{Z}_n\)&lt;/span&gt; is a representative of its entire congruence class, this means that in an expression like &lt;span class="math"&gt;\(a + b \mod n\)&lt;/span&gt;, either &lt;span class="math"&gt;\(a\)&lt;/span&gt; and &lt;span class="math"&gt;\(b\)&lt;/span&gt; (or both) can be reduced before adding if it makes the calculation easier.&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{gathered}
\textcolor{teal}{12309} + \textcolor{maroon}{235301} \equiv \space ? \mod 12 \\
\textcolor{teal}{12309} \equiv \textcolor{skyblue}{9} \mod 12 \qquad \textcolor{maroon}{235301} \equiv \textcolor{mediumpurple}{5} \mod 12 \\
\textcolor{skyblue}{9} + \textcolor{mediumpurple}{5} = 14 \equiv \textcolor{orange}{2} \mod 12
\end{gathered}
$$&lt;/div&gt;
&lt;p&gt;And indeed,&lt;/p&gt;
&lt;div class="math"&gt;$$ \textcolor{teal}{12309} + \textcolor{maroon}{235301} = 247610 \equiv \textcolor{orange}{2} \mod 12 $$&lt;/div&gt;
&lt;p&gt;This isn’t really that useful for addition and subtraction, but for iterative processes like multiplication (which is just repeated addition) and exponentiation (which is just repeated multiplication), reducing the result after each iteration can speed up computation dramatically, because computers prefer working with smaller numbers.&lt;/p&gt;
&lt;p&gt;Specifically, in Java (on which Clojure is based), the maximum value for an &lt;code class="highlight"&gt;int&lt;/code&gt;eger  is &lt;code class="highlight"&gt;2147483647&lt;/code&gt; and the maximum value for a &lt;code class="highlight"&gt;long&lt;/code&gt; integer is &lt;code class="highlight"&gt;9223372036854775807&lt;/code&gt;. These are the two so-called primitive data types for integers, which yield optimal computational performance.&lt;/p&gt;
&lt;p&gt;If you want a bigger number, you need to use either Clojure’s &lt;code class="highlight"&gt;bigint&lt;/code&gt; type (or use the auto-promoting &lt;code class="highlight"&gt;+' -' *' inc' dec'&lt;/code&gt; to safeguard against overflow) or Java’s &lt;code class="highlight"&gt;BigInteger&lt;/code&gt; type. However, computers treat &lt;code class="highlight"&gt;biginteger&lt;/code&gt;s as objects rather than numbers, so they have to work a bit harder (or use more memory) to manipulate them.&lt;/p&gt;
&lt;p&gt;(Side note: To coerce a number to &lt;code class="highlight"&gt;BigInteger&lt;/code&gt;, use the native Clojure function &lt;code class="highlight"&gt;biginteger&lt;/code&gt;. Camel-cased &lt;code class="highlight"&gt;BigInteger.&lt;/code&gt; with a period, is a Java invocation you can use to &lt;em&gt;create&lt;/em&gt; an instance of a &lt;code class="highlight"&gt;BigInteger&lt;/code&gt; object. This opens the doors to other features unavailable in the Clojure standard library, such as generating a random integer that is larger than the maximum &lt;code class="highlight"&gt;long&lt;/code&gt; value. More on this in upcoming posts.)&lt;/p&gt;
&lt;h1 id="going-beyond"&gt;Going beyond&lt;/h1&gt;
&lt;p&gt;Of course, there is more to arithmetic than just addition, subtraction, and multiplication. What about the rest of the primitive operations?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Division&lt;/strong&gt;: So far, you may notice that I have left out division. That’s because unlike addition, subtraction, and multiplication, there is no ”division” in modular arithmetic, at least not in the everyday sense. I will leave that for the next post.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Exponentiation&lt;/strong&gt;: I also hinted at modular exponentiation. Since it is merely repeated multiplication, the mechanics of it are not hard to understand. However, it opens the door to a whole host of interesting larger mathematical concepts that are worth at least a couple more posts.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Roots&lt;/strong&gt;: On the other hand, “undoing” exponentiation by taking a root &lt;span class="math"&gt;\(\mod n\)&lt;/span&gt; is much, much more involved than you would expect, given how simple exponentiation is. This works quite differently than roots in regular arithmetic.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Logarithms&lt;/strong&gt;: Going one step further, logarithms in modular arithmetic, also called &lt;em&gt;discrete logarithms&lt;/em&gt;, are even more different and difficult than their normal counterparts, although the underlying concept remains the same. However, it is precisely this difficulty that ensures the security of modern math-based encryption schemes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Stay tuned for upcoming posts in this series!&lt;/p&gt;</content><category term="modular arithmetic"></category></entry><entry><title>Number Theory in Clojure: AKS primality test</title><link href="http://tabidots.github.io/2019/04/number-theory-in-clojure-aks-primality-test" rel="alternate"></link><published>2019-04-08T22:34:04+07:00</published><updated>2019-04-08T22:34:04+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-04-08:/2019/04/number-theory-in-clojure-aks-primality-test</id><summary type="html">&lt;p&gt;The &lt;span class="caps"&gt;AKS&lt;/span&gt; test is an award-winning algorithm for proving whether an integer is prime, though I realized too late that it is too slow to be of any practical use. Writing the code itself was useful,&amp;nbsp;though.&lt;/p&gt;</summary><content type="html">
&lt;p&gt;After my &lt;a href="/2019/03/fundamental-theorem-arithmetic"&gt;previous post on the fundamental theorem of arithmetic&lt;/a&gt;, I had intended to move on to modular arithmetic, but I ended up getting pulled down a primality-testing rabbit hole. That ended up involving a return to &lt;a href="/2019/01/polynomial-long-division"&gt;polynomial long division&lt;/a&gt;, except this time in Clojure.&lt;/p&gt;
&lt;h1 id="the-aks-primality-test"&gt;The &lt;span class="caps"&gt;AKS&lt;/span&gt; primality test&lt;/h1&gt;
&lt;p&gt;In the quest to discover a better method for testing the primality of very large numbers, I came across the &lt;a href="https://en.wikipedia.org/wiki/AKS_primality_test"&gt;&lt;span class="caps"&gt;AKS&lt;/span&gt; primality test&lt;/a&gt;, which is relatively new and has won many awards.&lt;/p&gt;
&lt;p&gt;This “unconditional deterministic polynomial-time algorithm that determines whether
an input number is prime or composite” is of great theoretical significance and the algorithm has “only” 5 steps, so I thought it would be worth trying to implement. Plus, when I saw the phrase &lt;em&gt;multiplicative order&lt;/em&gt;, I thought, “Hey, I know what that is” and got excited.&lt;/p&gt;
&lt;p&gt;The original paper has a pretty bold, simple title: &lt;a href="https://www.cse.iitk.ac.in/users/manindra/algebra/primality_v6.pdf"&gt;&lt;em&gt;&lt;span class="caps"&gt;PRIMES&lt;/span&gt; is in P&lt;/em&gt;&lt;/a&gt;, but good luck understanding the contents.&lt;/p&gt;
&lt;p&gt;The essence of the algorithm—which I have &lt;em&gt;absolutely zero intuition for&lt;/em&gt;—is as follows. Given an integer &lt;span class="math"&gt;\(n &amp;gt; 1\)&lt;/span&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;If &lt;span class="math"&gt;\(n\)&lt;/span&gt; is a perfect power (i.e., &lt;span class="math"&gt;\(n = a^b\)&lt;/span&gt; for any &lt;span class="math"&gt;\(a, b \in ℤ\)&lt;/span&gt;), return &lt;strong&gt;composite&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Find the smallest &lt;span class="math"&gt;\(r\)&lt;/span&gt; coprime to &lt;span class="math"&gt;\(n\)&lt;/span&gt; such that &lt;span class="math"&gt;\(\textrm{ord}_r(n) &amp;gt; (\log_2 n)^2\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;If &lt;span class="math"&gt;\(n\)&lt;/span&gt; is divisible by &lt;span class="math"&gt;\(a\)&lt;/span&gt; for any &lt;span class="math"&gt;\(2 \leq a \leq \min (r, n - 1)\)&lt;/span&gt;, return &lt;strong&gt;composite&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;If &lt;span class="math"&gt;\(n \leq r\)&lt;/span&gt;, return &lt;strong&gt;prime&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;If &lt;span class="math"&gt;\((X + a)^n \not= X^n + a \mod (X^r - 1, n)\)&lt;/span&gt; for any &lt;span class="math"&gt;\(1 \leq a \leq \lfloor \sqrt{\varphi(r)} \log_2(n) \rfloor\)&lt;/span&gt;, return &lt;strong&gt;composite&lt;/strong&gt;. Else return &lt;strong&gt;prime&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="perfect-powers"&gt;Perfect powers&lt;/h1&gt;
&lt;p&gt;I knew I was in for a bit of a slog when I tried to implement the first step of the algorithm.&lt;/p&gt;
&lt;p&gt;What is the best way to determine if a number &lt;span class="math"&gt;\(n = a^b\)&lt;/span&gt; for some &lt;span class="math"&gt;\(a, b \in ℤ\)&lt;/span&gt;? You &lt;em&gt;could&lt;/em&gt; brute-force it, sure. But primality tests are usually concerned with really large numbers, so trying every possible combination of &lt;span class="math"&gt;\(a, b\)&lt;/span&gt; might take a lifetime or two.&lt;/p&gt;
&lt;p&gt;I decided to try a technique I learned from doing many, many Project Euler problems: flip the problem on its side and solve &lt;em&gt;that&lt;/em&gt; problem instead.&lt;/p&gt;
&lt;p&gt;Since we don’t need to know the &lt;em&gt;value&lt;/em&gt; of &lt;span class="math"&gt;\(a\)&lt;/span&gt; and are only concerned with whether or not &lt;span class="math"&gt;\(a \in ℤ\)&lt;/span&gt; (i.e., it is a whole number), we can test the &lt;span class="math"&gt;\(b\)&lt;/span&gt;th roots of &lt;span class="math"&gt;\(n\)&lt;/span&gt; up to some upper bound.&lt;/p&gt;
&lt;h2 id="highest-possible-power"&gt;Highest possible power?&lt;/h2&gt;
&lt;p&gt;First problem: How do you determine the upper bound? The answer is surprisingly simple.&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(a \in ℤ\)&lt;/span&gt;, but &lt;span class="math"&gt;\(a\)&lt;/span&gt; cannot be &lt;span class="math"&gt;\(1\)&lt;/span&gt; because &lt;span class="math"&gt;\(1^k = 1\)&lt;/span&gt; for any &lt;span class="math"&gt;\(k\)&lt;/span&gt;. So &lt;span class="math"&gt;\(2\)&lt;/span&gt; is the lower bound for &lt;span class="math"&gt;\(a\)&lt;/span&gt;, and will necessarily have the highest possible &lt;span class="math"&gt;\(b\)&lt;/span&gt;, because if &lt;span class="math"&gt;\(2^b = n\)&lt;/span&gt;, then &lt;span class="math"&gt;\(3^b &amp;gt; n\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We can thus find the highest possible &lt;span class="math"&gt;\(b\)&lt;/span&gt; by solving &lt;span class="math"&gt;\(2^b = n\)&lt;/span&gt; for &lt;span class="math"&gt;\(b\)&lt;/span&gt;, or in other words, &lt;span class="math"&gt;\(\log_2(n)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Since all composite powers can be broken down into prime powers, we only need to look at prime powers up to and including &lt;span class="math"&gt;\(b\)&lt;/span&gt;. Of course, since this is in the context of a primality-testing algorithm, it would be silly to use a prime sieve here. Testing &lt;span class="math"&gt;\(2\)&lt;/span&gt; and then all odd &lt;span class="math"&gt;\(b\)&lt;/span&gt; up to &lt;span class="math"&gt;\(\log_2(n)\)&lt;/span&gt; is sufficient.&lt;/p&gt;
&lt;h2 id="floating-point-fun"&gt;Floating-point fun&lt;/h2&gt;
&lt;p&gt;Second problem: When dealing with large numbers, floating-point errors can trick the computer into thinking a number is an integer when it shouldn’t be. For example, despite the obvious fact that &lt;span class="math"&gt;\(\sqrt{n}^2 = n\)&lt;/span&gt;, the following returns &lt;code class="highlight"&gt;false&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;923849028343489238498324908928349028490829058&lt;/span&gt;&lt;span class="nv"&gt;N&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/pow&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/sqrt&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="c1"&gt;;; false&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This is because Java’s built-in math functions return &lt;code class="highlight"&gt;Double&lt;/code&gt;s. What we need here is a way to determine the &lt;span class="math"&gt;\(n\)&lt;/span&gt;th root of a number to an arbitrary degree of precision.&lt;/p&gt;
&lt;p&gt;I wrote about the Babylonian square root algorithm &lt;a href="/2019/01/squarest-root-in-babylon"&gt;previously&lt;/a&gt;, and it can be adapted to compute &lt;span class="math"&gt;\(n\)&lt;/span&gt;th roots without too much trouble. The square root algorithm &lt;span class="math"&gt;\(t := \frac{t + \frac{x}{t}}{2}\)&lt;/span&gt; is actually:&lt;/p&gt;
&lt;div class="math"&gt;$$ t := \frac{(\textcolor{red}{2} - 1)t + \frac{x}{t^{\textcolor{red}{2} - 1}}}{\textcolor{red}{2}} $$&lt;/div&gt;
&lt;p&gt;So the &lt;span class="math"&gt;\(n\)&lt;/span&gt;th root algorithm is:&lt;/p&gt;
&lt;div class="math"&gt;$$ t := \frac{(n - 1)t + \frac{x}{t^{n - 1}}}{n} $$&lt;/div&gt;
&lt;p&gt;To maintain a little more control over the intermediate values, we can use &lt;code class="highlight"&gt;reduce&lt;/code&gt;d multiplication (&lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce * &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;repeat &lt;/span&gt;&lt;span class="nv"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;base&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/code&gt;) instead of &lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/pow&lt;/span&gt; &lt;span class="nv"&gt;base&lt;/span&gt; &lt;span class="nv"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/code&gt;, and &lt;code class="highlight"&gt;reduce&lt;/code&gt;d addition instead of multiplication.&lt;/p&gt;
&lt;p&gt;The result of that looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;naive-bab-nth-root&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;root&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;loop &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;t&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="nv"&gt;iters&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;gt;= &lt;/span&gt;&lt;span class="nv"&gt;iters&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;ts&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;repeat &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;- root &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce * &lt;/span&gt;&lt;span class="nv"&gt;ts&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce + &lt;/span&gt;&lt;span class="nv"&gt;ts&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;root&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
               &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;inc &lt;/span&gt;&lt;span class="nv"&gt;iters&lt;/span&gt;&lt;span class="p"&gt;))))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;However, the sticking point is the type, which is set by the initial approximation &lt;code class="highlight"&gt;t&lt;/code&gt;. Roots of integers are generally either integers or irrational numbers, so you can’t just slap an &lt;code class="highlight"&gt;M&lt;/code&gt; on it (coerce it to &lt;code class="highlight"&gt;BigDecimal&lt;/code&gt;) and call it a day:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Execution error (ArithmeticException) at java.math.BigDecimal/divide (BigDecimal.java:1690).
Non-terminating decimal expansion; no exact representable decimal result.
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You have to specify some level of precision (decimal places).&lt;/p&gt;
&lt;p&gt;Let’s think about this a bit more. This algorithm returns increasingly accurate values with each successive iteration. But due to &lt;strong&gt;&lt;a href="/2019/01/from-zero-to-ero"&gt;floating-point rounding errors&lt;/a&gt;&lt;/strong&gt;, the algorithm might never converge on a true whole number.&lt;/p&gt;
&lt;p&gt;This means that replacing the current stopping condition (based on iterations, &lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;gt;= &lt;/span&gt;&lt;span class="nv"&gt;iters&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/code&gt;) with one based on a simple heuristic like &lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/floor&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/code&gt; or &lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;bigint&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/code&gt; will produce lots of false negatives (for small inputs) and false positives (for large inputs). No bueno.&lt;/p&gt;
&lt;h2 id="epsilon-to-the-rescue"&gt;Epsilon to the rescue&lt;/h2&gt;
&lt;p&gt;My first encounter with floating-point rounding errors happened in the context of training a machine learning algorithm (detailed in the link above). Can we apply the same logic here?&lt;/p&gt;
&lt;p&gt;If we define an error threshold &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt;, then we can use that in our stopping condition. Let’s start with using a ridiculously small &lt;code class="highlight"&gt;BigDecimal&lt;/code&gt; value for our threshold. This should surely give us a whole number when the answer &lt;span class="math"&gt;\(\sqrt[b]{n} = a\)&lt;/span&gt; is actually a whole number—or at least enough zeroes after the decimal point that we can declare with confidence that it is a whole number.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_1_0" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_0"&gt;1. Fast but bad&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;more-precise-bab-nth-root&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;root&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="hll"&gt;  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;eps&lt;/span&gt; &lt;span class="mf"&gt;0.000000000000000000000000000000000000000001&lt;/span&gt;&lt;span class="nv"&gt;M&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/span&gt;    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;loop &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;t&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="nv"&gt;M&lt;/span&gt; &lt;span class="nv"&gt;iters&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;ts&lt;/span&gt;  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;repeat &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;- root &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="hll"&gt;            &lt;span class="nv"&gt;nxt&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;with-precision&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="nv"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;ts&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/span&gt;                                        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="nv"&gt;+&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;ts&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                                        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;root&lt;/span&gt;&lt;span class="p"&gt;)))]&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;or &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;gt;= &lt;/span&gt;&lt;span class="nv"&gt;iters&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="hll"&gt;                &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;lt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;.abs&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;- &lt;/span&gt;&lt;span class="nv"&gt;nxt&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="nv"&gt;eps&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;
&lt;/span&gt;          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="nv"&gt;nxt&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;inc &lt;/span&gt;&lt;span class="nv"&gt;iters&lt;/span&gt;&lt;span class="p"&gt;)))))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_1" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_1"&gt;2. Better but slow&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;naive-bigdec-nth-root&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;root&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="hll"&gt;  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;eps&lt;/span&gt; &lt;span class="mf"&gt;0.000000000000000000000000000000000000000001&lt;/span&gt;&lt;span class="nv"&gt;M&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;loop &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;t&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="nv"&gt;M&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/span&gt;      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;ts&lt;/span&gt;  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;repeat &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;- root &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="nv"&gt;nxt&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;with-precision&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="nv"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;ts&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                                        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="nv"&gt;+&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;ts&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                                        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;root&lt;/span&gt;&lt;span class="p"&gt;)))]&lt;/span&gt;
&lt;span class="hll"&gt;        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;lt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;.abs&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;- &lt;/span&gt;&lt;span class="nv"&gt;nxt&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="nv"&gt;eps&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;
&lt;/span&gt;          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="nv"&gt;nxt&lt;/span&gt;&lt;span class="p"&gt;))))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_2" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_2"&gt;3. Best&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;require&lt;/span&gt; &lt;span class="o"&gt;'&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;clojure.numeric-tower&lt;/span&gt; &lt;span class="ss"&gt;:as&lt;/span&gt; &lt;span class="nv"&gt;tower&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;babylonian-root&lt;/span&gt;
  &lt;span class="s"&gt;"High-precision BigDecimal nth-root using the Babylonian algorithm,&lt;/span&gt;
&lt;span class="s"&gt;  with a close initial approximation for ridiculously fast convergence."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;root&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;eps&lt;/span&gt; &lt;span class="mf"&gt;0.000000000000000000000000000000000000000001&lt;/span&gt;&lt;span class="nv"&gt;M&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="hll"&gt;    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;loop &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;t&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;bigdec&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;tower/expt&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;root&lt;/span&gt;&lt;span class="p"&gt;)))]&lt;/span&gt; &lt;span class="c1"&gt;;; rough initial approx&lt;/span&gt;
&lt;/span&gt;      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;ts&lt;/span&gt;  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;repeat &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;- root &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="nv"&gt;nxt&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;with-precision&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="nv"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;ts&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                                        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="nv"&gt;+&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;ts&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                                        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;root&lt;/span&gt;&lt;span class="p"&gt;)))]&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;lt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;.abs&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;- &lt;/span&gt;&lt;span class="nv"&gt;nxt&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="nv"&gt;eps&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="nv"&gt;nxt&lt;/span&gt;&lt;span class="p"&gt;))))))&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;babylonian-root&lt;/span&gt; &lt;span class="mi"&gt;92709463147897837085761925410587&lt;/span&gt; &lt;span class="mi"&gt;67&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;;; 3.000000000000000000000000000000000000000000000000000000000034073599999999794044017777778109595749154M&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;(Note, the apostrophes in &lt;code class="highlight"&gt;*'&lt;/code&gt; and &lt;code class="highlight"&gt;+'&lt;/code&gt; allow values to silently overflow from &lt;code class="highlight"&gt;long&lt;/code&gt; to &lt;code class="highlight"&gt;BigInteger&lt;/code&gt; if necessary.)&lt;/p&gt;
&lt;p&gt;In &lt;em&gt;1. Fast but bad&lt;/em&gt;, I used both iterations and epsilon as stopping conditions, thinking that a perfect power would stop the loop early and speed up computation. It did, but at the expense of accuracy. Even-numbered roots returned &lt;em&gt;really&lt;/em&gt; strange outputs (unrealistically large numbers). This is similar to gradient descent overshooting the minimum of the cost function in training a neural network because the learning rate is too high.&lt;/p&gt;
&lt;p&gt;That means that in some cases, more than 100 iterations were required for the algorithm to converge. So my next attempt was &lt;em&gt;2. Better but slow&lt;/em&gt;, in which I removed the iterations as a stopping condition, and let the algorithm run until the difference fell under the error threshold.&lt;/p&gt;
&lt;p&gt;That worked, but it was &lt;em&gt;slow&lt;/em&gt;. Try using it to calculate &lt;span class="math"&gt;\(\sqrt[67]{92709463147897837085761925410587}\)&lt;/span&gt;—it’s not very fast. Since this is just part of step one of a very complex algorithm, it should ideally happen in an instant.&lt;/p&gt;
&lt;p&gt;Then it occurred to me that the algorithm should not take so many iterations to converge. To be exact, the number of iterations required is a direct consequence of how accurate the initial approximation is. This matters less for small inputs, but makes a colossal difference with large inputs.&lt;/p&gt;
&lt;p&gt;There is probably a formula to determine a good initial guess without resorting to floating-point arithmetic, but doing so turned out to be a very fast and good enough solution nonetheless. Simply express &lt;span class="math"&gt;\(\sqrt[b]{n}\)&lt;/span&gt; as &lt;span class="math"&gt;\(n^{\frac{1}{b}}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In Clojure, that looks like &lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;tower/expt&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;root&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/code&gt;. (I prefer using &lt;code class="highlight"&gt;tower/expt&lt;/code&gt;, but you could certainly use built-in Java interop to do this with &lt;code class="highlight"&gt;Math/pow&lt;/code&gt; instead.) And voilà! We have arrived at &lt;em&gt;3. Best&lt;/em&gt;. It converges instantly and returns a highly accurate result.&lt;/p&gt;
&lt;h2 id="testing-wholeness"&gt;Testing wholeness&lt;/h2&gt;
&lt;p&gt;As we intended, the values returned by &lt;code class="highlight"&gt;babylonian-root&lt;/code&gt; have a ridiculous amount of decimal places, and we can safely assume that a result like&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;(scroll right ======&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;)
3.000000000000000000000000000000000000000000000000000000000034073599999999794044017777778109595749154M
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;is, with 99.9% certainty, a whole number. But there are still non-zero digits after the decimal point &lt;em&gt;at some point&lt;/em&gt;, which means simply using &lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/floor&lt;/span&gt; &lt;span class="nv"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/code&gt; won’t work here either.&lt;/p&gt;
&lt;p&gt;The best way to be sure if our &lt;span class="math"&gt;\(n\)&lt;/span&gt;th root is an integer is to &lt;code class="highlight"&gt;Math/floor&lt;/code&gt; it, then raise it to the &lt;span class="math"&gt;\(n\)&lt;/span&gt;th power and see if it equals our input value. Both values must be coerced to the same type in order to test equality, and coercing to &lt;code class="highlight"&gt;bigint&lt;/code&gt; ensures that small and large values will be accommodated equally well. (Using &lt;code class="highlight"&gt;*'&lt;/code&gt; will only cause values to overflow to &lt;code class="highlight"&gt;bigint&lt;/code&gt; if they are large enough.)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;nth-root-is-integer?&lt;/span&gt;
  &lt;span class="s"&gt;"Tests if the nth root of x is an integer in the mathematical&lt;/span&gt;
&lt;span class="s"&gt;  (not programming) sense—i.e., if it is a whole number.)."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;floor&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;bigint&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/floor&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;babylonian-root&lt;/span&gt; &lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
        &lt;span class="nv"&gt;exp&lt;/span&gt;   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;bigint&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="nv"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;repeat &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;floor&lt;/span&gt;&lt;span class="p"&gt;)))]&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="nv"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="testing-perfect-power-ness"&gt;Testing perfect power-ness&lt;/h2&gt;
&lt;p&gt;Finally, we’re ready to bring it all together. To test for a perfect power, we iterate through all possible &lt;span class="math"&gt;\(b\)&lt;/span&gt; up to the upper bound we established earlier and return &lt;code class="highlight"&gt;true&lt;/code&gt;, terminating early, if any &lt;span class="math"&gt;\(\sqrt[b]{n} = \lfloor \sqrt[b]{n} \rfloor\)&lt;/span&gt;. Otherwise, return &lt;code class="highlight"&gt;false.&lt;/code&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;perfect-power?&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;max-power&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/log&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/log&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="nv"&gt;powers&lt;/span&gt;    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;cons &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="nv"&gt;odd?&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;inc &lt;/span&gt;&lt;span class="nv"&gt;max-power&lt;/span&gt;&lt;span class="p"&gt;))))]&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;some &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;partial &lt;/span&gt;&lt;span class="nv"&gt;nth-root-is-integer?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;powers&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In Clojure, it is more idiomatic to use &lt;code class="highlight"&gt;some&lt;/code&gt;, although this will technically return the first non-&lt;code class="highlight"&gt;nil&lt;/code&gt; value rather than &lt;code class="highlight"&gt;true&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Phew! That was a lot of work just for a minor part of the algorithm. Let’s move on.&lt;/p&gt;
&lt;h1 id="r-u-ready"&gt;&lt;span class="math"&gt;\(r\)&lt;/span&gt; u ready?&lt;/h1&gt;
&lt;p&gt;The next few steps of the algorithm revolve around some number &lt;span class="math"&gt;\(r\)&lt;/span&gt; that satisfies certain criteria.&lt;/p&gt;
&lt;p&gt;The first step draws on a concept called &lt;em&gt;multiplicative order&lt;/em&gt;, which comes from modular arithmetic. I don’t want to cover it in full detail here, as I’m planning to write future posts on modular arithmetic in this series, so I will present just the functions and a simple explanation here.&lt;/p&gt;
&lt;p&gt;After we find &lt;span class="math"&gt;\(r\)&lt;/span&gt;, the next steps are pretty straightforward.&lt;/p&gt;
&lt;h2 id="multiplicative-order-in-brief"&gt;Multiplicative order (in brief)&lt;/h2&gt;
&lt;p&gt;It’s similar to the concept of &lt;em&gt;multiplicative inverse&lt;/em&gt;, which &lt;a href="/2019/01/mod-squad"&gt;I have covered before&lt;/a&gt;, although instead of looking for a number that is congruent to &lt;span class="math"&gt;\(1\)&lt;/span&gt; after multiplication, we are looking for a number that is congruent to &lt;span class="math"&gt;\(1\)&lt;/span&gt; after exponentiation.&lt;/p&gt;
&lt;p&gt;Implementing a multiplicative order function in code takes a few steps. If I were to explain them in full here, this blog post would become overwhelming, so I am just going to leave the code here and revisit modular arithmetic more thoroughly in future posts. I’ll provide a link here when those posts are ready.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;mod-pow&lt;/span&gt;
  &lt;span class="c1"&gt;;; Adapted from https://en.wikipedia.org/wiki/Modular_exponentiation&lt;/span&gt;
  &lt;span class="s"&gt;"Quickly calculates a ^ b % m. Useful when a and b are very large integers."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;base&lt;/span&gt; &lt;span class="nv"&gt;exp&lt;/span&gt; &lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;or &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="nv"&gt;m&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="nv"&gt;base&lt;/span&gt; &lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;loop &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;base&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mod&lt;/span&gt; &lt;span class="nv"&gt;base&lt;/span&gt; &lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;e&lt;/span&gt; &lt;span class="nv"&gt;exp&lt;/span&gt; &lt;span class="nv"&gt;res&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zero? &lt;/span&gt;&lt;span class="nv"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;res&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;base&lt;/span&gt; &lt;span class="nv"&gt;base&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mod&lt;/span&gt; &lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
               &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;bit-shift-right &lt;/span&gt;&lt;span class="nv"&gt;e&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
               &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;odd?&lt;/span&gt; &lt;span class="nv"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;res&lt;/span&gt; &lt;span class="nv"&gt;base&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mod&lt;/span&gt; &lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                 &lt;span class="nv"&gt;res&lt;/span&gt;&lt;span class="p"&gt;))))))&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;powers-of-a-mod-n&lt;/span&gt;
  &lt;span class="s"&gt;"a^k (mod n) for all 0 ≦ k &amp;lt; n, where k ∈ ℤ."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;map &lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mod-pow&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;%&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;multiplicative-order&lt;/span&gt;
  &lt;span class="s"&gt;"ord_n(a), the smallest positive integer k such that a^k ≡ 1 (mod n) where&lt;/span&gt;
&lt;span class="s"&gt;  a is coprime to n. a^0 ≡ 1 (mod n) for any n, so the quick way to find k&lt;/span&gt;
&lt;span class="s"&gt;  is to count the distinct powers of a (mod n)."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;when &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;coprime?&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;count &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;distinct &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;powers-of-a-mod-n&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\textrm{ord}_r(n)\)&lt;/span&gt; is read “the multiplicative order of &lt;span class="math"&gt;\(n \pmod r\)&lt;/span&gt;”. In the math notation, the modulus comes first, but when you read it aloud, the modulus comes last, so I have written the function with the arguments in the latter order.&lt;/p&gt;
&lt;h2 id="eulers-totient-varphi-phi-function"&gt;Euler’s totient (&lt;span class="math"&gt;\(\varphi\)&lt;/span&gt; phi) function&lt;/h2&gt;
&lt;p&gt;The (very complicated) last step of the algorithm requires first calculating &lt;span class="math"&gt;\(\varphi(r)\)&lt;/span&gt;, which is the number of integers less than &lt;span class="math"&gt;\(r\)&lt;/span&gt; that are coprime to it. That is, their greatest common divisor is &lt;span class="math"&gt;\(1\)&lt;/span&gt; (&lt;span class="math"&gt;\(4\)&lt;/span&gt; and &lt;span class="math"&gt;\(9\)&lt;/span&gt; are coprime to each other, for example.)&lt;/p&gt;
&lt;p&gt;For any prime number &lt;span class="math"&gt;\(p\)&lt;/span&gt;, &lt;span class="math"&gt;\(\varphi(p)\)&lt;/span&gt; is &lt;span class="math"&gt;\(p - 1\)&lt;/span&gt;. Of course, since we don’t know if our target number is prime, that doesn’t help us much in this case.&lt;/p&gt;
&lt;p&gt;There is another way to optimize the totient function using Euler’s product rule, but because that requires factorizing the number, that is also of little help here.&lt;/p&gt;
&lt;p&gt;So, let’s proceed with the most naïve, simplistic version of the function.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;naive-phi&lt;/span&gt;
  &lt;span class="s"&gt;"Naive version of Euler's totient function that only uses gcd, since&lt;/span&gt;
&lt;span class="s"&gt;  the optimized version requires factoring n first."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;count &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;tower/gcd&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;%&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id="the-crazy-polynomial-part"&gt;The crazy polynomial part&lt;/h1&gt;
&lt;p&gt;Now we come to the most formidable part of the algorithm. It took a while to even understand the notation at first. We have to find&lt;/p&gt;
&lt;div class="math"&gt;$$\textcolor{#1f77b4}{(X + a)^n} \stackrel{?}{=} \textcolor{#e377c2}{X^n + a} \mod (\textcolor{mediumpurple}{X^r - 1}, \textcolor{orange}{n}), 1 \leq a \leq \lfloor \sqrt{\varphi(r)} \log_2(n) \rfloor$$&lt;/div&gt;
&lt;p&gt;The capital letter &lt;span class="math"&gt;\(X\)&lt;/span&gt; is apparently a convention from abstract algebra. This way of notating polynomials reflects the fact that we are not concerned with actually filling in the value of &lt;span class="math"&gt;\(x\)&lt;/span&gt; in a given polynomial, as if it were a function; it is just a symbol.&lt;/p&gt;
&lt;p&gt;When I first saw this, the “double modulus” was the part I found most confusing. I’m still not sure of the correct terminology for what is going on here, but essentially, this is what we need to compare:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Left-hand side: Take the remainder of &lt;span class="math"&gt;\(\frac{\textcolor{#1f77b4}{(X + a)^n}}{\textcolor{mediumpurple}{X^r - 1}}\)&lt;/span&gt;, then reduce all coefficients &lt;span class="math"&gt;\(\mod \textcolor{orange}{n}\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Right-hand side: Take the remainder of &lt;span class="math"&gt;\(\frac{\textcolor{#e377c2}{X^n + a}}{\textcolor{mediumpurple}{X^r - 1}}\)&lt;/span&gt;, then reduce all coefficients &lt;span class="math"&gt;\(\mod \textcolor{orange}{n}\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This requires polynomial long division. Brace yourself.&lt;/p&gt;
&lt;h2 id="polynomials-in-clojure"&gt;Polynomials in Clojure&lt;/h2&gt;
&lt;p&gt;Thanks to &lt;em&gt;A Programmer’s Introduction to Mathematics&lt;/em&gt;, I was already familiar with the convention of representing polynomials in code as an array of coefficients, where the index of a coefficient represents the power of its associated term. For example, &lt;span class="math"&gt;\(x^3 - 2x^2 + 17\)&lt;/span&gt; would be &lt;code class="highlight"&gt;[17, 0, -2, 1]&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Trying to port this exact representation from Python (or Java, or some other C-type language) to Clojure got a bit messy as soon as I tried to implement an addition function, because Clojure does not have a built-in &lt;code class="highlight"&gt;map-longest&lt;/code&gt; function, or a clean way of writing one. Some helpful folks on the awesome &lt;a href="https://clojurians.slack.com"&gt;Clojurians Slack group&lt;/a&gt; advised me to try representing polynomials as a map instead, with the powers as keywords: &lt;code class="highlight"&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;17&lt;/span&gt;, &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;-2&lt;/span&gt;, &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In addition to being easier to manipulate in Clojure, this way of organizing the data has the added bonus of being order-agnostic and not being sensitive to omitted zero coefficients.&lt;/p&gt;
&lt;p&gt;Well, in order to &lt;em&gt;ensure&lt;/em&gt; that the zero coefficients don’t matter way or the other, we should write a “trim” function to save us from possibly pulling out our hair:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;poly-trim-&lt;/span&gt;
  &lt;span class="s"&gt;"Removes terms with zero coefficients from a polynomial."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;pnml&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;-&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zero? &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;get &lt;/span&gt;&lt;span class="nv"&gt;pnml&lt;/span&gt; &lt;span class="nv"&gt;%&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;keys &lt;/span&gt;&lt;span class="nv"&gt;pnml&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
       &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;dissoc &lt;/span&gt;&lt;span class="nv"&gt;%1&lt;/span&gt; &lt;span class="nv"&gt;%2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;pnml&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It’s an intuitively simple idea that requires a slightly roundabout functional implementation. Get the keys of the map (powers of the polynomial) whose coefficient is zero, then successively &lt;code class="highlight"&gt;dissoc&lt;/code&gt; (remove) those key-val pairs from the map.&lt;/p&gt;
&lt;h2 id="low-hanging-fruit"&gt;Low-hanging fruit&lt;/h2&gt;
&lt;p&gt;Let’s nail the low-hanging fruit first. Reducing the coefficients of a polynomial &lt;span class="math"&gt;\(\mod n\)&lt;/span&gt; is pretty easy:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;poly-mod&lt;/span&gt;
  &lt;span class="s"&gt;"Reduces the terms of a given polynomial mod n."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;pnml&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zipmap &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;keys &lt;/span&gt;&lt;span class="nv"&gt;pnml&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;map &lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mod&lt;/span&gt; &lt;span class="nv"&gt;%&lt;/span&gt; &lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;vals &lt;/span&gt;&lt;span class="nv"&gt;pnml&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Next, the right-hand-side term: &lt;span class="math"&gt;\(\textcolor{#e377c2}{X^n + a}\)&lt;/span&gt;. Since &lt;code class="highlight"&gt;n&lt;/code&gt; is the initial input to the algorithm and &lt;code class="highlight"&gt;a&lt;/code&gt; will be taken from a range, we can treat them as constants. We can thus write this as &lt;code class="highlight"&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;, &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Then, the polynomial modulus: &lt;span class="math"&gt;\(\textcolor{mediumpurple}{X^r - 1}\)&lt;/span&gt;. &lt;code class="highlight"&gt;r&lt;/code&gt; will have been defined in a previous step, so we can treat it as a constant. We can thus write this as &lt;code class="highlight"&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nv"&gt;r&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;, &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;That leaves two (rather tedious) things: Expanding &lt;span class="math"&gt;\(\textcolor{#1f77b4}{(X + a)^n}\)&lt;/span&gt;, which should be done using modular exponentiation to prevent the coefficients from exploding; and implementing polynomial long division.&lt;/p&gt;
&lt;h2 id="modular-exponentiation-of-polynomials"&gt;Modular exponentiation of polynomials&lt;/h2&gt;
&lt;p&gt;Exponentiation requires multiplication, which requires addition.&lt;/p&gt;
&lt;p&gt;Representing polynomials as hash-maps allows us to add polynomials extremely concisely using &lt;code class="highlight"&gt;merge-with&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;add&lt;/span&gt;
  &lt;span class="s"&gt;"Adds two polynomials."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;p1&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;poly-trim-&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;merge-with + &lt;/span&gt;&lt;span class="nv"&gt;p1&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To multiply polynomials, we take every pair of terms with non-zero coefficients, add their powers, and multiply their coefficients to obtain the new terms. If there are multiple terms with the same power, add those coefficients.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;mul&lt;/span&gt;
  &lt;span class="s"&gt;"Multiplies two polynomials."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;p1&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;-&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;for &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;powers1&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;keys &lt;/span&gt;&lt;span class="nv"&gt;p1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;powers2&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;keys &lt;/span&gt;&lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
         &lt;span class="p"&gt;{(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="nv"&gt;powers1&lt;/span&gt; &lt;span class="nv"&gt;powers2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;* &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;get &lt;/span&gt;&lt;span class="nv"&gt;p1&lt;/span&gt; &lt;span class="nv"&gt;powers1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;get &lt;/span&gt;&lt;span class="nv"&gt;p2&lt;/span&gt; &lt;span class="nv"&gt;powers2&lt;/span&gt;&lt;span class="p"&gt;))})&lt;/span&gt;
       &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;merge-with + &lt;/span&gt;&lt;span class="nv"&gt;%1&lt;/span&gt; &lt;span class="nv"&gt;%2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{})&lt;/span&gt;
       &lt;span class="nv"&gt;poly-trim-&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To exponentiate polynomials, just &lt;code class="highlight"&gt;reduce&lt;/code&gt;!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;exp&lt;/span&gt;
  &lt;span class="s"&gt;"Exponentiation of a polynomial, [p(x)]^e."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;pnml&lt;/span&gt; &lt;span class="nv"&gt;e&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="nv"&gt;mul&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;repeat &lt;/span&gt;&lt;span class="nv"&gt;e&lt;/span&gt; &lt;span class="nv"&gt;pnml&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;However, in this case, we need to exponentiate our polynomial &lt;span class="math"&gt;\(\mod n\)&lt;/span&gt;, so in order to keep the coefficients from exploding (because the values will quickly become astronomical, especially when testing very large numbers), let’s reduce the coefficients &lt;span class="math"&gt;\(\mod n\)&lt;/span&gt; after every multiplication.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;mod-exp&lt;/span&gt;
  &lt;span class="s"&gt;"Slightly faster version of [p(x)]^e (mod m), where p(x) is a polynomial.&lt;/span&gt;
&lt;span class="s"&gt;  Reduces the result of each multiplication mod m with every iteration, rather&lt;/span&gt;
&lt;span class="s"&gt;  than only once at the end, in order to keep the intermediate coefficients&lt;/span&gt;
&lt;span class="s"&gt;  from exploding."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;pnml&lt;/span&gt; &lt;span class="nv"&gt;e&lt;/span&gt; &lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;poly-mod&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mul&lt;/span&gt; &lt;span class="nv"&gt;%1&lt;/span&gt; &lt;span class="nv"&gt;%2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;repeat &lt;/span&gt;&lt;span class="nv"&gt;e&lt;/span&gt; &lt;span class="nv"&gt;pnml&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="polynomial-remainder-shortcut"&gt;Polynomial remainder (shortcut)&lt;/h2&gt;
&lt;p&gt;Interestingly, the particular polynomial divisor &lt;span class="math"&gt;\(\textcolor{mediumpurple}{X^r - 1}\)&lt;/span&gt; used in this algorithm seems to have some kind of special property related to &lt;em&gt;cyclotomic polynomials&lt;/em&gt;. I have no idea what those are, but someone who implemented the algorithm in JavaScript has found &lt;a href="https://medium.com/@sibu.it13/aks-primality-test-f184cf6365a1"&gt;an interesting shortcut&lt;/a&gt; to finding the remainder after dividing any polynomial by that divisor.&lt;/p&gt;
&lt;p&gt;I don’t know &lt;em&gt;why&lt;/em&gt; it works, but I was able to implement it pretty quickly in Clojure. Check out the Medium post linked above for an explanation of &lt;em&gt;how&lt;/em&gt; it works.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;quick-poly-rem&lt;/span&gt;
  &lt;span class="s"&gt;"Shortcut to finding the remainder of p(x) / (x^r - 1)."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;pnml&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;poly-trim-&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;reduce-kv&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;fn &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;res&lt;/span&gt; &lt;span class="nv"&gt;power&lt;/span&gt; &lt;span class="nv"&gt;coeff&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                           &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;merge-with + &lt;/span&gt;&lt;span class="nv"&gt;res&lt;/span&gt; &lt;span class="p"&gt;{(&lt;/span&gt;&lt;span class="nf"&gt;mod&lt;/span&gt; &lt;span class="nv"&gt;power&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;coeff&lt;/span&gt;&lt;span class="p"&gt;}))&lt;/span&gt;
                         &lt;span class="p"&gt;{}&lt;/span&gt; &lt;span class="nv"&gt;pnml&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="polynomial-long-division"&gt;Polynomial long division&lt;/h2&gt;
&lt;p&gt;However, I tend not to be satisfied with these hand-wavy magic tricks (or at least, it &lt;em&gt;seems&lt;/em&gt; hand-wavy because the author of that article didn’t provide the source of the “trick”). So I decided to roll up my sleeves and implement polynomial long division from scratch (ugh).&lt;/p&gt;
&lt;p&gt;Having done it once in Python, I was not looking forward to doing it again.&lt;/p&gt;
&lt;p&gt;First, we need to implement subtraction, because otherwise the intermediate steps of the division will get messy (because of the &lt;span class="caps"&gt;LISP&lt;/span&gt; syntax). We have multiplication already, so this is easy. Just multiply the polynomial by &lt;code class="highlight"&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;/code&gt;, a constant of &lt;span class="math"&gt;\(-1\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;sub&lt;/span&gt;
  &lt;span class="s"&gt;"Subtracts polynomial p2(x) from polynomial p1(x)."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;p1&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;neg-p2&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mul&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;})]&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;poly-trim-&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;add&lt;/span&gt; &lt;span class="nv"&gt;p1&lt;/span&gt; &lt;span class="nv"&gt;neg-p2&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;From there, it’s just a matter of translating the algorithm into Clojure. I found it easier to read and translate &lt;a href="http://www.math.ucla.edu/~radko/circles/lib/data/Handout-358-436.pdf"&gt;the long-hand procedure from English prose&lt;/a&gt; than translating pre-cooked implementations in other programming languages.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;degree&lt;/span&gt;
  &lt;span class="s"&gt;"Finds the degree (power of highest-power term) of a polynomial."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;pnml&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;apply max &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;keys &lt;/span&gt;&lt;span class="nv"&gt;pnml&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;lc&lt;/span&gt;
  &lt;span class="s"&gt;"Leading coefficient (coefficient of highest-power term) of a polynomial."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;pnml&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;get &lt;/span&gt;&lt;span class="nv"&gt;pnml&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;degree&lt;/span&gt; &lt;span class="nv"&gt;pnml&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;poly-quot-&lt;/span&gt;
  &lt;span class="s"&gt;"The quotient of a polynomial p1(x) divided by another p2(x).&lt;/span&gt;
&lt;span class="s"&gt;  Returns nil if p2 is of a higher degree than p1."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;p1&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;d1&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;degree&lt;/span&gt; &lt;span class="nv"&gt;p1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;d2&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;degree&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;when &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;gt;= &lt;/span&gt;&lt;span class="nv"&gt;d1&lt;/span&gt; &lt;span class="nv"&gt;d2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;{(&lt;/span&gt;&lt;span class="nb"&gt;- &lt;/span&gt;&lt;span class="nv"&gt;d1&lt;/span&gt; &lt;span class="nv"&gt;d2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                &lt;span class="c1"&gt;;; power = difference in degree&lt;/span&gt;
       &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;lc&lt;/span&gt; &lt;span class="nv"&gt;p1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;lc&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;))})))&lt;/span&gt;  &lt;span class="c1"&gt;;; coeff = quotient of lc's&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;div&lt;/span&gt;
  &lt;span class="s"&gt;"Polynomial long division of p1(x) / p2(x).&lt;/span&gt;
&lt;span class="s"&gt;  Returns nil if p2 is of a higher degree than p1."&lt;/span&gt;
  &lt;span class="c1"&gt;;; http://www.math.ucla.edu/~radko/circles/lib/data/Handout-358-436.pdf&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;p1&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;when-let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;q&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;poly-quot-&lt;/span&gt; &lt;span class="nv"&gt;p1&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;               &lt;span class="c1"&gt;;; sanity check&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;loop &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;qs&lt;/span&gt; &lt;span class="nv"&gt;q&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;-&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="nv"&gt;q&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mul&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;sub&lt;/span&gt; &lt;span class="nv"&gt;p1&lt;/span&gt;&lt;span class="p"&gt;))]&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;empty?&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="ss"&gt;:quotient&lt;/span&gt; &lt;span class="nv"&gt;qs&lt;/span&gt; &lt;span class="ss"&gt;:remainder&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="c1"&gt;;; divides evenly&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;if-let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;new-q&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;poly-quot-&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;conj &lt;/span&gt;&lt;span class="nv"&gt;qs&lt;/span&gt; &lt;span class="nv"&gt;new-q&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                 &lt;span class="c1"&gt;;; divides with remainder&lt;/span&gt;
                 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;-&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="nv"&gt;new-q&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mul&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;sub&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
          &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="ss"&gt;:quotient&lt;/span&gt; &lt;span class="nv"&gt;qs&lt;/span&gt; &lt;span class="ss"&gt;:remainder&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;})))))&lt;/span&gt;       &lt;span class="c1"&gt;;; can't divide anymore&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;poly-rem&lt;/span&gt;
  &lt;span class="s"&gt;"Remainder after dividing two polynomials, p1(x) / p2(x)."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;p1&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;:remainder&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;div&lt;/span&gt; &lt;span class="nv"&gt;p1&lt;/span&gt; &lt;span class="nv"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id="prime-time"&gt;Prime time&lt;/h1&gt;
&lt;p&gt;Finally, it’s time to combine all of the above into an implementation of the &lt;span class="caps"&gt;AKS&lt;/span&gt; algorithm. To reiterate, the algorithm is as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;If &lt;span class="math"&gt;\(n\)&lt;/span&gt; is a perfect power (i.e., &lt;span class="math"&gt;\(n = a^b\)&lt;/span&gt; for any &lt;span class="math"&gt;\(a, b \in ℤ\)&lt;/span&gt;), return &lt;strong&gt;composite&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Find the smallest &lt;span class="math"&gt;\(r\)&lt;/span&gt; coprime to &lt;span class="math"&gt;\(n\)&lt;/span&gt; such that &lt;span class="math"&gt;\(\textrm{ord}_r(n) &amp;gt; (\log_2 n)^2\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;If &lt;span class="math"&gt;\(n\)&lt;/span&gt; is divisible by &lt;span class="math"&gt;\(a\)&lt;/span&gt; for any &lt;span class="math"&gt;\(2 \leq a \leq \min (r, n - 1)\)&lt;/span&gt;, return &lt;strong&gt;composite&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;If &lt;span class="math"&gt;\(n \leq r\)&lt;/span&gt;, return &lt;strong&gt;prime&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;If &lt;span class="math"&gt;\((X + a)^n \not= X^n + a \mod (X^r - 1, n)\)&lt;/span&gt; for any &lt;span class="math"&gt;\(1 \leq a \leq \lfloor \sqrt{\varphi(r)} \log_2(n) \rfloor\)&lt;/span&gt;, return &lt;strong&gt;composite&lt;/strong&gt;. Else return &lt;strong&gt;prime&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Taking advantage of Clojure’s &lt;code class="highlight"&gt;when&lt;/code&gt; to keep things concise, here is my implementation, which returns &lt;code class="highlight"&gt;true&lt;/code&gt; if the input is prime, &lt;code class="highlight"&gt;nil&lt;/code&gt; if the input is proven composite before the final step, and &lt;code class="highlight"&gt;false&lt;/code&gt; if the input is proven composite in the last step.&lt;/p&gt;
&lt;p&gt;On my local version of this code, I’ve split the modular arithmetic and polynomial functions into different namespaces to keep things tidy. &lt;code class="highlight"&gt;tower&lt;/code&gt;, &lt;code class="highlight"&gt;ma&lt;/code&gt;, &lt;code class="highlight"&gt;h&lt;/code&gt;, and &lt;code class="highlight"&gt;p&lt;/code&gt; denote the namespaces &lt;code class="highlight"&gt;numeric-tower&lt;/code&gt;, &lt;code class="highlight"&gt;modular-arithmetic&lt;/code&gt;, &lt;code class="highlight"&gt;helpers&lt;/code&gt;, and &lt;code class="highlight"&gt;polynomial&lt;/code&gt; respectively.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;aks-prime?&lt;/span&gt;
  &lt;span class="s"&gt;"Uses the Agrawal–Kayal–Saxena primality test to determine if an integer n&lt;/span&gt;
&lt;span class="s"&gt;  is prime. Returns true if prime, nil or false otherwise."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="c1"&gt;;; 1. Check if n is a perfect power&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;when-not &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;perfect-power?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;;; 2. Find the smallest r such that ord_r(n) &amp;gt; (log_2 n)^2.&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;log&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/log&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/log&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;tower/expt&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
          &lt;span class="nv"&gt;r&lt;/span&gt;   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;first &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;keep&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;fn &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;when-let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;ord&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;ma/multiplicative-order&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
                                     &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;when &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;gt; &lt;/span&gt;&lt;span class="nv"&gt;ord&lt;/span&gt; &lt;span class="nv"&gt;log&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
                           &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;range&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
          &lt;span class="nv"&gt;lim&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;min &lt;/span&gt;&lt;span class="nv"&gt;r&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;- &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))]&lt;/span&gt;
      &lt;span class="c1"&gt;;; 3. For all 2 ≤ a ≤ min(r, n−1), check that a does not divide n&lt;/span&gt;
      &lt;span class="c1"&gt;;; (composite if so)&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;when &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;not-any? &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;partial &lt;/span&gt;&lt;span class="nv"&gt;h/divisible?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;inc &lt;/span&gt;&lt;span class="nv"&gt;lim&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
        &lt;span class="c1"&gt;;; 4. If n ≤ r, output prime.&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;lt;= &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;true&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;log2n&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/log&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/log&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                &lt;span class="nv"&gt;lim&lt;/span&gt;   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;-&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;tower/sqrt&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;naive-phi&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;* &lt;/span&gt;&lt;span class="nv"&gt;log2n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;bigint&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="nv"&gt;lhs&lt;/span&gt;   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;fn &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;p/poly-rem&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;p/mod-exp&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;, &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                                          &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nv"&gt;r&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;, &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;}))&lt;/span&gt;
                &lt;span class="nv"&gt;rhs&lt;/span&gt;   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;fn &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;p/poly-rem&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;, &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
                                          &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nv"&gt;r&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;, &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;}))]&lt;/span&gt;
            &lt;span class="c1"&gt;;; 5. If (X+a)^n != (X^n)+a (mod X^r − 1,n) for ANY a from 1 to lim,&lt;/span&gt;
            &lt;span class="c1"&gt;;; n is composite.&lt;/span&gt;
            &lt;span class="c1"&gt;;; In other words, prime? = true iff (X+a)^n = (X^n)+a (mod X^r − 1,n)&lt;/span&gt;
            &lt;span class="c1"&gt;;; for ALL a from 1 to lim&lt;/span&gt;
            &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;every? &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;fn &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;lhs&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;rhs&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="nv"&gt;lim&lt;/span&gt;&lt;span class="p"&gt;))))))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id="gotcha"&gt;Gotcha!&lt;/h1&gt;
&lt;p&gt;Congrats! You made it this far.&lt;/p&gt;
&lt;p&gt;If you test this function, though, you might be a bit disappointed with the results. Namely, it’s very slow, even for small inputs. The lag becomes apparent even with prime number inputs as small as &lt;span class="math"&gt;\(n = 37\)&lt;/span&gt;, and skyrockets exponentially as the size of &lt;span class="math"&gt;\(n\)&lt;/span&gt; increases.&lt;/p&gt;
&lt;p&gt;Indeed, despite all the groundbreaking features of the algorithm, &lt;a href="https://cs.stackexchange.com/questions/23260/when-is-the-aks-primality-test-actually-faster-than-other-tests/23360#23360"&gt;speed and practicality are not among them&lt;/a&gt;. Ordinarily, I would be inclined to call coding all of this a waste of time and curse myself for not having bothered to research this earlier, but since I learned a fair bit of Clojure and math in the process, I can’t quite call it a waste.&lt;/p&gt;
&lt;p&gt;However, it does mean I need to study up on elliptic curves!&lt;/p&gt;
&lt;h1 id="references"&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/AKS_primality_test"&gt;&lt;span class="caps"&gt;AKS&lt;/span&gt; primality test&lt;/a&gt;, Wikipedia&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/@sibu.it13/aks-primality-test-f184cf6365a1"&gt;&lt;span class="caps"&gt;AKS&lt;/span&gt; Primality Test (Primes is in P)&lt;/a&gt;, Sibaprasad Maiti&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.math.ucla.edu/~radko/circles/lib/data/Handout-358-436.pdf"&gt;Long division of polynomials&lt;/a&gt;, Olga Radko, &lt;span class="caps"&gt;UCLA&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cs.stackexchange.com/questions/23260/when-is-the-aks-primality-test-actually-faster-than-other-tests/23360#23360"&gt;When is the &lt;span class="caps"&gt;AKS&lt;/span&gt; primality test actually faster than other tests?&lt;/a&gt;, &lt;span class="caps"&gt;CS&lt;/span&gt; Stack Exchange&lt;/li&gt;
&lt;/ul&gt;</content><category term="number theory"></category><category term="clojure"></category><category term="algorithms"></category></entry><entry><title>Number Theory in Clojure: The Fundamental Theorem of Arithmetic</title><link href="http://tabidots.github.io/2019/03/fundamental-theorem-arithmetic" rel="alternate"></link><published>2019-03-31T19:47:21+07:00</published><updated>2019-03-31T19:47:21+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-03-31:/2019/03/fundamental-theorem-arithmetic</id><summary type="html">&lt;p&gt;The first post in a new series exploring number theory in Clojure, starting with a discussion of primality testing and prime&amp;nbsp;factorization.&lt;/p&gt;</summary><content type="html">
&lt;p&gt;I’ve had to hit the pause button on the blog for a bit because life got in the way, but I haven’t stopped my mathematical explorations. Actually, I got turned on to &lt;a href="https://projecteuler.net"&gt;Project Euler&lt;/a&gt; in the meantime, which became something of an addiction. Most people solve the problems in C/C++ or Python, but I decided to take the opportunity to sharpen my skills in Clojure (which is, let’s face it, the best-designed programming language out there 😉).&lt;/p&gt;
&lt;p&gt;In the beginning, the “mathematical discovery factor” increased with the difficulty, but after solving about 90 problems, those returns have plateaued and are now declining in relation to the diffficulty. So now it’s time to start posting about some of the cool things I’ve discovered along the way, and use this blog to explore those topics further.&lt;/p&gt;
&lt;h1 id="prime-time"&gt;Prime time&lt;/h1&gt;
&lt;p&gt;Thanks to Chapter 1 of &lt;a href="https://pimbook.org"&gt;A Programmer’s Introduction to Mathematics&lt;/a&gt;, I had already developed an interest in number theory and cryptography. This interest was further ignited by Project Euler, in whose problems number theory factors heavily (pun intended).&lt;/p&gt;
&lt;p&gt;Number theory is basically the study of the integers, &lt;span class="math"&gt;\(ℤ\)&lt;/span&gt;. This in turn shines the spotlight on prime numbers, a very special category of the integers due to their many interesting properties.&lt;/p&gt;
&lt;p&gt;In order to do anything interesting in number theory, we need to find a way to &lt;strong&gt;test the primality&lt;/strong&gt; of a number and to &lt;strong&gt;generate a sequence of prime numbers&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In imperative languages, it’s typical to separate these two tasks, and approach the latter by implementing what is called a “prime sieve,” such as the &lt;a href="https://en.wikipedia.org/wiki/Sieve_of_Eratosthenes"&gt;Sieve of Eratosthenes&lt;/a&gt;, which walks up an infinite sequence of numbers and crosses off more and more composite numbers with each iteration. You might start with an enormous array of &lt;code class="highlight"&gt;True&lt;/code&gt;s and switch the indices of composite numbers to &lt;code class="highlight"&gt;False&lt;/code&gt; as you go along.&lt;/p&gt;
&lt;p&gt;Clojure, on the other hand, is a functional language, in which mutating sequences in-place is neither idiomatic nor clean. &lt;a href="http://clj-me.cgrand.net/2009/07/30/everybody-loves-the-sieve-of-eratosthenes/"&gt;Lazy (lazily evaluated) infinite sequences are the way to go&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As the above link shows, it is possible to implement a Sieve of Eratosthenes in Clojure, but it’s quite difficult to read, and in any less than expert hands, &lt;a href="http://www.learningclojure.com/2009/11/sieve-of-eratosthenes.html"&gt;quite ugly&lt;/a&gt; as well. Meanwhile, I’ve found that it’s simpler to &lt;code class="highlight"&gt;filter&lt;/code&gt; primes in Clojure than sieving them, which also conveniently integrates the task of testing primality as well.&lt;/p&gt;
&lt;p&gt;This approach is highly readable and, when memoized, its performance does not catastrophically degrade until you start needing primes greater than 1 million or so. Obviously, actual cryptographic applications would require a more industrial-strength implementation, as real-world cryptography deals with integers that could be as large as 256 bits (hundreds of digits long), but for armchair explorations of number theory, this approach will suffice.&lt;/p&gt;
&lt;h2 id="primes-on-trial"&gt;Primes on trial&lt;/h2&gt;
&lt;p&gt;This method is called “trial division,” since it involves dividing &lt;span class="math"&gt;\(n\)&lt;/span&gt; by numbers in a range to test for divisibility. First, we have to define divisibility. A dividend &lt;span class="math"&gt;\(n\)&lt;/span&gt; is divisible by a divisor &lt;span class="math"&gt;\(d\)&lt;/span&gt; if no remainder is left after the division, or in other words, if &lt;span class="math"&gt;\(n\)&lt;/span&gt; is a multiple of &lt;span class="math"&gt;\(d\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In terms of modular arithmetic, this is conveniently expressed as a &lt;em&gt;congruence&lt;/em&gt;: &lt;span class="math"&gt;\(n \equiv 0 \mod d\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;divisible?&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;d&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zero? &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mod&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The most naïve, brute-force approach is to literally divide &lt;span class="math"&gt;\(n\)&lt;/span&gt; by all numbers in &lt;span class="math"&gt;\([1, n)\)&lt;/span&gt; and return &lt;code class="highlight"&gt;true&lt;/code&gt; (&lt;span class="math"&gt;\(n\)&lt;/span&gt; is prime) if &lt;span class="math"&gt;\(n\)&lt;/span&gt; is divisible by &lt;em&gt;none&lt;/em&gt; of those numbers:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;brute-force-prime?&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;not-any? &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;partial &lt;/span&gt;&lt;span class="nv"&gt;divisible?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This is extremely slow, though. For a number like &lt;span class="math"&gt;\(45565962173\)&lt;/span&gt;, this is completely intractable, but even  generating primes up to &lt;span class="math"&gt;\(100000\)&lt;/span&gt; is impractical with this method.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;time &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;doall &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="nv"&gt;brute-force-prime?&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;100000&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;span class="c1"&gt;;; Elapsed time: 67653.900002 msecs&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;A smarter way to do this starts with noticing that only potential divisors up to &lt;span class="math"&gt;\(\sqrt{n}\)&lt;/span&gt; need to be tried, because any divisor less than that will have a complementary divisor on the other side of &lt;span class="math"&gt;\(\sqrt{n}\)&lt;/span&gt;. For example, &lt;span class="math"&gt;\(\sqrt{28} \approx 5.3\)&lt;/span&gt;. &lt;span class="math"&gt;\(28\)&lt;/span&gt; is divisible by &lt;span class="math"&gt;\(2\)&lt;/span&gt;, and this division yields the complementary divisor &lt;span class="math"&gt;\(14\)&lt;/span&gt;. Likewise, &lt;span class="math"&gt;\(4\)&lt;/span&gt; yields &lt;span class="math"&gt;\(7\)&lt;/span&gt;.&lt;/p&gt;
&lt;h2 id="integer-square-root"&gt;Integer square root&lt;/h2&gt;
&lt;p&gt;An &lt;a href="https://en.wikipedia.org/wiki/Integer_square_root"&gt;upper integer bound &lt;span class="math"&gt;\(\lfloor \sqrt{n} \rfloor\)&lt;/span&gt;&lt;/a&gt; capable of handling fairly large numbers can be implemented quite simply as &lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;bigint&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/sqrt&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/code&gt;, taking advantage of Java interop.&lt;/p&gt;
&lt;p&gt;This has been effective for all of the Project Euler problems I’ve solved so far, though it is true that a proper arithmetical solution would not involve floating-point numbers. For sufficiently large &lt;span class="math"&gt;\(n\)&lt;/span&gt;, rounding errors would yield an upper bound that is too low to find all possible factors, especially in the worst case (where a very large &lt;span class="math"&gt;\(n\)&lt;/span&gt; is the product of two very large primes that are similar but not equal in value).&lt;/p&gt;
&lt;p&gt;I use the &lt;a href="https://github.com/clojure/math.numeric-tower"&gt;clojure.math.numeric-tower&lt;/a&gt; library here as
using Java interop for exponentiation (&lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/pow&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/code&gt;) similarly introduces floating-point numbers, and &lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;tower/expt&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/code&gt; is ever-so-slightly faster than &lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="nv"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;repeat &lt;/span&gt;&lt;span class="nv"&gt;e&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Here is a bulletproof integer square root function, which uses the simpler, faster method for &lt;span class="math"&gt;\(n &amp;lt; 10^24\)&lt;/span&gt; and a &lt;a href="https://cs.stackexchange.com/a/30383"&gt;more sophisticated algorithm&lt;/a&gt; (which I don’t really understand) for larger numbers.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;require&lt;/span&gt; &lt;span class="o"&gt;'&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;clojure.math.numeric-tower&lt;/span&gt; &lt;span class="ss"&gt;:as&lt;/span&gt; &lt;span class="nv"&gt;tower&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;isqrt&lt;/span&gt;
  &lt;span class="s"&gt;"floor(√n). When incremented, provides an upper bound for factorization."&lt;/span&gt;
  &lt;span class="c1"&gt;;; Java interop is super fast but not accurate for n &amp;gt; 1E24 (approx) due to&lt;/span&gt;
  &lt;span class="c1"&gt;;; floating-point rounding. Uses a slightly slower but pinpoint-precise method for n &amp;gt; 1E24.&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;lt; &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="nv"&gt;E24&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/sqrt&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;bigint&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;;; https://cs.stackexchange.com/a/30383&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;half-bit-length&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;quot &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;.bitLength&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;bigint&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;loop &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;tower/expt&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="nv"&gt;half-bit-length&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
             &lt;span class="nv"&gt;b&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt;
             &lt;span class="nv"&gt;c&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;cond&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zero? &lt;/span&gt;&lt;span class="nv"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;gt; &lt;/span&gt;&lt;span class="nv"&gt;c&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;-&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;quot &lt;/span&gt;&lt;span class="nv"&gt;b&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="nv"&gt;c&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="mi"&gt;-2&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;b&lt;/span&gt; &lt;span class="nv"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
          &lt;span class="ss"&gt;:else&lt;/span&gt;     &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;+&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;quot &lt;/span&gt;&lt;span class="nv"&gt;b&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="nv"&gt;c&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="nv"&gt;b&lt;/span&gt; &lt;span class="nv"&gt;b&lt;/span&gt;&lt;span class="p"&gt;))))))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="testing-primality"&gt;Testing primality&lt;/h2&gt;
&lt;p&gt;Next, let’s implement some basic checks to eliminate the need to do any calculations in the majority of cases. When testing for primality, we generally only consider &lt;span class="math"&gt;\(ℤ\)&lt;/span&gt;, the positive integers. Furthermore, &lt;span class="math"&gt;\(1\)&lt;/span&gt; is &lt;em&gt;not&lt;/em&gt; considered prime. So &lt;span class="math"&gt;\(n \leq 1\)&lt;/span&gt; is &lt;code class="highlight"&gt;false&lt;/code&gt; right off the bat. Next, all primes are odd except &lt;span class="math"&gt;\(2\)&lt;/span&gt;, so make an exception for &lt;span class="math"&gt;\(2\)&lt;/span&gt; and return &lt;code class="highlight"&gt;false&lt;/code&gt; for all &lt;code class="highlight"&gt;even?&lt;/code&gt; numbers.&lt;/p&gt;
&lt;p&gt;Clojure’s built-in &lt;code class="highlight"&gt;even?&lt;/code&gt; function has the added bonus of throwing an exception for &lt;code class="highlight"&gt;Ratio&lt;/code&gt;s and &lt;code class="highlight"&gt;float&lt;/code&gt;s.&lt;/p&gt;
&lt;p&gt;This leaves all odd numbers &lt;span class="math"&gt;\(\geq 3\)&lt;/span&gt;. Weeding out all even numbers means that there is no need to check for even divisors (odd numbers only have odd divisors).&lt;/p&gt;
&lt;p&gt;The most idiomatic way to write this would be:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;cond&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;lt;= &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="nv"&gt;false&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="nv"&gt;true&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;even?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;false&lt;/span&gt; &lt;span class="c1"&gt;;; Will also weed out non-integers&lt;/span&gt;
  &lt;span class="ss"&gt;:else&lt;/span&gt;     &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;not-any? &lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;divisible?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;%&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;inc &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;isqrt&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;but this is actually about 1.5x as slow as a more verbose translation using &lt;code class="highlight"&gt;loop&lt;/code&gt;/&lt;code class="highlight"&gt;recur&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;naive-prime?&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;cond&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;lt;= &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="nv"&gt;false&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="nv"&gt;true&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;even?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;false&lt;/span&gt; &lt;span class="c1"&gt;;; Will also weed out non-integers&lt;/span&gt;
    &lt;span class="ss"&gt;:else&lt;/span&gt;     &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;lim&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;int-root&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
                &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;loop &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;i&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;cond&lt;/span&gt;
                    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;gt;= &lt;/span&gt;&lt;span class="nv"&gt;i&lt;/span&gt; &lt;span class="nv"&gt;lim&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;       &lt;span class="nv"&gt;true&lt;/span&gt;
                    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;divisible?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;false&lt;/span&gt;
                    &lt;span class="ss"&gt;:else&lt;/span&gt;            &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="nv"&gt;i&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)))))))&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;def &lt;/span&gt;&lt;span class="nv"&gt;prime?&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;memoize&lt;/span&gt; &lt;span class="nv"&gt;naive-prime?&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;whose performance, non-memoized and memoized, is leaps and bounds above the original brute-force trial division function:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;require&lt;/span&gt; &lt;span class="o"&gt;'&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;criterium.core&lt;/span&gt; &lt;span class="ss"&gt;:as&lt;/span&gt; &lt;span class="nv"&gt;c&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;c/quick-bench&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;naive-prime?&lt;/span&gt; &lt;span class="mi"&gt;45565962173&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="c1"&gt;;; Execution time mean : 16.516873 ms&lt;/span&gt;
&lt;span class="c1"&gt;;; Execution time std-deviation : 1.053979 ms&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;c/quick-bench&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;prime?&lt;/span&gt; &lt;span class="mi"&gt;45565962173&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="c1"&gt;;; Execution time mean : 340.284934 ns&lt;/span&gt;
&lt;span class="c1"&gt;;; Execution time std-deviation : 10.658400 ns&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="leveraging-the-primality-test"&gt;Leveraging the primality test&lt;/h2&gt;
&lt;p&gt;This may not exactly be an industrial-strength method, but for my current purposes, it arguably allows more idiomatic and readable ways to accomplish tasks such as &lt;code class="highlight"&gt;filter&lt;/code&gt;, &lt;code class="highlight"&gt;take&lt;/code&gt;, and &lt;code class="highlight"&gt;nth&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;c/quick-bench&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;doall &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="nv"&gt;naive-prime?&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;100000&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;span class="c1"&gt;;; Execution time mean : 265.236965 ms&lt;/span&gt;
&lt;span class="c1"&gt;;; Execution time std-deviation : 6.784358 ms&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;c/quick-bench&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;doall &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="nv"&gt;prime?&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;100000&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;span class="c1"&gt;;; Execution time mean : 83.140024 ms&lt;/span&gt;
&lt;span class="c1"&gt;;; Execution time std-deviation : 1.655784 ms&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;c/quick-bench&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;take &lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="nv"&gt;prime?&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;range&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;span class="c1"&gt;;; Execution time mean : 88.645751 ns&lt;/span&gt;
&lt;span class="c1"&gt;;; Execution time std-deviation : 27.586353 ns&lt;/span&gt;

&lt;span class="c1"&gt;;; (dec n) gets the nth prime, because the sequence is zero-indexed&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;c/quick-bench&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;nth &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="nv"&gt;prime?&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;range&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;dec &lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="c1"&gt;;; Execution time mean : 2.473162 ms&lt;/span&gt;
&lt;span class="c1"&gt;;; Execution time std-deviation : 123.136771 µs&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id="prime-factorization"&gt;Prime factorization&lt;/h1&gt;
&lt;p&gt;With that out of the way, we come to the cornerstone of number theory:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;All integers greater than 1 are either a prime number or can be expressed as a unique product of prime numbers.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The algorithm to find the prime factors of an integer &lt;span class="math"&gt;\(n\)&lt;/span&gt; is surprisingly simple to implement. Start with an empty list of factors and an infinite list of primes. Begin with the first prime (that is, &lt;span class="math"&gt;\(2\)&lt;/span&gt;) and divide &lt;span class="math"&gt;\(n\)&lt;/span&gt; by &lt;span class="math"&gt;\(2\)&lt;/span&gt; until you can’t anymore. Each time you divide, add a &lt;span class="math"&gt;\(2\)&lt;/span&gt; to your list of factors.&lt;/p&gt;
&lt;p&gt;Then, proceed to the next prime (&lt;span class="math"&gt;\(3\)&lt;/span&gt;) and repeat up the list, adding factors, until the result of your division is &lt;span class="math"&gt;\(1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Let’s try &lt;span class="math"&gt;\(168 = 2 \times 2 \times 2 \times 3 \times 7\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;loop &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;       &lt;span class="mi"&gt;168&lt;/span&gt;
       &lt;span class="nv"&gt;primes&lt;/span&gt;  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="nv"&gt;prime?&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;range&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
       &lt;span class="nv"&gt;factors&lt;/span&gt; &lt;span class="p"&gt;[]]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;k&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;first &lt;/span&gt;&lt;span class="nv"&gt;primes&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;cond&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;          &lt;span class="nv"&gt;factors&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;divisible?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;primes&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;conj &lt;/span&gt;&lt;span class="nv"&gt;factors&lt;/span&gt; &lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
      &lt;span class="ss"&gt;:else&lt;/span&gt;            &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;rest &lt;/span&gt;&lt;span class="nv"&gt;primes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;factors&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;

&lt;span class="c1"&gt;;; [2 2 2 3 7]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Checks out. You can try a bunch of random numbers and you’ll instantly get its prime factorization, which is something like a fingerprint, since it’s unique for every number. Pretty cool!&lt;/p&gt;
&lt;p&gt;But again, a ridiculously large number like &lt;span class="math"&gt;\(245454537724879\)&lt;/span&gt; is too much for a simple algorithm. Actually, it’s not so much that the number is too large, but that it has very large prime factors, so it takes a very long time to iterate that far up the list of primes.&lt;/p&gt;
&lt;p&gt;This can be worked around &lt;em&gt;somewhat&lt;/em&gt; if we find the factors of &lt;span class="math"&gt;\(n\)&lt;/span&gt; first, then &lt;code class="highlight"&gt;filter&lt;/code&gt; the &lt;code class="highlight"&gt;prime?&lt;/code&gt; ones.&lt;/p&gt;
&lt;h2 id="regular-factorization"&gt;Regular factorization&lt;/h2&gt;
&lt;p&gt;This will look a bit like our initial foray into primality testing. Rather than checking if &lt;span class="math"&gt;\(n\)&lt;/span&gt; has no (that is, &lt;code class="highlight"&gt;not-any?&lt;/code&gt;) divisors &lt;span class="math"&gt;\(1 &amp;lt; d &amp;lt; n\)&lt;/span&gt;, we just filter all divisors &lt;span class="math"&gt;\(1 \leq d &amp;lt; n\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;brute-force-factors&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;partial &lt;/span&gt;&lt;span class="nv"&gt;divisible?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As you can imagine, since this is running through every possible number, this will take way too long for large &lt;span class="math"&gt;\(n\)&lt;/span&gt;. We can use the same upper bound as before, although that means that for every positive result, we have to add not only &lt;span class="math"&gt;\(d\)&lt;/span&gt;, but &lt;span class="math"&gt;\(\frac{n}{d}\)&lt;/span&gt; as well.&lt;/p&gt;
&lt;p&gt;Here is a clean way of doing that:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;factors&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;-&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;inc &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;isqrt&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
       &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;divisible?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;%&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
       &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;mapcat &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;fn &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;d&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;d&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)]))&lt;/span&gt;
       &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;into &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;sorted-set&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="more-optimized-prime-factorization"&gt;More optimized prime factorization&lt;/h2&gt;
&lt;p&gt;With this, we can now improve the performance of our prime factorization function by checking the size of the number first. If &lt;span class="math"&gt;\(n\)&lt;/span&gt; is smaller than some threshold (let’s say 1 million), then iterate up an infinite list of primes as before. If &lt;span class="math"&gt;\(n\)&lt;/span&gt; is larger than the threshold, though, then &lt;code class="highlight"&gt;filter&lt;/code&gt; the &lt;code class="highlight"&gt;prime?&lt;/code&gt; &lt;code class="highlight"&gt;factors&lt;/code&gt; first, and iterate up &lt;em&gt;that&lt;/em&gt; list instead.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;prime-factorization&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="s"&gt;"Returns the prime factorization of an integer, e.g., 168 -&amp;gt; [2 2 2 3 7]."&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;when &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;and &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;integer?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;pos? &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;   &lt;span class="c1"&gt;;; Sanity check&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;loop &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;       &lt;span class="nv"&gt;n&lt;/span&gt;
           &lt;span class="nv"&gt;primes&lt;/span&gt;  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;gt; &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;1000000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                     &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="nv"&gt;prime?&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;factors&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                     &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="nv"&gt;prime?&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;range&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
           &lt;span class="nv"&gt;factors&lt;/span&gt; &lt;span class="p"&gt;[]]&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;k&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;first &lt;/span&gt;&lt;span class="nv"&gt;primes&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;cond&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;          &lt;span class="nv"&gt;factors&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;divisible?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;primes&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;conj &lt;/span&gt;&lt;span class="nv"&gt;factors&lt;/span&gt; &lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
          &lt;span class="ss"&gt;:else&lt;/span&gt;            &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;rest &lt;/span&gt;&lt;span class="nv"&gt;primes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;factors&lt;/span&gt;&lt;span class="p"&gt;))))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This isn’t a perfect heuristic, as large numbers do not necessarily have large prime factors. For example, 12 bazillion-gajillion (&lt;span class="math"&gt;\(12 \times 10^{??}\)&lt;/span&gt;) still has only &lt;span class="math"&gt;\((2, 3, 5)\)&lt;/span&gt; as prime factors, just like &lt;span class="math"&gt;\(120\)&lt;/span&gt;. But at least it can reduce the time required for difficult cases, such as &lt;span class="math"&gt;\(n = 23897538974893789\)&lt;/span&gt;, and make them tractable.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;time &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;prime-factorization&lt;/span&gt; &lt;span class="mi"&gt;23897538974893789&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="c1"&gt;;; Elapsed time: 30579.928312 msecs&lt;/span&gt;
&lt;span class="c1"&gt;;; [211 23357 4849016507]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;(The brute-force version didn’t finish even after 5 minutes, so I abandoned it.)&lt;/p&gt;
&lt;h2 id="prime-omega-functions"&gt;Prime omega functions&lt;/h2&gt;
&lt;p&gt;There are a couple arithmetic that look and sound really impressive but are trivial to implement in code once you can factor an integer into primes.&lt;/p&gt;
&lt;p&gt;One is the little omega function &lt;span class="math"&gt;\(\omega(n)\)&lt;/span&gt;, which counts the number of distinct prime factors of &lt;span class="math"&gt;\(n\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;count &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;distinct &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;prime-factorization&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The other is the big omega function &lt;span class="math"&gt;\(\Omega(n)\)&lt;/span&gt;, which counts the number of prime factors of &lt;span class="math"&gt;\(n\)&lt;/span&gt; with multiplicity (i.e., if &lt;span class="math"&gt;\(2\)&lt;/span&gt; appears more than once, count both instances).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;count &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;prime-factorization&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id="prime-power-representation"&gt;Prime power representation&lt;/h1&gt;
&lt;p&gt;Given the prime factorization of a number, we can use this information to formulate its unique representation as a product of prime powers.&lt;/p&gt;
&lt;div class="math"&gt;$$ n = p_{1}^{e_{1}}p_{2}^{e_{2}}\cdots p_{k}^{e_{k}}
     = \prod_{i=1}^{k}p_{i}^{e_{i}} $$&lt;/div&gt;
&lt;p&gt;Returning to our simple example &lt;span class="math"&gt;\(168 = 2 \times 2 \times 2 \times 3 \times 7\)&lt;/span&gt; above, this can be written more succinctly as&lt;/p&gt;
&lt;div class="math"&gt;$$ 168 = 2^3 \times 3 \times 7 $$&lt;/div&gt;
&lt;p&gt;which is also called its &lt;strong&gt;canonical representation&lt;/strong&gt; or &lt;strong&gt;standard form&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;If we fill in the missing primes above with &lt;span class="math"&gt;\(p_{i}^{0}\)&lt;/span&gt;, which doesn’t affect the final product, then the sequence of &lt;span class="math"&gt;\(e_1 \cdots e_k\)&lt;/span&gt; in the above notation can also be extracted from the prime factorization, which gives us an &lt;strong&gt;exponent vector&lt;/strong&gt; (or &lt;em&gt;unique prime signature&lt;/em&gt;). For &lt;span class="math"&gt;\(168\)&lt;/span&gt;, this would be&lt;/p&gt;
&lt;div class="math"&gt;$$ 168 = 2^{\color{red}{3}} \times 3^{\color{red}{1}} \times 5^{\color{red}{0}} \times 7^{\color{red}{1}}
       = \begin{bmatrix}3 &amp;amp; 1 &amp;amp; 0 &amp;amp; 1\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;Here’s a simple way to implement that:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;prime-powers-integer&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="s"&gt;"Returns the exponent vector for the prime power representation of an integer,&lt;/span&gt;
&lt;span class="s"&gt;  e.g., 168 = 2*2*2*3*7 = 2^3 * 3^1 * 5^0 * 7^1 -&amp;gt; (3 1 0 1)"&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;when &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;and &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;integer?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;pos? &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;pf&lt;/span&gt;      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;prime-factorization&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="nv"&gt;primes&lt;/span&gt;  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="nv"&gt;prime?&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;inc &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;peek &lt;/span&gt;&lt;span class="nv"&gt;pf&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
            &lt;span class="nv"&gt;freqs&lt;/span&gt;   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;frequencies&lt;/span&gt; &lt;span class="nv"&gt;pf&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="nv"&gt;get-exp&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;fn &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;p&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;if-let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;exp&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;get &lt;/span&gt;&lt;span class="nv"&gt;freqs&lt;/span&gt; &lt;span class="nv"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
                              &lt;span class="nv"&gt;exp&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))]&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;map &lt;/span&gt;&lt;span class="nv"&gt;get-exp&lt;/span&gt; &lt;span class="nv"&gt;primes&lt;/span&gt;&lt;span class="p"&gt;)))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For &lt;span class="math"&gt;\(n = 168\)&lt;/span&gt;, the procedure works like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;pf&lt;/span&gt; &lt;span class="nv"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;primes&lt;/span&gt; &lt;span class="nv"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;;; one of each prime up to the last prime in pf&lt;/span&gt;
&lt;span class="nv"&gt;freqs&lt;/span&gt; &lt;span class="nv"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;, &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;, &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;map &lt;/span&gt;&lt;span class="nv"&gt;get-exp&lt;/span&gt; &lt;span class="nv"&gt;primes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;map &lt;/span&gt;&lt;span class="nv"&gt;get-exp&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="nv"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This works fine when the prime factors are small, but it isn’t the cleanest approach. Namely, one list of primes may already be generated by &lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;prime-factorization&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/code&gt;, so generating another (for the purpose of determining that &lt;span class="math"&gt;\(87\)&lt;/span&gt; is the &lt;span class="math"&gt;\(i\)&lt;/span&gt;th prime, for example) is not very efficient. If we limited the &lt;code class="highlight"&gt;prime-factorization&lt;/code&gt; function to the iterative approach, we could generate a map containing &lt;code class="highlight"&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="ss"&gt;:i&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="ss"&gt;:p&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="ss"&gt;:e&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;/code&gt; for each prime, which is a starting point for generating both the canonical representation and the exponent vector.&lt;/p&gt;
&lt;p&gt;However, since this is mostly for curiosity’s sake than actual applications, I’m leaving it at that. For cryptographic applications, what is more important than generating exponent vectors are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Finding the factors (prime or otherwise) of an integer themselves, and&lt;/li&gt;
&lt;li&gt;Specialized techniques for factoring specific types of numbers, such as semiprimes.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now, for completeness’ sake, let’s write a function to convert an exponent vector back to an integer.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;prime-powers-&amp;gt;num&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;pp&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;primes&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="nv"&gt;prime?&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;range&lt;/span&gt;&lt;span class="p"&gt;))]&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="nv"&gt;*&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;map &lt;/span&gt;&lt;span class="nv"&gt;tower/expt&lt;/span&gt; &lt;span class="nv"&gt;primes&lt;/span&gt; &lt;span class="nv"&gt;pp&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;prime-powers-&amp;gt;num&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="c1"&gt;;; 168&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="negative-exponents-too"&gt;Negative exponents too?&lt;/h2&gt;
&lt;p&gt;While writing this, I learned that allowing negative exponents in prime factorizations enables you to represent not only all the integers (&lt;span class="math"&gt;\(n \in ℤ\)&lt;/span&gt;), but all the rationals (&lt;span class="math"&gt;\(n \in ℚ\)&lt;/span&gt;) as well.&lt;/p&gt;
&lt;p&gt;For some rational number &lt;span class="math"&gt;\(q = \frac{a}{b}\)&lt;/span&gt;, let &lt;span class="math"&gt;\(\vec a, \vec b\)&lt;/span&gt; be the exponent vectors for the integers &lt;span class="math"&gt;\(a, b\)&lt;/span&gt;. The exponent vector for &lt;span class="math"&gt;\(q\)&lt;/span&gt; is then &lt;span class="math"&gt;\(\vec q = \vec a - \vec b\)&lt;/span&gt;. For example,&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{gathered}
q = \frac{171}{98} \\[0.8em]
\begin{aligned}
a = 171 &amp;amp;= 3^2 \times 19^1 \\
b = 98 &amp;amp;= 2^1 \times 7^2 \\[0.8em]
\end{aligned} \\
\begin{aligned}
\vec a &amp;amp;= \begin{bmatrix}\; \; \; 0 &amp;amp; 2 &amp;amp; 0 &amp;amp; \; \; \; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\end{bmatrix} \\
\vec b &amp;amp;= \begin{bmatrix}\; \; \; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; \; \; \; 2 &amp;amp; \textcolor{#bbb}{0} &amp;amp; \textcolor{#bbb}{0} &amp;amp; \textcolor{#bbb}{0} &amp;amp; \textcolor{#bbb}{0}\end{bmatrix} \\
\vec q &amp;amp;= \begin{bmatrix}-1 &amp;amp; 2 &amp;amp; 0 &amp;amp; -2 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\end{bmatrix} \\[0.8em]
\end{aligned} \\
\begin{aligned}
q &amp;amp;= 2^{-1} \times 3^2 \times 7^{-2} \times 19^1 \\
  &amp;amp;= \frac{1}{2} \times 9 \times \frac{1}{49} \times 19
\end{aligned}
\end{gathered}$$&lt;/div&gt;
&lt;p&gt;The following code is something I scratched up quickly as Clojure does not have a simple way to implement something like &lt;code class="highlight"&gt;map-longest&lt;/code&gt;. That is, a way to map over multiple collections, filling in dummy values to make each collection the same size as the largest—in this case, the light gray &lt;span class="math"&gt;\(\textcolor{#bbb}{0}\)&lt;/span&gt; in &lt;span class="math"&gt;\(\vec b\)&lt;/span&gt; above.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;prime-powers-rational&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;q&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;r&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;rationalize&lt;/span&gt; &lt;span class="nv"&gt;q&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="c1"&gt;;; Sanity check to accept decimal representations of rational numbers&lt;/span&gt;
    &lt;span class="c1"&gt;;; while still rejecting irrational numbers&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;when &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;or &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;ratio?&lt;/span&gt; &lt;span class="nv"&gt;q&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;= &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;double &lt;/span&gt;&lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;double &lt;/span&gt;&lt;span class="nv"&gt;q&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;prime-powers-integer&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;numerator&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="nv"&gt;d&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;prime-powers-integer&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;denominator&lt;/span&gt; &lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="nv"&gt;pn&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;concat &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;repeat &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;count &lt;/span&gt;&lt;span class="nv"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="nv"&gt;pd&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;concat &lt;/span&gt;&lt;span class="nv"&gt;d&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;repeat &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;count &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))]&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;-&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;map - &lt;/span&gt;&lt;span class="nv"&gt;pn&lt;/span&gt; &lt;span class="nv"&gt;pd&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
             &lt;span class="nv"&gt;reverse&lt;/span&gt;
             &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;drop-while &lt;/span&gt;&lt;span class="nv"&gt;zero?&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;;; truncate zeros from the end&lt;/span&gt;
             &lt;span class="nv"&gt;reverse&lt;/span&gt;&lt;span class="p"&gt;)))))&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;prime-powers-rational&lt;/span&gt; &lt;span class="mi"&gt;171&lt;/span&gt;&lt;span class="nv"&gt;/98&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;;; (-1 2 0 -2 0 0 0 1)&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;prime-powers-&amp;gt;num&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;-1&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;-2&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="c1"&gt;;; 171/98&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Pretty cool!&lt;/p&gt;
&lt;p&gt;While the rational version doesn’t reside strictly within the confines of number theory, as it goes beyond the integers, it is still mathematically interesting and can be wrapped up neatly in a bulletproof &lt;code class="highlight"&gt;prime-powers&lt;/code&gt; function that can handle both integer and rational inputs.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;prime-powers&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;when &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;pos? &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;integer?&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;prime-powers-integer&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;prime-powers-rational&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Apparently, this can be &lt;a href="https://math.stackexchange.com/questions/873455/factorization-of-rational-powers-of-rational-numbers"&gt;extended to rational powers of rational numbers&lt;/a&gt; as well, which would seem to allow irrational numbers to be represented as well, though that is starting to get a little deep for me 😅&lt;/p&gt;
&lt;p&gt;That’s all for now. Stay tuned for more posts in this series!&lt;/p&gt;
&lt;h1 id="references"&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Fundamental_theorem_of_arithmetic"&gt;Fundamental theorem of arithmetic&lt;/a&gt;, Wikipedia&lt;/li&gt;
&lt;li&gt;&lt;a href="https://oeis.org/wiki/Prime_factorization"&gt;Prime factorization&lt;/a&gt;, &lt;span class="caps"&gt;OEIS&lt;/span&gt; Wiki&lt;/li&gt;
&lt;/ul&gt;</content><category term="number theory"></category><category term="math"></category><category term="clojure"></category></entry><entry><title>djdw on the 0s and 1s</title><link href="http://tabidots.github.io/2019/02/backpropagation" rel="alternate"></link><published>2019-02-05T09:25:20+07:00</published><updated>2019-02-05T09:25:20+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-02-05:/2019/02/backpropagation</id><summary type="html">&lt;p&gt;After my previous fail trying to use autograd with pandas, I decided to set simple linear regression aside and attempt training a neural network. Here, I’ve adapted the network in the Welch Labs tutorial to accommodate an arbitrary number of layers. (However, floating-point arithmetic &lt;em&gt;doesn’t&lt;/em&gt; follow suit quite so&amp;nbsp;easily!)&lt;/p&gt;</summary><content type="html">
&lt;p&gt;I got frustrated with not being able to go farther with using &lt;code class="highlight"&gt;autodiff&lt;/code&gt; for my simple toy linear regression model, so I decided it was time to actually try training a toy neural network for the first time.&lt;/p&gt;
&lt;p&gt;For this, I followed Stephen Welch’s excellent &lt;a href="https://www.youtube.com/watch?v=bxe2T-V8XRs"&gt;Neural Networks Demystified&lt;/a&gt; series. I had actually encountered the series a few years ago, which I recall gave me my initial intuitive understanding of neural networks, but I was not at all into math at that time and did not think I could grok the relevant code.&lt;/p&gt;
&lt;p&gt;The tutorial is pretty short and the end result is not &lt;em&gt;that&lt;/em&gt; exciting—at least for me, anyway. So I knew I wouldn’t get much out of writing a post solely about the tutorial.&lt;/p&gt;
&lt;p&gt;However, in &lt;a href="https://www.youtube.com/watch?v=GlcnxUlrtek"&gt;Video #4&lt;/a&gt;, he breezes through backpropagation—the heart of neural networks—and while the tutorial gives enough of an understanding of the math to build similar neural networks to the ones in the video, with one hidden layer, I wanted to see if there was a tidy way to generalize his code to an arbitrary number of hidden layers.&lt;/p&gt;
&lt;p&gt;So that’s what this post will be about, although it does skip a few intermediate steps from the last linear regression post, math-wise.&lt;/p&gt;
&lt;h1 id="forward-propagation"&gt;Forward propagation&lt;/h1&gt;
&lt;h2 id="linear-regression-on-steroids"&gt;Linear regression on steroids&lt;/h2&gt;
&lt;p&gt;Before you can do backpropagation, you need to do forward propagation. That is, you feed your inputs forward through each successive layer of the network until you get to the last layer, which is your output.&lt;/p&gt;
&lt;p&gt;In the toy linear regression model from before, this was the process of getting an estimate &lt;span class="math"&gt;\(\hat y\)&lt;/span&gt; by initially setting the weights vector &lt;span class="math"&gt;\(\vec \theta\)&lt;/span&gt; to all zeros (or random values), and multiplying it by the input. The weights vector would then be updated and the input would be fed forward again on every iteration of gradient descent.&lt;/p&gt;
&lt;p&gt;In a neural network, it’s basically the same, just more complex. The linear regression model consisted of &lt;span class="math"&gt;\(j\)&lt;/span&gt; features contributing to one output; a neural network, meanwhile could have arbitrary layers of an arbitrary number of features.&lt;/p&gt;
&lt;p&gt;What was a single weights vector &lt;span class="math"&gt;\(\vec \theta\)&lt;/span&gt; is now one of several weights matrices &lt;span class="math"&gt;\(\textbf w\)&lt;/span&gt;. &lt;a href="https://medium.com/@erikhallstrm/backpropagation-from-the-beginning-77356edf427d"&gt;Erik Hallström’s post&lt;/a&gt; has some pretty clear graphics to illustrate:&lt;/p&gt;
&lt;p&gt;&lt;img src="../../images/backprop/weights_matrix.png" width="300"/&gt;&lt;/p&gt;
&lt;p&gt;The &lt;span class="math"&gt;\(j\)&lt;/span&gt;th row of the matrix is the weights (influence) of the six neurons (features) of the preceding layer on the &lt;span class="math"&gt;\(j\)&lt;/span&gt;th neuron (feature) of the next layer.&lt;/p&gt;
&lt;p&gt;Forward propagation is simply multiplying your input matrix by the first weight matrix, applying an activation function to the result. This result is the next input, which you multiply by the next weight matrix, and so on.&lt;/p&gt;
&lt;h2 id="sigmoid-sounds-like-steroid-but-isnt"&gt;Sigmoid (sounds like steroid, but isn’t)&lt;/h2&gt;
&lt;p&gt;Here, we are going to use the &lt;strong&gt;sigmoid function&lt;/strong&gt;, &lt;span class="math"&gt;\(\sigma(z)\)&lt;/span&gt;, as our activation function. This is pretty standard in basic neural network implementations.&lt;/p&gt;
&lt;div class="math"&gt;$$ \sigma(z) = \frac{1}{1 + e^{-z}} $$&lt;/div&gt;
&lt;p&gt;Or, in Python:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;sigmoid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src="../../images/backprop/sigmoid.png" width="300"/&gt;&lt;/p&gt;
&lt;p&gt;Neat.&lt;/p&gt;
&lt;h2 id="mathing-it-out"&gt;Mathing it out&lt;/h2&gt;
&lt;p&gt;So then, given an input matrix &lt;span class="math"&gt;\(\textbf X\)&lt;/span&gt;, this is what a basic forward propagation sequence looks like:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\textbf z_1 &amp;amp;:= \textbf X \textbf w_0 &amp;amp;\to \textbf a_1 &amp;amp;:= \sigma(\textbf z_1) \\
&amp;amp; &amp;amp; \textbf z_2 &amp;amp;:= \textbf a_1 \textbf w_1 &amp;amp;\to \textbf a_2 &amp;amp;:= \sigma(\textbf z_2) \\
&amp;amp; &amp;amp; &amp;amp; &amp;amp; \hat y &amp;amp;:= \textbf a_2
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(\textbf z_n\)&lt;/span&gt; are the “uncooked” products of inputs and weights at layer &lt;span class="math"&gt;\(n\)&lt;/span&gt; and &lt;span class="math"&gt;\(\textbf a_n\)&lt;/span&gt; are the “cooked” versions (activated values) of those products.&lt;/p&gt;
&lt;p&gt;You could write this as a single nested function, but like a programming one-liner, it’s unreadable. I have chosen to write it this way to highlight its recursive nature (&lt;em&gt;ahem&lt;/em&gt; &lt;code class="highlight"&gt;reduce&lt;/code&gt; &lt;em&gt;ahem&lt;/em&gt;).&lt;/p&gt;
&lt;h2 id="implementing-it-recursively"&gt;Implementing it recursively&lt;/h2&gt;
&lt;p&gt;If we conceive of our network’s weights matrices as a list of matrices &lt;code class="highlight"&gt;w&lt;/code&gt; &lt;span class="math"&gt;\(= [\textbf w_0, \textbf w_1, \cdots, \textbf w_{k-2}]\)&lt;/span&gt; where &lt;span class="math"&gt;\(k\)&lt;/span&gt; is the number of layers in our network, we can then use &lt;code class="highlight"&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;/code&gt; to refer to the weights between layers 0 and 1, and so on.&lt;/p&gt;
&lt;p&gt;(Notation such as &lt;span class="math"&gt;\(W_{jk}\)&lt;/span&gt; is common, but I’m using a single index to reduce clutter.)&lt;/p&gt;
&lt;p&gt;With that in mind, let’s rewrite &lt;code class="highlight"&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;NeuralNetwork&lt;/span&gt;&lt;/code&gt; to take a list of layer dimensions, such that
we can recreate the Welch Labs 2-3-1 network with the list &lt;code class="highlight"&gt;[2,3,1]&lt;/code&gt; and &lt;a href="https://www.youtube.com/watch?v=Ilg3gGewQ5U&amp;amp;index=4&amp;amp;list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&amp;amp;t=0s"&gt;3blue1brown’s number-recognition network&lt;/a&gt; with the list &lt;code class="highlight"&gt;[784,16,16,10]&lt;/code&gt;.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_1_0" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_0"&gt;Flexible&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;layer_dims&lt;/span&gt;
        &lt;span class="c1"&gt;# Initialize n-1 matrices containing random weights&lt;/span&gt;
        &lt;span class="c1"&gt;# Weight matrices must have rows like the prev layer&lt;/span&gt;
        &lt;span class="c1"&gt;# and columns like the next layer (otherwise you must transpose)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                                 &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
                  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_1" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_1"&gt;Hard-coded&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;# Hyperparameters&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;input_layer_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hidden_layer_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;output_layer_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

        &lt;span class="c1"&gt;# Weights&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;W1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;input_layer_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hidden_layer_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;W2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hidden_layer_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;output_layer_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;With this flexible setup, forward propagation is just a matter of &lt;code class="highlight"&gt;reduce&lt;/code&gt;, as I alluded to above:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_2_0" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_0"&gt;Flexible&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;functools&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nb"&gt;reduce&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;y_hat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;reduce&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;prv&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nex&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;prv&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;nex&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;initial_input&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_2_1" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_1"&gt;Hard-coded&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
          &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;W1&lt;/span&gt;
          &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sigmoid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
          &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a2&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;W2&lt;/span&gt;
          &lt;span class="n"&gt;y_hat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sigmoid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
          &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;y_hat&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Look how concise that is!&lt;/p&gt;
&lt;p&gt;However, thinking ahead, we will need to keep the intermediate values for when we do backpropagation, so let’s flesh this out a bit.&lt;/p&gt;
&lt;p&gt;Similar to our &lt;code class="highlight"&gt;w&lt;/code&gt; list, we should instantiate an &lt;code class="highlight"&gt;a&lt;/code&gt; list &lt;span class="math"&gt;\(= [\textbf a_0, \textbf a_1, \cdots, \textbf a_k]\)&lt;/span&gt; and a &lt;code class="highlight"&gt;z&lt;/code&gt; list &lt;span class="math"&gt;\(= [\textbf z_0, \textbf z_1, \cdots, \textbf z_k]\)&lt;/span&gt; when we run the function.&lt;/p&gt;
&lt;p&gt;To make bookkeeping a little easier, let’s add the necessary padding so that &lt;code class="highlight"&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;/code&gt; and &lt;code class="highlight"&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;/code&gt; refer to &lt;span class="math"&gt;\(\textbf z\)&lt;/span&gt; and &lt;span class="math"&gt;\(\textbf a\)&lt;/span&gt; at layer &lt;span class="math"&gt;\(n\)&lt;/span&gt; (starting from zero). There is no “uncooked” input, so &lt;code class="highlight"&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Meanwhile &lt;code class="highlight"&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;/code&gt; is technically the initial input matrix and &lt;code class="highlight"&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;/code&gt; is the output &lt;span class="math"&gt;\(\hat y\)&lt;/span&gt;.&lt;/p&gt;
&lt;h2 id="testing-it-out"&gt;Testing it out&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;activate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;inputs&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sigmoid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;initial_input&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;initial_input&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;# consider X as a_0&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;          &lt;span class="c1"&gt;# keep the indexes of z and a aligned&lt;/span&gt;
        &lt;span class="n"&gt;y_hat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;reduce&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;activate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;initial_input&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;y_hat&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can test this out with the Welch Labs toy data:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_3_0" name="__tabs_3" type="radio"/&gt;
&lt;label for="__tab_3_0"&gt;Input&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(([&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;],[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],[&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(([&lt;/span&gt;&lt;span class="mi"&gt;75&lt;/span&gt;&lt;span class="p"&gt;],[&lt;/span&gt;&lt;span class="mi"&gt;82&lt;/span&gt;&lt;span class="p"&gt;],[&lt;/span&gt;&lt;span class="mi"&gt;93&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# normalize data&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;amax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;

&lt;span class="n"&gt;NN&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;NN&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_3_1" name="__tabs_3" type="radio"/&gt;
&lt;label for="__tab_3_1"&gt;Output&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;array([[0.58313228],
       [0.5781811 ],
       [0.59692924]])
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The code works!&lt;/p&gt;
&lt;h1 id="backpropagation"&gt;Backpropagation&lt;/h1&gt;
&lt;p&gt;Now that we’ve fed our input &lt;em&gt;forward&lt;/em&gt; through the network, we now need to take its output and propagate the error (discrepancy between the output and truth) &lt;em&gt;backward&lt;/em&gt; through the network, to figure out how much to adjust the weights by.&lt;/p&gt;
&lt;p&gt;This is where the calculus becomes quite messy compared to the toy linear regression model. Each successive layer in the network introduces a new layer of functions that must be chain-ruled through in order to differentiate.&lt;/p&gt;
&lt;p&gt;I am not really the best candidate to explain the nitty-gritty details of backpropagation. What follows will be  mainly my notes, which were enough to help me understand how to generalize the code to any number of layers.&lt;/p&gt;
&lt;h2 id="sigmoid-prime-brother-of-modulus-prime"&gt;Sigmoid Prime (brother of Modulus Prime)&lt;/h2&gt;
&lt;p&gt;If, as a high school student, I had known advanced math would turn into a cast of Transformers characters, I might have stuck with it 😂&lt;/p&gt;
&lt;p&gt;Anyway, before we go further, we have to define &lt;span class="math"&gt;\(\sigma'(z)\)&lt;/span&gt;, the derivative of our sigmoid function.&lt;/p&gt;
&lt;div class="math"&gt;$$ \sigma'(z) = \frac{e^{-z}}{(1 + e^{-z})^2} $$&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;sigmoid_prime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src="../../images/backprop/sigmoid_prime.png" width="300"/&gt;&lt;/p&gt;
&lt;p&gt;Nice.&lt;/p&gt;
&lt;h2 id="fracpartial-textbf-jpartial-textbf-w-on-the-turntable-or-something"&gt;&lt;span class="math"&gt;\(\frac{\partial \textbf J}{\partial \textbf w}\)&lt;/span&gt; on the turntable… or something&lt;/h2&gt;
&lt;p&gt;In the toy linear regression model, gradient descent required finding &lt;span class="math"&gt;\(\frac{\partial J}{\partial \theta}\)&lt;/span&gt;. In our neural network, gradient descent is going to require finding &lt;span class="math"&gt;\(\frac{\partial \textbf J}{\partial \textbf w}\)&lt;/span&gt; for all &lt;span class="math"&gt;\(\textbf w\)&lt;/span&gt; in our list &lt;code class="highlight"&gt;w&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The tricky thing is that because the neural network is essentially functions layered on top of each other, the farther you go back toward the beginning of the network, the more complicated the derivatives become.&lt;/p&gt;
&lt;p&gt;You could think of this in the following way: Values farther toward the beginning of the network have a subtler effect on the final output, while values farther toward the output have a more direct effect on the final output, despite the fact that we cannot manipulate them directly.&lt;/p&gt;
&lt;p&gt;Here are the equations from the Welch Labs example, with the indices adjusted to reflect our zero-based setup.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\textrm{error} &amp;amp;= (\hat y - y) \\
\delta_2 &amp;amp;= (\hat y - y) \sigma'(\textbf z_2) &amp;amp;\to
\frac{\partial \textbf J}{\partial \textbf w_1} &amp;amp;= \textbf a_2^T \delta_2 \\[0.8em]
\delta_1 &amp;amp;= \delta_2 \textbf w_1^T \sigma'(\textbf z_1) &amp;amp;\to
\frac{\partial \textbf J}{\partial \textbf w_0} &amp;amp;= \textbf X^T \delta_1
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;Small delta &lt;span class="math"&gt;\(\delta\)&lt;/span&gt; (also a matrix), is referred to as the &lt;strong&gt;error signal&lt;/strong&gt;. &lt;span class="math"&gt;\(\delta_n\)&lt;/span&gt; indicates how much the output changes when &lt;span class="math"&gt;\(\textbf z_n\)&lt;/span&gt;, the “uncooked” values of layer &lt;span class="math"&gt;\(n\)&lt;/span&gt;, change.&lt;/p&gt;
&lt;p&gt;My main question here was: Given that these two gradients are not exactly the same, what would they look like in a neural network with more layers?&lt;/p&gt;
&lt;h2 id="chain-rule-forever-and-ever-and-ever-and"&gt;Chain rule forever and ever and ever and…&lt;/h2&gt;
&lt;p&gt;This looks really scary, but it was the only way I could figure out the pattern.&lt;/p&gt;
&lt;p&gt;Suppose we have a neural network with four layers (like the 3blue1brown network).&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\frac{\partial \textbf J}{\partial \textbf w_2} &amp;amp;=
\textcolor{#1f77b4}{(\hat y - y) \frac{\partial \hat y (=\textbf a_3)}{\partial \textbf z_3}}
\frac{\partial \textbf z_3}{\partial \textbf w_2} \\[0.8em]
&amp;amp;= \textcolor{#1f77b4}{\overbrace{(\hat y - y) \sigma'(\textbf z_3)}^{\delta_3}}
\frac{\partial \textbf z_3}{\partial \textbf w_2} \\[0.8em]
&amp;amp;= \textcolor{#1f77b4}{\delta_3} \frac{\partial \textbf z_3}{\partial \textbf w_2} \\[0.8em]
&amp;amp;= \textbf a_2^T \color{#1f77b4}{\delta_3} \\[1.2em]
\frac{\partial \textbf J}{\partial \textbf w_1} &amp;amp;=
\textcolor{#1f77b4}{(\hat y - y) \frac{\partial \textbf a_3}{\partial \textbf z_3}}
\textcolor{#e377c2}{\frac{\partial \textbf z_3}{\partial \textbf a_2}
\frac{\partial \textbf a_2}{\partial \textbf z_2}} \frac{\partial \textbf z_2}{\partial \textbf w_1} \\[0.8em]
&amp;amp;= \textcolor{#e377c2}{\overbrace{\textcolor{#1f77b4}{\overbrace{(\hat y - y) \sigma'(\textbf z_3)}^{\delta_3}} \frac{\partial \textbf z_3}{\partial \textbf a_2}
\sigma'(\textbf z_2)}^{\delta_2}} \frac{\partial \textbf z_2}{\partial \textbf w_1} \\[0.8em]
&amp;amp;= \textcolor{#e377c2}{\overbrace{\delta_3 \textbf w_2^T
\sigma'(\textbf z_2)}^{\delta_2}} \frac{\partial \textbf z_2}{\partial \textbf w_1} \\[0.8em]
&amp;amp;= \textcolor{#e377c2}{\delta_2} \frac{\partial \textbf z_2}{\partial \textbf w_1} \\[0.8em]
&amp;amp;= \textbf a_1^T \textcolor{#e377c2}{\delta_2} \\[1.2em]
\frac{\partial \textbf J}{\partial \textbf w_0} &amp;amp;=
\textcolor{#1f77b4}{(\hat y - y) \frac{\partial \textbf a_3}{\partial \textbf z_3}} \textcolor{#e377c2}{\frac{\partial \textbf z_3}{\partial \textbf a_2}
\frac{\partial \textbf a_2}{\partial \textbf z_2}} \textcolor{mediumpurple}{\frac{\partial \textbf z_2}{\partial \textbf a_1}
\frac{\partial \textbf a_1}{\partial \textbf z_1}} \frac{\partial \textbf z_1}{\partial \textbf w_0} \\[0.8em]
&amp;amp;= \textcolor{mediumpurple}{\overbrace{\textcolor{#e377c2}{\overbrace{\textcolor{#1f77b4}{\delta_3} \textbf w_2^T
\sigma'(\textbf z_2)}^{\delta_2}} \frac{\partial \textbf z_2}{\partial \textbf a_1}
\sigma'(\textbf z_1)}^{\delta_1}} \frac{\partial \textbf z_1}{\partial \textbf w_0} \\[0.8em]
&amp;amp;= \textcolor{mediumpurple}{\overbrace{\delta_2 \textbf w_1^T
\sigma'(\textbf z_1)}^{\delta_1}} \frac{\partial \textbf z_1}{\partial \textbf w_0} \\[0.8em]
&amp;amp;= \textcolor{mediumpurple}{\delta_1} \frac{\partial \textbf z_1}{\partial \textbf w_0} \\[0.8em]
&amp;amp;= \textbf a_0^T \textcolor{mediumpurple}{\delta_1} = \textbf X^T \textcolor{mediumpurple}{\delta_1}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;This reveals a few generalities.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\frac{\partial \textbf a_n}{\partial \textbf z_n}\)&lt;/span&gt;, or how much the “cooked” values of a layer change in relation to the “uncooked” values, is simply the derivative of the sigmoid function, since going from “uncooked” to “cooked” only involved the sigmoid function.
&lt;div class="math"&gt;$$ \frac{\partial \textbf a_n}{\partial \textbf z_n} = \sigma'(\textbf z_n) $$&lt;/div&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\frac{\partial \textbf z_{n+1}}{\partial \textbf a_n}\)&lt;/span&gt;, or how much a layer’s “cooked” values change the “uncooked” values of the next layer, is simply the weights between the two layers. Makes sense, right? The weights matrix does have to be transposed for the multiplication to work, though.
&lt;div class="math"&gt;$$ \frac{\partial \textbf z_{n+1}}{\partial \textbf a_n} = \textbf w_n^T $$&lt;/div&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The first error signal, &lt;span class="math"&gt;\(\textcolor{#1f77b4}{\delta_3}\)&lt;/span&gt;, is different, but after that, you can find the error signal of any layer, &lt;span class="math"&gt;\(\delta_n\)&lt;/span&gt;, by piling on more of the above two partial derivatives:
&lt;div class="math"&gt;$$ \delta_n = \delta_{n+1}
\frac{\partial \textbf z_{n+1}}{\partial \textbf a_n}
\frac{\partial \textbf a_n}{\partial \textbf z_n}
= \delta_{n+1} \textbf w_n^T \sigma'(\textbf z_n) $$&lt;/div&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Finally, if we save all the error signals in a list &lt;code class="highlight"&gt;deltas&lt;/code&gt; &lt;span class="math"&gt;\(= [\delta_k-1, \delta_2, \cdots, \delta_1]\)&lt;/span&gt; (note that this will be the same length as &lt;code class="highlight"&gt;w&lt;/code&gt;, one shorter than &lt;code class="highlight"&gt;a&lt;/code&gt;, and &lt;code class="highlight"&gt;z&lt;/code&gt;), then obtaining &lt;span class="math"&gt;\(\frac{\partial \textbf J}{\partial \textbf w_n}\)&lt;/span&gt; is just a matter of reversing &lt;code class="highlight"&gt;deltas&lt;/code&gt; and &lt;code class="highlight"&gt;zip&lt;/code&gt;ping it with &lt;code class="highlight"&gt;w&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="recursion-to-the-rescue"&gt;Recursion to the rescue&lt;/h2&gt;
&lt;p&gt;In the four-layer example, &lt;code class="highlight"&gt;deltas[0]&lt;/code&gt; &lt;span class="math"&gt;\(= \textcolor{#1f77b4}{\delta_3}\)&lt;/span&gt;, so we can start off defining&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;backward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;initial_error&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
        &lt;span class="n"&gt;deltas&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;initial_error&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sigmoid_prime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;From there, we need to walk backwards through the lists &lt;code class="highlight"&gt;w&lt;/code&gt; and &lt;code class="highlight"&gt;z&lt;/code&gt;, starting from the second-to-last value of each, to get the values we need.&lt;/p&gt;
&lt;p&gt;Since we are reusing the newest &lt;span class="math"&gt;\(\delta_n\)&lt;/span&gt; result (i.e., &lt;code class="highlight"&gt;&lt;span class="n"&gt;deltas&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;/code&gt;) in each iteration, the loop goes roughly like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;?&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;delta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;deltas&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="err"&gt;?&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sigmoid_prime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="err"&gt;?&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;deltas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;delta&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, once we have populated &lt;code class="highlight"&gt;deltas&lt;/code&gt;, then populating a list &lt;code class="highlight"&gt;djdw&lt;/code&gt; of all &lt;span class="math"&gt;\(\frac{\partial \textbf J}{\partial \textbf w_n}\)&lt;/span&gt; can be done in one line:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;djdw&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;reversed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;deltas&lt;/span&gt;&lt;span class="p"&gt;))]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This works out perfectly, because&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code class="highlight"&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;/code&gt; is the input &lt;span class="math"&gt;\(\textbf X\)&lt;/span&gt;, and&lt;/li&gt;
&lt;li&gt;even though &lt;code class="highlight"&gt;a&lt;/code&gt; is one longer than &lt;code class="highlight"&gt;deltas&lt;/code&gt;, &lt;code class="highlight"&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;/code&gt; is not used in these calculations and so &lt;code class="highlight"&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;/code&gt; will disregard it.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code class="highlight"&gt;djdw&lt;/code&gt; thus contains &lt;span class="math"&gt;\([\textbf X^T \delta_1, \textbf a_1^T \delta_2, \textbf a_2^T \delta_3] = [\frac{\partial \textbf J}{\partial \textbf w_0}, \frac{\partial \textbf J}{\partial \textbf w_1}, \frac{\partial \textbf J}{\partial \textbf w_2}]\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;That gives us our final backpropagation function. I’ve condensed it a little here just to highlight the comparison with the hard-coded version, but the full version with comments is posted at the bottom.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_4_0" name="__tabs_4" type="radio"/&gt;
&lt;label for="__tab_4_0"&gt;Flexible&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;backward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;initial_error&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
        &lt;span class="n"&gt;deltas&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;initial_error&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sigmoid_prime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
        &lt;span class="n"&gt;ll&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ll&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;delta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;deltas&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;ll&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sigmoid_prime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;ll&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="n"&gt;deltas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;delta&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;reversed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;deltas&lt;/span&gt;&lt;span class="p"&gt;))]&lt;/span&gt;        

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;djdw&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;djdw&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;NN&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;backward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_4_1" name="__tabs_4" type="radio"/&gt;
&lt;label for="__tab_4_1"&gt;Hard-coded&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cost_prime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y_hat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;delta3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y_hat&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sigmoid_prime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;delta3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;delta3&lt;/span&gt;
        &lt;span class="n"&gt;dJdW2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;delta3&lt;/span&gt;
        &lt;span class="n"&gt;delta2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;delta3&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;W2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sigmoid_prime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;dJdW1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;delta2&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;dJdW1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dJdW2&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;dJdW1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dJdW2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cost_prime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;dJdW1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;dJdW2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Nice and compact!&lt;/p&gt;
&lt;h2 id="testing-it-out_1"&gt;Testing it out&lt;/h2&gt;
&lt;p&gt;Let’s generate a random dataset and network similar to the 3blue1brown one. That is, there should be input layer with 784 neurons, followed by 2 hidden layers and 1 output layer. His network is &lt;code class="highlight"&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;784&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;/code&gt; but why not spice things up a bit and change the numbers around a little?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sklearn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;make_regression&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;784&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;NN&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;784&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;NN&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# 26048&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Awesome! It works. And there are a whopping &lt;strong&gt;26,048 weights&lt;/strong&gt; in this behemoth neural network. Wow.&lt;/p&gt;
&lt;p&gt;With some minor adjustments to the &lt;code class="highlight"&gt;get_params&lt;/code&gt; and &lt;code class="highlight"&gt;set_params&lt;/code&gt; methods in the original class, we should be able to drop this right into the Welch Labs &lt;code class="highlight"&gt;Trainer&lt;/code&gt; as-is.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_5_0" name="__tabs_5" type="radio"/&gt;
&lt;label for="__tab_5_0"&gt;Flexible&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;weight&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;weight&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;set_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;num_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;num_weights&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                                   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
            &lt;span class="n"&gt;params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;num_weights&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_5_1" name="__tabs_5" type="radio"/&gt;
&lt;label for="__tab_5_1"&gt;Hard-coded&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;#Get W1 and W2 unrolled into vector:&lt;/span&gt;
        &lt;span class="n"&gt;params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;W1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;W2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;set_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;#Set W1 and W2 using single paramater vector.&lt;/span&gt;
        &lt;span class="n"&gt;W1_start&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="n"&gt;W1_end&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hidden_layer_size&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;input_layer_size&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;W1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;W1_start&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;W1_end&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;input_layer_size&lt;/span&gt; &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hidden_layer_size&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="n"&gt;W2_end&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;W1_end&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hidden_layer_size&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;output_layer_size&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;W2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;W1_end&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;W2_end&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hidden_layer_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;output_layer_size&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Let’s train it (See &lt;code class="highlight"&gt;Trainer&lt;/code&gt; tab in “Summary” below.)!&lt;/p&gt;
&lt;p&gt;Well, being a newbie at this, it wasn’t quite so obvious to me, but it wasn’t feasible to train such a gigantic neural network with non-industrial-strength tools. Even with smaller networks, unnormalized data easily caused overflow errors.&lt;/p&gt;
&lt;p&gt;This post is already quite long and complicated, and I don’t want to stray from the topic of backpropagation by getting into numerical stability, so I decided to pare things down a bit instead.&lt;/p&gt;
&lt;p&gt;Still, the following network has five layers, which is reasonably complex and a further test of the math involved.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sklearn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;make_regression&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;
&lt;span class="n"&gt;NN&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Trainer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;NN&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src="../../images/backprop/nn_train.png"/&gt;&lt;/p&gt;
&lt;p&gt;Hooray! It works.&lt;/p&gt;
&lt;h1 id="summary"&gt;Summary&lt;/h1&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_6_0" name="__tabs_6" type="radio"/&gt;
&lt;label for="__tab_6_0"&gt;setup&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt;

&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sklearn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;make_regression&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;
&lt;span class="n"&gt;NN&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Trainer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;NN&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;sigmoid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;sigmoid_prime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_6_1" name="__tabs_6" type="radio"/&gt;
&lt;label for="__tab_6_1"&gt;NeuralNetwork&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;functools&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nb"&gt;reduce&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;NeuralNetwork&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;layer_dims&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                                  &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
                  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;activate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;inputs&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sigmoid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;initial_input&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;initial_input&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;# consider X as a_0&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;          &lt;span class="c1"&gt;# keep the indexes of z and a aligned&lt;/span&gt;
        &lt;span class="n"&gt;y_hat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;reduce&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;activate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;initial_input&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;y_hat&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;backward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;initial_error&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
        &lt;span class="c1"&gt;# Accumulate δ's in reverse order&lt;/span&gt;
        &lt;span class="n"&gt;deltas&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;initial_error&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sigmoid_prime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
        &lt;span class="n"&gt;ll&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ll&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;delta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;deltas&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;ll&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sigmoid_prime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;ll&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="n"&gt;deltas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;delta&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="c1"&gt;# get djdws by multiplying the transpose of each activation by each delta&lt;/span&gt;
        &lt;span class="c1"&gt;# X.T @ δ_1, a_1.T @ δ_2, a_2.T @ δ_3... (note that deltas[0] is δ_1)&lt;/span&gt;
        &lt;span class="n"&gt;djdw&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;reversed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;deltas&lt;/span&gt;&lt;span class="p"&gt;))]&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;djdw&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;djdw&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;djdw&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;NN&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;backward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y_hat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;J&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y_hat&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;J&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;weight&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;weight&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;set_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;num_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;num_weights&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                                   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layer_dims&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
            &lt;span class="n"&gt;params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;num_weights&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_6_2" name="__tabs_6" type="radio"/&gt;
&lt;label for="__tab_6_2"&gt;Trainer&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;scipy&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;optimize&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Trainer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="c1"&gt;# unedited from Welch labs version&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cost_wrapper&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;grad&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;grad&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;callback_f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;J&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;train&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;J&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="n"&gt;params0&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_params&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;options&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'maxiter'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'disp'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="n"&gt;_res&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;optimize&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;minimize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cost_wrapper&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;params0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;jac&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                 &lt;span class="n"&gt;method&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'BFGS'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;options&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;options&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;callback&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;callback_f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id="references"&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=bxe2T-V8XRs"&gt;Neural Networks Demystified&lt;/a&gt;, Welch Labs&lt;/li&gt;
&lt;li&gt;&lt;a href="https://towardsdatascience.com/multi-layer-neural-networks-with-sigmoid-function-deep-learning-for-rookies-2-bf464f09eb7f"&gt;Multi-Layer Neural Networks with Sigmoid Function— Deep Learning for Rookies (2)&lt;/a&gt;, Nahua Kang&lt;/li&gt;
&lt;/ul&gt;</content><category term="machine learning"></category><category term="neural networks"></category><category term="backpropagation"></category></entry><entry><title>Linear Regression, Part 1.9999: Autograd Fail</title><link href="http://tabidots.github.io/2019/02/deeper-into-linear-regression" rel="alternate"></link><published>2019-02-02T16:04:26+07:00</published><updated>2019-02-02T16:04:26+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-02-02:/2019/02/deeper-into-linear-regression</id><summary type="html">&lt;p&gt;I got halfway through this post only to be thwarted by the limits of the autograd module. The issue I opened on their GitHub repo has so far fallen on deaf ears, so I lost interest in linear regression for the time&amp;nbsp;being.&lt;/p&gt;</summary><content type="html">
&lt;p&gt;In &lt;a href="/squarest-root-in-babylon"&gt;the previous post&lt;/a&gt;, we looked at using automatic differentiation to simplify our linear regression model and make it more readable.&lt;/p&gt;
&lt;p&gt;Just to recap how far we’ve come with our implementation of linear regression:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Multiple regression&lt;/strong&gt;: Generalize the model to accept any number of features (&lt;span class="math"&gt;\(x_1, x_2, \cdots, x_n\)&lt;/span&gt;)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Vectorization&lt;/strong&gt;: Eliminate computationally-costly &lt;code class="highlight"&gt;for&lt;/code&gt;-loops with vector and matrix operations&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Error threshold&lt;/strong&gt;: Modify our &lt;code class="highlight"&gt;train_model()&lt;/code&gt; function to use an &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; error threshold rather than a set number of iterations&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Automatic differentiation&lt;/strong&gt;: Outsource the computation of the gradient to a library such as &lt;code class="highlight"&gt;autograd&lt;/code&gt;, which can do it faster, more simply, and more accurately&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;That’s a lot, and there are still many things left to explore! Thankfully, the mathematical heavy lifting is done for now. Now we can concentrate on the coding and data science side of things!&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Do data science&lt;/strong&gt;: Use &lt;code class="highlight"&gt;pandas&lt;/code&gt; instead of &lt;code class="highlight"&gt;numpy&lt;/code&gt;; use a publicly available dataset instead of randomly generating toy data every time, and preprocess it appropriately&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;span class="caps"&gt;OOP&lt;/span&gt;&lt;/strong&gt;: Encapsulate the linear regression model into a class&lt;/li&gt;
&lt;li&gt;Fine-tune the hyperparameters and evaluate the results&lt;/li&gt;
&lt;li&gt;Create similar models in Julia, R, and Clojure (the last one is a little ambitious)&lt;/li&gt;
&lt;li&gt;Compare our results to out-of-the-box linear regression models&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="public-data-preprocessing"&gt;Public data &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; preprocessing&lt;/h1&gt;
&lt;p&gt;We were generating toy datasets with random numbers before, but that is only good for testing that the code works. If we are going to evaluate models and hyperparameters, we need to use the same single dataset for consistency.&lt;/p&gt;
&lt;p&gt;I currently live in &lt;span class="caps"&gt;SE&lt;/span&gt; Asia and air pollution is a big issue here, so the &lt;a href="https://archive.ics.uci.edu/ml/datasets/PM2.5+Data+of+Five+Chinese+Cities"&gt;&lt;span class="caps"&gt;PM2&lt;/span&gt;.5 Data of Five Chinese Cities Data Set&lt;/a&gt; caught my eye as I was scrolling through the &lt;span class="caps"&gt;UCI&lt;/span&gt; Machine Learning Repository website.&lt;/p&gt;
&lt;p&gt;Let’s use &lt;code class="highlight"&gt;pandas&lt;/code&gt; to read in the Beijing data and generate a &lt;code class="highlight"&gt;DataFrame&lt;/code&gt; for us, which is a more sophisticated version of a NumPy &lt;code class="highlight"&gt;ndarray&lt;/code&gt;.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_1_0" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="c1"&gt;# You may have to change os.getcwd() and os.chdir() to tell Python where to look&lt;/span&gt;
&lt;span class="n"&gt;raw_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'FiveCitiePMData/BeijingPM20100101_20151231.csv'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;raw_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;info&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="c1"&gt;# https://datascience.stackexchange.com/questions/12645/how-to-count-the-number-of-missing-values-in-each-row-in-pandas-dataframe&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_1" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_1"&gt;Output&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;lt;class 'pandas.core.frame.DataFrame'&amp;gt;
RangeIndex: 52584 entries, 0 to 52583
Data columns (total 18 columns):
No                 52584 non-null int64
year               52584 non-null int64
month              52584 non-null int64
day                52584 non-null int64
hour               52584 non-null int64
season             52584 non-null int64
PM_Dongsi          25052 non-null float64
PM_Dongsihuan      20508 non-null float64
PM_Nongzhanguan    24931 non-null float64
PM_US Post         50387 non-null float64
DEWP               52579 non-null float64
HUMI               52245 non-null float64
PRES               52245 non-null float64
TEMP               52579 non-null float64
cbwd               52579 non-null object
Iws                52579 non-null float64
precipitation      52100 non-null float64
Iprec              52100 non-null float64
dtypes: float64(11), int64(6), object(1)
memory usage: 7.2+ MB
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Our &lt;code class="highlight"&gt;DataFrame&lt;/code&gt; has 52,584 entries (hourly snapshots of air pollution) and 18 columns, and there are a lot of “holes” in the data (as noted on the webpage).&lt;/p&gt;
&lt;p&gt;There’s also a lot of data we don’t really need. I’m not a meteorologist, and I’m not experienced enough with statistics to use this data to find out &lt;em&gt;which features&lt;/em&gt; correlate with air pollution.&lt;/p&gt;
&lt;p&gt;So, the objective of our model will be to find out &lt;em&gt;how&lt;/em&gt; the salient features correlate with air pollution, and use that to predict future &lt;span class="caps"&gt;PM2&lt;/span&gt;.5 readings.&lt;/p&gt;
&lt;p&gt;A quick-and-dirty Google search reveals that &lt;strong&gt;humidity&lt;/strong&gt; and &lt;strong&gt;air temperature&lt;/strong&gt; are the most influential factors on &lt;span class="caps"&gt;PM2&lt;/span&gt;.5 readings. So, let’s trim our data down to humidity (&lt;code class="highlight"&gt;HUMI&lt;/code&gt;), air temperature (&lt;code class="highlight"&gt;TEMP&lt;/code&gt;) and the &lt;span class="caps"&gt;PM2&lt;/span&gt;.5 reading.&lt;/p&gt;
&lt;p&gt;Note that there are several &lt;span class="caps"&gt;PM2&lt;/span&gt;.5 readings, but the &lt;code class="highlight"&gt;PM_US Post&lt;/code&gt; has the fewest holes (non-null values). So let’s ignore the others.&lt;/p&gt;
&lt;p&gt;Another consideration is the nature of each feature. Humidity and air temperature are both &lt;em&gt;continuous&lt;/em&gt; values, so we’re in the clear, but if we cared about the time of day or wind direction, we would have to deal with those &lt;em&gt;discrete&lt;/em&gt; values in a slightly different way.&lt;/p&gt;
&lt;h2 id="cleaning-the-data"&gt;Cleaning the data&lt;/h2&gt;
&lt;p&gt;Since we only need a few columns out of this entire table, let’s just create a whole new &lt;code class="highlight"&gt;DataFrame&lt;/code&gt;, using &lt;code class="highlight"&gt;filter&lt;/code&gt; to &lt;a href="https://stackoverflow.com/a/34683105"&gt;select our target columns&lt;/a&gt; and &lt;code class="highlight"&gt;dropna&lt;/code&gt; to remove the rows where any of those values are &lt;code class="highlight"&gt;NaN&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;raw_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s1"&gt;'HUMI'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s1"&gt;'TEMP'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'PM_US Post'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropna&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;That was easy!&lt;/p&gt;
&lt;p&gt;We’ve gotten rid of incomplete entries, but we might still have some bad values that, err, pollute our results. Let’s check:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_2_0" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;describe&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_2_1" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_1"&gt;Output&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;               HUMI          TEMP    PM_US Post
count  50048.000000  50048.000000  50048.000000
mean      54.580363     12.599504     95.773258
std       25.996814     12.107097     91.731446
min        2.000000    -19.000000      1.000000
25%       31.000000      2.000000     27.000000
50%       55.000000     14.000000     69.000000
75%       78.000000     23.000000    132.000000
max      100.000000     42.000000    994.000000
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Keep in mind that &lt;code class="highlight"&gt;HUMI&lt;/code&gt; is % and &lt;code class="highlight"&gt;TEMP&lt;/code&gt; is in degrees Celsius. Everything seems okay there.&lt;/p&gt;
&lt;p&gt;How about those pollution readings, though? The &lt;code class="highlight"&gt;max&lt;/code&gt; value seems a little off. I mean, I have heard of readings in the 300 range (which is still dangerous), but 994 seems like an outlier.&lt;/p&gt;
&lt;p&gt;How many readings were more than 3 standard deviations above the mean?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Source: https://stackoverflow.com/questions/23833763/pandas-count-number-of-elements-in-each-column-less-than-x&lt;/span&gt;
&lt;span class="n"&gt;high_pm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'PM_US Post'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'PM_US Post'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="n"&gt;high_readings&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'PM_US Post'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;high_pm&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count_nonzero&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;high_readings&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;1.86%. I’m tempted to remove them from the data, but a Google search turned up &lt;a href="https://www.telegraph.co.uk/news/worldnews/asia/china/11983156/Air-quality-plummets-as-heavy-smog-blankets-large-swaths-of-China.html"&gt;an article that suggests that such readings are not beyond the realm of possibility&lt;/a&gt;, sadly.&lt;/p&gt;
&lt;h2 id="feature-scaling"&gt;Feature scaling&lt;/h2&gt;
&lt;p&gt;One thing we didn’t do with the randomly generated datasets is &lt;strong&gt;feature scaling&lt;/strong&gt;, which refers to the process of either normalizing or standardizing the values to facilitate faster and more accurate computations during gradient descent (or other algorithms).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Min-max scaling&lt;/strong&gt;: Make all values fit within a certain range (between 0 and 1 or some other value)&lt;/p&gt;
&lt;div class="math"&gt;$$ X_{\textrm{norm}} = \frac{X - X_{\textrm{min}}}{X_{\textrm{max}} - X_{\textrm{min}}} $$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Standardization&lt;/strong&gt;: Coerce columns to have a mean (&lt;span class="math"&gt;\(\mu\)&lt;/span&gt;) of 0 and a standard deviation (&lt;span class="math"&gt;\(\sigma\)&lt;/span&gt;) of 1 by computing a &lt;span class="math"&gt;\(z\)&lt;/span&gt;-score from the values. This is something I vaguely remember from college stats.&lt;/p&gt;
&lt;div class="math"&gt;$$ z_i = \frac{x_i - \mu}{\sigma} $$&lt;/div&gt;
&lt;p&gt;Which is better?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;When in doubt, just standardize the data, it shouldn’t hurt. (&lt;a href="https://sebastianraschka.com/Articles/2014_about_feature_scaling.html#about-standardization"&gt;Source&lt;/a&gt;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Fair enough. &lt;code class="highlight"&gt;scikit-learn&lt;/code&gt; has built-in feature scaling methods, but one thing that did cross my mind is that if you train a model on normalized data, how can you make predictions from new data without the &lt;code class="highlight"&gt;min&lt;/code&gt; and &lt;code class="highlight"&gt;max&lt;/code&gt; (or &lt;code class="highlight"&gt;mean&lt;/code&gt; and &lt;code class="highlight"&gt;std&lt;/code&gt;) from every column?&lt;/p&gt;
&lt;p&gt;For now, I’ll proceed working with this dataset without doing feature scaling, but I’ll come back to this point if necessary.&lt;/p&gt;
&lt;h2 id="segregating-the-data"&gt;Segregating the data&lt;/h2&gt;
&lt;p&gt;Typically, for machine learning, you randomize the data and split it into three sets for training, validation, and testing. Training is for the model to learn the weights, validation is to fine-tune the hyperparameters (learning rate, convergence threshold, etc.), and testing is for evaluating the finalized model.&lt;/p&gt;
&lt;p&gt;The following code performs a 60:20:20 split on the data. You could also do 80:10:10.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Source: https://stackoverflow.com/questions/38250710/how-to-split-data-into-3-sets-train-validation-and-test&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;autograd.numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# guarantee same result every time&lt;/span&gt;
&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;permutation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;frac&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                                 &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;))])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Done!&lt;/p&gt;
&lt;h1 id="a-class-act"&gt;A class act&lt;/h1&gt;
&lt;p&gt;Now, we can move on to tightening up the code a little bit. Before we encapsulate it into a class, though, we should consider the fact that we are working with &lt;code class="highlight"&gt;pandas&lt;/code&gt; now, and not &lt;code class="highlight"&gt;numpy&lt;/code&gt;, which will affect a couple things.&lt;/p&gt;
&lt;p&gt;To add a column of ones (dummy features), the &lt;span class="math"&gt;\(x_0\)&lt;/span&gt; in our linear regression matrix:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_3_0" name="__tabs_3" type="radio"/&gt;
&lt;label for="__tab_3_0"&gt;NumPy&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hstack&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_3_1" name="__tabs_3" type="radio"/&gt;
&lt;label for="__tab_3_1"&gt;Pandas&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;insert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'dummy'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;To create a column vector of zeros (our initial weights), we can use a Pandas &lt;code class="highlight"&gt;Series&lt;/code&gt;:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_4_0" name="__tabs_4" type="radio"/&gt;
&lt;label for="__tab_4_0"&gt;NumPy&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;num_weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_4_1" name="__tabs_4" type="radio"/&gt;
&lt;label for="__tab_4_1"&gt;Pandas&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Series&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataframe_minus_truth&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The &lt;code class="highlight"&gt;list(dataframe_minus_truth)&lt;/code&gt; isn’t quite so transparent. I found that when doing matrix multiplication between a matrix and either a vector or a matrix in &lt;code class="highlight"&gt;pandas&lt;/code&gt;, not only must the number of columns in the matrix match the number of rows in the other object, but &lt;a href="https://stackoverflow.com/questions/16472729/matrix-multiplication-in-pandas/16473007"&gt;the column &lt;em&gt;names&lt;/em&gt; must match, too&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This is actually pretty smart, because it makes sure that your features don’t get messed up. But it’s still kind of a gotcha for the uninitiated (me).&lt;/p&gt;
&lt;p&gt;So, to fix that, &lt;code class="highlight"&gt;list(df)&lt;/code&gt; is a &lt;a href="https://stackoverflow.com/questions/19482970/get-list-from-pandas-dataframe-column-headers"&gt;quick way to get a list of your column names&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;With those translations in mind, let’s rewrite our linear regression model as a class.&lt;/p&gt;
&lt;p&gt;Our old &lt;code class="highlight"&gt;train_model&lt;/code&gt; function took separate &lt;code class="highlight"&gt;X&lt;/code&gt; and &lt;code class="highlight"&gt;y&lt;/code&gt; inputs, but we should make it more user-friendly by spliting the features from truth behind the scenes (we’ll assume that the last column is truth).&lt;/p&gt;
&lt;p&gt;Let’s flesh out the class with some extra methods, &lt;code class="highlight"&gt;test_on(dataset)&lt;/code&gt; and &lt;code class="highlight"&gt;predict()&lt;/code&gt;. For &lt;code class="highlight"&gt;test_on(dataset)&lt;/code&gt;, let’s have it return the mean error (easier to interpret) rather than the mean squared error.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;autograd&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;elementwise_grad&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;egrad&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;LinRegModel&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[:,:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;  &lt;span class="c1"&gt;# all but last column&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;insert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'dummy'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;         &lt;span class="c1"&gt;# padding (w_0)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;   &lt;span class="c1"&gt;# last column&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Series&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__cost__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;info&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'Model underwent {self.epochs} epochs of training.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Model weights:'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;train&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.001&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="c1"&gt;# just to know the value; not critical for training&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Series&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="n"&gt;grad_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;egrad&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__cost__&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;last_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;grad_cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;grad_cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;this_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__cost__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;this_cost&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;this_cost&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;last_cost&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;break&lt;/span&gt;
            &lt;span class="n"&gt;last_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;this_cost&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;info&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;test_on&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_set&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;test_X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[:,:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;   &lt;span class="c1"&gt;# all but last column&lt;/span&gt;
        &lt;span class="n"&gt;test_X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;insert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'dummy'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;          &lt;span class="c1"&gt;# padding (w_0)&lt;/span&gt;
        &lt;span class="n"&gt;test_y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;    &lt;span class="c1"&gt;# last column&lt;/span&gt;
        &lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;new_samples&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_samples&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;"list"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;new_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_samples&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;new_samples&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
            &lt;span class="k"&gt;pass&lt;/span&gt;
        &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;new_samples&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;new_samples&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;insert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'dummy'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Number of features does not match the model's dataset"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id="fail"&gt;Fail!&lt;/h1&gt;
&lt;p&gt;While &lt;code class="highlight"&gt;autograd&lt;/code&gt; can handle NumPy data types, it appears that it can’t deal with Pandas data types such as &lt;code class="highlight"&gt;Series&lt;/code&gt; and &lt;code class="highlight"&gt;DataFrames&lt;/code&gt;! This defeats the whole purpose of trying to convert the old code from NumPy to Pandas.&lt;/p&gt;
&lt;p&gt;I &lt;a href="https://github.com/HIPS/autograd/issues/469"&gt;opened an issue&lt;/a&gt; on the GitHub repo, but still have not received a response after a week. In the meantime, I lost interest in this topic (manual linear regression) for the time being, and will end this post here.&lt;/p&gt;
&lt;h1 id="references"&gt;References&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://sebastianraschka.com/Articles/2014_about_feature_scaling.html"&gt;About Feature Scaling and Normalization&lt;/a&gt;, Sebastian Raschka&lt;/p&gt;</content><category term="pandas"></category><category term="automatic differentiation"></category></entry><entry><title>The mod(ular arithmetic) squad</title><link href="http://tabidots.github.io/2019/02/mod-squad" rel="alternate"></link><published>2019-02-01T07:35:36+07:00</published><updated>2019-02-01T07:35:36+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-02-01:/2019/02/mod-squad</id><summary type="html">&lt;p&gt;Modular arithmetic is weird, cool, and generates some trippy&amp;nbsp;polynomials!&lt;/p&gt;</summary><content type="html">
&lt;p&gt;Finally, I’m on the last of the exercises from Chapter 2 of &lt;em&gt;A Programmer’s Introduction to Mathematics&lt;/em&gt;. The exercise prompts are deceptively terse, and their connection to the material presented in the chapter is not always immediately obvious. Working through them can take entire days (for me, anyway).&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Write a web app that implements the distribution and reconstruction of the secret sharing protocol using the polynomial interpolation algorithm presented in this chapter, using modular arithmetic modulo and a 32-bit modulus &lt;span class="math"&gt;\(p\)&lt;/span&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To be honest, it took many hours before I could even understand what I was actually being asked to do. I understood&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;part of the &lt;em&gt;what&lt;/em&gt;: the concept of modulo, and&lt;/li&gt;
&lt;li&gt;the &lt;em&gt;why&lt;/em&gt;: modular arithmetic avoids floating-point rounding errors that emerge in the &lt;span class="math"&gt;\(\frac{x - x_j}{x_i - x_j}\)&lt;/span&gt; operation of interpolating polynomials&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But I was clueless about the rest—namely&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;how modular arithmetic relates to polynomials; do you perform &lt;span class="math"&gt;\(\mod n\)&lt;/span&gt; on all the coefficients?&lt;/li&gt;
&lt;li&gt;how does division (fractional quantities) even work in modular arithmetic?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At first, I spent way too much time going down fruitless dead-ends. I tried adding in &lt;code class="highlight"&gt;mod&lt;/code&gt; in random places, but I still got floating-point rounding errors.&lt;/p&gt;
&lt;h1 id="multiplicative-inverse"&gt;Multiplicative inverse&lt;/h1&gt;
&lt;p&gt;Eventually, I found my way to &lt;a href="https://math.stackexchange.com/a/2924485"&gt;the key insight that got things moving&lt;/a&gt;: There is no “division” as such in modular arithmetic. Instead, there is the &lt;em&gt;multiplicative inverse&lt;/em&gt;, which is analogous in a somewhat non-obvious way to regular division.&lt;/p&gt;
&lt;p&gt;In normal arithmetic, the inverse of a number (let’s say &lt;span class="math"&gt;\(b\)&lt;/span&gt;) is the entity that, when multiplied by &lt;span class="math"&gt;\(b\)&lt;/span&gt;, gives &lt;span class="math"&gt;\(1\)&lt;/span&gt;. That will be the reciprocal, and if &lt;span class="math"&gt;\(b\)&lt;/span&gt; is a whole number, then the inverse of &lt;span class="math"&gt;\(b\)&lt;/span&gt; can be written &lt;span class="math"&gt;\(b^{-1}\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
b \cdot \textrm{inv} &amp;amp;= 1 \\
\textrm{inv} &amp;amp;= \frac{1}{b} \\
&amp;amp;= b^{-1}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;In modular arithmetic, the multiplicative inverse of a number &lt;span class="math"&gt;\(b\)&lt;/span&gt; in &lt;span class="math"&gt;\(\mod n\)&lt;/span&gt; is also written &lt;span class="math"&gt;\(b^{-1}\)&lt;/span&gt;, and it is the integer that, when multiplied by &lt;span class="math"&gt;\(b\)&lt;/span&gt;, gives &lt;span class="math"&gt;\(1 \mod n\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ b \cdot b^{-1} \equiv 1 \mod n $$&lt;/div&gt;
&lt;p&gt;Now, finding the inverse is not exactly straightforward. There is an algorithm, but let’s first explore some examples. The StackExchange answer linked above enumerates the multiplicative inverses of numbers in &lt;span class="math"&gt;\(\mod 11\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
1^{-1} &amp;amp;= 1 &amp;amp; 1 \cdot \textcolor{red}{1} &amp;amp;= 1 &amp;amp;\equiv 1 \mod 11 \\
2^{-1} &amp;amp;= 6 &amp;amp; 2 \cdot \textcolor{red}{6} &amp;amp;= 12 &amp;amp;\equiv 1 \mod 11 \\
3^{-1} &amp;amp;= 4 &amp;amp; 3 \cdot \textcolor{red}{4} &amp;amp;= 12 &amp;amp;\equiv 1 \mod 11 \\
4^{-1} &amp;amp;= 3 &amp;amp; 4 \cdot \textcolor{red}{3} &amp;amp;= 12 &amp;amp;\equiv 1 \mod 11 \\
5^{-1} &amp;amp;= 9 &amp;amp; 5 \cdot \textcolor{red}{9} &amp;amp;= 45 &amp;amp;\equiv 1 \mod 11 \\
6^{-1} &amp;amp;= 2 &amp;amp; 6 \cdot \textcolor{red}{2} &amp;amp;= 12 &amp;amp;\equiv 1 \mod 11 \\
7^{-1} &amp;amp;= 8 &amp;amp; 7 \cdot \textcolor{red}{8} &amp;amp;= 56 &amp;amp;\equiv 1 \mod 11 \\
8^{-1} &amp;amp;= 7 &amp;amp; 8 \cdot \textcolor{red}{7} &amp;amp;= 56 &amp;amp;\equiv 1 \mod 11 \\
9^{-1} &amp;amp;= 5 &amp;amp; 9 \cdot \textcolor{red}{5} &amp;amp;= 45  &amp;amp;\equiv 1 \mod 11 \\
10^{-1} &amp;amp;= 10 &amp;amp; 10 \cdot \textcolor{red}{10} &amp;amp;= 100 &amp;amp;\equiv 1 \mod 11
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;Back to division. In normal arithmetic, we can use the property of the inverse to rewrite fractions in a slightly awkward way: &lt;span class="math"&gt;\(\frac{a}{b} = a \cdot \frac{1}{b} = a \cdot b^{-1}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;By this logic, “division” can be performed in modular arithmetic by multiplying &lt;span class="math"&gt;\(a \cdot b^{-1} \mod n\)&lt;/span&gt; and reducing the answer you get &lt;span class="math"&gt;\(\mod n\)&lt;/span&gt;. For example, &lt;span class="math"&gt;\(\frac{7}{6}\)&lt;/span&gt; would be obtained in &lt;span class="math"&gt;\(\mod 11\)&lt;/span&gt; by:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
7 \cdot 6^{-1} &amp;amp;= 7 \cdot 2 \\ &amp;amp;= 14 \\ &amp;amp;\equiv 3 \mod 11
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;Interestingly, for prime moduli, there is &lt;a href="https://stackoverflow.com/a/4798776/4210855"&gt;a very quick and easy way to do it natively in Python&lt;/a&gt;, which is much faster and simpler than the full algorithm for arbitrary moduli:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;mod_inv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mod&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;pow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mod&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mod&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# Same as x ** mod-2 % mod&lt;/span&gt;

&lt;span class="n"&gt;mod_inv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# 2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I don’t really understand the &lt;code class="highlight"&gt;-2&lt;/code&gt; part, but it seems that in &lt;span class="math"&gt;\(\mod 11\)&lt;/span&gt;, any number raised to the &lt;em&gt;ninth power&lt;/em&gt; will produce a number that is one more than a multiple of 11.&lt;/p&gt;
&lt;h1 id="polynomial-interpolation-modularly"&gt;Polynomial interpolation, modularly&lt;/h1&gt;
&lt;p&gt;Now, to apply this finding to polynomial interpolation. This was the original, non-modular, non-cool version:&lt;/p&gt;
&lt;div class="math"&gt;$$ f(x) = \sum_{i=0}^n y_i \Bigg(\prod_{j \not= i} \frac{x - x_j}{x_i - x_j}\Bigg) $$&lt;/div&gt;
&lt;p&gt;To make it modular and cool, we do this:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
f(x) &amp;amp;= \sum_{i=0}^n y_i \Bigg(\prod_{j \not= i} \textcolor{teal}{\frac{1}{x_i - x_j}}x + \textcolor{orange}{\frac{-x_j}{x_i - x_j}}\Bigg) \\
&amp;amp;= \sum_{i=0}^n y_i \Bigg(\prod_{j \not= i} \textcolor{lightgray}{1 \cdot }\textcolor{teal}{(x_i - x_j)^{-1}} \cdot x + \textcolor{orange}{-x_j \cdot (x_i - x_j)^{-1}} \Bigg) \mod n
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;Keeping in mind that the equivlent of modular &lt;code class="highlight"&gt;a / b&lt;/code&gt; in Python is &lt;code class="highlight"&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;mod_inv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mod&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;mod&lt;/span&gt;&lt;/code&gt;, this is surprisingly easy to implement in the author’s &lt;code class="highlight"&gt;single_term&lt;/code&gt; function (original code is &lt;a href="https://github.com/pim-book/programmers-introduction-to-mathematics/blob/master/secret-sharing/interpolate.py"&gt;here&lt;/a&gt;). Let’s assume a global variable &lt;code class="highlight"&gt;MOD&lt;/code&gt; that we’ll create later.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_1_0" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_0"&gt;Broke&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;theTerm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;theTerm&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;xj&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xi&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;xj&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                                &lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xi&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;xj&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_1" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_1"&gt;Woke&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;theTerm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;theTerm&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;xj&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;mod_inv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xi&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;xj&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;MOD&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;MOD&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                &lt;span class="n"&gt;mod_inv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xi&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;xj&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;MOD&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;MOD&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The coefficients of the polynomial generated by the &lt;code class="highlight"&gt;interpolate&lt;/code&gt; function must also be reduced. Code-wise, that’s pretty easy:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_2_0" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_0"&gt;Broke&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;terms&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ZERO&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_2_1" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_1"&gt;Woke&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;terms&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ZERO&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;MOD&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Except for one thing—the original class made no provision for the &lt;code class="highlight"&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;/code&gt; operator. So we have to add that to the class (original code is &lt;a href="https://github.com/pim-book/programmers-introduction-to-mathematics/blob/master/secret-sharing/polynomial.py"&gt;here&lt;/a&gt;):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__mod__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coefficients&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coefficients&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, the value returned by &lt;code class="highlight"&gt;evaluateAt&lt;/code&gt; must also be reduced &lt;span class="math"&gt;\(\mod n\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_3_0" name="__tabs_3" type="radio"/&gt;
&lt;label for="__tab_3_0"&gt;Broke&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;theSum&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_3_1" name="__tabs_3" type="radio"/&gt;
&lt;label for="__tab_3_1"&gt;Woke&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;theSum&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;MOD&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;For some reason, the &lt;code class="highlight"&gt;ZERO&lt;/code&gt; polynomial has to be changed slightly:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_4_0" name="__tabs_4" type="radio"/&gt;
&lt;label for="__tab_4_0"&gt;Broke&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ZERO&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;([])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_4_1" name="__tabs_4" type="radio"/&gt;
&lt;label for="__tab_4_1"&gt;Woke&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ZERO&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id="making-floating-points-sink"&gt;Making floating points sink&lt;/h1&gt;
&lt;p&gt;Modular arithmetic only deals with integers, or &lt;code class="highlight"&gt;int&lt;/code&gt;, so care must be taken to avoid any accidental coercion to &lt;code class="highlight"&gt;float&lt;/code&gt;s in the course of the code. Otherwise, that defeats the purpose of going through all this trouble to avoid floating-point rounding errors.&lt;/p&gt;
&lt;p&gt;The initial value of each single term in the &lt;code class="highlight"&gt;single_term&lt;/code&gt; function is a &lt;code class="highlight"&gt;float&lt;/code&gt;, so let’s change that:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_5_0" name="__tabs_5" type="radio"/&gt;
&lt;label for="__tab_5_0"&gt;Broke&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;theTerm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_5_1" name="__tabs_5" type="radio"/&gt;
&lt;label for="__tab_5_1"&gt;Woke&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;theTerm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Summing a list of &lt;code class="highlight"&gt;Polynomial&lt;/code&gt;s (or even just adding two together) produced floating-point values even when the original coefficients were integers. It turns out that the author explicitly coerced the value in the function &lt;code class="highlight"&gt;add&lt;/code&gt; of the &lt;code class="highlight"&gt;Polynomial&lt;/code&gt; class (which was loaded into the operator via &lt;code class="highlight"&gt;__add__&lt;/code&gt;). Another easy fix:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_6_0" name="__tabs_6" type="radio"/&gt;
&lt;label for="__tab_6_0"&gt;Broke&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;zip_longest&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fillvalue&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_6_1" name="__tabs_6" type="radio"/&gt;
&lt;label for="__tab_6_1"&gt;Woke&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;zip_longest&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fillvalue&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id="modulus-prime"&gt;Modulus Prime&lt;/h1&gt;
&lt;p&gt;Man, the word &lt;em&gt;modulus&lt;/em&gt; is such a cool word. Anyway, we need to create one.&lt;/p&gt;
&lt;p&gt;The prompt in the book specifies the use of a 32-bit number. It just so happens that Python has a handy random number generator, &lt;code class="highlight"&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getrandbits&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/code&gt;, that takes &lt;code class="highlight"&gt;x&lt;/code&gt; bits as an argument.&lt;/p&gt;
&lt;p&gt;Since our simplified algorithm for modular exponentiation assumes that the modulus is prime, we also have to find some way to check for primality. &lt;code class="highlight"&gt;sympy&lt;/code&gt; has one such function; no need to reinvent the wheel. (While I am finding number theory very fascinating, I also don’t have 5 years to spend on one chapter of this book!)&lt;/p&gt;
&lt;p&gt;So, with that information, it should be pretty easy to come up with a random 32-bit prime modulus:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;random&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sympy.ntheory.primetest&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;isprime&lt;/span&gt;

&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;big_prime&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getrandbits&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# a random 32-bit number&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;isprime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;break&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;

&lt;span class="n"&gt;MOD&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;big_prime&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This instantly gives us gigantic numbers like &lt;code class="highlight"&gt;3898342621&lt;/code&gt; that automatically satisfy two conditions: (1) Occupy 32 bits and (2) Be prime. Perfect!&lt;/p&gt;
&lt;h1 id="the-proof-is-in-the-polynomials"&gt;The proof is in the polynomials&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;MOD&lt;/span&gt; &lt;span class="c1"&gt;# 2606193617&lt;/span&gt;
&lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;interpolate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# 347492486 + 2084954895 x^1 + 173746241 x^2&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xi&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;yi&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;# [5, 6, 7]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It works! Our interpolated polynomial is&lt;/p&gt;
&lt;div class="math"&gt;$$ f(x) = 173746241 x^2 + 2084954895 x + 347492486 \mod 2606193617 $$&lt;/div&gt;
&lt;p&gt;and despite the enormous coefficients, it does actually pass through the points I specified.&lt;/p&gt;
&lt;p&gt;It should be noted that this code &lt;em&gt;does not&lt;/em&gt; work for negative numbers, as someone commented in response to the quick-and-dirty modular exponentation function I found on Stack Exchange. You can make modular arithmetic work with negative numbers, but it takes a little more fiddling.&lt;/p&gt;
&lt;p&gt;You could also just take the lazy route and not use negative &lt;span class="math"&gt;\(y\)&lt;/span&gt; values when implementing this for secret-sharing.&lt;/p&gt;
&lt;p&gt;Just out of curiosity, what does this modular polynomial look like, compared to the non-modular one?&lt;/p&gt;
&lt;p&gt;&lt;img alt="polynomial interpolation" src="../../images/polynomial_interp.png"/&gt;&lt;/p&gt;
&lt;p&gt;The modular polynomial has an interesting shape! Note that the scale on the vertical axis is &lt;code class="highlight"&gt;1e9&lt;/code&gt;, or &lt;em&gt;one billion&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;I find it so bizarre and fascinating that the floating-point coefficients are off by such a small amount, yet result in an inaccuracy that would make the result completely useless for cryptography, while the modular coefficients are so gigantic (along with the fluctuations in the graph) yet do create a polynomial that passes through the given points.&lt;/p&gt;
&lt;p&gt;To illustrate just how small the floating-point errors are, here is a comparison between the floating-point and decimal version of the hand-interpolated polynomial:&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{gathered}
-0.1\overline{3} x^2 + 1.4 x + 3.7\overline{3}  \\
-0.13333333333333358 x^2 + 1.3999999999999995 x + 3.733333333333336
\end{gathered}$$&lt;/div&gt;
&lt;p&gt;That’s enough for this post. I’ll get on implementing this into an actual toy-cryptography web app soon!&lt;/p&gt;
&lt;h1 id="references"&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://math.stackexchange.com/questions/2922433/how-to-compute-prod-i-1ny-i-left-prod-genfrac01j-not-ij-1"&gt;How to compute &lt;span class="math"&gt;\(\prod_{i=1}^n y'{_i}^{\big(\prod_{j \not=i, j=1}^n \frac{x_j}{x_j-x_i}\big)}\)&lt;/span&gt; with modular arithmetic for Lagrange&lt;/a&gt;, Stack Exchange Mathematics&lt;/li&gt;
&lt;li&gt;&lt;a href="https://stackoverflow.com/a/4798776/4210855"&gt;Modular multiplicative inverse function in Python&lt;/a&gt;, Stack Overflow&lt;/li&gt;
&lt;/ul&gt;</content><category term="modular arithmetic"></category></entry><entry><title>Polynomial long division &amp; GCD</title><link href="http://tabidots.github.io/2019/01/polynomial-long-division" rel="alternate"></link><published>2019-01-28T20:28:55+07:00</published><updated>2019-01-28T20:28:55+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-01-28:/2019/01/polynomial-long-division</id><summary type="html">&lt;p&gt;Exercise 2.11 in A Programmer’s Introduction to&amp;nbsp;Mathematics.&lt;/p&gt;</summary><content type="html">
&lt;p&gt;This is my go at Exercise 2.11 in &lt;em&gt;A Programmer’s Introduction to Mathematics&lt;/em&gt;. The task was to write an implementation of the extended Euclidean algorithm to find the greatest common divisor of two polynomials.&lt;/p&gt;
&lt;p&gt;This took me way longer than it maybe should have. Implementing polynomial long division with reference to the “long division” notation was not very straightforward, and required constant checking of the intermediate output, especially because I wanted to use &lt;code class="highlight"&gt;while&lt;/code&gt; loops instead of keeping track of the iterations.&lt;/p&gt;
&lt;p&gt;I hope this is somewhere in the ballpark of an elegant solution 😅&lt;/p&gt;
&lt;h1 id="polynomial-long-division"&gt;Polynomial long division&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;typing&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;poly_longdiv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dividend&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;divisor&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="sd"&gt;'''This function assumes the arguments are the author's implementation of&lt;/span&gt;
&lt;span class="sd"&gt;    Polynomials in `Programmer's Intro to Mathematics`, which orders the terms&lt;/span&gt;
&lt;span class="sd"&gt;    ascending by degree.&lt;/span&gt;
&lt;span class="sd"&gt;    '''&lt;/span&gt;
    &lt;span class="n"&gt;dividend&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reversed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dividend&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coefficients&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;divisor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reversed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;divisor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coefficients&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;remainder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dividend&lt;/span&gt;
    &lt;span class="n"&gt;quotient&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;quo&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;remainder&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;divisor&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;quotient&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;quo&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;bottom&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;quo&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;term&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;term&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;divisor&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;remainder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;bot&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;top&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bot&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;remainder&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bottom&lt;/span&gt;&lt;span class="p"&gt;)][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;remainder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dividend&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;quotient&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;divisor&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="k"&gt;except&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ne"&gt;IndexError&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"quotient"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reversed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;quotient&lt;/span&gt;&lt;span class="p"&gt;))),&lt;/span&gt;
                    &lt;span class="s2"&gt;"remainder"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reversed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;remainder&lt;/span&gt;&lt;span class="p"&gt;)))}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;See &lt;a href="https://github.com/pim-book/programmers-introduction-to-mathematics/blob/master/secret-sharing/polynomial.py"&gt;here&lt;/a&gt; for the author’s implementation of the &lt;code class="highlight"&gt;Polynomial&lt;/code&gt; class.&lt;/p&gt;
&lt;h1 id="polynomial-greatest-common-divisor"&gt;Polynomial greatest common divisor&lt;/h1&gt;
&lt;p&gt;Meanwhile, this was pretty straightforward once I found &lt;a href="http://www.math.ucla.edu/~radko/circles/lib/data/Handout-358-436.pdf"&gt;this super-concise explanation&lt;/a&gt;. The Wikipedia article was incomprehensible.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;poly_gcd&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="sd"&gt;'''Find the GCD of two polynomials using the Extended Euclidean algorithm.&lt;/span&gt;
&lt;span class="sd"&gt;    '''&lt;/span&gt;
    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;small&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;big&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;division&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;big&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;small&lt;/span&gt;
    &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;division&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"quotient"&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;division&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"remainder"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;big&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;small&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;small&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;
        &lt;span class="n"&gt;division&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;big&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;small&lt;/span&gt;
        &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;division&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"quotient"&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;division&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"remainder"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;small&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Update: And just for completeness, regular &lt;span class="caps"&gt;GCD&lt;/span&gt; with integers (copied from &lt;a href="https://www.geeksforgeeks.org/gcd-in-python/"&gt;Geeks for Geeks&lt;/a&gt;):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;gcd&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="sd"&gt;'''Find the GCD of two integers using the Extended Euclidean algorithm.&lt;/span&gt;
&lt;span class="sd"&gt;    '''&lt;/span&gt;
    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;small&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;big&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;small&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;big&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;small&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;small&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;big&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;small&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;big&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Rewriting my answer:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;poly_gcd&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="sd"&gt;'''Find the GCD of two polynomials using the Extended Euclidean algorithm.&lt;/span&gt;
&lt;span class="sd"&gt;    '''&lt;/span&gt;
    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;small&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;big&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;small&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;big&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;small&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;small&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;big&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;small&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="s2"&gt;"remainder"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;big&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="polynomials"></category></entry><entry><title>Real control points have curves (or something like that)</title><link href="http://tabidots.github.io/2019/01/real-control-points-have-curves" rel="alternate"></link><published>2019-01-27T11:42:28+07:00</published><updated>2019-01-27T11:42:28+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-01-27:/2019/01/real-control-points-have-curves</id><summary type="html">&lt;p&gt;In which I generate Bézier curves and learn how to use matplotlib the hard&amp;nbsp;way.&lt;/p&gt;</summary><content type="html">
&lt;p&gt;This is my go at Exercise 2.8 in &lt;em&gt;A Programmer’s Introduction to Mathematics&lt;/em&gt;. The task is to write a program that computes and animates a Bézier curve.&lt;/p&gt;
&lt;p&gt;The code is quite long, and I wrote more sophisticated versions as I went along, so I will include them all here in a tabbed block, and continue with the text below.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_1_0" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_0"&gt;Setup&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;matplotlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;animation&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rc&lt;/span&gt;
&lt;span class="n"&gt;rc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'animation'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'html5'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_1" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_1"&gt;4. Final code&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;bezier_curve_plots&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;static_t&lt;/span&gt;&lt;span class="o"&gt;=.&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# input validation&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Need at least 2 points to generate a Bézier curve.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# a vector of 200 evenly spaced values from 0 to 1&lt;/span&gt;
    &lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;# facilitate vector multiplication&lt;/span&gt;
    &lt;span class="n"&gt;static_points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;6.75&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;ncols&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nrows&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ctrl_ys&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;the_axes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="n"&gt;original_lines&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'o-'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'o-'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'o-'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'C7o'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;initial_ctrl&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'ko'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'ko'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'ko'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'ko'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;end_ctrl&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'ko'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'ko'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'ko'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'ko'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;t_text1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'$t = {static_t}$'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;transform&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transAxes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;t_text2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;''&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;transform&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transAxes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;t_text3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;''&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;transform&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transAxes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;style&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xytext&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;textcoords&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'offset pixels'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'left'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;#############&lt;/span&gt;
    &lt;span class="c1"&gt;# SUBPLOT 3 (mostly)&lt;/span&gt;
    &lt;span class="c1"&gt;#############&lt;/span&gt;
    &lt;span class="c1"&gt;# Create a plotting space for each iteration of de Casteljau&lt;/span&gt;
    &lt;span class="n"&gt;plotting_spaces&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;([],&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="s1"&gt;'o-'&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="c1"&gt;# Initial annotations for Subplots 3 and 4&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;annotate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'$P_{{{i}}}$'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;original_lines&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_color&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;style&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;annotate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'$P_{{{i}}}$'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;original_lines&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_color&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;style&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;annotate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'$P_{{{i}}}$'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;original_lines&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_color&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;style&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;annotate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'$P_{{{i}}}$'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;original_lines&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_color&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;style&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;annotations&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;point_sets&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;find_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
        &lt;span class="n"&gt;point_sets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;annotations&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;annotate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;''&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;style&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;
        &lt;span class="n"&gt;static_points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;find_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;static_points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;static_points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;static_t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                         &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;static_points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
        &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;static_points&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="s1"&gt;'o-'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;#############&lt;/span&gt;
    &lt;span class="c1"&gt;# SUBPLOT 4 #&lt;/span&gt;
    &lt;span class="c1"&gt;#############&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="c1"&gt;# Create a plot for line and final split point&lt;/span&gt;
    &lt;span class="n"&gt;curve&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;final_point&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;([],&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="s1"&gt;'C6-'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                          &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;([],&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="s1"&gt;'C6o'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lw&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;init&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="n"&gt;t_text2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;''&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;([],&lt;/span&gt; &lt;span class="p"&gt;[])&lt;/span&gt;

        &lt;span class="n"&gt;t_text3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;''&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;curve&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;([],&lt;/span&gt; &lt;span class="p"&gt;[])&lt;/span&gt;
        &lt;span class="n"&gt;final_point&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;([],&lt;/span&gt; &lt;span class="p"&gt;[])&lt;/span&gt;

        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;plotting_spaces&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;  &lt;span class="c1"&gt;# value of `num` is advanced by the animation function&lt;/span&gt;
        &lt;span class="n"&gt;t_text2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'$t = {round(num / len(t), 2)}$'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;t_text3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'$t = {round(num / len(t), 2)}$'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="c1"&gt;# SUBPLOT 3&lt;/span&gt;
            &lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;point_sets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt;
                                        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;point_sets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
            &lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;the_axes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;annotations&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
                &lt;span class="n"&gt;annotations&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'$P_{{{j}}}^{{{i + 1}}}$'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;annotations&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_color&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_color&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
                &lt;span class="n"&gt;annotations&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;point_sets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                                        &lt;span class="n"&gt;point_sets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;   &lt;span class="c1"&gt;# Make the final point bigger&lt;/span&gt;
                &lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_markersize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="c1"&gt;# SUBPLOT 4&lt;/span&gt;
        &lt;span class="n"&gt;curve&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="n"&gt;curve&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;the_axes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;final_point&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;plotting_spaces&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;animation&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;FuncAnimation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;fargs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[],&lt;/span&gt;
                                   &lt;span class="n"&gt;init_func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;init&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;interval&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;blit&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;random_points&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
   &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hstack&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_2" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_2"&gt;1. Brute force&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;make_bezier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

    &lt;span class="n"&gt;P&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# a vector of 100 evenly spaced values from 0 to 1&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Need at least 2 points"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; \
              &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; \
              &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Cubic curve. Come back later"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"too many points"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Reference to https://stackoverflow.com/questions/28074461/animating-growing-line-plot-in-python-matplotlib&lt;/span&gt;
    &lt;span class="c1"&gt;# Set up the graph&lt;/span&gt;
    &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'k'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Plot the static points&lt;/span&gt;
    &lt;span class="n"&gt;pts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pts&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;pts&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'ro'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# This function runs repeatedly for len(t) times as specified below&lt;/span&gt;
    &lt;span class="c1"&gt;# x and y are a list of values, computed once for each value in t&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pts&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pts&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pts&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pts&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;animation&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;FuncAnimation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;fargs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;interval&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;blit&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;linear_anim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;make_bezier&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;span class="n"&gt;quadratic_anim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;make_bezier&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],[&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;],[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;span class="c1"&gt;# linear_anim.save('./content/images/bezier/linear_bezier.gif', writer='imagemagick', fps=24)&lt;/span&gt;
&lt;span class="c1"&gt;# quadratic_anim.save('./content/images/bezier/quadratic_bezier.gif', writer='imagemagick', fps=24)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_3" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_3"&gt;2. Animate splits&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;find_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;this_point&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;next_point&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;this_point&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;next_point&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;animate_splits&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# input validation&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Need at least 2 points to generate a Bézier curve.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# a vector of 200 evenly spaced values from 0 to 1&lt;/span&gt;
    &lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;# facilitate vector multiplication&lt;/span&gt;

    &lt;span class="c1"&gt;# Set up the graph, layout, and static elements&lt;/span&gt;
    &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ctrl_ys&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;the_axes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'o-'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                              &lt;span class="c1"&gt;# Lines between all control points&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'ko'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;     &lt;span class="c1"&gt;# Initial control point&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'ko'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c1"&gt;# End control point&lt;/span&gt;

    &lt;span class="c1"&gt;# Need to create a plotting space for each iteration of de Casteljau&lt;/span&gt;
    &lt;span class="n"&gt;plotting_spaces&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;([],&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="s1"&gt;'o-'&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;init&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;([],&lt;/span&gt; &lt;span class="p"&gt;[])&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;plotting_spaces&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;  &lt;span class="c1"&gt;# value of `num` is advanced by the animation function&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

            &lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;find_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
            &lt;span class="c1"&gt;# `points` consists of all split points in the current iteration&lt;/span&gt;
            &lt;span class="c1"&gt;# each point consists of an x list and a y list, each with t number of coordinates&lt;/span&gt;

            &lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;  &lt;span class="c1"&gt;# list of xs&lt;/span&gt;
                                        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;  &lt;span class="c1"&gt;# list of ys&lt;/span&gt;
            &lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;the_axes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;   &lt;span class="c1"&gt;# Make the final point bigger&lt;/span&gt;
                &lt;span class="n"&gt;plotting_spaces&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_markersize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;plotting_spaces&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;animation&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;FuncAnimation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;fargs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                                   &lt;span class="n"&gt;init_func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;init&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;interval&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;blit&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;fivepts_anim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;animate_splits&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                                 
&lt;span class="c1"&gt;# fivepts_anim.save('./content/images/bezier/fivept_bezier.mp4', extra_args=['-vcodec', 'libx264'], fps=60)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_4" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_4"&gt;3. Trace curve&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;trace_curve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# input validation&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Need at least 2 points to generate a Bézier curve.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# a vector of 200 evenly spaced values from 0 to 1&lt;/span&gt;
    &lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;# facilitate vector multiplication&lt;/span&gt;

    &lt;span class="c1"&gt;# Set up the graph, layout, and static elements&lt;/span&gt;
    &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ctrl_ys&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;the_axes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctrl_xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ctrl_ys&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'C7o'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                             &lt;span class="c1"&gt;# Intermediate control points&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'ko'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;     &lt;span class="c1"&gt;# Initial control point&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'ko'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c1"&gt;# End control point&lt;/span&gt;

    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;find_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="c1"&gt;# Create a plot for line and final split point&lt;/span&gt;
    &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;final_point&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;([],&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="s1"&gt;'C6-'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                         &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;([],&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="s1"&gt;'C6o'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lw&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;t_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;''&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;transform&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transAxes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;init&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;([],&lt;/span&gt; &lt;span class="p"&gt;[])&lt;/span&gt;
        &lt;span class="n"&gt;final_point&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;([],&lt;/span&gt; &lt;span class="p"&gt;[])&lt;/span&gt;
        &lt;span class="n"&gt;t_text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;''&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;final_point&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t_text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;the_axes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;final_point&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="n"&gt;t_text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'$t = {round(num / len(t), 2)}$'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;final_point&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t_text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;animation&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;FuncAnimation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;init_func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;init&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;interval&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;blit&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;bezier_curve&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;trace_curve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;      
&lt;span class="c1"&gt;# bezier_curve.save('./content/images/bezier/bezier_curve_trace.mp4', extra_args=['-vcodec', 'libx264'], fps=60)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id="sample-results"&gt;Sample results&lt;/h1&gt;
&lt;p&gt;Input:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;multi_plots&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;bezier_curve_plots&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Output:&lt;/p&gt;
&lt;p&gt;&lt;span class="videobox"&gt;
&lt;video controls="" height="350" poster="http://www.judosaltgenius.com/images/bezier/bezier_curve_plots_preview.png" preload="none" width="680"&gt;&lt;source src="/../images/bezier/bezier_curve_plots.mp4" type='video/mp4; codecs="avc1.42E01E, mp4a.40.2"'/&gt;&lt;/video&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;I was already well-acquainted with &lt;em&gt;manipulating&lt;/em&gt; Bézier curves from working with the Pen tool in Photoshop and Illustrator.&lt;/p&gt;
&lt;p&gt;&lt;img alt="bezier curve with handles" src="../../images/bezier/bezier.gif" title="Bezier curve with handles, source: http://guity-novin.blogspot.com/2013/04/chapter-66-bezier-curves-for-digital.html"/&gt;&lt;/p&gt;
&lt;p&gt;In graphics programs, you can create Bézier curves of arbitrary complexity by defining a start point, end point, and any number of &lt;em&gt;control points&lt;/em&gt; in between. The curve passes through all the control points and the shape of the curve can be further manipulated using “handles” on the control points.&lt;/p&gt;
&lt;p&gt;However, this is a top-down, end-user way of looking at control points that abstracts away the process of mathematically generating the curve. At first glance, my searches for understandable explanations of the math turned up short.&lt;/p&gt;
&lt;p&gt;So, since the problem also said to look up the definition of quadratic and cubic Bézier curves, I started out by brute-forcing it. That still took a lot of time because &lt;code class="highlight"&gt;matplotlib&lt;/code&gt; is quite complicated and getting animations working for the first time was not so straightforward.&lt;/p&gt;
&lt;h1 id="brute-force"&gt;Brute force&lt;/h1&gt;
&lt;p&gt;A cursory read through the Wikipedia definition turned up a lot of rather opaque equations. Finally I managed to find some basic definitions &lt;a href="http://luthuli.cs.uiuc.edu/~daf/courses/cs-419/Week-12/Interpolation-2013.pdf"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Bold &lt;span class="math"&gt;\(\textbf B\)&lt;/span&gt; and &lt;span class="math"&gt;\(\textbf P_n\)&lt;/span&gt; are 2D coordinates that are treated as vectors in these equations. These functions run over the range &lt;span class="math"&gt;\(0 \leq t \leq 1\)&lt;/span&gt; and output a set of points &lt;span class="math"&gt;\(\textbf B\)&lt;/span&gt; that generate a Bézier curve that fits the given constraints.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\textbf B_{\textrm{linear}}(t) &amp;amp;= (1 - t)\textbf P_0 + t \textbf P_1 \\
\textbf B_{\textrm{quadratic}}(t) &amp;amp;= (1 - t)^2 \textbf P_0 + 2t (1 - t) \textbf P_1 + t^2 \textbf P_2 \\
\textbf B_{\textrm{cubic}}(t) &amp;amp;= (1 - t)^3\textbf P_0 + 3(1 -t)^2 t \textbf P_1 + 3(1 - t)t^2 \textbf P_2 + t^3 \textbf P_3
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;That got me this far:&lt;/p&gt;
&lt;p&gt;&lt;img alt="linear bezier" src="../../images/bezier/linear_bezier.gif" title="Linear bezier curve animation"/&gt;
&lt;img alt="quadratic bezier" src="../../images/bezier/quadratic_bezier.gif" title="Quadratic bezier curve animation"/&gt;&lt;/p&gt;
&lt;p&gt;I’m basically a &lt;code class="highlight"&gt;matplotlib&lt;/code&gt; Picasso! 😅&lt;/p&gt;
&lt;p&gt;However, I can’t exactly say I fully understood what I was doing.&lt;/p&gt;
&lt;p&gt;I could see some pattern to the equations—some Pascal’s triangle action happening with the coefficients of those polynomials—but I couldn’t really understand how to generate the polynomials themselves.&lt;/p&gt;
&lt;p&gt;I also noticed that the quadratic curve didn’t actually pass through the second point I had specified, which means that the mathetmatical control points of Bézier curves are a little different than the “end-user” control points I’m used to working with in Illustrator.&lt;/p&gt;
&lt;p&gt;When I tried to dig deeper, I found some crazy stuff with what looked like Einstein notation (&lt;span class="math"&gt;\(\textbf P^2_0\)&lt;/span&gt;), which really threw me for a loop. What does this have to do with matrices?&lt;/p&gt;
&lt;p&gt;&lt;img alt="de Casteljau splitting lines" src="../../images/bezier/de_casteljau.png"/&gt;&lt;/p&gt;
&lt;h1 id="dividing-lines"&gt;Dividing lines&lt;/h1&gt;
&lt;p&gt;It took me a while to figure out what the notation meant.&lt;/p&gt;
&lt;p&gt;Maybe I should have just searched on YouTube first:&lt;/p&gt;
&lt;p&gt;&lt;span class="videobox"&gt;
&lt;iframe allowfullscreen="" frameborder="0" height="480" mozallowfullscreen="" src="https://www.youtube.com/embed/7-Q9Ue_qKTE" webkitallowfullscreen="" width="640"&gt;
&lt;/iframe&gt;
&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;(I ended up finding &lt;a href="https://www.jasondavies.com/animated-bezier/"&gt;this amazing JavaScript [D3] visualization&lt;/a&gt; later.)&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(t\)&lt;/span&gt; runs over the range &lt;span class="math"&gt;\([0,1]\)&lt;/span&gt;, right? So that means any intermediate value of &lt;span class="math"&gt;\(t\)&lt;/span&gt; is a fraction.&lt;/p&gt;
&lt;p&gt;However, since we’re looking at &lt;span class="math"&gt;\(t\)&lt;/span&gt; &lt;em&gt;and&lt;/em&gt; &lt;span class="math"&gt;\(1 - t\)&lt;/span&gt;, we can look at &lt;span class="math"&gt;\(t\)&lt;/span&gt; as a split point. For example, when &lt;span class="math"&gt;\(t = 0.7\)&lt;/span&gt;, then &lt;span class="math"&gt;\(1 - t = 0.3\)&lt;/span&gt;, producing a 70/30 split.&lt;/p&gt;
&lt;p&gt;Using the illustration above as reference, the points &lt;span class="math"&gt;\(b\)&lt;/span&gt; with &lt;em&gt;only&lt;/em&gt; subscripts (&lt;span class="math"&gt;\(b_0, b_1, b_2\)&lt;/span&gt;) are the original user-specified control points. Between these three control points, two connecting lines can be drawn.&lt;/p&gt;
&lt;p&gt;Let &lt;span class="math"&gt;\(t\)&lt;/span&gt; be a split point to split each of those lines in two. Since &lt;span class="math"&gt;\(t\)&lt;/span&gt; varies between &lt;span class="math"&gt;\([0,1]\)&lt;/span&gt;, you can imagine the lines as “rollers” that the points run across. When &lt;span class="math"&gt;\(t = 0\)&lt;/span&gt;, the split points are at the initial end of each line; when &lt;span class="math"&gt;\(t = 1\)&lt;/span&gt;, the split points are at the final end of each line.&lt;/p&gt;
&lt;p&gt;Now draw a line between the two split points, and split &lt;em&gt;that&lt;/em&gt; line at &lt;span class="math"&gt;\(t\)&lt;/span&gt;. That is the final split point, which traces the curve as &lt;span class="math"&gt;\(t\)&lt;/span&gt; runs over the range &lt;span class="math"&gt;\([0,1]\)&lt;/span&gt;.&lt;/p&gt;
&lt;h1 id="de-casteljaus-algorithm"&gt;de Casteljau’s algorithm&lt;/h1&gt;
&lt;p&gt;This can be done recursively to find the curve given any number of control points. You repeat the process until you end up with one line, and thus one split point.&lt;/p&gt;
&lt;p&gt;The Einstein-looking notation above thus means:&lt;/p&gt;
&lt;div class="math"&gt;$$ \textbf P^{r \textrm{ th iteration}}_{i \textrm{ th point}} $$&lt;/div&gt;
&lt;p&gt;For the 0th iteration (control points), the superscript &lt;span class="math"&gt;\(0\)&lt;/span&gt; is usually omitted, it seems.&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(n\)&lt;/span&gt; control points require &lt;span class="math"&gt;\(n - 1\)&lt;/span&gt; iterations to find the final split point, so the task is to find the point &lt;span class="math"&gt;\(\textbf P^{n - 1}_0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Let’s try working this out from the simplest building block. The split point between any two points is&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{bmatrix} x \\ y \end{bmatrix}_{\textrm{split}} =  
(1 - t)\begin{bmatrix} x \\ y \end{bmatrix}_{\textrm{beginning}} +
t \begin{bmatrix} x \\ y \end{bmatrix}_{\textrm{end}}
$$&lt;/div&gt;
&lt;p&gt;We’ll use NumPy &lt;code class="highlight"&gt;array&lt;/code&gt;s to represent vectors for this.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;split_point&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;this_point&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;next_point&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now, we need to loop through the initial control points in the following way. &lt;span class="math"&gt;\(n\)&lt;/span&gt; number of points results in &lt;span class="math"&gt;\(n-1\)&lt;/span&gt; number of split points.&lt;/p&gt;
&lt;p&gt;Assume we input our points as a list of lists. Each iteration, then, should give us a list that is one smaller than the last iteration. And when the length of the list is 1, we know we’ve found our point.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;find_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;this_point&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;next_point&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;this_point&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;next_point&lt;/span&gt;

&lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt; &lt;span class="c1"&gt;# random number&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="s1"&gt;'o-'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;find_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="s1"&gt;'o-'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# plt.savefig('./split_points2.png')&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img alt="Bézier split points" src="../../images/bezier/split_points.png"/&gt;&lt;/p&gt;
&lt;p&gt;Doing this with an arbitrary of random points can be kinda fun:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img alt="crazy Bézier split points" src="../../images/bezier/split_points2.png"/&gt;&lt;/p&gt;
&lt;h1 id="some-intermediate-results"&gt;Some intermediate results&lt;/h1&gt;
&lt;p&gt;Animating the intermediate lines:&lt;/p&gt;
&lt;p&gt;&lt;span class="videobox"&gt;
&lt;video controls="" height="360" poster="http://www.judosaltgenius.com/images/bezier/fivept_bezier_preview.png" preload="none" width="480"&gt;&lt;source src="/../images/bezier/fivept_bezier.mp4" type='video/mp4; codecs="avc1.42E01E, mp4a.40.2"'/&gt;&lt;/video&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Tracing the curve:&lt;/p&gt;
&lt;p&gt;&lt;span class="videobox"&gt;
&lt;video controls="" height="360" poster="http://www.judosaltgenius.com/images/bezier/bezier_curve_trace_preview.png" preload="none" width="480"&gt;&lt;source src="/../images/bezier/bezier_curve_trace.mp4" type='video/mp4; codecs="avc1.42E01E, mp4a.40.2"'/&gt;&lt;/video&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Crazy curve and annotations:&lt;/p&gt;
&lt;p&gt;&lt;span class="videobox"&gt;
&lt;video controls="" height="350" poster="http://www.judosaltgenius.com/images/bezier/crazy_bezier_preview.png" preload="none" width="680"&gt;&lt;source src="/../images/bezier/crazy_bezier_curve_lines.mp4" type='video/mp4; codecs="avc1.42E01E, mp4a.40.2"'/&gt;&lt;/video&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h1 id="references"&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://louistiao.me/posts/notebooks/save-matplotlib-animations-as-gifs/"&gt;Save Matplotlib Animations as GIFs&lt;/a&gt;, Louis Tiao&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jakevdp.github.io/blog/2012/08/18/matplotlib-animation-tutorial/"&gt;Matplotlib Animation Tutorial&lt;/a&gt;, Jake VanderPlas&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jakevdp.github.io/PythonDataScienceHandbook/04.09-text-and-annotation.html"&gt;Text and Annotation&lt;/a&gt;, Jake VanderPlas&lt;/li&gt;
&lt;li&gt;&lt;a href="http://luthuli.cs.uiuc.edu/~daf/courses/cs-419/Week-12/Interpolation-2013.pdf"&gt;Interpolating Curves&lt;/a&gt;, &lt;span class="caps"&gt;CS&lt;/span&gt; 419, &lt;span class="caps"&gt;UIUC&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cs.huji.ac.il/course/2005/cg/lectures/08-CurvesSurfaces.pdf"&gt;Curves and Surfaces&lt;/a&gt;, Computer Graphics, Benin School of Computer Science&lt;/li&gt;
&lt;/ul&gt;</content><category term="matplotlib"></category><category term="bézier curves"></category></entry><entry><title>PIM notes, Chapter 2: Exercises</title><link href="http://tabidots.github.io/2019/01/pim-notes-chapter-2-exercises" rel="alternate"></link><published>2019-01-25T16:55:04+07:00</published><updated>2019-01-25T16:55:04+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-01-25:/2019/01/pim-notes-chapter-2-exercises</id><summary type="html">&lt;p&gt;Exercises from Chapter 2 of &lt;span class="caps"&gt;PIM&lt;/span&gt;, minus the coding&amp;nbsp;projects.&lt;/p&gt;</summary><content type="html">
&lt;p&gt;These exercises exclude the coding projects, which I will write about later and post on GitHub.&lt;/p&gt;
&lt;p&gt;Answering these has been very tedious. The first few were easy, but they quickly ballooned in difficulty / time required and so they got put on the back burner for a bit. I hope this book becomes more enjoyable.&lt;/p&gt;
&lt;h1 id="21"&gt;2.1&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The highest-degree term in &lt;span class="math"&gt;\(f\)&lt;/span&gt; is &lt;span class="math"&gt;\(x^2\)&lt;/span&gt;; the highest-degree term in &lt;span class="math"&gt;\(g\)&lt;/span&gt; is &lt;span class="math"&gt;\(x\)&lt;/span&gt;. The highest possible power of &lt;span class="math"&gt;\(x\)&lt;/span&gt; that can occur in &lt;span class="math"&gt;\(f \cdot g\)&lt;/span&gt; is &lt;span class="math"&gt;\(x^2 \cdot x\)&lt;/span&gt;, or &lt;span class="math"&gt;\(x^3\)&lt;/span&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The highest-degree term in &lt;span class="math"&gt;\(f\)&lt;/span&gt; is &lt;span class="math"&gt;\(x^n\)&lt;/span&gt;; the highest-degree term in &lt;span class="math"&gt;\(g\)&lt;/span&gt; is &lt;span class="math"&gt;\(m\)&lt;/span&gt;. The highest possible power of &lt;span class="math"&gt;\(x\)&lt;/span&gt; that can occur in &lt;span class="math"&gt;\(f \cdot g\)&lt;/span&gt; is &lt;span class="math"&gt;\(x^n \cdot x^m = x^{n + m}\)&lt;/span&gt;, resulting in a polynomial of degree &lt;span class="math"&gt;\(n+m\)&lt;/span&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;This does not hold when &lt;span class="math"&gt;\(f\)&lt;/span&gt; or &lt;span class="math"&gt;\(g\)&lt;/span&gt; are the zero polynomial. The generalization could be changed to say that &lt;span class="math"&gt;\(f\)&lt;/span&gt; and &lt;span class="math"&gt;\(g\)&lt;/span&gt; are polynomials with degrees &lt;span class="math"&gt;\(n\)&lt;/span&gt; and &lt;span class="math"&gt;\(m\)&lt;/span&gt; where &lt;span class="math"&gt;\(n \geq 0\)&lt;/span&gt; and &lt;span class="math"&gt;\(m \geq 0\)&lt;/span&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="22"&gt;2.2&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If &lt;span class="math"&gt;\(n = 24\)&lt;/span&gt;, then the relative prime numbers of &lt;span class="math"&gt;\(n\)&lt;/span&gt; are &lt;span class="math"&gt;\(5, 7, 11, 13, 17, 19, 23\)&lt;/span&gt;, which means &lt;span class="math"&gt;\(\phi(n) = 8\)&lt;/span&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;One example of a monic polynomial is &lt;span class="math"&gt;\(f(x) = x^5 + 3x^4 + 12x^3 + x + 7\)&lt;/span&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If &lt;span class="math"&gt;\(f(x) = 6x^3 + 18x^2 - 3x\)&lt;/span&gt;, a &lt;span class="math"&gt;\(3x\)&lt;/span&gt; can be factored out of each term, leaving the factors &lt;span class="math"&gt;\(g(x) = 2x^3 + 6x^2 - 1\)&lt;/span&gt; and &lt;span class="math"&gt;\(h(x) = 3x\)&lt;/span&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span class="math"&gt;\(f(x) = 17x^3 - 2\)&lt;/span&gt; and &lt;span class="math"&gt;\(g(x) = 6x^2\)&lt;/span&gt; are relatively prime polynomials. &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; is also irreducible. For the functions &lt;span class="math"&gt;\(f(x) = 2x^2 + 4\)&lt;/span&gt; and &lt;span class="math"&gt;\(g(x) = 4x^2 + 8\)&lt;/span&gt;, their greatest common divisor, since it must be monic, is &lt;span class="math"&gt;\((j)x = x^2 + 4\)&lt;/span&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="23"&gt;2.3&lt;/h1&gt;
&lt;p&gt;According to Euler’s theorem, &lt;span class="math"&gt;\(a^{\varphi(n)}\over{n}\)&lt;/span&gt; has remainder &lt;span class="math"&gt;\(1\)&lt;/span&gt; (or &lt;span class="math"&gt;\(a^{\varphi(n)}\)&lt;/span&gt; &lt;code class="highlight"&gt;mod&lt;/code&gt; &lt;span class="math"&gt;\(n = 1\)&lt;/span&gt;). This means that
    &lt;/p&gt;
&lt;div class="math"&gt;$$\begin{aligned}
    a^{\varphi(n)} \bmod n &amp;amp;= 1 \\
    \frac{a^{\varphi(n)}}{n} &amp;amp;= c + \frac{1}{n} \\
    a^{\varphi(n)} &amp;amp;= cn + 1 \\
    \end{aligned}$$&lt;/div&gt;
&lt;p&gt;
&lt;span class="math"&gt;\(c\)&lt;/span&gt; must be a nonnegative integer, which means that &lt;span class="math"&gt;\(\frac{a^{\varphi(n)} - 1}{n}\)&lt;/span&gt; must be a nonnegative integer. Using the numbers from the previous example (&lt;span class="math"&gt;\(n = 24\)&lt;/span&gt;, &lt;span class="math"&gt;\(\varphi(n) = 8\)&lt;/span&gt;), we can let &lt;span class="math"&gt;\(a = 5\)&lt;/span&gt;.
    &lt;/p&gt;
&lt;div class="math"&gt;$$\begin{aligned}
    \frac{5^{8}}{24} &amp;amp;= c + \frac{1}{24} \\
    5^{8} &amp;amp;= 24c + 1 \\
    390625 - 1 &amp;amp;= 24c \\
    c &amp;amp;= 16276
    \end{aligned}$$&lt;/div&gt;
&lt;p&gt;
  Indeed, &lt;span class="math"&gt;\(\frac{390625 - 1}{24}\)&lt;/span&gt; is a nonnegative integer.&lt;/p&gt;
&lt;h1 id="24"&gt;2.4&lt;/h1&gt;
&lt;p&gt;Based on the definition, a number &lt;span class="math"&gt;\(z\)&lt;/span&gt; is algebraic if there is some polynomial function &lt;span class="math"&gt;\(f(x) = a_0 + a_1x + \cdots + a_nx^n\)&lt;/span&gt;, where all &lt;span class="math"&gt;\(a_i\)&lt;/span&gt; are rational, such that &lt;span class="math"&gt;\(f(z) = 0\)&lt;/span&gt;. &lt;span class="math"&gt;\(\sqrt 2\)&lt;/span&gt; is algebraic because it is the root of &lt;span class="math"&gt;\(x^2 - 2\)&lt;/span&gt;, which has the rational coefficients &lt;span class="math"&gt;\(a_0 = -2\)&lt;/span&gt;, &lt;span class="math"&gt;\(a_1 = 0\)&lt;/span&gt;, and &lt;span class="math"&gt;\(a_2 = 1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;You can find this by trying to get to &lt;span class="math"&gt;\(z\)&lt;/span&gt; from 0, then going backwards through that order of operations starting with &lt;span class="math"&gt;\(x\)&lt;/span&gt;. I find this easier to visualize by writing in Clojure:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;sqrt&lt;/span&gt;         &lt;span class="c1"&gt;; x^2&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;    &lt;span class="c1"&gt;; - 2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;What about &lt;span class="math"&gt;\(\phi = \frac{1 + \sqrt 5}{2}\)&lt;/span&gt;?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;              &lt;span class="c1"&gt;; 2x&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;            &lt;span class="c1"&gt;; - 1&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;sqrt&lt;/span&gt;         &lt;span class="c1"&gt;; all of that ^2&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;  &lt;span class="c1"&gt;; - 5&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Thus,&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
f(x) &amp;amp;= (2x - 1)^2 - 5 \\
&amp;amp;= 2x^2 - 4x + 1 - 5 \\
&amp;amp;= 2x^2 - 4x - 4
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;So, we have a polynomial. Since we started from 0 and worked in reverse to come up with this polynomial, that should mean &lt;span class="math"&gt;\(\phi\)&lt;/span&gt; is algebraic. Let’s check:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
f(\phi) &amp;amp;= \Big(\cancel{2}(\frac{1 + \sqrt 5}{\cancel{2}}) - 1\Big)^2 - 5 \\
&amp;amp;= (\cancel{1} + \sqrt 5 - \cancel{1})^2 - 5 \\
&amp;amp;= (\sqrt 5)^2 - 5 \\
&amp;amp;= 0
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;And &lt;span class="math"&gt;\(\phi\)&lt;/span&gt; is its root, so yes, &lt;span class="math"&gt;\(\phi\)&lt;/span&gt; is an algebraic number. Now, how about &lt;span class="math"&gt;\(\sqrt 2 + \sqrt 3\)&lt;/span&gt;? At first I tried to work it out with Clojure and I got the wrong answer. But there is definitely a way to make &lt;span class="math"&gt;\(\sqrt 2 + \sqrt 3 = 0\)&lt;/span&gt;. I did it the old-fashioned way, filling up an entire sheet of paper with algebra.&lt;/p&gt;
&lt;p&gt;You have to square the term to get rid of the square roots, but because &lt;span class="math"&gt;\((a + b)^2 = a^2 + 2ab + b^2\)&lt;/span&gt;, you’ll also have to get rid of the &lt;span class="math"&gt;\(2\sqrt 2\sqrt 3\)&lt;/span&gt; that remains when you do &lt;span class="math"&gt;\((\sqrt 2 + \sqrt 3)^2\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
f(x) &amp;amp;= \Big(\frac{x^2 - 5}{2}\Big)^2 - 6 \\
&amp;amp;= \frac{1}{4}x^4 + \frac{5}{2}x^2 + \frac{25}{4} - 6 \\
&amp;amp;= \frac{1}{4}x^4 + \frac{5}{2}x^2 + \frac{1}{4}
\end{aligned} $$&lt;/div&gt;
&lt;h1 id="25"&gt;2.5&lt;/h1&gt;
&lt;h2 id="product-and-sum-of-algebraic-numbers"&gt;Product and sum of algebraic numbers&lt;/h2&gt;
&lt;p&gt;A polynomial encompasses the operations of addition, multiplication, and exponentiation. To find the root of a polynomial is to perform the ”opposite” of these operations.&lt;/p&gt;
&lt;p&gt;Addition and multiplication are commutative, so their opposite is themselves; the opposite of exponentiation is to take a root.&lt;/p&gt;
&lt;p&gt;It would seem from the above work that any number made from combinations of these “opposite” operations performed on rational numbers is the root of &lt;em&gt;some&lt;/em&gt; polynomial and is therefore algebraic.&lt;/p&gt;
&lt;p&gt;Therefore, for any two algebraic numbers, their sum and their product are both algebraic as well.&lt;/p&gt;
&lt;h2 id="proof-regarding-pie-and-pi-e"&gt;Proof regarding &lt;span class="math"&gt;\(\pi+e\)&lt;/span&gt; and &lt;span class="math"&gt;\(\pi e\)&lt;/span&gt; &lt;/h2&gt;
&lt;p&gt;For this part, I was stuck, so I got some help from the author himself:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For the &lt;span class="math"&gt;\(\pi+e\)&lt;/span&gt; and &lt;span class="math"&gt;\(\pi e\)&lt;/span&gt; part, there are two steps: (1) prove that a number which is the root of a polynomial whose coefficients are algebraic is also algebraic, and (2) construct a polynomial whose roots are &lt;span class="math"&gt;\(\pi\)&lt;/span&gt; and &lt;span class="math"&gt;\(e\)&lt;/span&gt;, and whose coefficients can be expressed in terms of &lt;span class="math"&gt;\(\pi+e\)&lt;/span&gt; and &lt;span class="math"&gt;\(\pi e\)&lt;/span&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The author said the second part was easy. It is, but it’s not obvious. Apparently you can create a polynomial from a series of roots by just &lt;a href="https://www.purplemath.com/modules/fromzero2.htm"&gt;subtracting them from &lt;span class="math"&gt;\(x\)&lt;/span&gt; and multiplying them together&lt;/a&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ (x-r_1)(x-r_2) $$&lt;/div&gt;
&lt;p&gt;Since we want a polynomial with roots &lt;span class="math"&gt;\(\pi\)&lt;/span&gt; and &lt;span class="math"&gt;\(e\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
f(x) &amp;amp;= (x-\pi)(x-e) \\
&amp;amp;= x^2 - ex - \pi x + \pi e \\
&amp;amp;= x^2 - (\textcolor{teal}{\pi + e})x + \textcolor{orange}{\pi e}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;Done!&lt;/p&gt;
&lt;p&gt;Now, back to the first part. In a more general form, the statement about the roots of a polynomial would look like&lt;/p&gt;
&lt;div class="math"&gt;$$ f(x) = \prod_{i=1}^n (x-r_i) $$&lt;/div&gt;
&lt;p&gt;for a polynomial with &lt;span class="math"&gt;\(n\)&lt;/span&gt; roots.&lt;/p&gt;
&lt;p&gt;That means all that can ever happen to any &lt;span class="math"&gt;\(r_i\)&lt;/span&gt; is the accumulation of multiplication or addition operations.&lt;/p&gt;
&lt;p&gt;As discussed above, for any two algebraic numbers, their sum and their product are both algebraic as well. So for a set of &lt;span class="math"&gt;\(r_1, \cdots, r_n\)&lt;/span&gt; that are all algebraic, &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; will also be algebraic.&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\pi\)&lt;/span&gt; and &lt;span class="math"&gt;\(e\)&lt;/span&gt; are known to &lt;em&gt;not&lt;/em&gt; be algebraic, so accumulating multiplication or addition with algebraic numbers will never &lt;em&gt;make&lt;/em&gt; them algebraic. Therefore the resulting coefficients will not be algebraic.&lt;/p&gt;
&lt;p&gt;Let’s try making &lt;span class="math"&gt;\(\pi + e\)&lt;/span&gt; a root of a polynomial that has an &lt;em&gt;algebraic&lt;/em&gt; root as well.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
g(x) &amp;amp;= \Big(x - (\pi + e)\Big)(x + 2) \\
&amp;amp;= x^2 + 2x - (\pi + e)x - 2(\pi + e) \\
&amp;amp;= x^2 + (2 - \pi - e)x - 2\pi - e
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;Nope! How about &lt;span class="math"&gt;\(\pi e\)&lt;/span&gt;?&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
h(x) &amp;amp;= (x - \pi e)(x + 2) \\
&amp;amp;= x^2 + 2x - \pi e x - 2 \pi e \\
&amp;amp;= x^2 + (2 - \pi e)x - 2 \pi e
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;Here, we cannot know for sure. If &lt;span class="math"&gt;\(\pi e\)&lt;/span&gt; is algebraic, then &lt;span class="math"&gt;\(h(x)\)&lt;/span&gt; will also be algebraic. But we don’t know. So it is true that &lt;span class="math"&gt;\(\pi\)&lt;/span&gt; and &lt;span class="math"&gt;\(e\)&lt;/span&gt; are not algebraic, but &lt;span class="math"&gt;\(\pi + e\)&lt;/span&gt; and &lt;span class="math"&gt;\(\pi e\)&lt;/span&gt; cannot &lt;em&gt;both&lt;/em&gt; be algebraic.&lt;/p&gt;
&lt;h1 id="26"&gt;2.6&lt;/h1&gt;
&lt;p&gt;I don’t know how to prove Vieta’s formulas other than working through them. The product is easier than the sum and can be done without substituting actual numbers. Let’s try a polynomial of degree 3 (&lt;span class="math"&gt;\(n=3\)&lt;/span&gt;):&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{gathered}
(x - r_3)(x - r_2)(x - r_1) \\
(x^2 - r_2x - r_3x + \textcolor{red}{r_2r_3})(x - r_1) \\
x^3 - r_2x^2 - r_3x^2 + r_2r_3x - (r_1x^2 + r_1r_2x + r_1r_3x - \textcolor{red}{r_1r_2r_3}) \\
x^3 \textcolor{teal}{- r_2x^2 - r_3x^2} + \textcolor{orange}{r_2r_3x} - \textcolor{teal}{r_1x^2} \textcolor{orange}{- r_1r_2x - r_1r_3x} + \textcolor{red}{r_1r_2r_3} \\
{\underbrace{\textcolor{lightgray}{1}}_{a_3}} x^3 + {\underbrace{(\textcolor{teal}{-r_1 - r_2- r_3}}_{a_2})} x^2 + {\underbrace{(\textcolor{orange}{-r_1r_2 - r_1r_3 + r_2r_3})}_{a_1}} x + \underbrace{\textcolor{red}{r_1r_2r_3}}_{a_0}
\end{gathered} $$&lt;/div&gt;
&lt;p&gt;According to Vieta’s formula, the following should be true:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\prod_{i=1}^n r_i &amp;amp;= (-1)^n \frac{a_0}{a_n} \\
r_1r_2r_3 &amp;amp;\overset{?}{=} (-1)^3 \frac{r_1r_2r_3}{1} \end{aligned} $$&lt;/div&gt;
&lt;p&gt;Indeed it is! And if you look at the term I went back and highlighted in red above, you can see why:&lt;/p&gt;
&lt;p&gt;As you keep multiplying binomials, the final coefficient (the one without a variable) is always going to be the cumulative product of the roots (the term in the binomials without a variable), with the sign switching for each binomial you multiply.&lt;/p&gt;
&lt;p&gt;But what about the sum of the roots?&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\sum_{i=1}^n r_i &amp;amp;= -\frac{a_{n-1}}{a_n} \\
r_1 + r_2 + r_3 &amp;amp;\overset{?}{=} -\frac{a_2}{a_3} \\
&amp;amp;\overset{?}{=} -\frac{-r_1 - r_2 - r_3}{1} \\
&amp;amp;= r_1 + r_2 + r_3
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;I can’t explain why this is the case, but I can see that it does work.&lt;/p&gt;
&lt;p&gt;So Vieta’s formulas are basically saying that for any degree &lt;span class="math"&gt;\(n\)&lt;/span&gt; polynomial &lt;span class="math"&gt;\(a_n \prod_{i=1}^n (x - r_i)\)&lt;/span&gt; with roots &lt;span class="math"&gt;\(r_1, ..., r_n\)&lt;/span&gt;, where &lt;span class="math"&gt;\(a_n\)&lt;/span&gt; acts to “scale” the polynomial, then&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class="math"&gt;\(a_0\)&lt;/span&gt; (the coefficient without a variable) is the de-scaled product of all the roots (flipping its sign for each iteration), and&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(a_{n-1}\)&lt;/span&gt;, the coefficient of the second highest term, is the flipped-sign de-scaled sum of all the roots.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="29"&gt;2.9&lt;/h1&gt;
&lt;p&gt;Wilkinson’s polynomial has a very precise shape because it was created from multiplying very simple binomials. It is “infinitely” steep near its roots (almost a straight line) and because the terms are of such a high order, altering the coefficients slightly turns what was a very “simple” function (the product of simple binomials) into an extremely complicated one.&lt;/p&gt;
&lt;h1 id="212"&gt;2.12&lt;/h1&gt;
&lt;p&gt;As far as I found, fields of math involved in different proofs of the Fundamental Theorem of Algebra include: Complex analysis, real analysis, topology, and Riemannian differential geometry. Pretty scary stuff.&lt;/p&gt;</content></entry><entry><title>The squarest root in Babylon and automatic differentiation</title><link href="http://tabidots.github.io/2019/01/squarest-root-in-babylon" rel="alternate"></link><published>2019-01-22T15:47:33+07:00</published><updated>2019-01-22T15:47:33+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-01-22:/2019/01/squarest-root-in-babylon</id><summary type="html">&lt;p&gt;If you thought 1 + ϵ = 1 was weird, wait till you see what ϵ² equates&amp;nbsp;to.&lt;/p&gt;</summary><content type="html">
&lt;p&gt;In my previous post on &lt;a href="/2019/01/from-zero-to-ero"&gt;&lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; (epsilon)&lt;/a&gt;, I wrote about this statement:&lt;/p&gt;
&lt;div class="math"&gt;$$ 1 + \epsilon = 1 $$&lt;/div&gt;
&lt;p&gt;which seemed like it came from a planet that had fallen out of orbit or something. Well, try this one on for size:&lt;/p&gt;
&lt;div class="math"&gt;$$ \epsilon^2 = 0 $$&lt;/div&gt;
&lt;p&gt;Another math koan! &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; is still a stand-in for the same concept here—an infinitesimal value—but its function is a little different. This post will be about &lt;strong&gt;dual numbers&lt;/strong&gt; and what you can do with them.&lt;/p&gt;
&lt;p&gt;But first, let’s start with another devilishly complex (har har) number: &lt;span class="math"&gt;\(i\)&lt;/span&gt;.&lt;/p&gt;
&lt;h1 id="same-same-but-different"&gt;Same same but different&lt;/h1&gt;
&lt;p&gt;You might remember imaginary and complex numbers from high school trigonometry. There is a number &lt;span class="math"&gt;\(i\)&lt;/span&gt; such that&lt;/p&gt;
&lt;div class="math"&gt;$$ i^2 = -1 $$&lt;/div&gt;
&lt;p&gt;which really tempts you to find the value of just plain &lt;span class="math"&gt;\(i\)&lt;/span&gt;. Since it doesn’t really exist, we just have to treat it like an &lt;span class="math"&gt;\(x\)&lt;/span&gt;: &lt;span class="math"&gt;\(2 + 3i\)&lt;/span&gt; (a complex number), etc.&lt;/p&gt;
&lt;p&gt;But the kicker is that the point of &lt;span class="math"&gt;\(i\)&lt;/span&gt; is not its value but &lt;em&gt;what it lets us do&lt;/em&gt;. The point is that this property of &lt;span class="math"&gt;\(i\)&lt;/span&gt; makes it possible for us to reason about rotation around a circle, because its sign changes as you keep multiplying it by itself.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I may or may not have learned that last point in high school, but if you’re anything like me, it is helpful to have a refresher that is more lucid and engaging than any high school math class: &lt;a href="https://www.youtube.com/watch?v=spUNpyF58BY"&gt;3blue1brown&lt;/a&gt; / &lt;a href="https://betterexplained.com/articles/a-visual-intuitive-guide-to-imaginary-numbers/"&gt;BetterExplained&lt;/a&gt; / &lt;a href="https://www.youtube.com/watch?v=65wYmy8Pf-Y"&gt;Welch Labs&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id="coding-with-i"&gt;Cod&lt;span class="math"&gt;\(i\)&lt;/span&gt;ng with &lt;span class="math"&gt;\(i\)&lt;/span&gt;?&lt;/h1&gt;
&lt;p&gt;While we’re on the subject of complex numbers, let’s play with them a bit. I was a bit surprised to discover that built-in &lt;code class="highlight"&gt;complex&lt;/code&gt; data types are not rare among modern programming languages. It’s not a surprise that Julia has them natively, but so do R, Python, and even Ruby. (Sadly, Clojure does not.)&lt;/p&gt;
&lt;p&gt;Of course, there is some variation in coolness of implementation:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_1_0" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_0"&gt;Julia&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;# You can use `im` to implicitly denote the imaginary part of a complex number&lt;/span&gt;
&lt;span class="c"&gt;# Not much different than typing LaTeX. Pretty slick!&lt;/span&gt;
&lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="nb"&gt;im&lt;/span&gt;
&lt;span class="n"&gt;typeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                     &lt;span class="c"&gt;# Complex{Int64}&lt;/span&gt;
&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;                            &lt;span class="c"&gt;# 6 + 8im&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="nb"&gt;im&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;                       &lt;span class="c"&gt;# -1 + 0im. Don't need to declare 0 real part&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="nb"&gt;im&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="nb"&gt;im&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;         &lt;span class="c"&gt;# 5 + 7im&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="nb"&gt;im&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="nb"&gt;im&lt;/span&gt;                     &lt;span class="c"&gt;# 0 + 0im&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="nb"&gt;im&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="nb"&gt;im&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;         &lt;span class="c"&gt;# 5 + 5im&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_1" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_1"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Python follows the electrical engineering convention of using j for i&lt;/span&gt;
&lt;span class="c1"&gt;# because i means current in that field (pun intended)&lt;/span&gt;
&lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;complex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;             &lt;span class="c1"&gt;# (3+4j)&lt;/span&gt;
&lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                       &lt;span class="c1"&gt;# complex&lt;/span&gt;
&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;z&lt;/span&gt;                         &lt;span class="c1"&gt;# (6+8j)&lt;/span&gt;
&lt;span class="nb"&gt;complex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;            &lt;span class="c1"&gt;# (-1+0j)&lt;/span&gt;
&lt;span class="nb"&gt;complex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;complex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# (5+7j)&lt;/span&gt;
&lt;span class="nb"&gt;complex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nb"&gt;complex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# 0j. interesting output&lt;/span&gt;
&lt;span class="nb"&gt;complex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nb"&gt;complex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# (5+5j)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_2" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_2"&gt;R&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Syntax is a bit cumbersome&lt;/span&gt;
&lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;complex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;imaginary&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;    &lt;span class="c1"&gt;# 3 + 4i&lt;/span&gt;
&lt;span class="nf"&gt;typeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                                &lt;span class="c1"&gt;# complex&lt;/span&gt;
&lt;span class="nf"&gt;complex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;imaginary&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;    &lt;span class="c1"&gt;# -1 + 0i&lt;/span&gt;
&lt;span class="nf"&gt;complex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;imaginary&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nf"&gt;complex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;imaginary&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# 5 + 7i&lt;/span&gt;

&lt;span class="c1"&gt;# Sorry R, but I can't be bothered to type so much&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Okay, that was fun. Now let’s return to &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt;.&lt;/p&gt;
&lt;h1 id="dual-numbers"&gt;Dual numbers&lt;/h1&gt;
&lt;p&gt;Dual numbers are pretty similar to complex numbers, except with &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; instead of &lt;span class="math"&gt;\(i\)&lt;/span&gt;. &lt;span class="math"&gt;\(2 + 3\epsilon\)&lt;/span&gt; is a dual number, for example.&lt;/p&gt;
&lt;p&gt;We could say that it still represents an infinitesimal here, a value so small that when you square it, it is effectively zero. Thus,&lt;/p&gt;
&lt;div class="math"&gt;$$ \epsilon^2 = 0 $$&lt;/div&gt;
&lt;p&gt;But as with &lt;span class="math"&gt;\(i\)&lt;/span&gt;, the significance of &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; is not in the exact value, but rather the mathematical play that it opens up for us. Watch what happens to this unsuspecting parabola:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
f(x) &amp;amp;= x^2 \\
f(x + \epsilon) &amp;amp;= (x + \epsilon)^2 \\
&amp;amp;= x^2 + 2x\epsilon + \epsilon^2 \\
&amp;amp;= x^2 + 2x\epsilon + \cancel{0}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;We can rewrite this further, since our original function has reappeared in the result:&lt;/p&gt;
&lt;div class="math"&gt;$$ f(x + \epsilon) = f(x) + 2x\epsilon $$&lt;/div&gt;
&lt;p&gt;And what is &lt;span class="math"&gt;\(2x\)&lt;/span&gt; but the &lt;strong&gt;derivative&lt;/strong&gt; of &lt;span class="math"&gt;\(x^2\)&lt;/span&gt;? 🤔&lt;/p&gt;
&lt;div class="math"&gt;$$ f(x + \epsilon) \overset{?}{=} f(x) + f'(x)\epsilon $$&lt;/div&gt;
&lt;p&gt;Just to make sure this isn’t a one-off, let’s try it with a more complex polynomial, and scale the &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; component:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
f(x) &amp;amp;= 2x^3 + 5x - 7 \\
f(x + \textcolor{magenta}{2} \epsilon) &amp;amp;= 2(x + \textcolor{magenta}{2} \epsilon)^3 + 5(x + \textcolor{magenta}{2} \epsilon) - 7 \\
&amp;amp;= 2(x^3 + 6x^2\epsilon + 12x\epsilon^2 + 8\epsilon^3) + 5(x + 2\epsilon) - 7 \\
&amp;amp;= \textcolor{teal}{2x^3} + \textcolor{orange}{12x^2\epsilon} + \textcolor{lightgray}{24x\epsilon^2} + \textcolor{orange}{16\epsilon^3} + \textcolor{teal}{5x} + \textcolor{orange}{10\epsilon} - \textcolor{teal}{7} \\
&amp;amp;= \textcolor{teal}{2x^3 + 5x - 7} + \textcolor{magenta}{2} \textcolor{orange}{(6x^2 + 5 } \textcolor{lightgray}{+ 8\epsilon^2}\textcolor{orange}{)\epsilon} \\
&amp;amp;= \textcolor{teal}{f(x)} + \textcolor{magenta}{2} \textcolor{orange}{f'(x) \epsilon}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;Indeed, we still obtain the derivative of our original function, multiplied by the dual component of our input. 😮 This means&lt;/p&gt;
&lt;div class="math"&gt;$$ f(a + b \epsilon) = f(a) + bf'(a)\epsilon $$&lt;/div&gt;
&lt;p&gt;In other words, we found the output and a local derivative in one go—automagically!—without having to find the derivative by hand first (that would be &lt;em&gt;symbolic differentiation&lt;/em&gt;, i.e., through manipulating symbols).&lt;/p&gt;
&lt;p&gt;It should be possibly to exploit this property of &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; with functions whose derivatives are not so straightforward to find.&lt;/p&gt;
&lt;p&gt;Well, technically, you could also approximate the derivative with &lt;em&gt;finite differences&lt;/em&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img alt="derivative animation" src="../../images/derivative_animation.gif" title="source: https://sites.google.com/a/student.ashcoll.school.nz/bcashcoll/13-mac/differentiation-as-3-6-91578"/&gt;&lt;/p&gt;
&lt;p&gt;But this is tedious at best and still not perfectly accurate when done by hand, and prone to all sorts of errors when done by computer (truncation errors, rounding errors, etc.).&lt;/p&gt;
&lt;h1 id="diy-automatic-differentiation"&gt;&lt;span class="caps"&gt;DIY&lt;/span&gt; automatic differentiation&lt;/h1&gt;
&lt;p&gt;This brings us to automatic differentiation, which is a &lt;em&gt;huge&lt;/em&gt; topic in machine learning. There are libraries to do this, but it is important to understand how they work by implementing automatic differentiation from scratch.&lt;/p&gt;
&lt;p&gt;One stumbling block, however, is that outside of machine learning, dual numbers are a pretty obscure piece of mathematics. No language comes with them built-in; you have to implement a class yourself.&lt;/p&gt;
&lt;h2 id="the-squarest-root-in-babylon"&gt;The squarest root in Babylon&lt;/h2&gt;
&lt;p&gt;Before we build the class, let’s set a goalpost.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=vAp6nUMrKYg"&gt;Alan Edelman’s demonstration of automatic differentiation in Julia&lt;/a&gt; is pretty nifty, though I think it moves pretty fast for a newcomer to automatic differentiation. So let’s break down what he is trying to do.&lt;/p&gt;
&lt;p&gt;He wants to find the derivative of &lt;span class="math"&gt;\(\sqrt x\)&lt;/span&gt;. With the same power rule we used for the polynomials above, that’s pretty trivial to do symbolically, right?&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
f(x) = \sqrt x &amp;amp;= x^{\frac{1}{2}} \\
\frac{df}{dx} = \frac{1}{2} x^{-\frac{1}{2}} &amp;amp;= \frac{1}{2\sqrt x}
 \end{aligned} $$&lt;/div&gt;
&lt;p&gt;Done. Blog post over!&lt;/p&gt;
&lt;p&gt;🤦🏻&lt;/p&gt;
&lt;p&gt;Okay, but let’s say we didn’t know that &lt;span class="math"&gt;\(\sqrt x = x^{\frac{1}{2}}\)&lt;/span&gt;. Now whatcha gonna do?&lt;/p&gt;
&lt;p&gt;Apparently the Babylonians knew a way to approximate the square root.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{gathered}
t := \frac{t + \frac{x}{t}}{2} \\
\textrm{Repeat until }t \textrm{ converges to } \sqrt x
\end{gathered} $$&lt;/div&gt;
&lt;p&gt;The tutorial is of course intended to show off how well-suited Julia is to the overall task, but I’d say this preliminary work is a fun task for Clojure. Let &lt;code class="highlight"&gt;n&lt;/code&gt; denote the number of iterations.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_2_0" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_0"&gt;Clojure&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;bab-sqrt&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;loop &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;t&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="nv"&gt;acc&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;gt;= &lt;/span&gt;&lt;span class="nv"&gt;acc&lt;/span&gt; &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
         &lt;span class="nv"&gt;t&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="nv"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="nv"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
               &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;inc &lt;/span&gt;&lt;span class="nv"&gt;acc&lt;/span&gt;&lt;span class="p"&gt;)))))&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;bab-sqrt&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c1"&gt;; 1.414213562373095&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;Math/sqrt&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;    &lt;span class="c1"&gt;; 1.4142135623730951&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_2_1" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_1"&gt;Julia&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;# the original code from Alan Edelman's notebook&lt;/span&gt;
&lt;span class="k"&gt;function&lt;/span&gt; &lt;span class="n"&gt;Babylonian&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;  &lt;span class="k"&gt;end&lt;/span&gt;    
  &lt;span class="n"&gt;t&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="n"&gt;Babylonian&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c"&gt;# 1.414213562373095&lt;/span&gt;
&lt;span class="o"&gt;√&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;             &lt;span class="c"&gt;# 1.4142135623730951&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_2_2" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_2"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;bab_root&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;iters&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;iters&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;
&lt;span class="n"&gt;bab_root&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;That converged pretty quick! Not to mention, it’s more than an “approximation”—it’s practically indistinguishable to the true value after just five iterations.&lt;/p&gt;
&lt;p&gt;Okay, so we have our function. Since we already know the derivative of &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; through symbolic differentiation, we can compute a true value for &lt;span class="math"&gt;\(f'(x)\)&lt;/span&gt; at any point &lt;span class="math"&gt;\(x = a\)&lt;/span&gt;, against which we can validate the result of automatically differentiating &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; at &lt;span class="math"&gt;\(x = a\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The first step to differentiate the Babylonian square root function at &lt;span class="math"&gt;\(x = 2\)&lt;/span&gt; &lt;em&gt;symbolically&lt;/em&gt; using dual numbers would look like this:&lt;/p&gt;
&lt;div class="math"&gt;$$ \frac{t + \frac{2 + \epsilon}{t}}{2} $$&lt;/div&gt;
&lt;p&gt;which should yield a satisfactorily precise result after 5 iterations.&lt;/p&gt;
&lt;p&gt;We thus need to implement our class similarly to the imaginary number classes, so that something like &lt;code class="highlight"&gt;&lt;span class="n"&gt;bab_root&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/code&gt; will give us the derivative of &lt;span class="math"&gt;\(f(x) = \sqrt x\)&lt;/span&gt; at &lt;span class="math"&gt;\(x = 5\)&lt;/span&gt; &lt;em&gt;without having to explicitly write anything about&lt;/em&gt; &lt;span class="math"&gt;\(\frac{1}{2\sqrt 5}\)&lt;/span&gt;.&lt;/p&gt;
&lt;h2 id="getting-classy"&gt;Getting classy&lt;/h2&gt;
&lt;p&gt;The basic task here is to create a class that overloads the basic arithmetic operators so that dual numbers can be manipulated like normal numbers. In other words, extend the operators to follow the rules of dual number arithmetic (included below).&lt;/p&gt;
&lt;p&gt;To be honest, defining classes is above my current level of Clojure skills, I’ve never overloaded operators in Python before, and I’m almost completely new to Julia. So I will adapt the Python code from &lt;a href="http://eviatarbach.com/2013/05/13/dual-numbers-and-automatic-differentiation/"&gt;this post&lt;/a&gt; and the Julia code from &lt;a href="https://nbviewer.jupyter.org/github/alanedelman/YouTubeNotebooks/blob/master/Automatic%20Differentiation%20in%2010%20Minutes.ipynb"&gt;this notebook&lt;/a&gt;, break it down and proceed from there.&lt;/p&gt;
&lt;p&gt;The rules of dual number arithmetic are as follows. Addition and multiplication work just like with complex numbers or polynomials (&lt;span class="caps"&gt;FOIL&lt;/span&gt;):&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
(a + b\epsilon) \pm (c + d\epsilon) &amp;amp;= \textcolor{teal}{(a + c)} \pm \textcolor{orange}{(b + d)}\epsilon \\
(a + b\epsilon) (c + d\epsilon) &amp;amp;= \textcolor{teal}{(ac)} + \textcolor{orange}{(bc + ad)}\epsilon
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;Division is not so obvious, but this is the rule (&lt;a href="https://en.wikipedia.org/wiki/Dual_number#Division"&gt;from Wikipedia&lt;/a&gt;):&lt;/p&gt;
&lt;div class="math"&gt;$$ \frac{a + b\epsilon}{c + d\epsilon} = \textcolor{teal}{\frac{a}{c}} + \textcolor{orange}{\frac{bc - ad}{c^2}} \epsilon $$&lt;/div&gt;
&lt;p&gt;Our result should have the teal part as its real component and the orange part as its dual component. We can treat &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; as merely a symbol to be printed when the value needs to be displayed for us humans to read.&lt;/p&gt;
&lt;p&gt;The Python code looks really long, but don’t get intimidated; it’s mostly boilerplate.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_3_0" name="__tabs_3" type="radio"/&gt;
&lt;label for="__tab_3_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dual&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Overload basic operators&lt;/span&gt;
    &lt;span class="c1"&gt;# Copying these to the "r" functions ensures that a mixed expression can be&lt;/span&gt;
    &lt;span class="c1"&gt;# computed regardless of the order of arguments (Real+Dual / Dual+Real)&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__add__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;isinstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="fm"&gt;__radd__&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="fm"&gt;__add__&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__sub__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;isinstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__rsub__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__mul__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;isinstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="fm"&gt;__rmul__&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="fm"&gt;__mul__&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__truediv__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;isinstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__rtruediv__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__truediv__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__pow__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="c1"&gt;# For human-readable representation&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__repr__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;repr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s1"&gt;' + '&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;repr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s1"&gt;'ϵ'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_3_1" name="__tabs_3" type="radio"/&gt;
&lt;label for="__tab_3_1"&gt;Julia&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;# taken from Alan's notebook&lt;/span&gt;
&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Base&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;convert&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;promote_rule&lt;/span&gt;

&lt;span class="n"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;:&lt;/span&gt; &lt;span class="kt"&gt;Number&lt;/span&gt;  &lt;span class="c"&gt;# D is a function-derivative pair&lt;/span&gt;
    &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;Tuple&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="kt"&gt;Float64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="kt"&gt;Float64&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;

&lt;span class="c"&gt;# Overload basic operators&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;.+&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;.-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])))&lt;/span&gt;
&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c"&gt;# Convert(D, 3)&lt;/span&gt;
&lt;span class="n"&gt;convert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;Type&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;Real&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;zero&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="c"&gt;# Operations with a dual number and a real number return a dual value&lt;/span&gt;
&lt;span class="n"&gt;promote_rule&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;Type&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt; &lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;Type&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;:&lt;/span&gt;&lt;span class="kt"&gt;Number&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;
&lt;span class="c"&gt;# For human-readable representation&lt;/span&gt;
&lt;span class="n"&gt;Base&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;io&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;IO&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;io&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="s"&gt;" + "&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="s"&gt;"ϵ"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;I think it’s noteworthy how short the Julia code is, even beyond Alan’s use of single-letter variables, for accomplishing the same thing (with the exception of accepting &lt;code class="highlight"&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/code&gt; and returning &lt;code class="highlight"&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/code&gt;, which I’m sure is also possible). It’s almost like halfway between Python and Clojure! (And it almost makes Python look like Java 😆)&lt;/p&gt;
&lt;p&gt;Let’s play around a bit.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_4_0" name="__tabs_4" type="radio"/&gt;
&lt;label for="__tab_4_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Complete input&lt;/span&gt;
&lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                &lt;span class="c1"&gt;# 3.0 + 5.0ϵ&lt;/span&gt;
&lt;span class="c1"&gt;# Real-only input&lt;/span&gt;
&lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                   &lt;span class="c1"&gt;# 3.0 + 0.0ϵ&lt;/span&gt;
&lt;span class="c1"&gt;# Confirming the characteristic property of ϵ&lt;/span&gt;
&lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;           &lt;span class="c1"&gt;# 0.0 + 0.0ϵ&lt;/span&gt;
&lt;span class="c1"&gt;# Random arithmetic&lt;/span&gt;
&lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# 12.0 + 64.0ϵ&lt;/span&gt;
&lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;            &lt;span class="c1"&gt;# 5.0 + 2.0ϵ&lt;/span&gt;
&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;           &lt;span class="c1"&gt;# 1.4 + -8.4ϵ  &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_4_1" name="__tabs_4" type="radio"/&gt;
&lt;label for="__tab_4_1"&gt;Julia&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;# Complete input&lt;/span&gt;
&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;                &lt;span class="c"&gt;# 3.0 + 5.0ϵ&lt;/span&gt;
&lt;span class="c"&gt;# Convert real numbers to dual numbers&lt;/span&gt;
&lt;span class="n"&gt;convert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c"&gt;# Confirming the characteristic property of ϵ&lt;/span&gt;
&lt;span class="c"&gt;# Note that Julia doesn't require ^ to be explicitly defined!&lt;/span&gt;
&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;           &lt;span class="c"&gt;# 0.0 + 0.0ϵ&lt;/span&gt;
&lt;span class="c"&gt;# Random arithmetic&lt;/span&gt;
&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  &lt;span class="c"&gt;# 12.0 + 64.0ϵ&lt;/span&gt;
&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;            &lt;span class="c"&gt;# 5.0 + 2.0ϵ&lt;/span&gt;
&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;           &lt;span class="c"&gt;# 1.4 + -8.4ϵ  &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id="ready-for-liftoff"&gt;Ready for liftoff&lt;/h2&gt;
&lt;p&gt;This makes it quite simple to do more sophisticated things with dual numbers, because our classes work with just the salient parts: the real and dual components. The &lt;span class="math"&gt;\(+\)&lt;/span&gt; and &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; are just there for decoration.&lt;/p&gt;
&lt;p&gt;What that means is when we input a &lt;code class="highlight"&gt;Dual(my_real, 1)&lt;/code&gt; into &lt;code class="highlight"&gt;my_func(x)&lt;/code&gt;, we get another &lt;code class="highlight"&gt;Dual(dual, real)&lt;/code&gt; back. The &lt;code class="highlight"&gt;real&lt;/code&gt; component of this &lt;code class="highlight"&gt;Dual&lt;/code&gt; result is the value of &lt;code class="highlight"&gt;my_func(my_real)&lt;/code&gt;. The &lt;code class="highlight"&gt;dual&lt;/code&gt; component of the result (which is just a &lt;code class="highlight"&gt;float&lt;/code&gt;, not another &lt;code class="highlight"&gt;Dual&lt;/code&gt;) is the derivative of &lt;code class="highlight"&gt;my_func(x)&lt;/code&gt; at &lt;code class="highlight"&gt;my_real&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The code is simpler than the explanation:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_5_0" name="__tabs_5" type="radio"/&gt;
&lt;label for="__tab_5_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;auto_diff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_5_1" name="__tabs_5" type="radio"/&gt;
&lt;label for="__tab_5_1"&gt;Julia&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;function&lt;/span&gt; &lt;span class="n"&gt;AutoDiff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Let’s start with a softball. How about &lt;span class="math"&gt;\(f'(2)\)&lt;/span&gt; if &lt;span class="math"&gt;\(f(x) = x^2\)&lt;/span&gt;?&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_6_0" name="__tabs_6" type="radio"/&gt;
&lt;label for="__tab_6_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;auto_diff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;    &lt;span class="c1"&gt;# 4.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_6_1" name="__tabs_6" type="radio"/&gt;
&lt;label for="__tab_6_1"&gt;Julia&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;AutoDiff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Not bad! How about &lt;span class="math"&gt;\(f'(10)\)&lt;/span&gt; if &lt;span class="math"&gt;\(f(x) = x^{\sqrt e} + x^{\sqrt \pi}\)&lt;/span&gt;?&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_7_0" name="__tabs_7" type="radio"/&gt;
&lt;label for="__tab_7_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;math&lt;/span&gt;
&lt;span class="n"&gt;auto_diff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pi&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# 17.839035180965308&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;And how about &lt;span class="math"&gt;\(f'(\pi)\)&lt;/span&gt; if &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; is the Babylonian square root (&lt;span class="math"&gt;\(\frac{t + \frac{x}{t}}{2}\)&lt;/span&gt;)? The wild thing is that we can actually compute the derivative with more and more precision by increasing the number of iterations of the original function.&lt;/p&gt;
&lt;p&gt;(Hmm, that sounds vaguely akin to gradient descent… 🤔)&lt;/p&gt;
&lt;p&gt;Let’s modify &lt;code class="highlight"&gt;auto_diff&lt;/code&gt; to allow this, and then iteratively show more and more precise values for &lt;span class="math"&gt;\(f(\pi)\)&lt;/span&gt; and &lt;span class="math"&gt;\(f'(\pi)\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_8_0" name="__tabs_8" type="radio"/&gt;
&lt;label for="__tab_8_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;auto_diff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Dual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;func&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;bab_root&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;iters&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;deriv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;auto_diff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bab_root&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;iters&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"{func}, {deriv}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_8_1" name="__tabs_8" type="radio"/&gt;
&lt;label for="__tab_8_1"&gt;Julia&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;function&lt;/span&gt; &lt;span class="n"&gt;AutoDiff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt; &lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;
    &lt;span class="n"&gt;func&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Babylonian&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;π&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;deriv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AutoDiff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Babylonian&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;π&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;println&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"&lt;/span&gt;&lt;span class="si"&gt;$&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s"&gt;, &lt;/span&gt;&lt;span class="si"&gt;$&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;deriv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;What is impressive is that not only does this &lt;em&gt;work&lt;/em&gt;, it’s also more manageable, computationally faster, and more accurate to take derivatives this way. I won’t bore you with the evidence (you can check other blogs for that) because I’m mostly interested in the math behind this.&lt;/p&gt;
&lt;p&gt;Plus, I can already believe that this is a better way. The only thing is that it’s a black box; you can’t see the general derivative &lt;span class="math"&gt;\(f'(x)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Or can you?&lt;/p&gt;
&lt;h2 id="automatic-symbolic-differentiation"&gt;Automatic symbolic differentiation?&lt;/h2&gt;
&lt;p&gt;Thanks to Alan’s notebook, I discovered SymPy, which can generate properly typeset &lt;span class="math"&gt;\(\LaTeX\)&lt;/span&gt; &lt;em&gt;directly from your code&lt;/em&gt; and manipulate variables like &lt;span class="math"&gt;\(x\)&lt;/span&gt; as symbols rather than values!&lt;/p&gt;
&lt;p&gt;I tried to hack SymPy’s &lt;code class="highlight"&gt;ImaginaryUnit&lt;/code&gt; class to implement a symbolic version of dual numbers, but I was too unfamiliar with it to get any results (everything was coming back zero). So to demonstrate this, I’m going to jump ahead a bit and use Julia’s built-in &lt;code class="highlight"&gt;diff&lt;/code&gt; function.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;# Pkg.add("SymPy")  # if you don't already have it&lt;/span&gt;
&lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;SymPy&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;symbols&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"x"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;
    &lt;span class="n"&gt;display&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;simplify&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Babylonian&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;
    &lt;span class="n"&gt;display&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;simplify&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;diff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;simplify&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Babylonian&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Watch what happens as we do successive iterations of the function &lt;code class="highlight"&gt;Babylonian&lt;/code&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{gathered}
\frac{x}{2} + \frac{1}{2} \\[0.8em]
\frac{x + \frac{\left(x + 1\right)^{2}}{4}}{x + 1} \\[1em]
\frac{x^{4} + 28 x^{3} + 70 x^{2} + 28 x + 1}{8 \left(x^{3} + 7 x^{2} + 7 x + 1\right)} \\[1em]
\frac{x^{8} + 120 x^{7} + 1820 x^{6} + 8008 x^{5} + 12870 x^{4} + 8008 x^{3} + 1820 x^{2} + 120 x + 1}{16 \left(x^{7} + 35 x^{6} + 273 x^{5} + 715 x^{4} + 715 x^{3} + 273 x^{2} + 35 x + 1\right)}
\end{gathered} $$&lt;/div&gt;
&lt;p&gt;Watch what happens as we do successive iterations of its derivative:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{gathered}
\frac{1}{2} \\[0.8em]
\frac{x^{2} + 2 x + 5}{4 \left(x^{2} + 2 x + 1\right)} \\[1em]
\frac{x^{6} + 14 x^{5} + 147 x^{4} + 340 x^{3} + 375 x^{2} + 126 x + 21}{8 \left(x^{6} + 14 x^{5} + 63 x^{4} + 100 x^{3} + 63 x^{2} + 14 x + 1\right)}
\end{gathered} $$&lt;/div&gt;
&lt;p&gt;Once you go beyond the third iteration, the polynomial expression of the derivative of the Babylonian square root function explodes to a length that is way beyond any computer monitor (and I can’t get the &lt;span class="math"&gt;\(\KaTeX\)&lt;/span&gt; renderer to do line-wrapping), so you’ll have to be convinced by this.&lt;/p&gt;
&lt;p&gt;It should be noted that this is &lt;em&gt;not&lt;/em&gt; what the computer is doing in order to &lt;code class="highlight"&gt;diff&lt;/code&gt; our function, but it &lt;em&gt;is&lt;/em&gt; what &lt;em&gt;we&lt;/em&gt; would have to do by hand if&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We wanted an exact answer, but&lt;/li&gt;
&lt;li&gt;Our &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; couldn’t be differentiated with simple rules like the power rule, and&lt;/li&gt;
&lt;li&gt;Dual numbers didn’t exist.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Imagine!&lt;/p&gt;
&lt;h1 id="automatic-differentiation"&gt;Automatic differentiation&lt;/h1&gt;
&lt;p&gt;It’s showtime.&lt;/p&gt;
&lt;h2 id="out-of-the-box-solutions"&gt;Out-of-the-box solutions&lt;/h2&gt;
&lt;p&gt;Earlier, I hinted at the relevance of automatic differentiation to gradient descent. Indeed, it is &lt;em&gt;hugely relevant&lt;/em&gt; to gradient descent, and thus to machine learning more generally. It should come as no surprise, then, that major machine learning libraries like PyTorch and Google-backed TensorFlow leverage it heavily.&lt;/p&gt;
&lt;p&gt;You can go &lt;em&gt;really&lt;/em&gt; deep with this stuff, but for the purposes of this blog post (and where I’m at in my studies of all this), it’s enough just to get automatic differentiation working out of the box in Python (with &lt;code class="highlight"&gt;Autograd&lt;/code&gt;) and Julia (with &lt;code class="highlight"&gt;ForwardDiff&lt;/code&gt;).&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_9_0" name="__tabs_9" type="radio"/&gt;
&lt;label for="__tab_9_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;autograd.numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;autograd&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;grad&lt;/span&gt;

&lt;span class="c1"&gt;# Our DIY version&lt;/span&gt;
&lt;span class="n"&gt;auto_diff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bab_root&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# 0.35355339059327373&lt;/span&gt;

&lt;span class="c1"&gt;# Autograd version&lt;/span&gt;
&lt;span class="n"&gt;dbab_root&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;grad&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bab_root&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;dbab_root&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;2.&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;           &lt;span class="c1"&gt;# 0.35355339059327373&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_9_1" name="__tabs_9" type="radio"/&gt;
&lt;label for="__tab_9_1"&gt;Julia&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;# Pkg.add("ForwardDiff") # if you don't have it&lt;/span&gt;
&lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;ForwardDiff&lt;/span&gt;

&lt;span class="c"&gt;# Our DIY version&lt;/span&gt;
&lt;span class="n"&gt;AutoDiff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Babylonian&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                      &lt;span class="c"&gt;# 0.3535533905932738&lt;/span&gt;

&lt;span class="c"&gt;# ForwardDiff version&lt;/span&gt;
&lt;span class="n"&gt;ForwardDiff&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;derivative&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;Babylonian&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c"&gt;# 0.35355339059327373&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Cool! It works out of the box—no fiddling with making dual number classes. That’s been done for us (and done more comprehensively and faster too).&lt;/p&gt;
&lt;p&gt;Now, we got &lt;code class="highlight"&gt;grad&lt;/code&gt; to auto-differentiate &lt;code class="highlight"&gt;bab_root&lt;/code&gt; for us, a function &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; that accepts a scalar and returns a scalar, &lt;span class="math"&gt;\(f'(x)\)&lt;/span&gt;.&lt;/p&gt;
&lt;h2 id="epsilon-in-the-cost-function"&gt;&lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; in the cost function&lt;/h2&gt;
&lt;p&gt;Can &lt;code class="highlight"&gt;grad&lt;/code&gt; auto-gradiate(?) the cost function &lt;span class="math"&gt;\(J(\theta)\)&lt;/span&gt; of &lt;a href="/from-zero-to-ero#convergence-threshold"&gt;our linear regression model from before&lt;/a&gt;, finding multiple partial derivatives in one swoop?&lt;/p&gt;
&lt;p&gt;Let’s first take a step back and think about what we’re actually doing here.&lt;/p&gt;
&lt;p&gt;Our cost function &lt;span class="math"&gt;\(J(\theta)\)&lt;/span&gt; takes a vector of weights &lt;span class="math"&gt;\(\theta\)&lt;/span&gt;. The cost function returns a vector where each value indicates how “off” the model is due to each weight.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
J(θ) &amp;amp;= \frac{1}{2m}\sum_{i=1}^m{\Big[h_θ(x^i) - y_i\Big]}^2 \\
&amp;amp;= \frac{1}{2m} \Big[\vec o^T (h_θ{\textbf X} - \vec y)\Big]^2
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;In this case, there are 6 weights (5 features + the bias), so &lt;span class="math"&gt;\(J(\theta)\)&lt;/span&gt; has 6 components.&lt;/p&gt;
&lt;p&gt;The partial derivatives of &lt;span class="math"&gt;\(J(\theta)\)&lt;/span&gt; takes the same vector of weights and return the gradient &lt;span class="math"&gt;\(\nabla J\)&lt;/span&gt;, which is a vector where each value indicates the “velocity” of each misestimation due to the corresponding weight. (Returning to the coffee mug analogy, the gradient tells us the slope in each dimension &lt;span class="math"&gt;\(x, y, z\)&lt;/span&gt; at our current point on the coffee mug.)&lt;/p&gt;
&lt;div class="math"&gt;$$ \frac{\partial J(θ)}{\partial θ_j} = \frac{1}{m}\sum_{i=1}^m\Big[h_θ(x^i) - y_i\Big]x_j^i $$&lt;/div&gt;
&lt;p&gt;These “velocities” tell us how to change our weights so that we can get a little closer to the minimum of the function (convergence, or the bottom of the mug).&lt;/p&gt;
&lt;p&gt;When we did this before, we still had to find the partial derivatives manually, even though we did use matrix operations to streamline it all a bit:&lt;/p&gt;
&lt;div class="math"&gt;$$
\nabla J = \begin{bmatrix}
  \frac{1}{m} \sum_{i=1}^m x_0^i{(e_1)}^2 \\[0.5em]
  \frac{1}{m} \sum_{i=1}^m x_1^i{(e_1)}^2 \\[0.5em]
  \vdots \\[0.5em]
  \frac{1}{m} \sum_{i=1}^m x_n^i{(e_1)}^2
\end{bmatrix} $$&lt;/div&gt;
&lt;p&gt;What we are asking now is: Can we get the velocities straight from the cost function without explicitly doing any math to find partial derivatives?&lt;/p&gt;
&lt;p&gt;That is, can we write code to do &lt;span class="math"&gt;\(J(\theta + \epsilon)\)&lt;/span&gt;?&lt;/p&gt;
&lt;div class="math"&gt;$$
\theta = \begin{bmatrix}
  \theta_0 \\ \theta_1 \\ \vdots \\ \theta_n
\end{bmatrix} \qquad
\theta + \epsilon = \begin{bmatrix}
  \theta_0 + \epsilon \\ \theta_1 + \epsilon \\ \vdots \\ \theta_n + \epsilon
\end{bmatrix}
$$&lt;/div&gt;
&lt;p&gt;Spoiler alert: The answer is &lt;em&gt;yes&lt;/em&gt;!&lt;/p&gt;
&lt;h2 id="making-the-loopless-loop-mathless-too"&gt;Making the loopless loop mathless, too?&lt;/h2&gt;
&lt;p&gt;Let’s get our setup going again.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt;

&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sklearn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;make_regression&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hstack&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# padding for bias column&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# this just fixes a quirk of sklearn's output&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After much trial and error, it seems to me that &lt;code class="highlight"&gt;grad&lt;/code&gt; can only take one argument. Mathematically, this makes sense.&lt;/p&gt;
&lt;p&gt;This will require re-working the code a little bit, since I originally wrote it in a way that was more modular but also required more variables (Clojure thinking pattern, perhaps?).&lt;/p&gt;
&lt;p&gt;Also, I learned that &lt;code class="highlight"&gt;numpy&lt;/code&gt; has a built-in &lt;code class="highlight"&gt;mean()&lt;/code&gt; method, which makes it possible to simplify the cost function by quite a bit (eliminating the need for the &lt;code class="highlight"&gt;ones&lt;/code&gt; vector and the &lt;code class="highlight"&gt;num_samples&lt;/code&gt; variables), and make it very readable.&lt;/p&gt;
&lt;p&gt;I suppose that since we’re doing automatic differentiation, we don’t need the &lt;code class="highlight"&gt;cost&lt;/code&gt; value to be divided by 2, since the original purpose of that was to make the symbolic differentiation easier.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;/span&gt;    &lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
&lt;span class="hll"&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/span&gt;
&lt;span class="n"&gt;dummy_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dummy_weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;     &lt;span class="c1"&gt;# a big number. I got 7177.83591830956&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To take this to the next level, just &lt;em&gt;one line&lt;/em&gt; is needed!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;dcost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;grad&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# returns a new function&lt;/span&gt;
&lt;span class="n"&gt;dcost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dummy_weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Returns a vector of values for each weight. I got this:&lt;/span&gt;
&lt;span class="c1"&gt;# array([[  7.68455105],&lt;/span&gt;
&lt;span class="c1"&gt;#        [-70.49488731],&lt;/span&gt;
&lt;span class="c1"&gt;#        [-77.80611382],&lt;/span&gt;
&lt;span class="c1"&gt;#        [-40.00725071],&lt;/span&gt;
&lt;span class="c1"&gt;#        [  5.90183055],&lt;/span&gt;
&lt;span class="c1"&gt;#        [ -3.48617932]])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Amazing! Now we should be able to rewrite the &lt;code class="highlight"&gt;train_model&lt;/code&gt; function a bit.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;train_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.001&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;last_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="c1"&gt;# just to know the value; not critical for training&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="hll"&gt;        &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;dcost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;        &lt;span class="n"&gt;this_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;this_cost&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;last_cost&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;break&lt;/span&gt;
        &lt;span class="n"&gt;last_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;this_cost&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Completed {epochs} epochs of training."&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="hll"&gt;    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Final cost: {cost(weights)}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;

&lt;span class="n"&gt;train_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Completed 699 epochs of training.&lt;/span&gt;
&lt;span class="c1"&gt;# Final cost: 0.06114217689306121&lt;/span&gt;
&lt;span class="c1"&gt;# array([[-0.09259437],&lt;/span&gt;
&lt;span class="c1"&gt;#        [81.0788861 ],&lt;/span&gt;
&lt;span class="c1"&gt;#        [88.26630974],&lt;/span&gt;
&lt;span class="c1"&gt;#        [43.93549829],&lt;/span&gt;
&lt;span class="c1"&gt;#        [ 4.96655198],&lt;/span&gt;
&lt;span class="c1"&gt;#        [ 2.08424121]])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;🔥🔥🔥&lt;/p&gt;
&lt;p&gt;And that’s it for this post. Stay tuned for more!&lt;/p&gt;
&lt;h1 id="summary"&gt;Summary&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;autograd.numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt; &lt;span class="c1"&gt;# use instead of normal numpy&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;autograd&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;grad&lt;/span&gt;
&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt;

&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sklearn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;make_regression&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hstack&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# padding for bias column&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# this just fixes a quirk of sklearn's output&lt;/span&gt;

&lt;span class="hll"&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;/span&gt;    &lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
&lt;span class="hll"&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/span&gt;
&lt;span class="n"&gt;dcost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;grad&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# returns a new function&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;train_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.001&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;last_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="c1"&gt;# just to know the value; not critical for training&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="hll"&gt;        &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;dcost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;        &lt;span class="n"&gt;this_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;this_cost&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;last_cost&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;break&lt;/span&gt;
        &lt;span class="n"&gt;last_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;this_cost&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Completed {epochs} epochs of training."&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="hll"&gt;    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Final cost: {cost(weights)}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;

&lt;span class="n"&gt;train_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id="references"&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Automatic differentiation in 10 minutes with Julia (&lt;a href="https://www.youtube.com/watch?v=vAp6nUMrKYg"&gt;video&lt;/a&gt; / &lt;a href="https://nbviewer.jupyter.org/github/alanedelman/YouTubeNotebooks/blob/master/Automatic%20Differentiation%20in%2010%20Minutes.ipynb"&gt;notebook&lt;/a&gt;), Alan Edelman&lt;/li&gt;
&lt;li&gt;Automatic differentiation in Ruby (&lt;a href="https://www.youtube.com/watch?v=TI7mtWB4WiA"&gt;video&lt;/a&gt; / &lt;a href="https://github.com/tomstuart/dual_number"&gt;code&lt;/a&gt;), Tom Stuart&lt;/li&gt;
&lt;li&gt;&lt;a href="http://eviatarbach.com/2013/05/13/dual-numbers-and-automatic-differentiation/"&gt;Dual numbers and automatic differentiation&lt;/a&gt;, Eviatar Bach&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/HIPS/autograd/blob/master/docs/tutorial.md"&gt;Autograd tutorial&lt;/a&gt;, Autograd docs&lt;/li&gt;
&lt;/ul&gt;</content><category term="dual numbers"></category><category term="automatic differentiation"></category><category term="machine learning"></category></entry><entry><title>Model Thinker notes, Ch. 2 and 3</title><link href="http://tabidots.github.io/2019/01/model-thinker-notes-chapters-2-3" rel="alternate"></link><published>2019-01-20T10:30:47+07:00</published><updated>2019-01-20T10:30:47+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-01-20:/2019/01/model-thinker-notes-chapters-2-3</id><summary type="html">&lt;p&gt;Getting reacquainted with statistics for the first time since my ill-fated stint in introductory statistics in&amp;nbsp;college.&lt;/p&gt;</summary><content type="html">
&lt;p&gt;Along with &lt;a href="http://www.pimbook.org/"&gt;&lt;em&gt;A Programmer’s Introduction to Mathematics&lt;/em&gt;&lt;/a&gt;, I started reading &lt;a href="https://www.amazon.com/Model-Thinker-What-Need-Know/dp/0465094627/ref=zg_bs_13884_41?_encoding=UTF8&amp;amp;psc=1&amp;amp;refRID=ZK3QGA2250Q3CJSWR8Q2"&gt;&lt;em&gt;Model Thinker: What You Need to Know to Make Data Work for You&lt;/em&gt;&lt;/a&gt; as a sort of analogous non-statistician’s introduction to statistics.&lt;/p&gt;
&lt;p&gt;Or perhaps I should say &lt;em&gt;re&lt;/em&gt;-introduction, since I had to take Intro to Stats in college. But I passed that class by the skin of my teeth and really developed an aversion to statistical analysis from that course. But it’s a necessary part of data science, so…&lt;/p&gt;
&lt;h1 id="chapter-2"&gt;Chapter 2&lt;/h1&gt;
&lt;p&gt;Chapter 2 is about what models can do and their strength in numbers.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Models can take one of three approaches:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;embodiment&lt;/em&gt; approach (simplified but still realistic, like a geological model)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;analogy&lt;/em&gt; approach (abstracted from reality: &lt;em&gt;Think of the situation as a…&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;alternative reality&lt;/em&gt; approach&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Models must be &lt;em&gt;communicable&lt;/em&gt; and &lt;em&gt;tractable&lt;/em&gt; (analyzable). This means that it should be possible to translate them precisely into math, code, or some other formal language. (Most models are mathematical in nature, but this is not a must.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;All models are wrong in their own way, so no single model can accurately represent complex phenomena, but many, together, are useful.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Models are a superhero &lt;em&gt;&lt;span class="caps"&gt;REDCAPE&lt;/span&gt;&lt;/em&gt;: Reason, explain, design, communicate, action, predict, explore.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Many models can be applied to the same problem (many-to-one). And with &lt;em&gt;creativity&lt;/em&gt;, one model can also be put to many uses. For example, how many applications are there for a random walk? (What a relief to know that there is a place at the table for creativity and a non-&lt;span class="caps"&gt;STEM&lt;/span&gt; background!)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="chapter-3"&gt;Chapter 3&lt;/h1&gt;
&lt;p&gt;Chapter 3 is about how there is a Goldilocks-esque balance to be struck with regard to the diversity of models and the accuracy of any given model.&lt;/p&gt;
&lt;p&gt;More is better, until it’s not; more accurate is better, until it’s not.&lt;/p&gt;
&lt;p&gt;The chapter uses some fancy-looking equations dressed up in terms that are specific to this context, but the equations are actually rooted in statistics and often have simpler, more intuitive explanations.&lt;/p&gt;
&lt;h2 id="diversity"&gt;Diversity&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Condorcet jury theorem&lt;/strong&gt;: If all jury members in a case have an above-average probability of choosing the correct verdict, then each successive jury member after the first increases the probability of the whole jury choosing the correct verdict. The probability approaches 1 as you keep adding members.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Wisdom of the crowd&lt;/strong&gt;: The author’s &lt;em&gt;model diversity theorem&lt;/em&gt; is an adaptation of &lt;a href="https://www.archania.org/theorems/diversity/"&gt;the wisdom of the crowd theorem&lt;/a&gt;, and it uses the &lt;em&gt;error&lt;/em&gt; as we calculated in linear regression. (Actually, all of the equations in this chapter are based on a mean squared error of some sort.) The book presents it as follows:
  &lt;br/&gt;
&lt;div class="math"&gt;$$ \underbrace{(\bar{M} - V)^2}_{\textrm{Many-Model Error}} =
  \underbrace{\sum_{i=1}^N \frac{(M_i - V)^2}{N}}_{\textrm{Average-Model Error}} -
  \underbrace{\textcolor{teal}{\sum_{i=1}^N} \frac{\textcolor{teal}{(M_i - \bar{M})^2}}{N}}_{\textrm{Diversity of Model Predictions}} $$&lt;/div&gt;
&lt;br/&gt;
  where &lt;span class="math"&gt;\(M_i\)&lt;/span&gt; is the prediction of model &lt;span class="math"&gt;\(i\)&lt;/span&gt;, &lt;span class="math"&gt;\(\bar{M}\)&lt;/span&gt; is the average value of all models, and &lt;span class="math"&gt;\(V\)&lt;/span&gt; is the true value. In other words,&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;if you have only one model (&lt;span class="math"&gt;\(M_i = \bar{M}\)&lt;/span&gt;), you can never decrease the discrepancy between its prediction and truth.&lt;/li&gt;
&lt;li&gt;Even if you have many models that make identical predictions (still &lt;span class="math"&gt;\(M_i = \bar{M}\)&lt;/span&gt;), they will collectively misestimate truth by as much as each one misestimates truth.&lt;/li&gt;
&lt;li&gt;However, as the models’ predictions diverge from each other (that is, as &lt;span class="math"&gt;\(\color{teal}\sum_{i=1}^N (M_i - \bar{M})^2\)&lt;/span&gt; increases), their &lt;em&gt;collective misestimation&lt;/em&gt; goes on decreasing. This is similar to the Condorcet jury theorem, except in continuous rather than binary terms.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;However, there is a diminishing rate of returns as you &lt;em&gt;include more models&lt;/em&gt;: Accuracy seems to converge on a limit of some sort, not unlike gradient descent. Conceived in that way, you should stop adding models once the error between &lt;span class="math"&gt;\(n\)&lt;/span&gt; models and &lt;span class="math"&gt;\(n-1\)&lt;/span&gt; models is lower than some &lt;a href="/2019/01/from-zero-to-ero"&gt;&lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; threshold value&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Why is this the case? Diversity is a factor of the data’s dimensionality. Models using the same (or similar) subsets of salient features are liable to predict similarly.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There is a limit to how independent (&lt;em&gt;accurate&lt;/em&gt; and &lt;em&gt;diverse&lt;/em&gt;) a given group of models can be. Accuracy may suffer as a result of artificially trying to increase diversity (categorizing a list of locations by alphabetical order, for example).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="accuracy"&gt;Accuracy&lt;/h2&gt;
&lt;p&gt;Increasing the fit (and thus predictive accuracy) of a model by increasing its granularity (adding categories, features, etc.) can backfire after a certain point.&lt;/p&gt;
&lt;p&gt;The rest of the chapter is a long and slightly overly complicated explanation of the what statisticians call the &lt;strong&gt;bias-variance tradeoff&lt;/strong&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The relationship between bias and variance is similar to the relationship between &lt;em&gt;precision&lt;/em&gt; and &lt;em&gt;recall&lt;/em&gt; for binary classification. Ideal B-V are both as low as possible; ideal P-R are both as high as possible. However, they have a diametrically opposing relationship, so this is not actually feasible.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="bias"&gt;Bias&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;High &lt;strong&gt;bias&lt;/strong&gt; ⟶ underfitting (model is too coarse to capture the general trend of the data). &lt;img alt="underfitting" src="../../images/underfitting.png"/&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Source for this illustration and the following ones: &lt;a href="https://medium.freecodecamp.org/using-machine-learning-to-predict-the-quality-of-wines-9e2e13d7480d"&gt;FreeCodeCamp&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the context of the chapter’s house price example, high bias is also called &lt;strong&gt;categorization error&lt;/strong&gt;. This is the discrepancy between the samples in each category and the mean of that category.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bias (categorization error) ↑ if your categories are bad and don’t accurately reflect any shared characteristics among the samples. This makes sense because in terms of a scatter plot, the data points in each category will be spread out randomly and have no trend. In terms of house prices, this could be like lumping real estate markets of states that begin with the same letter together.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bias (categorization error) ↓ as category granularity ↑ (gets more precise)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bias (categorization error) also ↓ as sample size ↑, because the law of large numbers dictates that a larger number of samples in a category will tend toward the mean of that category. This makes sense because more data points should more clearly indicate a trend for the model to follow.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="variance"&gt;Variance&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;High &lt;strong&gt;variance&lt;/strong&gt; ⟶ overfitting (model is so fine that it starts to capture noise in the data, or in other words, every little &lt;em&gt;variation&lt;/em&gt;).
&lt;img alt="overfitting" src="../../images/underfitting.png"/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the context of the chapter’s house price example, high bias is also called &lt;strong&gt;valuation error&lt;/strong&gt;. This is the total discrepancy between the estimated category means and the actual category means.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Variance (valuation error) ↓ as categories get larger, again because of the law of large numbers.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="we-all-want-what-we-cant-have"&gt;We all want what we can’t have&lt;/h2&gt;
&lt;p&gt;We want low variance and low bias:
&lt;img alt="good fit" src="../../images/goodfit.png"/&gt;&lt;/p&gt;
&lt;p&gt;But decreasing variance increases bias, and decreasing bias increases variance. So good luck with that.&lt;/p&gt;
&lt;h2 id="a-more-intuitive-explanation-of-r2"&gt;A more intuitive explanation of &lt;span class="math"&gt;\(R^2\)&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;There are many ways to measure a model’s accuracy, and there is a sidebar mentioning &lt;span class="math"&gt;\(R^2\)&lt;/span&gt;, which quantifies the predictive accuracy of a regression model. However, it doesn’t explain it anywhere near as intuitively as illustration on Wikipedia:&lt;/p&gt;
&lt;p&gt;&lt;img alt="R² image" src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/86/Coefficient_of_Determination.svg/640px-Coefficient_of_Determination.svg.png" title="By Orzetto - Own work, CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=11398293"/&gt;&lt;/p&gt;
&lt;p&gt;The chapter’s definition of &lt;span class="math"&gt;\(R^2\)&lt;/span&gt; is a pretty common one: &lt;em&gt;The proportion of variance explained by the model&lt;/em&gt;. That’s pretty abstract.&lt;/p&gt;
&lt;p&gt;A more intuitive explanation, based on the above illustration, is: &lt;em&gt;How much better is a prediction made with your model than just taking the average of the data?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;You want the total area of the blue squares (including overlaps) to be as small as possible compared to the total area of the red squares (including overlaps).&lt;/p&gt;
&lt;h2 id="model-error-decomposition-theorem"&gt;Model error decomposition theorem&lt;/h2&gt;
&lt;p&gt;The problem with a score like &lt;span class="math"&gt;\(R^2\)&lt;/span&gt; is that it doesn’t tell you how much of the error is due to bias and how much is due to variance. I suppose that might be helpful if you know exactly how to fine-tune one or the other.&lt;/p&gt;
&lt;p&gt;The author presents the &lt;strong&gt;model error decomposition theorem&lt;/strong&gt; to solve this problem.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{gathered}
\textrm{Model Error} = \textrm{Categorization Error} + \textrm{Valuation Error} \\
\underbrace{\sum_{x \in \textbf X} \Big(M(x) - V(x) \Big)^2}_\textrm{Model Error} =
\underbrace{\sum_{i=1}^n \sum_{x \in S_i} \Big(V(x) - V_i \Big)^2}_\textrm{Categorization Error} +
\underbrace{\sum_{i=1}^n \Big(M_i - V_i \Big)^2}_\textrm{Valuation Error}
\end{gathered} $$&lt;/div&gt;
&lt;p&gt;Lotta variables here.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;Variable&lt;/th&gt;
&lt;th align="left"&gt;Meaning&lt;/th&gt;
&lt;th align="left"&gt;Variable&lt;/th&gt;
&lt;th align="left"&gt;Meaning&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;span class="math"&gt;\(x\)&lt;/span&gt;&lt;/td&gt;
&lt;td align="left"&gt;sample&lt;/td&gt;
&lt;td align="left"&gt;&lt;span class="math"&gt;\(S_i\)&lt;/span&gt;&lt;/td&gt;
&lt;td align="left"&gt;category &lt;span class="math"&gt;\(i\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;span class="math"&gt;\(\textbf X\)&lt;/span&gt;&lt;/td&gt;
&lt;td align="left"&gt;dataset&lt;/td&gt;
&lt;td align="left"&gt;&lt;span class="math"&gt;\(M_i\)&lt;/span&gt;&lt;/td&gt;
&lt;td align="left"&gt;mean of model’s predictions for category &lt;span class="math"&gt;\(i\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;span class="math"&gt;\(M(x)\)&lt;/span&gt;&lt;/td&gt;
&lt;td align="left"&gt;model’s predicition for sample &lt;span class="math"&gt;\(x\)&lt;/span&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;span class="math"&gt;\(V_i\)&lt;/span&gt;&lt;/td&gt;
&lt;td align="left"&gt;mean of true values for category &lt;span class="math"&gt;\(i\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;span class="math"&gt;\(V(x)\)&lt;/span&gt;&lt;/td&gt;
&lt;td align="left"&gt;true value for sample &lt;span class="math"&gt;\(x\)&lt;/span&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Thus,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\textrm{Model Error}\)&lt;/span&gt;: sum discrepancy between model and truth for all samples&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\textrm{Categorization Error}\)&lt;/span&gt;: sum discrepancy between true values in a category and true mean of that category for all categories&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\textrm{Valuation Error}\)&lt;/span&gt;: sum discrepancy between predicted mean and true mean for all categories&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It seems like you could do &lt;span class="math"&gt;\(\sqrt{\textrm{Model Error}}\)&lt;/span&gt; to find a number the average amount that a prediction made with the model will be off by.&lt;/p&gt;
&lt;h1 id="references"&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://medium.freecodecamp.org/using-- machine-learning-to-predict-the-quality-of-wines-9e2e13d7480d"&gt;Using Machine Learning to Predict the Quality of Wines&lt;/a&gt;, FreeCodeCamp&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff"&gt;Bias-variance tradeoff&lt;/a&gt;, Wikipedia&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Coefficient_of_determination"&gt;Coefficient of determination&lt;/a&gt;, Wikipedia&lt;/li&gt;
&lt;/ul&gt;</content><category term="bias"></category><category term="variance"></category><category term="model error decomposition"></category><category term="predictive accuracy"></category><category term="R²"></category><category term="wisdom of the crowd"></category></entry><entry><title>From zero to “ε-ro”: Infinitesimals, floating-point, convergence, and random error</title><link href="http://tabidots.github.io/2019/01/from-zero-to-ero" rel="alternate"></link><published>2019-01-19T17:32:22+07:00</published><updated>2019-01-19T17:32:22+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-01-19:/2019/01/from-zero-to-ero</id><summary type="html">&lt;p&gt;Who knew so much could be said about a value so small? I didn’t even cover&amp;nbsp;everything!&lt;/p&gt;</summary><content type="html">
&lt;p&gt;One of the questions I left open from my blog’s inaugural post on linear regression was &lt;em&gt;How do you know when you’ve reached convergence?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;That led me to learning about &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; (epsilon), or I suppose re-learning, if you count high school calculus, in which I think it made a single brief appearance in the formal definition of limit.&lt;/p&gt;
&lt;p&gt;I’m going to take a rather circuitous route to explaining the role of &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; in linear regression, as I kept discovering interesting new things along the way.&lt;/p&gt;
&lt;p&gt;Hopefully your attention span is larger than the value of &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; (har har)!&lt;/p&gt;
&lt;h1 id="all-the-small-things"&gt;All the small things&lt;/h1&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; can be found in a variety of contexts, but it always represents an &lt;strong&gt;infinitesimal&lt;/strong&gt;: a quantity that it is infinitely small and basically zero, but not zero-y &lt;em&gt;enough&lt;/em&gt; to not exist.&lt;/p&gt;
&lt;p&gt;In high school calculus, &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; is the difference between&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the value of a function, &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt;, near its limit point, &lt;span class="math"&gt;\(x \rightarrow a\)&lt;/span&gt;, and&lt;/li&gt;
&lt;li&gt;the hypothetical value &lt;span class="math"&gt;\(L\)&lt;/span&gt; that the function appears to tend toward at the actual limit point &lt;span class="math"&gt;\(a\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As the distance between &lt;span class="math"&gt;\(x\)&lt;/span&gt; and &lt;span class="math"&gt;\(a\)&lt;/span&gt; (which is called &lt;span class="math"&gt;\(\delta\)&lt;/span&gt;, delta) shrinks, so does &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt;, so the upper bounds of the two quantities move in tandem.&lt;/p&gt;
&lt;p&gt;You can also use &lt;span class="math"&gt;\(\delta\)&lt;/span&gt; and &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; to describe derivatives; i.e., if &lt;span class="math"&gt;\(dx = \delta\)&lt;/span&gt; and &lt;span class="math"&gt;\(\frac{dy}{dx} = \epsilon\)&lt;/span&gt;, you can imagine how shrinking one shrinks the other, and more importantly, that the ideal value for both of them is &lt;em&gt;as close as you can get to zero without vanishing&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="derivative animation" src="../../images/derivative_animation.gif" title="source: https://sites.google.com/a/student.ashcoll.school.nz/bcashcoll/13-mac/differentiation-as-3-6-91578"/&gt;&lt;/p&gt;
&lt;h1 id="machine-epsilon"&gt;Machine epsilon&lt;/h1&gt;
&lt;p&gt;There is also a quantity that computer scientists call &lt;strong&gt;machine epsilon&lt;/strong&gt;, which defines the smallest number that a given computing environment can represent.&lt;/p&gt;
&lt;p&gt;It is the largest &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; that satisfies&lt;/p&gt;
&lt;div class="math"&gt;$$ 1 + \epsilon = 1 $$&lt;/div&gt;
&lt;p&gt;which looks like another math koan, or at least some Orwellian “newmath” like &lt;span class="math"&gt;\(2 + 2 = 5\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Actually, that &lt;span class="math"&gt;\(+\)&lt;/span&gt; should have a &lt;span class="math"&gt;\(\bigcirc\)&lt;/span&gt; around it: &lt;span class="math"&gt;\(\oplus\)&lt;/span&gt;, giving us&lt;/p&gt;
&lt;div class="math"&gt;$$ 1 \oplus \epsilon = 1 $$&lt;/div&gt;
&lt;p&gt;The &lt;span class="math"&gt;\(\oplus\)&lt;/span&gt; means &lt;em&gt;floating-point addition&lt;/em&gt;.  &lt;/p&gt;
&lt;p&gt;Now, in my programming life, I have not had a need for significant precision until now, with my new interest in fields that require numerical computing.&lt;/p&gt;
&lt;p&gt;I also started with Python (well, JavaScript if you go way back), so I never even really had to distinguish between &lt;code class="highlight"&gt;float&lt;/code&gt;s and &lt;code class="highlight"&gt;int&lt;/code&gt;s in my code—much less think about the consequences or even know the difference, really. I just knew that if you wanted a number with a decimal point, it had to be a &lt;code class="highlight"&gt;float&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Once you get into doing real math with computers, though, you can’t just keep &lt;code class="highlight"&gt;float&lt;/code&gt;ing along like that, because the limitations of machines come into play.&lt;/p&gt;
&lt;h2 id="floating-point-arithmetic"&gt;Floating-point arithmetic&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Floating-point arithmetic&lt;/em&gt; was devised because computer memory, especially in machines from the very early days of computing, can only allocate a finite amount of resources to data.&lt;/p&gt;
&lt;p&gt;Floating-point is basically scientific notation. Let’s consider the mass of a proton in scientific notation (this post isn’t about physics, but as an astoundingly small value, it’s a good example):&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned} &amp;amp; 0.0000000000000000000000000016726 \space \textrm{kg} \\
&amp;amp;= \underbrace{1.6726}_{\textrm{significand}} \times \underbrace{10}_{\textrm{base}}  \!\!\!\!^{\overbrace{-27}^{\textrm{exponent}}} \space \textrm{kg}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;The goal of scientific notation is to translate numbers of extreme magnitude into more human-friendly terms. But computers don’t operate like humans do. So how can we translate this number into &lt;em&gt;computer&lt;/em&gt;-friendly terms?&lt;/p&gt;
&lt;p&gt;First, computers use &lt;em&gt;binary&lt;/em&gt;, not base 10 (decimal system). Of course, we know that, but what does that actually mean? I always thought binary sequences were random collections of ones and zeros—as if computer programs were like canvasses assaulted by a digital Jackson Pollock armed with buckets of bits and bytes.&lt;/p&gt;
&lt;p&gt;&lt;img alt="binary counter" src="https://upload.wikimedia.org/wikipedia/commons/7/75/Binary_counter.gif" title="(source: Ephert [CC BY-SA 4.0] https://creativecommons.org/licenses/by-sa/4.0, from Wikimedia Commons)"/&gt;&lt;/p&gt;
&lt;p&gt;I am not well-versed enough in binary to explain this in words, but you can definitely see some sort of pattern in the movement of the values here.&lt;/p&gt;
&lt;p&gt;Anyway, let’s rewrite the mass of a proton in binary (scroll sideways, it’s a long one):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100001001000010
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And in binary scientific notation (sort of):&lt;/p&gt;
&lt;div class="math"&gt;$$ 1.00001001000010_{\textrm{bin}} \times 2^{-89} $$&lt;/div&gt;
&lt;p&gt;Almost there. Let’s take a look at how computers actually store floating-point numbers:&lt;/p&gt;
&lt;p&gt;&lt;img alt="64-bit floating point storage structure" src="https://upload.wikimedia.org/wikipedia/commons/a/a9/IEEE_754_Double_Floating_Point_Format.svg" title="source: Codekaizen - Own work, [CC BY-SA 4.0] https://commons.wikimedia.org/w/index.php?curid=3595583"/&gt;&lt;/p&gt;
&lt;p&gt;Every number is allocated 64 bits of memory (this can vary, but let’s stick with 64). There are 52 bits for the &lt;em&gt;mantissa&lt;/em&gt; (computer science term for significand), 11 for the exponent, and 1 for the sign (positve or negative). Each bit can be 1 or 0, which is the whole reason for using binary in the first place.&lt;/p&gt;
&lt;p&gt;Storing the mantissa, then, is just a matter of finding a way to fit the relevant sequence of ones and zeros into the 52 slots allocated for it. If there are too many digits, chop them off; if there are too few (as in this case), add padding. This is where floating-point differs from scientific notation.&lt;/p&gt;
&lt;div class="math"&gt;$$ 00000000 \space 00000000 \space 00000000 \space 00000000 \space
00000\textcolor{teal}{100 \space 00100100 \space 0010} \times 2^{-51} $$&lt;/div&gt;
&lt;p&gt;Looks like a lot of zeros. Incidentally, the method to obtain a base-10 number from this can be expressed mathematically in a cool way:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
&amp;amp; \Bigg(\sum_{n=0}^{p-1} \textrm{bit}_n \times 2^{-n} \Bigg) \times 2^e \\
&amp;amp;= (0 \times 2^{-0} + 0 \times 2^{-1} + 0 \times 2^{-2} + \cdots + 1 \times 2^{-50} + 0 \times 2^{-51}) \times 2^{-51} \\
&amp;amp;= (1 \times 2^{-37} + 1 \times 2^{-42} + 1 \times 2^{-45} + 1 \times 2^{-50}) \times 2^{-51}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(\textrm{bit}_n\)&lt;/span&gt; is the binary value of the bit at index &lt;span class="math"&gt;\(n\)&lt;/span&gt; (from the left, starting at 0), &lt;span class="math"&gt;\(p\)&lt;/span&gt; is the precision (number of bits), and &lt;span class="math"&gt;\(e\)&lt;/span&gt; is the exponent (which just happens to be &lt;span class="math"&gt;\(-51\)&lt;/span&gt; here; it has nothing to do with the number of bits for the mantissa).&lt;/p&gt;
&lt;p&gt;Okay, that was fun. Now what?&lt;/p&gt;
&lt;h2 id="rounding-errors"&gt;Rounding errors&lt;/h2&gt;
&lt;p&gt;&lt;img alt="xkcd comic" src="https://imgs.xkcd.com/comics/e_to_the_pi_minus_pi.png" title="XKCD #217 https://xkcd.com/217/"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If there are too many digits, chop them off&lt;/em&gt;. This opens up a big can of worms. Or an infinitesimal one, given the topic at hand (har har).&lt;/p&gt;
&lt;p&gt;In exchange for the computability (read: speed and power) and storeability of floating-point numbers, we have to accept a limit to their precision. The digits of &lt;span class="math"&gt;\(\pi\)&lt;/span&gt;, for example, repeat endlessly. We can’t expect a computer to handle them all, or a calculator, for that matter.&lt;/p&gt;
&lt;p&gt;Even totally pedestrian numbers like &lt;span class="math"&gt;\(\frac{1}{3}\)&lt;/span&gt; go on forever. This means that computers cannot reason about fractional quantities in the way that the human mind can.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
1 + \frac{1}{3} &amp;amp;= \frac{4}{3}_{\textrm{human}} \\[0.8em]
&amp;amp;= 1.333\overline{3}_{\textrm{dec}} \\
&amp;amp;= 1.1010\overline{10}_{\textrm{bin}}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;That is, unless you are working in some baller language like Clojure that has &lt;code class="highlight"&gt;Ratio&lt;/code&gt; data types:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_1_0" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_0"&gt;Clojure&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;        &lt;span class="c1"&gt;; 1/3&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;type&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;; clojure.lang.Ratio&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;/ &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  &lt;span class="c1"&gt;; 4/3&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_1" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_1"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# 1.3333333333333333&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Most languages seem to have implemented some sort of corrective mechanism that works in simple cases, but notice what happens with the following expressions in Python:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="c1"&gt;# 1.0&lt;/span&gt;
&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# 1.0&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;
&lt;span class="c1"&gt;# 0.9999999999999998&lt;/span&gt;
&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;
&lt;span class="c1"&gt;# False&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Keep in mind that we’re working in binary here. Unexpectedly (if you are not proficient in binary), many “simple” numbers that don’t repeat in decimal do in binary:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\frac{1}{10} &amp;amp;= 0.1_{\textrm{dec}} \\
&amp;amp;= 0.1100\overline{1100}_{\textrm{bin}}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;All of this leads to &lt;strong&gt;floating-point rounding errors&lt;/strong&gt; that can quickly snowball into massively erroneous output over many iterations. Here’s the example from the &lt;a href="https://youtu.be/8iGzBMboA0I?t=3247"&gt;Rachel Thomas lecture&lt;/a&gt;. Start with &lt;span class="math"&gt;\(x = \frac{1}{10}\)&lt;/span&gt; and keep applying the function to the output you get:&lt;/p&gt;
&lt;div class="math"&gt;$$ f(x) = \begin{cases}
2x     &amp;amp; \textrm{if } x \leq \frac{1}{2} \\
2x - 1 &amp;amp; \textrm{if } x &amp;gt; \frac{1}{2}
\end{cases} $$&lt;/div&gt;
&lt;p&gt;If you do this by hand you get&lt;/p&gt;
&lt;div class="math"&gt;$$ \{\tfrac{1}{10}, \tfrac{1}{5}, \tfrac{2}{5}, \tfrac{4}{5}, \tfrac{3}{5}, \overline{\tfrac{1}{5}, \tfrac{2}{5}, \tfrac{4}{5}, \tfrac{3}{5}}, \cdots\} $$&lt;/div&gt;
&lt;p&gt;but when you try to execute this on a computer:&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_2_0" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;80&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_2_1" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_1"&gt;Clojure&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;use&lt;/span&gt; &lt;span class="ss"&gt;'clojure.pprint&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;f&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;lt;= &lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;* &lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;- &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;* &lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;pprint&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;take &lt;/span&gt;&lt;span class="mi"&gt;80&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;iterate &lt;/span&gt;&lt;span class="nv"&gt;f&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;it doesn’t take long before the value converges on 1, which is very bizarre.&lt;/p&gt;
&lt;h2 id="granularity"&gt;Granularity&lt;/h2&gt;
&lt;p&gt;Limited storage space leads to limited precision. A related consequence of this is that floating-point numbers are discrete, not continuous like the number line we picture in our minds. (As a kid, I think I imagined a spectrum. Fun? Yes. Accurate? Not sure.) Computers are capable of pretty precise calculations, but not perfectly precise.&lt;/p&gt;
&lt;p&gt;Think of floating-point numbers like pixels. While it is true that computer displays have become less and less “pixelly-looking” over the years, and text rendered on a Retina screen can almost look like a printed page, we know that such output still consists of pixels.&lt;/p&gt;
&lt;p&gt;The same is true for floating-point numbers. They allow for some degree of precision, but the number line they form is more like a dotted line than a solid line. (Even stranger, the density of the line changes at different scales, but I’ll leave that one for someone else to explain!)&lt;/p&gt;
&lt;p&gt;Take the binary number &lt;code class="highlight"&gt;1.0&lt;/code&gt; (regular binary, not floating-point). This is equal to the decimal number 1 as well. If we keep moving the 1 to the right and adding zeros accordingly, the value is halved:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
1.0_\textrm{bin} = 1_\textrm{dec} \\
0.1_\textrm{bin} = \tfrac{1}{2}_\textrm{dec} \\
0.01_\textrm{bin} = \tfrac{1}{4}_\textrm{dec} \\
0.001_\textrm{bin} = \tfrac{1}{8}_\textrm{dec}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;It is pretty clear that with 52 slots for binary values, you are going to run out of room at some point—even with the orders-of-magnitude wiggle room that the exponent provides.&lt;/p&gt;
&lt;p&gt;This means that after enough iterations, a value can no longer be halved. &lt;em&gt;That unhalvable value&lt;/em&gt; is the smallest difference that that computing environment can represent, and it is the distance between a given number and its closest possible neighbor on the floating-point number line.&lt;/p&gt;
&lt;p&gt;You could think of that as the size of a ”number pixel.” The whole pixel has the value of (say) its left edge, and any quantity that falls within the space of the pixel gets rounded to the edge of that pixel or the next one.&lt;/p&gt;
&lt;p&gt;Machine epsilon, then, is the &lt;em&gt;largest quantity&lt;/em&gt; that is less than the width of a number pixel. So it makes sense, then, that &lt;span class="math"&gt;\(1 \oplus \epsilon = 1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;This means that machine epsilon is the &lt;em&gt;largest possible rounding error&lt;/em&gt; of a floating-point system.&lt;/p&gt;
&lt;p&gt;It also means that on our continuous human number line, as soon as you move &lt;em&gt;rightward&lt;/em&gt; of machine epsilon, you have entered the territory of the next machine-perceptible number. That is how machine epsilon defines the smallest possible difference that the system can represent.&lt;/p&gt;
&lt;h2 id="calculating-machine-epsilon"&gt;Calculating machine epsilon&lt;/h2&gt;
&lt;p&gt;Before I started writing this post, I just wanted to see the code to calculate machine epsilon. But I didn’t fully understand what was going on, and my dissatisfaction with that led me to go back through all the stuff I just explained. (Of course, it didn’t help that I wasn’t sure about the syntax of &lt;code class="highlight"&gt;loop&lt;/code&gt; in Clojure 🙈)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;; Source: https://github.com/log0ymxm/gorilla-worksheets/blob/master/src/machine-epsilon.clj&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;loop &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;k&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="nv"&gt;s&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;or &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;lt;= &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="nv"&gt;s&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;gt; &lt;/span&gt;&lt;span class="nv"&gt;k&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="nb"&gt;dec &lt;/span&gt;&lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;, &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;* &lt;/span&gt;&lt;span class="mf"&gt;2.0&lt;/span&gt; &lt;span class="nv"&gt;s&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;recur&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;inc &lt;/span&gt;&lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;* &lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt; &lt;span class="nv"&gt;s&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;span class="c1"&gt;; [53 2.220446049250313E-16]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This loop is trying to find the unhalvable value I wrote about earlier. Start with &lt;code class="highlight"&gt;s = 1.0&lt;/code&gt; and keep halving that (moving the binary 1 rightward) until &lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;&amp;lt;= &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="nv"&gt;s&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/code&gt; or &lt;span class="math"&gt;\(1 + s \leq 1\)&lt;/span&gt;. That is, until the computer no longer recognizes &lt;code class="highlight"&gt;s&lt;/code&gt; as having value.&lt;/p&gt;
&lt;p&gt;Once that happens, you’ve gone too far and fallen within the bounds of a number pixel. To find the edge of the next pixel—that is, the next adjacent perceptibly different number—move the binary 1 left by one place (in decimal, that’s multiplying by 2).&lt;/p&gt;
&lt;p&gt;That’s the reason for the final &lt;code class="highlight"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;* &lt;/span&gt;&lt;span class="mf"&gt;2.0&lt;/span&gt; &lt;span class="nv"&gt;s&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/code&gt; once the terminating condition is met.&lt;/p&gt;
&lt;p&gt;&lt;code class="highlight"&gt;k&lt;/code&gt; tells us that the 1 is in the &lt;span class="math"&gt;\(k\)&lt;/span&gt;th place after the decimal point. Here, that’s the 53rd place. That’s no surprise; we know it’s a 64-bit number. But &lt;code class="highlight"&gt;k&lt;/code&gt; could be larger or smaller depending on the precision of the floating-point system, with higher values meaning more available places and thus higher precision.&lt;/p&gt;
&lt;p&gt;Julia, NumPy, and R have built-in ways to find machine epsilon (or rather, the value just a hair larger than machine epsilon). Of the three, Julia’s value is the most precise (to the same level of precision as Clojure above).&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_3_0" name="__tabs_3" type="radio"/&gt;
&lt;label for="__tab_3_0"&gt;Julia&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;# source: https://docs.julialang.org/en/v1/manual/integers-and-floating-point-numbers/index.html&lt;/span&gt;
&lt;span class="n"&gt;julia&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;eps&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;         
&lt;span class="mf"&gt;2.220446049250313e-16&lt;/span&gt;
&lt;span class="n"&gt;julia&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;eps&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;Float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c"&gt;# 32-bit (single-precision) number&lt;/span&gt;
&lt;span class="mf"&gt;1.1920929f-7&lt;/span&gt;
&lt;span class="n"&gt;julia&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;eps&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="mf"&gt;1.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_3_1" name="__tabs_3" type="radio"/&gt;
&lt;label for="__tab_3_1"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# source: https://stackoverflow.com/questions/19141432/python-numpy-machine-epsilon&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;finfo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eps&lt;/span&gt;        
&lt;span class="mf"&gt;2.22044604925e-16&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;finfo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eps&lt;/span&gt; &lt;span class="c1"&gt;# 32-bit (single-precision) number&lt;/span&gt;
&lt;span class="mf"&gt;1.19209e-07&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;finfo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eps&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="mf"&gt;1.0&lt;/span&gt;
 &lt;span class="sb"&gt;``&lt;/span&gt;&lt;span class="err"&gt;`&lt;/span&gt;

&lt;span class="sb"&gt;``&lt;/span&gt;&lt;span class="err"&gt;`&lt;/span&gt;&lt;span class="n"&gt;R&lt;/span&gt; &lt;span class="n"&gt;tab&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;
&lt;span class="c1"&gt;# source: https://stackoverflow.com/questions/2619543/how-do-i-obtain-the-machine-epsilon-in-r&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Machine&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;double&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eps&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="mf"&gt;2.220446e-16&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Machine&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;double&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eps&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Just for completeness, this is that value in math notation:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\epsilon_{\textrm{mach}} &amp;amp;= 2.220446049250313 \times 10^{-16} \\
&amp;amp;= 0.000 \space 000 \space 000 \space 000 \space 000 \space 000 \space 000 \space
222 \space 044 \space 604 \space 9250
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;So, even though I don’t immediately see myself caring about the specific &lt;em&gt;value&lt;/em&gt; of machine epsilon (as opposed to its &lt;em&gt;implications&lt;/em&gt;), that’s pretty neat.&lt;/p&gt;
&lt;p&gt;Speaking of the implications of &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt;—of the machine and non-machine variety—I have to bring the discussion back to what brought me to &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; in the first place: convergence in linear regression.&lt;/p&gt;
&lt;h1 id="linear-regression"&gt;Linear regression&lt;/h1&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; has &lt;em&gt;two&lt;/em&gt; meanings in linear regression depending on whether you are creating the model or using the model.&lt;/p&gt;
&lt;h2 id="convergence-threshold"&gt;Convergence threshold&lt;/h2&gt;
&lt;p&gt;&lt;a href="/2019/01/loopless-loop"&gt;Previously&lt;/a&gt;, we performed stochastic gradient descent in a way that we could see the cost decreasing with every iteration, but we still had to adjust the number of iterations manually and judge convergence by looking through the output to find the point where the next iteration wasn’t really worth it.&lt;/p&gt;
&lt;p&gt;It’s conceptually very simple to have the computer do this for you. On each iteration, just keep track of the cost obtained after the previous iteration and compare it to the current cost. If the difference is below a certain threshold value, stop iterating.&lt;/p&gt;
&lt;div class="math"&gt;$$ | J(\theta_{\textrm{current}}) - J(\theta_{\textrm{previous}}) | &amp;lt; \epsilon $$&lt;/div&gt;
&lt;p&gt;In this context, the threshold value is called &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt;. Something like &lt;span class="math"&gt;\(0.0001\)&lt;/span&gt; might be adequate.&lt;/p&gt;
&lt;p&gt;Let’s take first part of the code from the last post:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt;

&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sklearn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;make_regression&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hstack&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# padding for bias column&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# this just fixes a quirk of sklearn's output&lt;/span&gt;

&lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;num_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;o&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;num_samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
    &lt;span class="n"&gt;cost_array&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;num_samples&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;cost_array&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and modify our &lt;code class="highlight"&gt;train_model&lt;/code&gt; function to show us the difference between the current and the last cost on every 50th iteration, and train for 1500 epochs.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;train_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;num_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="hll"&gt;    &lt;span class="n"&gt;last_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;/span&gt;    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
        &lt;span class="n"&gt;step_distance&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;num_samples&lt;/span&gt;
        &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;step_distance&lt;/span&gt;
&lt;span class="hll"&gt;        &lt;span class="n"&gt;this_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;            &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;this_cost&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;last_cost&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;        &lt;span class="n"&gt;last_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;this_cost&lt;/span&gt;
&lt;/span&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;

&lt;span class="n"&gt;train_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1500&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;At 600 epochs, the difference falls to about &lt;code class="highlight"&gt;0.001&lt;/code&gt; and at 700 epochs, it falls to about &lt;code class="highlight"&gt;0.0001&lt;/code&gt;. Considering the difference between the initial 20 iterations was in the hundreds, I think &lt;code class="highlight"&gt;0.001&lt;/code&gt; is a sufficiently good &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Let’s rewrite the function to stop training based on a value of &lt;code class="highlight"&gt;epsilon&lt;/code&gt; rather than a number &lt;code class="highlight"&gt;epochs&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;train_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.001&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;/span&gt;    &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;num_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;last_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="hll"&gt;    &lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="c1"&gt;# just to know the value; not critical for training&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;        &lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;/span&gt;        &lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
        &lt;span class="n"&gt;step_distance&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;num_samples&lt;/span&gt;
        &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;step_distance&lt;/span&gt;
        &lt;span class="n"&gt;this_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="hll"&gt;        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;this_cost&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;last_cost&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;            &lt;span class="k"&gt;break&lt;/span&gt;
&lt;/span&gt;        &lt;span class="n"&gt;last_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;this_cost&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Completed {epochs} epochs of training."&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Final cost: {cost(X, y, weights)}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;

&lt;span class="n"&gt;train_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Completed 612 epochs of training.&lt;/span&gt;
&lt;span class="c1"&gt;# Final cost: 0.05001815274191081&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Nice!&lt;/p&gt;
&lt;h2 id="random-error"&gt;Random error&lt;/h2&gt;
&lt;p&gt;I sort of lied when I said linear regression is&lt;/p&gt;
&lt;div class="math"&gt;$$ h_{\theta}(x) = \theta_0x_0 + \theta_1x_1 + \cdots + \theta_nx_n $$&lt;/div&gt;
&lt;p&gt;I mean, it is. But that function gives the idealized, &lt;em&gt;predicted&lt;/em&gt; value, the &lt;span class="math"&gt;\(\hat y\)&lt;/span&gt;. The &lt;em&gt;real&lt;/em&gt; value is&lt;/p&gt;
&lt;div class="math"&gt;$$ y = \theta_0x_0 + \theta_1x_1 + \cdots + \theta_nx_n + \textcolor{magenta}{\epsilon} $$&lt;/div&gt;
&lt;p&gt;(And in statistics they use &lt;span class="math"&gt;\(\beta\)&lt;/span&gt; rather than &lt;span class="math"&gt;\(\theta\)&lt;/span&gt;, just to keep you on your toes.)&lt;/p&gt;
&lt;p&gt;This &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; is called the &lt;strong&gt;random error&lt;/strong&gt;, which sounds like the consequence of a really sloppy programmer, but is simply a way of dealing with the unavoidable fact that no model can be perfect.&lt;/p&gt;
&lt;p&gt;Remember how we used the &lt;em&gt;actual&lt;/em&gt; error (&lt;span class="math"&gt;\(\hatY - Y\)&lt;/span&gt;) to compute the distance between our hypothetical line of best fit and each data point? The random error is basically saying that&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The regression line is the line that best fits—not &lt;em&gt;perfectly&lt;/em&gt; fits—the data used to create it, and&lt;/li&gt;
&lt;li&gt;Because of that, predictions made with the model are not likely to fall directly &lt;em&gt;on&lt;/em&gt; the line.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That doesn’t mean they &lt;em&gt;won’t&lt;/em&gt;, but we can’t know for sure, and it’s not likely. This uncertainty is captured by &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; (which we should hope is a small value, if not infinitesimal 😅). &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; is considered to be taken from&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;a normally distributed (bell curve) set of values&lt;/li&gt;
&lt;li&gt;with a mean of 0&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The second property makes sense; our line is the best-fitting line, so its underestimates should equal its overestimates). The first property is arbitrary—you could choose any kind of probability distribution, but a bell curve is apparently the simplest one that is correct enough frequently enough.&lt;/p&gt;
&lt;p&gt;This is more of a theoretical shim than anything that concerns atually coding a model, but it’s still an important variable.&lt;/p&gt;
&lt;p&gt;In a future post, I will talk about a topic that takes &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; to the next level. Stay tuned!&lt;/p&gt;
&lt;h1 id="references"&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikibooks.org/wiki/Floating_Point/Epsilon"&gt;Floating Point/Epsilon&lt;/a&gt;, Wikibooks&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Floating-point_arithmetic"&gt;Floating-point arithmetic&lt;/a&gt;, Wikipedia&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www0.gsb.columbia.edu/faculty/pglasserman/B6014/Regression.pdf"&gt;B6014 Managerial Statistics: Linear Regression&lt;/a&gt;, Columbia Business School&lt;/li&gt;
&lt;li&gt;&lt;a href="https://math.stackexchange.com/questions/1051863/assumption-of-a-random-error-term-in-a-regression"&gt;Assumption of a Random error term in a regression&lt;/a&gt;, StackExchange Mathematics&lt;/li&gt;
&lt;/ul&gt;</content><category term="convergence"></category><category term="floating-point"></category><category term="error"></category><category term="epsilon"></category></entry><entry><title>PIM notes, Chapter 2 (Polynomials)</title><link href="http://tabidots.github.io/2019/01/pim-notes-chapter-2" rel="alternate"></link><published>2019-01-17T12:54:19+07:00</published><updated>2019-01-17T12:54:19+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-01-17:/2019/01/pim-notes-chapter-2</id><summary type="html">&lt;p&gt;My first experience with something that resembles a math textbook in many years, but this time with “big kid math.” It’s&amp;nbsp;hard!&lt;/p&gt;</summary><content type="html">
&lt;p&gt;I started reading Jeremy Kun’s &lt;em&gt;&lt;a href="https://pimbook.org/"&gt;A Programmer’s Introduction to Mathematics&lt;/a&gt;&lt;/em&gt;. This is just a collection of my notes from Chapter 2, or code/math that I felt like writing/typesetting as an exercise while working through the chapter.&lt;/p&gt;
&lt;p&gt;I activated the SuperFences Markdown plugin in the blog’s settings, so it’s really cool to write code for the same thing in different languages side-by-side. (The Java lexer is a little off, though.)&lt;/p&gt;
&lt;p&gt;Note: The chapter is divided into the “main material,” an implementation of something that uses the relevant math, and exercises. I had actually gotten through the material and code part of the chapter last week, before I wrote about Markov matrices, and thought I’d be able to publish the complete notes in one go.&lt;/p&gt;
&lt;p&gt;However, the exercises are time-consuming and quickly get very difficult, so my impatience compels me to split this post in two, since it’d be strange to be writing about &lt;span class="math"&gt;\(\Pi\)&lt;/span&gt; notation after covering way more advanced material! I’ll publish my answers to the exercises another week.&lt;/p&gt;
&lt;h1 id="sum-summation"&gt;&lt;span class="math"&gt;\(\sum\)&lt;/span&gt; (Summation)&lt;/h1&gt;
&lt;p&gt;Summation notation wasn’t new to me (I learned it the hard way trying to make sense of the linear regression stuff), nor was the Python equivalent. However, since it was presented in Java, I thought it was good opportunity to see the correspondence between Python and Java. When I first started learning to code (beyond web development), I ran away from Java with my tail between my legs, but now it makes a lot more sense. It’s just terribly verbose and inefficient.&lt;/p&gt;
&lt;p&gt;Also, I wanted to use an easy example to get reacquainted with Clojure, my other favorite language, and pick up some R and Julia along the way too.&lt;/p&gt;
&lt;div class="math"&gt;$$ f(x) = \sum_{i=0}^x i $$&lt;/div&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_1_0" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;sum_to&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;sum_to&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;list_comp_sum_to&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_1" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_1"&gt;Clojure&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;sum-to&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="nv"&gt;+&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;

&lt;span class="nv"&gt;user=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;sum-to&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;6&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_2" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_2"&gt;Java&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;main&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
  &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;sumTo&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;mySum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
      &lt;span class="n"&gt;mySum&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;mySum&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
  &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;

&lt;span class="n"&gt;jshell&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;sumTo&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;$9&lt;/span&gt; &lt;span class="o"&gt;==&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;55&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_3" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_3"&gt;Julia&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;function&lt;/span&gt; &lt;span class="n"&gt;sum_to&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;
        &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;
    &lt;span class="k"&gt;end&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;

&lt;span class="n"&gt;julia&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;sum_to&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;6&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_1_4" name="__tabs_1" type="radio"/&gt;
&lt;label for="__tab_1_4"&gt;R&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sum_to&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;
  &lt;span class="nf"&gt;for &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="n"&gt;result&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;sum_to&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;[1]&lt;/span&gt; &lt;span class="m"&gt;4&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id="prod-pi-product"&gt;&lt;span class="math"&gt;\(\prod\)&lt;/span&gt; (Pi-product)&lt;/h1&gt;
&lt;p&gt;This was new to me, and so was the existence of the &lt;code class="highlight"&gt;*=&lt;/code&gt; operator, which I guess I had never had a need for.&lt;/p&gt;
&lt;div class="math"&gt;$$ g(x) = \prod_{j=1}^x i $$&lt;/div&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_2_0" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;mult_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;*=&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;mult_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="mi"&gt;120&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_2_1" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_1"&gt;Clojure&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;mult-all&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="nv"&gt;*&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;

&lt;span class="nv"&gt;user=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;mult-all&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;120&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_2_2" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_2"&gt;Java&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;main&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
  &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;multAll&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;myProd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
      &lt;span class="n"&gt;myProd&lt;/span&gt; &lt;span class="o"&gt;*=&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;myProd&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
  &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;

&lt;span class="n"&gt;jshell&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;multAll&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;$10&lt;/span&gt; &lt;span class="o"&gt;==&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;120&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_2_3" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_3"&gt;Julia&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;function&lt;/span&gt; &lt;span class="n"&gt;mult_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;
        &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;*=&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;
    &lt;span class="k"&gt;end&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;

&lt;span class="n"&gt;julia&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;mult_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;120&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_2_4" name="__tabs_2" type="radio"/&gt;
&lt;label for="__tab_2_4"&gt;R&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;mult_all&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;
  &lt;span class="nf"&gt;for &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="n"&gt;result&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;mult_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;[1]&lt;/span&gt; &lt;span class="m"&gt;120&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id="sumprod-nested-product-in-sum"&gt;&lt;span class="math"&gt;\(\sum\prod\)&lt;/span&gt; (Nested product in sum)&lt;/h1&gt;
&lt;p&gt;Pretty wild. I tried really hard to translate this into Clojure, but I couldn’t as-is.&lt;/p&gt;
&lt;div class="math"&gt;$$ f(x) = \sum_{i=0}^n \textrm{bar}(i) \Bigg(\prod_{j \not = i} \textrm{foo}(i, j)\Bigg) $$&lt;/div&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_3_0" name="__tabs_3" type="radio"/&gt;
&lt;label for="__tab_3_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;inner&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;continue&lt;/span&gt;
        &lt;span class="n"&gt;inner&lt;/span&gt; &lt;span class="o"&gt;*=&lt;/span&gt; &lt;span class="n"&gt;foo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;bar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;inner&lt;/span&gt;
&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_3_1" name="__tabs_3" type="radio"/&gt;
&lt;label for="__tab_3_1"&gt;Java&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;innerProd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="o"&gt;++)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
      &lt;span class="n"&gt;innerProd&lt;/span&gt; &lt;span class="o"&gt;*=&lt;/span&gt; &lt;span class="n"&gt;foo&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
  &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;bar&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;inner&lt;/span&gt;
  &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id="horners-method"&gt;Horner’s Method&lt;/h1&gt;
&lt;p&gt;I had never heard of this until I encountered it in the code for the author’s &lt;code class="highlight"&gt;Polynomial&lt;/code&gt; class. It is definitely easier to understand how it works in Python than it is to understand why it works mathematically!&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned} \sum_{i=0}^{n-1} a_i x^i &amp;amp;= a_0 + a_1 x + a_2 x^2 + \cdots + a_{n-1} x^{n-1} \\
&amp;amp;= a_0 + x(a_1 + x(a_2 + \cdots + x\,a_{n-1})) \end{aligned} $$&lt;/div&gt;
&lt;p&gt;Cooler still, the recursion evident in the Python code means that it can be implemented as a &lt;code class="highlight"&gt;reduce&lt;/code&gt; in functional programming, making it extremely concise and loopless.&lt;/p&gt;
&lt;p&gt;If &lt;span class="math"&gt;\(f(x) = 2x^3 + 4x + 3\)&lt;/span&gt;, let’s find &lt;span class="math"&gt;\(f(2)\)&lt;/span&gt; with Horner’s method.&lt;/p&gt;
&lt;div class="superfences-tabs"&gt;
&lt;input checked="checked" id="__tab_4_0" name="__tabs_4" type="radio"/&gt;
&lt;label for="__tab_4_0"&gt;Python&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;horners_method&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coefficients&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;reversed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coefficients&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;horners_method&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="mi"&gt;27&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_4_1" name="__tabs_4" type="radio"/&gt;
&lt;label for="__tab_4_1"&gt;Clojure&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;horners-method&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;coefs&lt;/span&gt; &lt;span class="nv"&gt;x&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reduce &lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+ &lt;/span&gt;&lt;span class="nv"&gt;%2&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;* &lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="nv"&gt;%1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reverse &lt;/span&gt;&lt;span class="nv"&gt;coefs&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

&lt;span class="nv"&gt;user=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;horners-method&lt;/span&gt; &lt;span class="nv"&gt;coefs&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;27&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;input id="__tab_4_2" name="__tabs_4" type="radio"/&gt;
&lt;label for="__tab_4_2"&gt;Java&lt;/label&gt;
&lt;div class="superfences-content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;main&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
  &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="nf"&gt;hornersMethod&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;coefficients&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;coefficients&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;length&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;--)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
      &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;coefficients&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;];&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
  &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;

&lt;span class="n"&gt;jshell&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;hornersMethod&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;[]&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;},&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;$32&lt;/span&gt; &lt;span class="o"&gt;==&amp;gt;&lt;/span&gt; &lt;span class="mf"&gt;27.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id="nested-polynomials"&gt;Nested polynomials&lt;/h1&gt;
&lt;p&gt;Speaking of nested polynomials, in the section on interpolating polynomials (normal ones), I was stuck on this line in the function &lt;code class="highlight"&gt;single_term()&lt;/code&gt; for a bit:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;single_term&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;theTerm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;xi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;yi&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;continue&lt;/span&gt;

        &lt;span class="n"&gt;xj&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="hll"&gt;        &lt;span class="n"&gt;theTerm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;theTerm&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;xj&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xi&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;xj&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xi&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;xj&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;
&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;theTerm&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;yi&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This function is supposed to get us the term of the polynomial for point &lt;span class="math"&gt;\(i\)&lt;/span&gt; of the points we feed it. It’s this, without the summation:&lt;/p&gt;
&lt;div class="math"&gt;$$ f(x) = \sum_{i=0}^n y_i \Bigg(\prod_{j \not= i} \frac{x - x_j}{x_i - x_j}\Bigg) $$&lt;/div&gt;
&lt;p&gt;How does the fraction &lt;span class="math"&gt;\(\frac{x - x_j}{x_i - x_j}\)&lt;/span&gt; get broken down into &lt;code class="highlight"&gt;Polynomial(&lt;/code&gt;&lt;span class="math"&gt;\(\frac{-x_j}{x_i - x_j}, \frac{1}{x_i - x_j}\)&lt;/span&gt;&lt;code class="highlight"&gt;)&lt;/code&gt;?&lt;/p&gt;
&lt;p&gt;&lt;code class="highlight"&gt;&lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;/code&gt; produces a polynomial &lt;span class="math"&gt;\(a\textcolor{lightgray}{x^0} + b\textcolor{orange}x\textcolor{lightgray}{^1} + c\textcolor{orange}{x^2}\)&lt;/span&gt;, so &lt;code class="highlight"&gt;&lt;span class="n"&gt;Polynomial&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;xj&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xi&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;xj&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xi&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;xj&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;&lt;/code&gt; yields&lt;/p&gt;
&lt;div class="math"&gt;$$\frac{-\textcolor{maroon}{x_j}}{\textcolor{teal}{x_i} - \textcolor{maroon}{x_j}} + \frac{1}{\textcolor{teal}{x_i} - \textcolor{maroon}{x_j}}\textcolor{orange}x = \frac{\textcolor{orange}x - \textcolor{maroon}{x_j}}{\textcolor{teal}{x_i} - \textcolor{maroon}{x_j}}$$&lt;/div&gt;
&lt;p&gt;Ah, makes sense. It‘s easy to miss (for me, anyway), but the function &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; isn’t the only polynomial here—the term within the &lt;span class="math"&gt;\(\prod\)&lt;/span&gt; is itself also a polynomial.&lt;/p&gt;
&lt;p&gt;At first, I thought it was just a clever trick, but the reason for factoring out the &lt;span class="math"&gt;\(x\)&lt;/span&gt; without a subscript is basically that unlike everything else in the entire function, that &lt;span class="math"&gt;\(x\)&lt;/span&gt; is &lt;em&gt;not&lt;/em&gt; being iterated over by either the &lt;span class="math"&gt;\(\prod\)&lt;/span&gt; (iterator &lt;span class="math"&gt;\(j\)&lt;/span&gt;) or &lt;span class="math"&gt;\(\sum\)&lt;/span&gt; (iterator &lt;span class="math"&gt;\(i\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;It’s the general indeterminate quantity &lt;span class="math"&gt;\(\textcolor{orange}x\)&lt;/span&gt;, and not &lt;span class="math"&gt;\(\textcolor{teal}{x_i}\)&lt;/span&gt; or &lt;span class="math"&gt;\(\textcolor{maroon}{x_j}\)&lt;/span&gt; (i.e., the x-coordinate of one of the &lt;span class="math"&gt;\(n\)&lt;/span&gt; points that we provided to the function), which are actually part of the coefficients here. Incidentally, separating the static &lt;code class="highlight"&gt;x&lt;/code&gt; from the dynamic &lt;code class="highlight"&gt;x&lt;/code&gt;s was a stumbling block for me as I imagined how to tackle this.&lt;/p&gt;</content><category term="pimbook"></category></entry><entry><title>Zen Coding: A Markov chain in Clojure</title><link href="http://tabidots.github.io/2019/01/markov-chain-in-clojure" rel="alternate"></link><published>2019-01-16T21:06:57+07:00</published><updated>2019-01-16T21:06:57+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-01-16:/2019/01/markov-chain-in-clojure</id><summary type="html">&lt;p&gt;Clojure is so terse and Zen-like. I love it. This is the Clojure translation of the Markov chain implementation I wrote in Python&amp;nbsp;yesterday.&lt;/p&gt;</summary><content type="html">
&lt;p&gt;I’m currently in the middle of, among learning many new things, getting back into Clojure. I never really could imagine deploying production-grade Clojure programs, but writing code in a functional paradigm is always a fascinating, challenging, and rewarding exercise.&lt;/p&gt;
&lt;p&gt;Plus, any Lisp looks pretty cool syntactically, and such languages are always extremely terse.&lt;/p&gt;
&lt;p&gt;Here’s a Clojure adaptation of the &lt;span class="caps"&gt;HIV&lt;/span&gt;/&lt;span class="caps"&gt;AIDS&lt;/span&gt; Markov chain scenario model that I wrote about and implemented in Python yesterday. Look at how short it is!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;require&lt;/span&gt; &lt;span class="o"&gt;'&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;clojupyter.misc.helper&lt;/span&gt; &lt;span class="ss"&gt;:as&lt;/span&gt; &lt;span class="nv"&gt;helper&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;helper/add-dependencies&lt;/span&gt; &lt;span class="o"&gt;'&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;net.mikera/core.matrix&lt;/span&gt; &lt;span class="s"&gt;"0.62.0"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;use&lt;/span&gt; &lt;span class="o"&gt;'&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;clojure.core.matrix&lt;/span&gt; &lt;span class="ss"&gt;:as&lt;/span&gt; &lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;def &lt;/span&gt;&lt;span class="nv"&gt;hiv&lt;/span&gt; &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mf"&gt;0.9&lt;/span&gt; &lt;span class="mf"&gt;0.07&lt;/span&gt; &lt;span class="mf"&gt;0.02&lt;/span&gt; &lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mf"&gt;0.93&lt;/span&gt; &lt;span class="mf"&gt;0.05&lt;/span&gt; &lt;span class="mf"&gt;0.02&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mf"&gt;0.85&lt;/span&gt; &lt;span class="mf"&gt;0.15&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;def &lt;/span&gt;&lt;span class="nv"&gt;p-0&lt;/span&gt; &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mf"&gt;0.85&lt;/span&gt;, &lt;span class="mf"&gt;0.1&lt;/span&gt;, &lt;span class="mf"&gt;0.05&lt;/span&gt;, &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;evolutions&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;p-matrix&lt;/span&gt; &lt;span class="nv"&gt;initial&lt;/span&gt; &lt;span class="nv"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;reductions&lt;/span&gt; &lt;span class="nv"&gt;m/mmul&lt;/span&gt;
              &lt;span class="nv"&gt;initial&lt;/span&gt;
              &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;repeat &lt;/span&gt;&lt;span class="nv"&gt;steps&lt;/span&gt; &lt;span class="nv"&gt;p-matrix&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;future-distribution&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;p-matrix&lt;/span&gt; &lt;span class="nv"&gt;initial&lt;/span&gt; &lt;span class="nv"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;last&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;evolutions&lt;/span&gt; &lt;span class="nv"&gt;p-matrix&lt;/span&gt;
                &lt;span class="nv"&gt;initial&lt;/span&gt;
                &lt;span class="nv"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;watch-evolve&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;column&lt;/span&gt; &lt;span class="nv"&gt;p-matrix&lt;/span&gt; &lt;span class="nv"&gt;initial&lt;/span&gt; &lt;span class="nv"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;evolutions&lt;/span&gt; &lt;span class="nv"&gt;p-matrix&lt;/span&gt;
                  &lt;span class="nv"&gt;initial&lt;/span&gt;
                  &lt;span class="nv"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;get-column&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;get-column&lt;/span&gt; &lt;span class="nv"&gt;column&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: It’s written in a way that works in &lt;a href="https://blog.nteract.io/hydrogen-interactive-computing-in-atom-89d291bcc4dd"&gt;Hydrogen&lt;/a&gt; for Atom (i.e., via a hidden Jupyter Notebook). I’m not sure how you’d go about importing &lt;a href="https://github.com/mikera/core.matrix/"&gt;core.matrix&lt;/a&gt; in a one-off &lt;span class="caps"&gt;REPL&lt;/span&gt; session (not a Leiningen project), but now that I’ve discovered Hydrogen, I doubt there will be many terminal &lt;span class="caps"&gt;REPL&lt;/span&gt; sessions in my future!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Coding in Clojure means non-object-oriented and no mutable state. You can write a function to compute the probability distribution at time &lt;span class="math"&gt;\(t\)&lt;/span&gt;, but the system won’t stay in that state.&lt;/p&gt;
&lt;p&gt;In fact, there &lt;em&gt;is&lt;/em&gt; no system—&lt;strong&gt;only evolution&lt;/strong&gt;. In that sense, you quite literally end up with a &lt;em&gt;memoryless&lt;/em&gt; Markov chain. The design philosophy of Clojure is all about impermanence, which is very Zen, when you think about it. (Would that make each program a koan?)&lt;/p&gt;
&lt;p&gt;Let’s take a quick tour of the functions.&lt;/p&gt;
&lt;p&gt;First, there is &lt;code class="highlight"&gt;evolutions [p-matrix initial steps]&lt;/code&gt;. That’s a base function that works as a building block for the other functions. In pseudo-math, it would look like this:&lt;/p&gt;
&lt;div class="math"&gt;$$ E(P, \pi^{(0)}, t) = {\pi^{(1)}, \cdots, \pi^{(t)}} $$&lt;/div&gt;
&lt;p&gt;It’s easy to see that computing some &lt;span class="math"&gt;\(\pi^{(n)}\)&lt;/span&gt;, the probability distribution (state of the system) at a given time, can be accomplished with a single &lt;code class="highlight"&gt;reduce&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;But Clojure has an interesting function &lt;code class="highlight"&gt;reductions&lt;/code&gt; (&lt;a href="https://clojuredocs.org/clojure.core/reductions"&gt;docs&lt;/a&gt;), which stores all of the intermediate outputs in a list, with the expected output of &lt;code class="highlight"&gt;reduce&lt;/code&gt; as the last entry. So it makes sense to write two functions here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;one, &lt;code class="highlight"&gt;evolutions&lt;/code&gt;, that gives us &lt;em&gt;all&lt;/em&gt; &lt;span class="math"&gt;\(\{\pi^{(1)}, \cdots, \pi^{(t)}\}\)&lt;/span&gt;, and&lt;/li&gt;
&lt;li&gt;another, &lt;code class="highlight"&gt;future-distribution&lt;/code&gt;, that takes the same inputs and outputs only the &lt;code class="highlight"&gt;last&lt;/code&gt; evolution.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In pseudo-math:&lt;/p&gt;
&lt;div class="math"&gt;$$ F(P, \pi^{(0)}, t) = \pi^{(t)} $$&lt;/div&gt;
&lt;p&gt;In action:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;future-distribution&lt;/span&gt; &lt;span class="nv"&gt;hiv&lt;/span&gt; &lt;span class="nv"&gt;p-0&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;; =&amp;gt; [[0.10334015640198398 0.24687062185910383 0.12037223090781371 0.5294169908310989]]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;What else can we do with the output of &lt;code class="highlight"&gt;evolutions&lt;/code&gt;? Well, we can choose one state of the system and watch its distribution evolve over time by picking out the &lt;span class="math"&gt;\(k\)&lt;/span&gt;-th item of each evolution (a row vector).&lt;/p&gt;
&lt;p&gt;In this case, we can observe how the proportion of a segment of the population (asymptomatic, symptomatic, has &lt;span class="caps"&gt;AIDS&lt;/span&gt;, dead) changes over &lt;span class="math"&gt;\(t\)&lt;/span&gt; time-steps.&lt;/p&gt;
&lt;p&gt;In pseudo-math:&lt;/p&gt;
&lt;div class="math"&gt;$$ W(s, P, \pi^{(0)}, t) = \Big\{ P(s_0), P(s_1 | s_0), \cdots, P(s_t | s_{t-1}) \Big\} $$&lt;/div&gt;
&lt;p&gt;In action:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;watch-evolve&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;hiv&lt;/span&gt; &lt;span class="nv"&gt;p-0&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;; =&amp;gt; [0.85 0.765 0.6885 0.61965 0.5576850000000001 0.5019165000000001]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;What a cool language.&lt;/p&gt;</content><category term="clojure"></category><category term="recursion"></category><category term="markov chain"></category></entry><entry><title>Outer State Space Race: Markov chains and matrices</title><link href="http://tabidots.github.io/2019/01/outer-state-space-race" rel="alternate"></link><published>2019-01-16T02:10:30+07:00</published><updated>2019-01-16T02:10:30+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-01-16:/2019/01/outer-state-space-race</id><summary type="html">&lt;p&gt;”State space” is the coolest term I’ve learned in a while. Also, I implemented a simple Markov chain, from scratch, as a Python&amp;nbsp;class.&lt;/p&gt;</summary><content type="html">
&lt;p&gt;I had heard of Markov chains before, but because my perspective had always been tightly focused on language, I never felt they were really useful.&lt;/p&gt;
&lt;p&gt;To review, a Markov chain basically describes a scenario or system where one event leads to other events (and so on, perhaps in a cycle) with varying probabilities, but &lt;em&gt;the probability of any one event leading to another given event is completely independent of all other probabilities&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;In &lt;a href="https://www.youtube.com/watch?v=0Il-y_WLTo4"&gt;the &lt;span class="caps"&gt;HIV&lt;/span&gt;/&lt;span class="caps"&gt;AIDS&lt;/span&gt; scenario model&lt;/a&gt; that originally got me interested in learning about Markov chains, the chances of your next “step”—future health outcome—depend &lt;em&gt;only&lt;/em&gt; on your present status.&lt;/p&gt;
&lt;p&gt;This is called the &lt;strong&gt;Markov property&lt;/strong&gt;. It’s like the opposite of the Monty Hall problem I wrote about previously. The probability of there being a car behind Door 2 &lt;em&gt;changes&lt;/em&gt; after Monty opens Door 3. Meanwhile, in a Markov chain, every probability is independent of the others.&lt;/p&gt;
&lt;p&gt;Markov chains, as far as I know, have limited usefulness in natural language processing, because sequences of language data—letters, words, sentences, paragraphs—are highly dependent on not only the previous item, but to some extent &lt;em&gt;all&lt;/em&gt; previous items.&lt;/p&gt;
&lt;p&gt;You can see the implications of this in Markov text generators, based on everything from Shakespeare to Eminem, that struggle to produce anything meaningful. Or in the case of part-of-speech tagging, it is simply inaccurate that a &lt;span class="caps"&gt;POS&lt;/span&gt; of a word could depend &lt;em&gt;only&lt;/em&gt; on the &lt;span class="caps"&gt;POS&lt;/span&gt; of the previous word.&lt;/p&gt;
&lt;p&gt;(Even human brains falter in processing so-called &lt;em&gt;garden path sentences&lt;/em&gt;, such as “The horse raced past the barn fell,” where you expect perhaps an adverb of some sort after the word “barn.”)&lt;/p&gt;
&lt;h1 id="matrix-izing-a-markov-chain"&gt;Matrix-izing a Markov chain&lt;/h1&gt;
&lt;p&gt;The simplest representation of a Markov chain is called a &lt;em&gt;transition diagram&lt;/em&gt;, which basically looks like a flowchart (although it could be cyclical) with arrows going between different states and probability values attached to those arrows.&lt;/p&gt;
&lt;p&gt;Now, what recently got me interested in Markov chains, as I &lt;a href="2019/01/monty-hall-beginner"&gt;wrote previously&lt;/a&gt;, is the fact that they can also be represented by matrices, and manipulated with the tools of linear algebra.&lt;/p&gt;
&lt;p&gt;The following is a Markov chain as a matrix, also known as a &lt;strong&gt;transition matrix&lt;/strong&gt;, since the values in the matrix represent the probabilities of transitioning from one state to another. In this case, suppose our system has five states.&lt;/p&gt;
&lt;p&gt;(Annotating a matrix is beyond my &lt;span class="math"&gt;\(\LaTeX\)&lt;/span&gt; skills—and perhaps the capabilities of the &lt;span class="math"&gt;\(\KaTeX\)&lt;/span&gt; renderer—so I will use a code block.)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;                  &lt;span class="n"&gt;you&lt;/span&gt; &lt;span class="n"&gt;want&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;go&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt;
                      &lt;span class="n"&gt;A&lt;/span&gt;  &lt;span class="n"&gt;B&lt;/span&gt;  &lt;span class="n"&gt;C&lt;/span&gt;  &lt;span class="n"&gt;D&lt;/span&gt;  &lt;span class="n"&gt;E&lt;/span&gt;
                  &lt;span class="n"&gt;A&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="n"&gt;probabilities&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;sum&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;reading&lt;/span&gt; &lt;span class="n"&gt;across&lt;/span&gt;
                  &lt;span class="n"&gt;B&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="n"&gt;probabilities&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;          &lt;span class="s"&gt;""&lt;/span&gt;
&lt;span class="hll"&gt; &lt;span class="n"&gt;you&lt;/span&gt; &lt;span class="n"&gt;are&lt;/span&gt; &lt;span class="kp"&gt;in&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="n"&gt;probabilities&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;          &lt;span class="s"&gt;""&lt;/span&gt;
&lt;/span&gt;                  &lt;span class="n"&gt;D&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="n"&gt;probabilities&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;          &lt;span class="s"&gt;""&lt;/span&gt;
                  &lt;span class="n"&gt;E&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="n"&gt;probabilities&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;          &lt;span class="s"&gt;""&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The collection of &lt;em&gt;possible states&lt;/em&gt; of a system is called its &lt;strong&gt;state space&lt;/strong&gt; (what a cool term!) and notated as &lt;span class="math"&gt;\(S = \{1,2,3,\cdots,N\}\)&lt;/span&gt; in the general case. For our system, it’s &lt;span class="math"&gt;\(S = \{A, B, C, D, E\}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;To give a more concrete example, for a text-generating Markov chain, the state space would include all the relevant units (letters of the alphabet plus spaces and punctuation for a character-by-character generator, words in the vocabulary for a word-by-word generator, etc.).&lt;/p&gt;
&lt;p&gt;In formal notation, a possible &lt;strong&gt;transition matrix&lt;/strong&gt; (a.k.a. Markov matrix, stochastic matrix) might look something like this:&lt;/p&gt;
&lt;div class="math"&gt;$$ P = \begin{bmatrix}
1\over4 &amp;amp; 1\over2 &amp;amp; 1\over4 \\[0.5em]
1\over3 &amp;amp; 0       &amp;amp; 2\over3 \\[0.5em]
1\over2 &amp;amp; 0       &amp;amp; 1\over2 \end{bmatrix} $$&lt;/div&gt;
&lt;p&gt;Capital &lt;span class="math"&gt;\(P\)&lt;/span&gt; represents the whole matrix and each small &lt;span class="math"&gt;\(p\)&lt;/span&gt; with subscripts (&lt;span class="math"&gt;\(p_{ij}\)&lt;/span&gt;, like &lt;span class="math"&gt;\(p_{DE}\)&lt;/span&gt;) represents the probability of going from state &lt;span class="math"&gt;\(i\)&lt;/span&gt; (some row) to state &lt;span class="math"&gt;\(j\)&lt;/span&gt; (some column in that row). &lt;span class="math"&gt;\(p_{ij}\)&lt;/span&gt; can also be used in a general sense to mean &lt;em&gt;all&lt;/em&gt; of the probabilities in the matrix.&lt;/p&gt;
&lt;p&gt;Each row must add up to 1 because it includes every possible next step from that state.&lt;/p&gt;
&lt;p&gt;Also note that the probabilities of the state &lt;em&gt;staying the same&lt;/em&gt; from one time step to the next run along the diagonal from top left to bottom right, which means that the identity matrix would represent a static system—one that &lt;em&gt;never changes&lt;/em&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ P = \begin{bmatrix}
1 &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; 1 &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 1 \end{bmatrix} $$&lt;/div&gt;
&lt;h1 id="when-pi-is-not-pi"&gt;When &lt;span class="math"&gt;\(\pi\)&lt;/span&gt; is not &lt;span class="math"&gt;\(\pi\)&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;Now, a transition matrix by itself doesn’t really have any added value compared to the transition diagram it represents, other than looking nicely organized. So let’s make a simple matrix with some random values and do matrix-y stuff with it, like multiply it by something.&lt;/p&gt;
&lt;p&gt;For the time being, I live in Southeast Asia and I eat mostly local food, which means that for any given meal, there’ll either be rice or noodles on my plate. (Not that I’m complaining—everything is ridiculously tasty!)&lt;/p&gt;
&lt;p&gt;Consider a system &lt;span class="math"&gt;\(X\)&lt;/span&gt; (that’s the conventional choice of letter) that describes my meals with a state space &lt;span class="math"&gt;\(S = \{N, R\}\)&lt;/span&gt;. The transition matrix &lt;span class="math"&gt;\(P\)&lt;/span&gt; is then&lt;/p&gt;
&lt;div class="math"&gt;$$ P = \begin{bmatrix}
0.4 &amp;amp; 0.6 \\
0.2 &amp;amp; 0.8 \end{bmatrix} $$&lt;/div&gt;
&lt;p&gt;Again, I can’t label the rows and columns of the matrix, so let’s stick to alphabetical order and make &lt;span class="math"&gt;\(N\)&lt;/span&gt; first. Thus:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class="math"&gt;\(p_{NN}\)&lt;/span&gt;, probability of repeating noodles: &lt;span class="math"&gt;\(0.4\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(p_{NR}\)&lt;/span&gt;, probability of rice after noodles: &lt;span class="math"&gt;\(0.6\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(p_{RN}\)&lt;/span&gt;, probability of noodles after rice: &lt;span class="math"&gt;\(0.2\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(p_{RR}\)&lt;/span&gt;, probability of repeating rice: &lt;span class="math"&gt;\(0.8\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The initial state can be represented by a row vector with &lt;span class="math"&gt;\(S\)&lt;/span&gt; values (i.e., as many values as there are possible states), with a 1 in the spot corresponding to the current state and a 0 for all other states.&lt;/p&gt;
&lt;p&gt;If my first meal was a noodle dish, then I can express that initial state like this:&lt;/p&gt;
&lt;div class="math"&gt;$$ \pi^{(0)} = \begin{bmatrix}1 &amp;amp; 0\end{bmatrix} $$&lt;/div&gt;
&lt;p&gt;The math notation for this is not so straightforward.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Lowercase &lt;em&gt;pi&lt;/em&gt; here represents a given state, &lt;strong&gt;not&lt;/strong&gt; the constant &lt;em&gt;pi&lt;/em&gt; that relates to circles! I don’t know who came up with that idea, but I don’t think it was a wise choice.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The superscript number is also not what it seems: it’s not an exponent, but rather the &lt;em&gt;number of time steps from now&lt;/em&gt;. So &lt;span class="math"&gt;\(\pi^{(0)}\)&lt;/span&gt; means our state at 0 time steps from now, or in other words, now.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Why is this vector of the more uncommon horizontal variety (i.e., a row vector)? That’s a more complicated question (and the reason that I got stuck on the warmup problem in the Linear Algebra for Coders course).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This is the part where I turned to Python because I couldn’t get any farther with the math alone.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="n"&gt;meals&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mf"&gt;0.4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.6&lt;/span&gt;&lt;span class="p"&gt;],[&lt;/span&gt;&lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.8&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;span class="n"&gt;now&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id="the-next-step-and-the-ones-thereafter"&gt;The next step (and the ones thereafter)&lt;/h1&gt;
&lt;p&gt;To find the probabilities for the next meal, we can multiply this vector and the transition matrix together. If you &lt;a href="https://www.youtube.com/watch?v=kYB8IZa5AuE"&gt;imagine matrix-vector multiplication as a vector undergoing a linear transformation&lt;/a&gt;, then this sort of makes sense.&lt;/p&gt;
&lt;p&gt;There’s a catch, though. Transition matrices are set up to be read &lt;em&gt;across&lt;/em&gt;, from left to right, with each row telling us the next-step probabilities &lt;em&gt;if&lt;/em&gt; we are in that state:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;                &lt;span class="n"&gt;you&lt;/span&gt; &lt;span class="n"&gt;want&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;go&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt;
                      &lt;span class="n"&gt;N&lt;/span&gt;    &lt;span class="n"&gt;R&lt;/span&gt;
&lt;span class="hll"&gt; &lt;span class="n"&gt;you&lt;/span&gt; &lt;span class="n"&gt;are&lt;/span&gt; &lt;span class="kp"&gt;in&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="mf"&gt;0.4&lt;/span&gt;  &lt;span class="mf"&gt;0.6&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;
&lt;/span&gt;                  &lt;span class="n"&gt;R&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="mf"&gt;0.2&lt;/span&gt;  &lt;span class="mf"&gt;0.8&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So if we already &lt;em&gt;know&lt;/em&gt; that we will be in state &lt;span class="math"&gt;\(N\)&lt;/span&gt; to begin with, we can essentially filter out the other rows, leaving a single row:&lt;/p&gt;
&lt;div class="math"&gt;$$ \pi^{(1)} = \begin{bmatrix}p_{NN} &amp;amp; p_{NR}\end{bmatrix} = \begin{bmatrix}0.4 &amp;amp; 0.6\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;Now, if we suppose that our state vector is a column vector &lt;span class="math"&gt;\(\vec v\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$ \vec v = \begin{bmatrix}1 \\ 0\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;and multiply it by the matrix,&lt;/p&gt;
&lt;div class="math"&gt;$$ \pi^{(1)} \stackrel{?}{=} P\vec v
= \begin{bmatrix}
0.4 &amp;amp; 0.6 \\
0.2 &amp;amp; 0.8 \end{bmatrix} \begin{bmatrix}1 \\ 0\end{bmatrix}
= \begin{bmatrix}
1\cdot0.4 + \textcolor{lightgray}{0\cdot0.6} \\
1\cdot0.2 + \textcolor{lightgray}{0\cdot0.8} \end{bmatrix}
= \begin{bmatrix} 0.4 \\ 0.2 \end{bmatrix} $$&lt;/div&gt;
&lt;p&gt;Hmm, that’s not quite right. The values don’t match what we know about our system, and we want a row, not a column.&lt;/p&gt;
&lt;p&gt;Since the product of a matrix and a vector is the shape of the vector, &lt;span class="math"&gt;\(\pi^{(0)}\)&lt;/span&gt; should be a row vector if we want &lt;span class="math"&gt;\(\pi^{(1)}\)&lt;/span&gt; to be a row vector. We could also transpose the matrix, but then the rows of the matrix no longer represent probabilities of transitioning from a given state. Using a row vector maintains the idea that rows describe origin states and the property that values of rows add up to 1.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\pi^{(1)} = \pi^{(0)}P &amp;amp;= \begin{bmatrix}1 &amp;amp; 0\end{bmatrix} \begin{bmatrix}
0.4 &amp;amp; 0.6 \\
0.2 &amp;amp; 0.8 \end{bmatrix} \\
&amp;amp;= \begin{bmatrix}
1\cdot0.4 + \textcolor{lightgray}{0\cdot0.2} &amp;amp;
1\cdot0.6 + \textcolor{lightgray}{0\cdot0.8} \end{bmatrix} \\
&amp;amp;= \begin{bmatrix} 0.4 &amp;amp; 0.6 \end{bmatrix}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;Intuitively, you can imagine that you’re “feeding” the collection of probabilities through the state and getting the “transformed” probabilities.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;now&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;meals&lt;/span&gt;
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mf"&gt;0.4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.6&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Also, since the probabilities at time &lt;span class="math"&gt;\(t + 1\)&lt;/span&gt; only depend on the probabilities at time &lt;span class="math"&gt;\(t\)&lt;/span&gt;, we can do this recursively to find &lt;span class="math"&gt;\(\pi^{(n)}\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;p1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;now&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;meals&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;p1&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;meals&lt;/span&gt;
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mf"&gt;0.28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.72&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt; &lt;span class="c1"&gt;# this is pi^(2), or probabilities at time 2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;On a day where I had noodles for breakfast, then, I have a 40% chance of having noodles and a 60% chance of having rice for lunch, and then a 28% chance of having noodles and a 72% chance of having rice for dinner.&lt;/p&gt;
&lt;h1 id="other-possibilities-for-the-state-vector"&gt;Other possibilities for the state vector&lt;/h1&gt;
&lt;p&gt;Actually, I oversimplified the above example a bit. The state vector doesn’t have to be a binary thing. Since its values must sum to 1, it can also reflect an initial probability &lt;em&gt;distribution&lt;/em&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ \pi^{(0)} = \begin{bmatrix}0.45 &amp;amp; 0.55\end{bmatrix} $$&lt;/div&gt;
&lt;p&gt;As you can see, this changes the subsequent probabilities:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;now&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mf"&gt;0.45&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.55&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;now&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;meals&lt;/span&gt;
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mf"&gt;0.29&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.71&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In the &lt;span class="caps"&gt;HIV&lt;/span&gt;/&lt;span class="caps"&gt;AIDS&lt;/span&gt; scenario I referred to at the beginning of this post, the initial state vector is used to represent the population (since subsets of a population can be expressed as the probability that a random person will belong to that subset).&lt;/p&gt;
&lt;p&gt;Here are the givens of that problem. The states are &lt;em&gt;&lt;span class="caps"&gt;HIV&lt;/span&gt; asymptomatic, &lt;span class="caps"&gt;HIV&lt;/span&gt; symptomatic, &lt;span class="caps"&gt;AIDS&lt;/span&gt;,&lt;/em&gt; and &lt;em&gt;death&lt;/em&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{gathered} P = \begin{bmatrix}
0.97 &amp;amp; 0.07 &amp;amp; 0.02 &amp;amp; 0.01 \\
0    &amp;amp; 0.93 &amp;amp; 0.05 &amp;amp; 0.02 \\
0    &amp;amp; 0    &amp;amp; 0.85 &amp;amp; 0.15 \\
0    &amp;amp; 0    &amp;amp; 0    &amp;amp; 1.00 \end{bmatrix} \\
\pi^{(0)} = \begin{bmatrix} 0.85 &amp;amp; 0.10 &amp;amp; 0.05 &amp;amp; 0 \end{bmatrix}
\end{gathered} $$&lt;/div&gt;
&lt;p&gt;This means that the initial population was 85% asymptomatic, 10% symptomatic, 5% &lt;span class="caps"&gt;AIDS&lt;/span&gt; patients, and 0% dead.&lt;/p&gt;
&lt;p&gt;If we used a vector with a single 1 and the rest 0s, then that would represent the outcomes for a homogenous population, or more likely, a single person.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;hiv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mf"&gt;0.9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.07&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.02&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;  &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.93&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.02&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;  &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.85&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.15&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;  &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;   &lt;span class="p"&gt;]])&lt;/span&gt;
&lt;span class="n"&gt;population&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mf"&gt;0.85&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;33&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;population&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;hiv&lt;/span&gt;
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;33&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mf"&gt;0.765&lt;/span&gt; &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.1525&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.0645&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.018&lt;/span&gt; &lt;span class="p"&gt;]])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So the outcomes after 1 year (&lt;span class="math"&gt;\(t = 1\)&lt;/span&gt;) are 76.5% asymptomatic, 15.25% symptomatic, 6.45% &lt;span class="caps"&gt;AIDS&lt;/span&gt; patients, and 1.8% dead.&lt;/p&gt;
&lt;h1 id="python-izing-a-markov-chain"&gt;Python-izing a Markov chain&lt;/h1&gt;
&lt;p&gt;Maybe this is kind of overkill, but we can implement our system as a class.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;MarkovChain&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;init_state&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;# Validate the matrix&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ndarray&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;init_state&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ndarray&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;TypeError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'The Markov matrix and state vector must be NumPy arrays.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Markov matrices must be square.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;matrix&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;any&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;init_state&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;any&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Probabilities cannot be negative.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Each row in a Markov matrix must sum to 1.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# Validate the init_state&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;init_state&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ndarray&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;TypeError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'The initial state vector must be a NumPy array.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;init_state&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'The state vector must have a shape of 1 x {matrix.shape[1]}.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;init_state&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'The values in the state vector must sum to 1.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matrix&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;init_state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;init_state&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;

        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;probs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;init_state&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;evolve&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;evolve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;            
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;probs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;probs&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matrix&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;status&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;probs_list&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;round&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;"%"&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;probs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'At time {self.time}, the transition probabilities are'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;probs_list&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;restart&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;init_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
          &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;init_state&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
              &lt;span class="n"&gt;init_state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;init_state&lt;/span&gt;
          &lt;span class="c1"&gt;# call with no args to start over with same initial state&lt;/span&gt;
          &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;init_state&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now we can see what the population will be like after many years with just a few keystrokes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MarkovChain&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hiv&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;population&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;At&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;transition&lt;/span&gt; &lt;span class="n"&gt;probabilities&lt;/span&gt; &lt;span class="n"&gt;are&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'76.5%'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'15.25%'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'6.45%'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'1.8%'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;41&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;evolve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;At&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;transition&lt;/span&gt; &lt;span class="n"&gt;probabilities&lt;/span&gt; &lt;span class="n"&gt;are&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'26.67%'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'31.53%'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'13.58%'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'28.21%'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;evolve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;At&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt; &lt;span class="mi"&gt;21&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;transition&lt;/span&gt; &lt;span class="n"&gt;probabilities&lt;/span&gt; &lt;span class="n"&gt;are&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'9.3%'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'23.68%'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'11.67%'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'55.34%'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;43&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;evolve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;At&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt; &lt;span class="mi"&gt;31&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;transition&lt;/span&gt; &lt;span class="n"&gt;probabilities&lt;/span&gt; &lt;span class="n"&gt;are&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'3.24%'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'14.4%'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'7.71%'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'74.65%'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;75% dead after 30 years—grim outlook, to say the least. (Though to be fair, the model takes into account that people may and do die of things other than &lt;span class="caps"&gt;HIV&lt;/span&gt;/&lt;span class="caps"&gt;AIDS&lt;/span&gt;. This is represented in the matrix by the nonzero probabilities of asymptomatic people transitioning right to death.)&lt;/p&gt;
&lt;p&gt;…aaaand on that note, I’ll end this post here for now. I will write about Markov chains again in the near future.&lt;/p&gt;
&lt;h1 id="references"&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=0Il-y_WLTo4"&gt;Concepts of Markov Chains&lt;/a&gt; (video), Paul Harper&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.stat.auckland.ac.nz/~fewster/325/notes/ch8.pdf"&gt;Stats 325, Chapter 8: Markov Chains&lt;/a&gt;, Rachel Fewster&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/@balamurali_m/markov-chain-simple-example-with-python-985d33b14d19"&gt;Markov Chain: Simple example with Python&lt;/a&gt;, Balamurali M&lt;/li&gt;
&lt;/ul&gt;</content><category term="Markov chain"></category><category term="linear algebra"></category></entry><entry><title>Monty, Monte, and… Bayes: Statistics and probability</title><link href="http://tabidots.github.io/2019/01/monty-hall-beginner" rel="alternate"></link><published>2019-01-12T10:54:19+07:00</published><updated>2019-01-12T10:54:19+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-01-12:/2019/01/monty-hall-beginner</id><summary type="html">&lt;p&gt;Getting stumped by some basic probability questions led me down a rabbit hole whereupon I stumbled across Bayes’&amp;nbsp;theorem.&lt;/p&gt;</summary><content type="html">
&lt;p&gt;I thought I had familiarized myself enough with the basic workings of linear algebra after Week 1 that I thought Rachel Thomas’ (&lt;a href="www.fast.ai"&gt;fast.ai&lt;/a&gt;)’s &lt;a href="https://www.youtube.com/watch?v=8iGzBMboA0I&amp;amp;index=2&amp;amp;list=PLtmWHNX-gukIc92m1K0P6bIOnZb-mg0hY&amp;amp;t=0s"&gt;Linear algebra for coders&lt;/a&gt; course would be a good way to deepen my knowledge by applying these newly learned concepts in Python.&lt;/p&gt;
&lt;p&gt;But embarrassingly, even the first warmup problem was beyond me. It required the use of a Markov matrix, which is the application of linear algebra to probability. Then I realized I had no background in probability, so I tried Brilliant’s &lt;a href="https://brilliant.org/courses/probability/introduction-to-probability/"&gt;Intro to Probability&lt;/a&gt;, whereupon I roundly botched a bunch of basic probability questions.&lt;/p&gt;
&lt;p&gt;I found it really odd that I had just learned these mathematical techniques (basic linear algebra and multivariable calculus) to solve problems in a new way, yet while these probability problems &lt;em&gt;could&lt;/em&gt; be solved computationally, they are meant to be solved “intuitively.” Of course, that seems like a cruel joke, since their counterintuitive solutions make such problems seem more like Zen koans.&lt;/p&gt;
&lt;h1 id="the-monty-hall-problem"&gt;The Monty Hall problem&lt;/h1&gt;
&lt;p&gt;Take, for example, the &lt;a href="https://en.wikipedia.org/wiki/Monty_Hall_problem"&gt;Monty Hall problem&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Suppose you’re on a game show, and you’re given the choice of three doors: Behind one door is a car; behind the others, goats.&lt;/p&gt;
&lt;p&gt;You pick a door, say No. 1, and the host, who knows what’s behind the doors, opens another door, say No. 3, which has a goat. He then says to you, “Do you want to pick door No. 2?”&lt;/p&gt;
&lt;p&gt;Is it to your advantage to switch your choice?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Spoiler alert&lt;/strong&gt;: The answer is that you &lt;em&gt;do&lt;/em&gt; switch, because you would then have a &lt;span class="math"&gt;\(\frac{2}{3}\)&lt;/span&gt; probability of choosing the car.&lt;/p&gt;
&lt;p&gt;Wait, what? How does a single door go from having a &lt;span class="math"&gt;\(\frac{1}{3}\)&lt;/span&gt; chance that the car is behind it to a &lt;span class="math"&gt;\(\frac{2}{3}\)&lt;/span&gt; chance? It seemed to me that you would now have a 50/50 chance, since there were two doors left.&lt;/p&gt;
&lt;p&gt;People tend to explain the rationale for the solution by increasing the number of doors to 100, and the number of doors revealed to 98. But this didn’t change anything for me; you still ended up with 2 doors, and thus a 50/50 chance.&lt;/p&gt;
&lt;p&gt;No number of doors, visual explanation, or animation seemed to help me understand it. Finally, I managed to find a &lt;a href="https://www.reddit.com/r/explainlikeimfive/comments/58cdw3/eli5_the_monty_hall_problem/d8zanoq"&gt;comment&lt;/a&gt; in an old &lt;a href="https://www.reddit.com/r/explainlikeimfive"&gt;&lt;span class="caps"&gt;ELI5&lt;/span&gt;&lt;/a&gt; thread that made it click for me:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;As simply as possible: Don’t think of it as three doors. Think of it as your door, and Monty’s doors. The odds that you picked the right door are 1 in 3, and the odds that you didn’t are 2 in 3, right?&lt;/p&gt;
&lt;p&gt;When Monty gets rid of one bad choice, he doesn’t change the odds that your door is right - it’s still 1 in 3. That means he’s also not changing the odds that you aren’t right - it’s still 2 in 3.&lt;/p&gt;
&lt;p&gt;Therefore you’re not picking one door - you’re picking two doors at the same time and getting the best possible outcome. If either of Monty’s doors was right, you win; If both of Monty’s doors were bad, you lose.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Explained this way, it then makes sense that there would only be a 50/50 chance if you had two doors &lt;em&gt;to begin with&lt;/em&gt;. Or, if you had fallen into “the probability trap of treating non-random information as if it were random,” as it has been described &lt;a href="https://sites.google.com/site/psmartinsite/Home/bridge-articles/the-monty-hall-trap"&gt;elsewhere&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id="statistical-approach"&gt;Statistical approach&lt;/h1&gt;
&lt;p&gt;Let’s first try to simulate the game in Python. I’ll skip over explaining what’s going on in the code here, as it’s pretty elementary.&lt;/p&gt;
&lt;p&gt;I just added perpetual loops to avoid the problem of bad input (if you were going to get other people to play, for example).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;random&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;monty_hall&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;doors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"a"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s2"&gt;"b"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s2"&gt;"c"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;car&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;first_choice&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Choose a door (a/b/c): "&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;first_choice&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;doors&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;break&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;doors&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;car&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;first_choice&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;monty_opens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;action&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Monty opens door {monty_opens}; do you switch? (y/n) "&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;"y"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="c1"&gt;# switch doors&lt;/span&gt;
            &lt;span class="n"&gt;final_choice&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;doors&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;first_choice&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;monty_opens&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            &lt;span class="k"&gt;break&lt;/span&gt;
        &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;"n"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;final_choice&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;first_choice&lt;/span&gt;
            &lt;span class="k"&gt;break&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;continue&lt;/span&gt;

    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Your final choice is door {final_choice}."&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;final_choice&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;car&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"You win! The car is behind door {car}."&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"You lose. The car was behind door {car}."&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Next, let’s automate the process so that the computer decides randomly whether or not to switch, and returns us the information we need to analyze the outcomes (&lt;em&gt;stay/switch&lt;/em&gt; and &lt;em&gt;win/lose&lt;/em&gt;).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;monty_hall&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;doors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"a"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s2"&gt;"b"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s2"&gt;"c"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;car&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;first_choice&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;doors&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;car&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;first_choice&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;monty_opens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt;

    &lt;span class="n"&gt;switch_doors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;final_choice&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;doors&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;first_choice&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;door&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;monty_opens&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;switch_doors&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="n"&gt;first_choice&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;final_choice&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;car&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"switch_doors"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;switch_doors&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"result"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;monty_hall&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'switch_doors'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'result'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Just as we can get the computer to flip a million coins for us, we can also get it to confront the Monty Hall problem a million times (if we want). This is called a &lt;strong&gt;Monte Carlo simulation&lt;/strong&gt;. I was already familiar with this concept, but to offer a quick summary here, it basically leverages the &lt;strong&gt;law of large numbers&lt;/strong&gt;: If you perform the same experiment enough times, the real result eventually converges on the theoretical result.&lt;/p&gt;
&lt;p&gt;So let’s code it with a simple loop, tallying the results in two lists, and taking advantage of the truthiness of booleans in Python to quickly analyze the results:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;monte_monty&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;switch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stay&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;monty_hall&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"switch_doors"&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
            &lt;span class="n"&gt;switch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"result"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;stay&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"result"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;switch&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="c1"&gt;# avoid division by zero errors if you do 1 or 2 trials&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Switching won {sum(switch)} out of {len(switch)} times; probability of {round(sum(switch)/len(switch) * 100, 2)}%."&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;stay&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Staying won {sum(stay)} out of {len(stay)} times; probability of {round(sum(stay)/len(stay) * 100, 2)}%."&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To reiterate the explanation above, &lt;em&gt;if you perform the same experiment enough times, the real result eventually converges on the theoretical result.&lt;/em&gt; Watch what happens with just 25 simulations:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;monte_monty&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Switching&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;58.33&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;
&lt;span class="n"&gt;Staying&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;30.77&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It is already clear after just 25 simulations that the probability of switching is significantly greater than that of staying. Let’s keep going.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;21&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;monte_monty&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Switching&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;18&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;29&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;62.07&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;
&lt;span class="n"&gt;Staying&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;21&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;33.33&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;monte_monty&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Switching&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;51&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;62.75&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;
&lt;span class="n"&gt;Staying&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;49&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;32.65&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;monte_monty&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Switching&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;330&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;496&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;66.53&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;
&lt;span class="n"&gt;Staying&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;169&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;504&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;33.53&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;monte_monty&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Switching&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;3376&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;5053&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;66.81&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;
&lt;span class="n"&gt;Staying&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;1675&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;4947&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;33.86&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;monte_monty&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Switching&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;33289&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;49759&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;66.9&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;
&lt;span class="n"&gt;Staying&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;16789&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;50241&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;33.42&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;26&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;monte_monty&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1000000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Switching&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;333204&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;500463&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;66.58&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;
&lt;span class="n"&gt;Staying&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;166298&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;499537&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;33.29&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;27&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;monte_monty&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10000000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Switching&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;3331217&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;4998552&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;66.64&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;
&lt;span class="n"&gt;Staying&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt; &lt;span class="mi"&gt;1666441&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;5001448&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;33.32&lt;/span&gt;&lt;span class="o"&gt;%.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After 1000 runs, we pretty much obtain the theoretical probability of &lt;span class="math"&gt;\(\frac{2}{3}\)&lt;/span&gt; chance of a winning switch and &lt;span class="math"&gt;\(\frac{1}{3}\)&lt;/span&gt; chance of a winning stay, and after 10 million runs, we come within a hair’s breadth of it.&lt;/p&gt;
&lt;p&gt;In this way, the Monte Carlo method is not that different from stochastic gradient descent.&lt;/p&gt;
&lt;h1 id="probabilistic-approach"&gt;Probabilistic approach&lt;/h1&gt;
&lt;p&gt;There is another, less brute-force, more theoretical way of working out this answer using &lt;strong&gt;Bayesian inference&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Let’s rephrase the problem. Instead of focusing on the probability of a certain action (&lt;em&gt;stay/switch&lt;/em&gt;) winning, we’ll examine the probability of a car being behind door &lt;span class="math"&gt;\(x\)&lt;/span&gt; after Monty opens door &lt;span class="math"&gt;\(y\)&lt;/span&gt;, or in the language of &lt;strong&gt;conditional probability&lt;/strong&gt;, &lt;em&gt;given&lt;/em&gt; that Monty opens door &lt;span class="math"&gt;\(y\)&lt;/span&gt;. That is,&lt;/p&gt;
&lt;div class="math"&gt;$$ P(\textrm{car}_x | \textrm{Monty}_y) $$&lt;/div&gt;
&lt;p&gt;Let’s start with the &lt;em&gt;unconditional&lt;/em&gt; probability (i.e., before the game starts) of the car being behind each of the doors, &lt;span class="math"&gt;\(P(\textrm{car}_x)\)&lt;/span&gt;. There are three doors and one car, so&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{gathered} P(\textrm{car}_x) = \tfrac{1}{3} \\
\therefore P(\textrm{car}_a) = P(\textrm{car}_b) = P(\textrm{car}_c) = \tfrac{1}{3} \end{gathered} $$&lt;/div&gt;
&lt;p&gt;Next, let’s determine the &lt;em&gt;unconditional&lt;/em&gt; probabilities (i.e., before the game starts) of Monty choosing each of the doors. Since he cannot choose the door you will have chosen, that leaves him with two doors:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{gathered} P(\textrm{Monty}_x) = \tfrac{1}{2} \\
\therefore P(\textrm{Monty}_a) = P(\textrm{Monty}_b) = P(\textrm{Monty}_c) = \tfrac{1}{2} \end{gathered} $$&lt;/div&gt;
&lt;p&gt;Now that we have our building blocks, let’s plug in what we can into the theorem:&lt;/p&gt;
&lt;div class="math"&gt;$$ P(H|E) = \frac{P(E|H) P(H)}{P(E)} $$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(H\)&lt;/span&gt; is the hypothesis we’re interested in and &lt;span class="math"&gt;\(E\)&lt;/span&gt; is the plot-twist, game-changing event.&lt;/p&gt;
&lt;p&gt;Let’s assume our first choice is door A. If we want to know the probability of the car being behind door A after Monty opens door C (i.e., we win by staying), we can fill in what we know:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned} P(\textrm{car}_a|\textrm{Monty}_c) &amp;amp;= \frac{P(\textrm{Monty}_c|\textrm{car}_a) P(\textrm{car}_a)}{P(\textrm{Monty}_c)} \\
&amp;amp;= \frac{P(\textrm{Monty}_c|\textrm{car}_a) \cdot \tfrac{1}{3} }{\tfrac{1}{2}} \end{aligned} $$&lt;/div&gt;
&lt;p&gt;which leaves one last probability to calculate, &lt;span class="math"&gt;\(P(\textrm{Monty}_c|\textrm{car}_a)\)&lt;/span&gt;. That is the probability that Monty will open door C if the car is behind door A.&lt;/p&gt;
&lt;p&gt;Monty can’t choose your door (A) or the door with the car (also A), leaving him two choices. He is therefore equally likely to choose door B or C, which means that &lt;span class="math"&gt;\(P(\textrm{Monty}_c|\textrm{car}_a) = \tfrac{1}{2}\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$ P(\textrm{car}_a|\textrm{Monty}_c) = \frac{P(\textrm{Monty}_c|\textrm{car}_a) P(\textrm{car}_a)}{P(\textrm{Monty}_c)} = \frac{\tfrac{1}{2} \cdot \tfrac{1}{3} }{\tfrac{1}{2}} = \frac{1}{3} $$&lt;/div&gt;
&lt;p&gt;Though the theorem is quite convoluted, this answer agrees with our intuition and the Monte Carlo results.&lt;/p&gt;
&lt;p&gt;What about the probability that we win by switching (i.e., the probability that the car is behind door B after Monty opens door C)?&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned} P(\textrm{car}_b|\textrm{Monty}_c) &amp;amp;= \frac{P(\textrm{Monty}_c|\textrm{car}_b) P(\textrm{car}_b)}{P(\textrm{Monty}_c)} \\
&amp;amp;= \frac{P(\textrm{Monty}_c|\textrm{car}_b) \cdot \tfrac{1}{3} }{\tfrac{1}{2}} \end{aligned} $$&lt;/div&gt;
&lt;p&gt;In the case of &lt;span class="math"&gt;\(P(\textrm{Monty}_c|\textrm{car}_b)\)&lt;/span&gt;, we have chosen door A and the car is behind door B. Monty knows this, and he also can’t choose the door you’ve chosen, door A.&lt;/p&gt;
&lt;p&gt;His &lt;em&gt;only&lt;/em&gt; choice, then, is to choose door C, and therefore &lt;span class="math"&gt;\(P(\textrm{Monty}_c|\textrm{car}_b) = 1\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$ P(\textrm{car}_b|\textrm{Monty}_c) = \frac{P(\textrm{Monty}_c|\textrm{car}_b) P(\textrm{car}_b)}{P(\textrm{Monty}_c)} = \frac{1 \cdot \tfrac{1}{3} }{\tfrac{1}{2}} = \frac{2}{3} $$&lt;/div&gt;
&lt;p&gt;Again, the theorem agrees with the Monte Carlo results, although whether or not it also agrees with your intuition is a different question!&lt;/p&gt;
&lt;h1 id="where-do-we-go-from-here"&gt;Where do we go from here?&lt;/h1&gt;
&lt;p&gt;I know that the Monte Carlo method can be used to make predictions about the movements of the stock market. However, I’m totally new to probability theory, so I’m not yet sure where to go after Bayes’ theorem. I’ll update this section once I find out and post about more generalized and sophisticated ways to apply Monte Carlo and Bayes’ theorem. Stay tuned!&lt;/p&gt;
&lt;h1 id="references"&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://datant.wordpress.com/2017/01/16/the-monty-hall-problem-and-3-ways-to-solve-it/"&gt;The Monty Hall problem and 3 ways to solve it&lt;/a&gt;, Anthony O’Farrell&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.countbayesie.com/blog/2015/2/18/bayes-theorem-with-lego"&gt;Bayes’ Theorem with Lego&lt;/a&gt;, Will Kurt&lt;/li&gt;
&lt;li&gt;&lt;a href="https://sc5.io/posts/how-to-solve-the-monty-hall-problem-using-bayesian-inference/#gref"&gt;How to solve the Monty Hall problem using Bayesian inference&lt;/a&gt;, Max Pagels&lt;/li&gt;
&lt;/ul&gt;</content><category term="Monte Carlo"></category><category term="Bayesian inference"></category></entry><entry><title>The Loopless Loop (or How I made my code run 7,000 times faster)</title><link href="http://tabidots.github.io/2019/01/loopless-loop" rel="alternate"></link><published>2019-01-10T19:00:46+07:00</published><updated>2019-01-10T19:00:46+07:00</updated><author><name>Justin Douglas</name></author><id>tag:tabidots.github.io,2019-01-10:/2019/01/loopless-loop</id><summary type="html">&lt;p&gt;In which I (1) discover that the purpose of linear algebra is not to just manipulate spreadsheets and move vectors around but to make your code faster and cleaner—in other words, to give it a Zen uppercut; and (2) learn LaTeX and start a blog just to see syntax-highlighted code and properly typeset math on the same&amp;nbsp;page.&lt;/p&gt;</summary><content type="html">
&lt;h1 id="part-1-ugly-math-ugly-code"&gt;Part 1: Ugly math, ugly code&lt;/h1&gt;
&lt;p&gt;As I embarked on my journey to learn the math side of machine learning, all of the blog posts seemed to point to linear algebra as the starting point. The problem was, nothing I read made it immediately clear &lt;em&gt;how&lt;/em&gt; linear algebra played a role in machine learning.&lt;/p&gt;
&lt;p&gt;Worse yet, the whole discussion of vectors, matrices, linear combinations, and linear transformations seemed completely disconnected from my layman’s understanding of machine learning.&lt;/p&gt;
&lt;p&gt;The Khan Academy videos on linear algebra are quite tedious and I didn’t feel I was getting anywhere. &lt;a href="https://www.youtube.com/watch?v=fNk_zzaMoSs&amp;amp;list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab"&gt;3blue1brown’s Linear Algebra series&lt;/a&gt; is much more engaging and lucid, but I was still getting bogged down in the theory without seeing the application.&lt;/p&gt;
&lt;p&gt;Needless to say, it was pretty slow going.&lt;/p&gt;
&lt;h2 id="my-linear-algebra-a-ha-moment"&gt;My linear algebra &lt;em&gt;a-ha&lt;/em&gt; moment&lt;/h2&gt;
&lt;p&gt;It wasn’t until I switched gears and decided, on a whim, to tackle &lt;em&gt;linear regression&lt;/em&gt; that linear algebra really started to click for me. On a practical level, code that uses linear-algebraic methods simplifies work for the computer by orders of magnitude, making it possible to process massive datasets—and process them rapidly. This is obviously a critical requirement in the age of Big Data.&lt;/p&gt;
&lt;p&gt;And on a conceptual level, it gave me my first mathematical &lt;em&gt;a-ha&lt;/em&gt; moment:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;By manipulating matrices and vectors, you can achieve the same outcome as a loop without explicitly looping—a loopless loop&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;That&lt;/em&gt; is why linear algebra is the cornerstone of machine learning.&lt;/p&gt;
&lt;p&gt;The only thing is, no single resource I found on the internet seemed to really clarify the mathematical and programmatic aspects &lt;em&gt;at the same time&lt;/em&gt; without getting too abstract on the math side of things.&lt;/p&gt;
&lt;p&gt;As a self-taught and formerly math-phobic coder, I needed a guide that progressed from from inelegant code (which I could understand) and inelegant math to (mind-blowingly) elegant math, which would then lay the groundwork for writing extremely elegant—and performant—code (which is incomprehensible without understanding the math).&lt;/p&gt;
&lt;p&gt;This is that guide, created from my notes from Week 1 of my machine learning journey. I’ve split it up into multiple posts, since it’s quite long.&lt;/p&gt;
&lt;h2 id="how-to-make-a-computer-explode"&gt;How to make a computer explode&lt;/h2&gt;
&lt;p&gt;I always thought that for-loops were simply a fact of life.&lt;/p&gt;
&lt;p&gt;While I understood the basic principle behind stochastic gradient descent, I had never implemented it myself before. If I had tried my hand at it before learning the math involved, I probably would have come up with this monster:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# DON'T TRY THIS&lt;/span&gt;

&lt;span class="n"&gt;samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;lists&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;actual&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;train_lr_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;actual&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;feature&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;samples&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="c1"&gt;# 0 to start&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weight&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;summation_part_of_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sample&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;samples&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                &lt;span class="n"&gt;sum_of_sq_errs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hypothesis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;actual&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
                &lt;span class="n"&gt;summation_part_of_cost&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;sum_of_sq_errs&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            &lt;span class="n"&gt;partial_deriv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;samples&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;summation_part_of_cost&lt;/span&gt;
            &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;partial_deriv&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;

&lt;span class="c1"&gt;# I REALLY HOPE YOU DIDN'T TRY THIS&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Okay, maybe not. (It would be pretty hard to write this without understanding the math involved.)&lt;/p&gt;
&lt;p&gt;Count those loops—&lt;em&gt;three&lt;/em&gt;, to be exact! Terrifying. Now, being handy with Python, I could probably have calculated &lt;code class="highlight"&gt;partial_deriv&lt;/code&gt; in one line with an even more terrifying list comprehension, just to show off:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;partial_deriv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;samples&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hypothesis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;actual&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sample&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;samples&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;…which shaves off four lines, at the expense of all readability. But bigger problems remain:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;The time complexity of this program is off the charts.&lt;/strong&gt; In &lt;a href="https://en.wikipedia.org/wiki/Time_complexity"&gt;Big-O time complexity&lt;/a&gt; terms, it is &lt;em&gt;at least&lt;/em&gt; &lt;span class="math"&gt;\(O(n^3)\)&lt;/span&gt;, if not more, which is cubic time, or (literally) &lt;em&gt;exponentially &lt;a href="http://bigocheatsheet.com/"&gt;horrible&lt;/a&gt;&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;It doesn’t even work.&lt;/strong&gt; Even with a dataset of unremarkable size, you’re bound to get a &lt;code class="highlight"&gt;&lt;span class="n"&gt;RuntimeWarning&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;overflow&lt;/span&gt; &lt;span class="n"&gt;encountered&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="n"&gt;square&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;/code&gt; that can’t be avoided even if you set the &lt;code class="highlight"&gt;learning_rate&lt;/code&gt; to an impractically small value like &lt;code class="highlight"&gt;0.00001&lt;/code&gt;. Trust me, I’ve tried.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Is there any way beyond this impasse?&lt;/p&gt;
&lt;h2 id="meeting-a-zen-master-on-the-road"&gt;Meeting a Zen master on the road&lt;/h2&gt;
&lt;p&gt;In Zen Buddhism, there is a famous book called &lt;em&gt;The Gateless Gate&lt;/em&gt;, which is a collection of &lt;em&gt;koans&lt;/em&gt;. A Zen &lt;em&gt;koan&lt;/em&gt; is a riddle that cannot be approached with the rational mind. For example:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Goso said: “When you meet a Zen master on the road, you cannot talk to him, but neither can you face him with silence. What are you going to do?”&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To solve it, you have to transcend the duality of &lt;em&gt;this&lt;/em&gt; and &lt;em&gt;not-this&lt;/em&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Give him an uppercut&lt;br/&gt;
And you will be called one who understands Zen.&lt;/em&gt;&lt;br/&gt;
—The Gateless Gate, Koan #36&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As you might imagine, linear algebra—&lt;strong&gt;the loopless loop&lt;/strong&gt;—is the Zen uppercut of coding. What, then is the target of our uppercut?&lt;/p&gt;
&lt;h2 id="linear-regression-a-basic-overview"&gt;Linear regression: A basic overview&lt;/h2&gt;
&lt;p&gt;Basically, linear regression is used to make predictions about a &lt;em&gt;thing&lt;/em&gt; based on its characteristics, assuming that&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;that there is some correlation among those characteristics and&lt;/li&gt;
&lt;li&gt;that you have plenty of data about other &lt;em&gt;things&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The intuition here can be explained with middle school algebra. Imagine you know the square footage and price of 200 houses and you want to estimate the price of a house with a given square footage.&lt;/p&gt;
&lt;p&gt;Obviously, this is an oversimplified correlation for the sake of example. (And for some reason, everyone seems to explain this concept using houses, so why reinvent the wheel?)&lt;/p&gt;
&lt;p&gt;If you were to make a scatter plot of that data, with the area along the x-axis and the price along the y-axis, the pattern might roughly look like it follows a line—not perfectly linear, but linear &lt;em&gt;enough&lt;/em&gt; to predict the price of a house with &lt;span class="math"&gt;\(x\)&lt;/span&gt; square footage. You can use linear regression to work backward from the data to determine this line, &lt;strong&gt;the line of best fit&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In middle school algebra, lines are written in the form&lt;/p&gt;
&lt;div class="math"&gt;$$ y = \textcolor{magenta}{m}\textcolor{teal}{x} + \textcolor{orange}{b} $$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(\textcolor{teal}{x}\)&lt;/span&gt; is the input, &lt;span class="math"&gt;\(\textcolor{magenta}{m}\)&lt;/span&gt; is the slope of the line, &lt;span class="math"&gt;\(\textcolor{orange}{b}\)&lt;/span&gt; moves the line up and down on the graph, and &lt;span class="math"&gt;\(y\)&lt;/span&gt; is the height of the line at point &lt;span class="math"&gt;\(\textcolor{teal}{x}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Our house problem can also be framed as a line, where &lt;span class="math"&gt;\(\textcolor{teal}{x}\)&lt;/span&gt; is the square footage, which influences the price by some value &lt;span class="math"&gt;\(\textcolor{magenta}{m}\)&lt;/span&gt;, to which we add some kind of base price to bring us to the final price, &lt;span class="math"&gt;\(y\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Well, that was easy enough, right?&lt;/p&gt;
&lt;h2 id="multiple-linear-regression-because-more-is-better-or-something"&gt;Multiple linear regression: Because more is better (or something)&lt;/h2&gt;
&lt;p&gt;In the real world, of course, area is not the only factor that decides the price of a house. There are many others. Can we still adapt our middle school equation to this problem if each house has 3 features—say, area, nearby property values, and age of the building?&lt;/p&gt;
&lt;div class="math"&gt;$$ y = \textcolor{magenta}{m}\textcolor{teal}{x} + \textcolor{magenta}{n}\textcolor{teal}{z} + \textcolor{magenta}{o}\textcolor{teal}{a} + \textcolor{orange}{b} $$&lt;/div&gt;
&lt;p&gt;We can, but it’s messy. (It’s also no longer a line, but let’s ignore that for now.) First, let’s rewrite that “base price” as &lt;span class="math"&gt;\(b \cdot 1\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$ y = \textcolor{magenta}{m}\textcolor{teal}{x} + \textcolor{magenta}{n}\textcolor{teal}{z} + \textcolor{magenta}{o}\textcolor{teal}{a} + \textcolor{magenta}{b}\cdot\textcolor{teal}{1} $$&lt;/div&gt;
&lt;p&gt;This gives us a nice symmetry: Notice that all of the teal variables are features, which are multiplied by their degree of influence (called a &lt;em&gt;coefficient&lt;/em&gt; in statistics, or a &lt;em&gt;weight&lt;/em&gt; in machine learning). When you add all these together, you get the price of the house.&lt;/p&gt;
&lt;p&gt;This is called &lt;strong&gt;multiple linear regression&lt;/strong&gt;. Most people wouldn’t skip directly to multiple &lt;span class="caps"&gt;LR&lt;/span&gt; after introducing single &lt;span class="caps"&gt;LR&lt;/span&gt;, but single &lt;span class="caps"&gt;LR&lt;/span&gt; is pretty easy to digest if you can understand high school calculus (derivatives), so it didn’t level up my math knowledge.&lt;/p&gt;
&lt;p&gt;Now, let’s code our equation, putting all the feature values into a &lt;em&gt;list&lt;/em&gt; &lt;code class="highlight"&gt;features&lt;/code&gt; and the weights into another &lt;em&gt;list&lt;/em&gt; &lt;code class="highlight"&gt;weights&lt;/code&gt;. In Python, in increasing order of elegance, we can write the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Using completely random numbers just to show the code&lt;/span&gt;
&lt;span class="n"&gt;features&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;# 3 features; first value is the “dummy feature”&lt;/span&gt;
&lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.75&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;# Brute-force addition&lt;/span&gt;
&lt;span class="n"&gt;price&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If we use &lt;span class="math"&gt;\(x\)&lt;/span&gt;s to denote our features, &lt;span class="math"&gt;\(θ\)&lt;/span&gt;s to denote our weights, and subscript numbers to denote the position of each item in a list (series), then we can rewrite our equation in a slightly more organized way:&lt;/p&gt;
&lt;div class="math"&gt;$$ h_θ(x) = \textcolor{magenta}{θ_0}\textcolor{lightgray}{x_0} + \textcolor{magenta}{θ_1}\textcolor{teal}{x_1} + \cdots + \textcolor{magenta}{θ_n}\textcolor{teal}{x_n}  $$&lt;/div&gt;
&lt;p&gt;which just happens to be the &lt;strong&gt;generalized form of linear regression&lt;/strong&gt;—&lt;em&gt;general&lt;/em&gt; in the sense that it can accommodate any number of features, whether that’s 1 or 1,000.&lt;/p&gt;
&lt;p&gt;Here, &lt;span class="math"&gt;\(x\)&lt;/span&gt; is the collection of all feature values &lt;span class="math"&gt;\(\textcolor{teal}{x_1}\)&lt;/span&gt; through &lt;span class="math"&gt;\(\textcolor{teal}{x_n}\)&lt;/span&gt;, where &lt;span class="math"&gt;\(n\)&lt;/span&gt; is the number of features. (And &lt;span class="math"&gt;\(x_{1000}\)&lt;/span&gt; actually isn’t too crazy in terms of real-world datasets!) It also includes the dummy feature &lt;span class="math"&gt;\(\textcolor{lightgray}{x_0} = 1\)&lt;/span&gt;. Likewise, &lt;span class="math"&gt;\(θ\)&lt;/span&gt; is the collection of all weights, including &lt;span class="math"&gt;\(\textcolor{magenta}{θ_0}\)&lt;/span&gt;, the “base price” in our example. In machine learning, this is called the &lt;em&gt;bias&lt;/em&gt; value.&lt;/p&gt;
&lt;p&gt;Finally, the function notation &lt;span class="math"&gt;\(h_θ(x)\)&lt;/span&gt; indicates that this is the &lt;strong&gt;hypothesis&lt;/strong&gt; for item (house) &lt;span class="math"&gt;\(x\)&lt;/span&gt; given the collection of weights &lt;span class="math"&gt;\(θ\)&lt;/span&gt;.&lt;/p&gt;
&lt;h2 id="how-to-python-in-math-lesson-1"&gt;How to Python in math (Lesson 1)&lt;/h2&gt;
&lt;p&gt;If you know anything about programming, you know that the last line of code above is no way to write a program. Accommodating 100 features would be a chore, and accommodating a variable number of features would be impossible. Naturally, we would use the magic of iteration:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Super-basic iteration over the lists&lt;/span&gt;
&lt;span class="n"&gt;price&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;price&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;No one actually writes the linear regression formula like this, but if you wanted to, you could express the above code in math using a &lt;em&gt;summation&lt;/em&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ h_θ(x) = \sum_{j=0}^n \textcolor{magenta}{θ_j}\textcolor{teal}{x_j} $$&lt;/div&gt;
&lt;p&gt;That Greek letter &lt;span class="math"&gt;\(\sum\)&lt;/span&gt; (sigma) means &lt;em&gt;summation&lt;/em&gt;. Basically, run a for-loop that adds the result of the following expression for each sample (house) starting at &lt;span class="math"&gt;\(j=0\)&lt;/span&gt; until &lt;span class="math"&gt;\(j=n\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;If you know Python better than you know math (as I did), then you might try further refactoring the code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Functional programming version&lt;/span&gt;
&lt;span class="n"&gt;price&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;price&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt;

&lt;span class="c1"&gt;# More Pythonic version of the above&lt;/span&gt;
&lt;span class="n"&gt;price&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I didn’t realize this when I wrote the first draft of this post, but even expressing the simple Python function &lt;code class="highlight"&gt;zip(x, y)&lt;/code&gt; in math requires linear algebra. I’ll get back to the non-fancy version of linear regression in just a minute, but for sake of thoroughness, if &lt;span class="math"&gt;\(x\)&lt;/span&gt; and &lt;span class="math"&gt;\(θ\)&lt;/span&gt; are both vectors, then&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\vec x = \begin{bmatrix} x_0 \\ x_1 \\ \vdots \\ x_n \end{bmatrix} &amp;amp; \qquad{}
\vec θ = \begin{bmatrix} θ_0 \\ θ_1 \\ \vdots \\ θ_n \end{bmatrix} &amp;amp; \quad{}
z(\vec x, \vec θ) = \vec θ\vec x \end{aligned} $$&lt;/div&gt;
&lt;p&gt;Similarly, we can rewrite our equation as a function in Python, too. Let’s leave vectors aside for now, but keep the &lt;code class="highlight"&gt;zip&lt;/code&gt; and encapsulate it into a function, because it’s clean and easy to understand.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;hypothesis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="einstein-notation-making-math-less-confusing-by-making-it-more-confusing"&gt;Einstein notation: Making math less confusing by making it more confusing&lt;/h2&gt;
&lt;p&gt;This is all great if there’s only one &lt;span class="math"&gt;\(x\)&lt;/span&gt; (house). But we will need tons of houses to make a decent prediction. Our list &lt;code class="highlight"&gt;houses&lt;/code&gt; needs to be changed into a &lt;em&gt;list of lists&lt;/em&gt;. For the sake of example, if we had three houses and three features, &lt;code class="highlight"&gt;houses&lt;/code&gt; would look like this (remember the dummy feature):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;houses&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
          &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
          &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="c1"&gt;# random values&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This also allows us to refer to specific features of specific houses using two indexes, &lt;code class="highlight"&gt;houses[i][j]&lt;/code&gt;. How do we do this in math, though? Enter &lt;strong&gt;Einstein notation&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$ h_θ(x^i) = θ_0x_0^i + θ_1x_1^i + \cdots + θ_nx_n^i  $$&lt;/div&gt;
&lt;p&gt;The superscript numbers here &lt;em&gt;aren’t&lt;/em&gt; exponents. You would think Einstein, of all people, could come up with something less confusing, but that is the convention, so it’s important to become familiar with it.&lt;/p&gt;
&lt;p&gt;Just remember that in linear regression, there are conventional choices for the variable names. &lt;span class="math"&gt;\(i\)&lt;/span&gt; denotes the &lt;span class="math"&gt;\(i\)&lt;/span&gt;th house, and &lt;span class="math"&gt;\(j\)&lt;/span&gt; the &lt;span class="math"&gt;\(j\)&lt;/span&gt;th feature.&lt;/p&gt;
&lt;div class="math"&gt;$$ x^{\textcolor{orange}{i \textrm{th sample}}}_{\textcolor{blue}{j \textrm{th feature}}} $$&lt;/div&gt;
&lt;p&gt;So if we were to start describing each hypothesis for our dataset individually,&lt;/p&gt;
&lt;div class="math"&gt;$$ h_θ(x^i) = \left\{\begin{array}{ll}
h_θ(x^0) = θ_0x_0^0 + θ_1x_1^0 + \cdots + θ_nx_n^0 \\[0.5em]
h_θ(x^1) = θ_0x_0^1 + θ_1x_1^1 + \cdots + θ_nx_n^1 \\[0.5em]
h_θ(x^2) = θ_0x_0^2 + θ_1x_1^2 + \cdots + θ_nx_n^2 \\[0.5em]
h_θ(x^3) = θ_0x_0^2 + θ_1x_1^2 + \cdots + θ_nx_n^2
\end{array}\right. $$&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;hypothesis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;hypothesis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;hypothesis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;hypothesis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;hyps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;hypothesis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;house&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;house&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="cost-function-how-accurate-are-our-predictions"&gt;Cost function: How accurate are our predictions?&lt;/h2&gt;
&lt;p&gt;Seeing as the goal of linear regression is to come up with a line that best fits the data, we need some way to evaluate a line’s &lt;strong&gt;goodness of fit&lt;/strong&gt; to the data. One measure of that is the &lt;strong&gt;mean squared error&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id="error"&gt;Error&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Error&lt;/em&gt; is how far the prediction for one sample (house) is from its actual value.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\textrm{error}_i &amp;amp;= \textrm{prediction}_i - \textrm{actual}_i\\
&amp;amp;= \hat{Y}_i - Y_i
\end{aligned} $$&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Note&lt;/em&gt;: The subscript &lt;span class="math"&gt;\(i\)&lt;/span&gt; here is &lt;strong&gt;not&lt;/strong&gt; Einstein notation, because these are just lists of values, not a “spreadsheet” of rows and columns. The Einstein notation in this discussion of linear regression only applies to &lt;span class="math"&gt;\(x\)&lt;/span&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\hat Y\)&lt;/span&gt; is read “Y-hat,” which is just a statistical convention. It can be substituted with our function &lt;span class="math"&gt;\(h_θ(x^i)\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$ \textrm{error}_i = h_θ(x^i) - Y_i $$&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;actual_values&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;# 3 houses; random values&lt;/span&gt;
&lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.75&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;error&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;hypothesis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;actual_values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="squared-error"&gt;Squared error&lt;/h3&gt;
&lt;p&gt;We &lt;em&gt;square&lt;/em&gt; it so that (1) all values are positive, preventing underestimates and overestimates from canceling each other out; and (2) larger errors are considered proportionally “more erroneous” than smaller errors.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\textrm{SE}_i &amp;amp;= \textrm{error}^2\\
&amp;amp;= (\hat{Y}_i - Y_i)^2\\
&amp;amp;= (h_θ(x^i) - Y_i)^2
\end{aligned} $$&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;se&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="mean-squared-error"&gt;Mean squared error&lt;/h3&gt;
&lt;p&gt;The &lt;em&gt;mean&lt;/em&gt; value of the squared error for all samples can give us an idea about our line’s goodness of fit.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\textrm{MSE} &amp;amp;= \frac{\textrm{SE}_\textcolor{red}{1} \textcolor{blue}{+ \cdots + } \textrm{ SE}_\textcolor{red}{\textrm{number of samples}}}{\textrm{number of samples}}\\
&amp;amp;= \frac{\textcolor{blue}{\sum}_{\textcolor{red}{i=1}}^{\textcolor{red}{m}} \textrm{SE}}{m}\\
&amp;amp;= \frac{\sum_{\textcolor{red}{i=1}}^{\textcolor{red}{m}} (\hat{Y}_{\textcolor{red}i} - Y_{\textcolor{red}i})^2}{m}\\
&amp;amp;= \frac{1}{m} \sum_{\textcolor{red}{i=1}}^{\textcolor{red}{m}} (\hat{Y}_{\textcolor{red}i} - Y_{\textcolor{red}i})^2\\
&amp;amp;= \frac{1}{m} \sum_{\textcolor{red}{i=1}}^{\textcolor{red}{m}} (h_θ(x^{\textcolor{red}i}) - Y_{\textcolor{red}i})^2
\end{aligned} $$&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;total_se&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;total_se&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;se&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;mse&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;total_se&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;

&lt;span class="c1"&gt;# More Pythonic and more similar to the actual math notation&lt;/span&gt;
&lt;span class="n"&gt;mse&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;se&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;house&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;house&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Note&lt;/em&gt;: &lt;span class="caps"&gt;MSE&lt;/span&gt; gives us an indication of goodness of fit, but it’s difficult to tie that value directly to the data. You can use the &lt;span class="caps"&gt;RMSE&lt;/span&gt; (root mean squared error), which is just the square root of the &lt;span class="caps"&gt;MSE&lt;/span&gt;, to reframe the average error in terms of the data. In this case, the &lt;span class="caps"&gt;RMSE&lt;/span&gt; would tell us how much (in dollars) that our prediction line was off by.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Let’s use the mean squared error to rewrite this equation as a function of the collection of weights. Every time we change the weights, we will obtain a different line with a different goodness of fit (&lt;span class="caps"&gt;MSE&lt;/span&gt;), and this relationship can be illustrated by a function called the &lt;em&gt;cost function&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;se&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;house&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;house&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Well, almost. This function is conventionally named &lt;span class="math"&gt;\(J\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ J(θ) = \frac{1}{\textcolor{magenta}{2}m} \sum_{i=1}^m (h_θ(x^i) - Y_i)^2 $$&lt;/div&gt;
&lt;p&gt;Where did that &lt;span class="math"&gt;\(\textcolor{magenta}{2}\)&lt;/span&gt; come from? Again, this is just a matter of convention. The &lt;span class="math"&gt;\(\textcolor{magenta}{2}\)&lt;/span&gt; will cancel out in the the next step.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;se&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;house&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;house&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Keep in mind that &lt;span class="math"&gt;\(θ\)&lt;/span&gt; and &lt;span class="math"&gt;\(Y\)&lt;/span&gt; are lists and &lt;span class="math"&gt;\(x\)&lt;/span&gt; is a list of lists. What this means is that in a situation with two features (plus the dummy feature),&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned} h_{θ_\textcolor{teal}{0}, θ_\textcolor{teal}{1}, θ_\textcolor{teal}{2}}(x) &amp;amp;= h_{θ_\textcolor{teal}{0}}(x_\textcolor{teal}{0}) + h_{θ_\textcolor{teal}{1}}(x_\textcolor{teal}{1}) + h_{θ_2}(x_\textcolor{teal}{2}) \\
h_{θ_\textcolor{teal}{0}, θ_\textcolor{teal}{1}, θ_\textcolor{teal}{2}}(x^\textcolor{red}{i}) &amp;amp;= h_{θ_\textcolor{teal}{0}}(x_\textcolor{teal}{0}^\textcolor{red}{i}) + h_{θ_\textcolor{teal}{1}}(x_\textcolor{teal}{1}^\textcolor{red}{i}) + h_{θ_\textcolor{teal}{2}}(x_\textcolor{teal}{2}^\textcolor{red}{i}) \\
J(θ_\textcolor{teal}{0}, θ_\textcolor{teal}{1}, θ_\textcolor{teal}{2}) &amp;amp;= \frac{1}{2m} \sum_{\textcolor{red}{i=1}}^\textcolor{red}{m} \Big[h_{θ_\textcolor{teal}{0}}(x_\textcolor{teal}{0}^\textcolor{red}{i}) + h_{θ_\textcolor{teal}{1}}(x_\textcolor{teal}{1}^\textcolor{red}{i}) + h_{θ_\textcolor{teal}{2}}(x_\textcolor{teal}{2}^\textcolor{red}{i}) - Y_{\textcolor{red}i}\Big]^2
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;Numbers in teal represent feature numbers; numbers in red represent sample numbers.&lt;/p&gt;
&lt;h2 id="multivariable-calculus-how-much-effect-does-each-weight-have"&gt;Multivariable calculus: How much effect does each weight have?&lt;/h2&gt;
&lt;p&gt;Now, imagine each feature as knobs on a radio. Increasing or decreasing the weight of each feature is like turning up or down the knob for that feature. We want to “tune” our line to be as close to the data as possible by “dialing” the features up and down. In order to do this, we need to determine the effect that a given combination of knob settings has on the final output.&lt;/p&gt;
&lt;p&gt;In math terms, this is akin to asking “How much does &lt;span class="math"&gt;\(J\)&lt;/span&gt; change when &lt;span class="math"&gt;\(θ\)&lt;/span&gt; changes?” Sounds like derivatives from high school calculus.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned} f(x) &amp;amp;= 5x^2 \\
\frac{df}{dx} &amp;amp;= 5\cdot2x^{2-1} \\
&amp;amp;= 10x
\end{aligned}
$$&lt;/div&gt;
&lt;p&gt;Our function &lt;span class="math"&gt;\(J\)&lt;/span&gt; is actually one function inside of another, so the chain rule applies. Bonus points if you remember that from high school—I didn’t.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
J(θ) &amp;amp;= \textcolor{purple}{\frac{1}{2m}} \textcolor{purple}{\sum_{i=1}^m} \textcolor{purple}{\Big[} \textcolor{orange}{h_θ(x^i)} \textcolor{purple}{- Y_i)\Big]^2} \\
\frac{dJ(θ)}{dθ} &amp;amp;= d_\textcolor{purple}{\textrm{outer}} \cdot d_\textcolor{orange}{\textrm{inner}}
\end{aligned} $$&lt;/div&gt;
&lt;div class="math"&gt;$$
\begin{aligned}
\textcolor{purple}{\textrm{outer}} &amp;amp;= \textcolor{purple}{\frac{1}{2m}} \textcolor{purple}{\sum_{i=1}^m} \textcolor{purple}{(} \textcolor{orange}{\textrm{inner}} \textcolor{purple}{- Y_i)^2} &amp;amp;
\textcolor{orange}{\textrm{inner}} &amp;amp;= \textcolor{magenta}{θ_0}\textcolor{teal}{x_0} + \textcolor{magenta}{θ_1}\textcolor{teal}{x_1} + \cdots + \textcolor{magenta}{θ_n}\textcolor{teal}{x_n} \\
d_\textcolor{purple}{\textrm{outer}} &amp;amp;= \textcolor{purple}{\frac{\cancel{2}}{\cancel{2}m}} \textcolor{purple}{\sum_{i=1}^m} \textcolor{purple}{\Big[} \textcolor{orange}{h_θ(x^i)} \textcolor{purple}{{- Y_i\Big]}^2} &amp;amp; d_\textcolor{orange}{\textrm{inner}} &amp;amp;= ???
\end{aligned}
$$&lt;/div&gt;
&lt;p&gt;This is where I got stuck. &lt;span class="math"&gt;\(θ\)&lt;/span&gt; is a collection of values, not just a single value. Each knob on our radio affects the output individually, and we have to determine the individual effect of each knob.&lt;/p&gt;
&lt;p&gt;It helps to start by breaking down what the chain rule is actually saying.&lt;/p&gt;
&lt;div class="math"&gt;$$ \frac{d[\textcolor{purple}{\textrm{outer}}(\textcolor{orange}{\textrm{inner}}(x))]}{dx} = \frac{d_\textcolor{purple}{\textrm{outer}}}{d_\textcolor{orange}{\textrm{inner}}} \cdot \frac{d_\textcolor{orange}{inner}}{dx} $$&lt;/div&gt;
&lt;p&gt;This means our “outer derivative” &lt;span class="math"&gt;\(d_\textcolor{purple}{\textrm{outer}}\)&lt;/span&gt; tells us how much our cost function &lt;span class="math"&gt;\(J(θ)\)&lt;/span&gt; changes in response to a given change in our hypothesis &lt;span class="math"&gt;\(h(x)\)&lt;/span&gt;. We now need to find the “inner derivative” &lt;span class="math"&gt;\(d_{\textcolor{orange}{\textrm{inner}}}\)&lt;/span&gt;, which tells us how much our hypothesis &lt;span class="math"&gt;\(h(x)\)&lt;/span&gt; changes in response to a given change in our weights &lt;span class="math"&gt;\(θ\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;But since &lt;span class="math"&gt;\(θ\)&lt;/span&gt; is a collection of values, there isn’t a single derivative, but rather several &lt;em&gt;partial derivatives&lt;/em&gt;, which indicate how much our hypothesis &lt;span class="math"&gt;\(h(x^i)\)&lt;/span&gt; for a specific sample (house) &lt;span class="math"&gt;\(x^i\)&lt;/span&gt; changes in response to a given change in &lt;em&gt;each&lt;/em&gt; of the weights &lt;span class="math"&gt;\(θ_j\)&lt;/span&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Note&lt;/em&gt;: Another labeling convention—just as &lt;span class="math"&gt;\(i\)&lt;/span&gt; is used to refer to, or “index,” samples from &lt;span class="math"&gt;\(1\)&lt;/span&gt; through &lt;span class="math"&gt;\(m\)&lt;/span&gt;, the total number of samples, lowercase &lt;span class="math"&gt;\(j\)&lt;/span&gt; is used to index features from &lt;span class="math"&gt;\(0\)&lt;/span&gt; through &lt;span class="math"&gt;\(n\)&lt;/span&gt;, the total number of features. To return to our Einstein notation,
&lt;div class="math"&gt;$$ x^{1 \leq \space i^\textrm{th} \textrm{ sample} \space \leq \space m \textrm{ samples}}_{0 \space \leq \space j^\textrm{th} \textrm{ feature} \space \leq \space n \textrm{ features}} $$&lt;/div&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In math notation, this is written with a funny “d” called a “del,” &lt;span class="math"&gt;\(\partial\)&lt;/span&gt;, like this:&lt;/p&gt;
&lt;div class="math"&gt;$$ \frac{\partial h_θ(x^i)}{\partial θ_j} $$&lt;/div&gt;
&lt;p&gt;This looks crazy, but the process of finding these partial derivatives is really the same as finding a normal derivative, except you &lt;em&gt;treat all the other variables as constant&lt;/em&gt;, effectively ignoring them. So, for we now only have to concern ourselves with&lt;/p&gt;
&lt;div class="math"&gt;$$ h_{θ_j}(x^i) = \begin{cases}
\textcolor{magenta}{θ_0}\textcolor{teal}{x_0^i} \textcolor{lightgray}{+θ_1x_1^i + θ_2x_2^i} &amp;amp; \text{when } j=0 \\
\textcolor{lightgray}{θ_0x_0^i} \textcolor{lightgray}{+} \textcolor{magenta}{θ_1}\textcolor{teal}{x_1^i} \textcolor{lightgray}{+θ_2x_2^i} &amp;amp; \text{when } j=1 \\
\textcolor{lightgray}{θ_0x_0^i + θ_1x_1^i} \textcolor{lightgray}{+} \textcolor{magenta}{θ_2}\textcolor{teal}{x_2^i} &amp;amp; \text{when } j=2 \\
\end{cases} $$&lt;/div&gt;
&lt;p&gt;The derivative of a variable times something else is just the &lt;em&gt;something else&lt;/em&gt;. (For a line &lt;span class="math"&gt;\(y = 2x\)&lt;/span&gt;, &lt;span class="math"&gt;\(\frac{dy}{dx}\)&lt;/span&gt; is just &lt;span class="math"&gt;\(2\)&lt;/span&gt;, since its slope will be 2 at every point along the line.) Thus,&lt;/p&gt;
&lt;div class="math"&gt;$$ \frac{\partial h_θ(x)}{\partial θ_j} = \begin{cases}
\frac{\partial h_θ(x)}{\partial θ_0} &amp;amp;= \textcolor{lightgray}{θ_0} \textcolor{teal}{x_0^i} &amp;amp; \text{when } j=0 \\[0.5em]
\frac{\partial h_θ(x)}{\partial θ_1} &amp;amp;= \textcolor{lightgray}{θ_1} \textcolor{teal}{x_1^i} &amp;amp; \text{when } j=1 \\[0.5em]
\frac{\partial h_θ(x)}{\partial θ_2} &amp;amp;= \textcolor{lightgray}{θ_2} \textcolor{teal}{x_2^i} &amp;amp; \text{when } j=2
\end{cases} $$&lt;/div&gt;
&lt;p&gt;Or just&lt;/p&gt;
&lt;div class="math"&gt;$$ \frac{\partial h_θ(x)}{\partial θ_j} = \left\{\begin{array}{lr}
x_0^i &amp;amp; \text{when } j=0 \\[0.5em]
x_1^i &amp;amp; \text{when } j=1 \\[0.5em]
x_2^i &amp;amp; \text{when } j=2
\end{array}\right\}
= \textcolor{red}{x_j^i} $$&lt;/div&gt;
&lt;p&gt;That’s &lt;span class="math"&gt;\(d_{\textcolor{orange}{\textrm{inner}}}\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\frac{\partial{J(θ)}}{\partial{θ_j}} &amp;amp;= d_\textcolor{purple}{\textrm{outer}} \cdot d_\textcolor{orange}{\textrm{inner}} \\
&amp;amp;= \frac{1}{m} \sum_{i=1}^m (h_θ(x^i) - Y_i) \cdot \textcolor{red}{x_j^i}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;Phew! That was a lot of abstract math. Finally, we have something that can be translated into code.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;effect_of_weight&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;which_weight&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;house&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;which_weight&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;house&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;houses&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="n"&gt;effect_of_all_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;effect_of_weight&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="stochastic-gradient-descent-making-regression-lines-fit-again"&gt;Stochastic gradient descent: Making regression lines fit again&lt;/h2&gt;
&lt;p&gt;Strictly speaking, &lt;span class="math"&gt;\(\frac{1}{m} \sum_{i=1}^m (h_θ(x^i) - Y_i) \cdot x_j^i\)&lt;/span&gt; is not a derivative, but a &lt;strong&gt;gradient&lt;/strong&gt;—a collection of partial derivatives. In high school calculus, the derivative at a given point is visualized as the line that is tangent to the graph’s curve at that point. In multivariable calculus, the gradient at a given point is visualized as the &lt;em&gt;plane&lt;/em&gt; that is tangent to the graph’s surface at the point.&lt;/p&gt;
&lt;p&gt;In more concrete terms, imagine running a small piece of cardboard around the sides of a coffee mug so that the cardboard follows the curvature of the mug. Every point on the surface of the mug corresponds to some combination of weights, and the closer we are to the top of the mug, the greater the value of our cost function is, and so the more inaccurate our prediction is. We want to find the bottom of the mug, where the piece of cardboard is parallel to the ground, because that is where the value of the cost function is as low as possible.&lt;/p&gt;
&lt;p&gt;When that value is zero, the line would fit our data perfectly. However, that’s not possible for real-world data, so we will settle for the lowest value—that is, we want to &lt;em&gt;minimize&lt;/em&gt; the cost function.&lt;/p&gt;
&lt;div class="math"&gt;$$ \underset{θ}{\arg\min} \, J(θ) $$&lt;/div&gt;
&lt;p&gt;In the language of math (and neural networks), this is called &lt;strong&gt;stochastic gradient descent&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;em&gt;gradient&lt;/em&gt; is the thing we’re trying to minimize.&lt;/li&gt;
&lt;li&gt;This process is &lt;em&gt;stochastic&lt;/em&gt; (random) because we start with random weights (all zeros), which puts us at a random point on the mug.&lt;/li&gt;
&lt;li&gt;It is a &lt;em&gt;descent&lt;/em&gt; because we want to move down to a progressively flatter region of the mug with each attempt (combination of weights).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The descent occurs in “steps.” Imagine, for a moment, a basic parabola &lt;span class="math"&gt;\(f(x) = x^2\)&lt;/span&gt; instead of a mug. The derivative at any point &lt;span class="math"&gt;\(x\)&lt;/span&gt; is &lt;span class="math"&gt;\(2x\)&lt;/span&gt;. Positive &lt;span class="math"&gt;\(x\)&lt;/span&gt; values give us positive derivatives and negative &lt;span class="math"&gt;\(x\)&lt;/span&gt; values give us negative derivatives. If we started at some point to the right of 0 and wanted to follow the parabola to its trough, we could do that by subtracting something from &lt;span class="math"&gt;\(x\)&lt;/span&gt;. Likewise, if we started at some point to the left of 0, we’d want to add something to &lt;span class="math"&gt;\(x\)&lt;/span&gt;—or rather, subtract a negative value.&lt;/p&gt;
&lt;p&gt;This means that if we start at any point &lt;span class="math"&gt;\(x\)&lt;/span&gt; and subtract &lt;span class="math"&gt;\(\frac{dy}{dx}\)&lt;/span&gt;, we will tend toward the trough. We don’t necessarily know exactly what our new &lt;span class="math"&gt;\(x\)&lt;/span&gt; value will be, but we can assume that subtracting &lt;span class="math"&gt;\(\frac{dy}{dx}\)&lt;/span&gt; again will take us closer to the trough, although slightly less closer. Each step brings us increasingly closer but in progressively smaller steps. At some point, we will reach &lt;strong&gt;convergence&lt;/strong&gt;, or a point that is close enough to minimum.&lt;/p&gt;
&lt;p&gt;The same applies to gradients. The gradient for any set of weights &lt;span class="math"&gt;\(θ\)&lt;/span&gt; tells us the &lt;em&gt;opposite&lt;/em&gt; direction we should go in to find the bottom of the mug. That means that if we start with some initial collection of weights &lt;span class="math"&gt;\(θ\)&lt;/span&gt; and keep subtracting the gradient, which is notated &lt;span class="math"&gt;\(\nabla J\)&lt;/span&gt;, we should eventually arrive at the bottom.&lt;/p&gt;
&lt;div class="math"&gt;$$ \textrm{repeat } θ := θ - \nabla J \textrm{ until convergence} $$&lt;/div&gt;
&lt;p&gt;But try translating this into Python.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;gradient_of_cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;my_weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;effect_of_weight&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;my_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;last_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;my_weights&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="n"&gt;gradient_of_cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;last_weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# ???&lt;/span&gt;
    &lt;span class="n"&gt;last_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;my_weights&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;convergence&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="c1"&gt;# ???&lt;/span&gt;
        &lt;span class="k"&gt;break&lt;/span&gt;

&lt;span class="n"&gt;minimum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;my_weights&lt;/span&gt; &lt;span class="c1"&gt;# ???&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In doing so, a couple of questions arise (besides the suspicion that there are way too many loops and functions):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How do you compare weights so that you can know which of two collections is “lesser” and which is “greater”?&lt;/li&gt;
&lt;li&gt;How do you know when you’ve reached convergence?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It‘s clear that we have more or less come as far as we can with the level of math and coding that we have used so far.&lt;/p&gt;
&lt;h1 id="part-2-crazy-math-beautiful-code"&gt;Part 2: Crazy math, beautiful code&lt;/h1&gt;
&lt;p&gt;When you think about it, it almost seems a little backwards to call linear algebra the starting point of machine learning. After all, we’ve come this far without it. Multivariable calculus strikes me as more fundamental, although I suppose that it might be hard to imagine the output of a two-variable function as a bowl- or mug-shaped object without the concept of vectors.&lt;/p&gt;
&lt;p&gt;In any case, it’s time for that Zen uppercut.&lt;/p&gt;
&lt;p&gt;I won’t go into the mechanics of vector and matrix operations here; they are too tedious to write about, and I’m certainly not the best person to explain them. What I’m more interested in is the concept of &lt;strong&gt;vectorization&lt;/strong&gt;: the “translation” (pun intended) of the algebra and calculus above into linear algebra and multivariable calculus, as well as what that looks like in Python (using NumPy).&lt;/p&gt;
&lt;h2 id="vectorize-all-the-things"&gt;Vectorize all the things!!!&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Ninja mode activated! (That was easy, eh?) First of all, let’s convert all lists to &lt;em&gt;vectors&lt;/em&gt; and all lists of lists to &lt;em&gt;matrices&lt;/em&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\textbf X =
\begin{bmatrix}
  x_1^1 &amp;amp; x_2^1 &amp;amp; \dots  &amp;amp; x_n^1 \\[0.5em]
  x_1^2 &amp;amp; x_2^2 &amp;amp; \dots  &amp;amp; x_n^2 \\[0.5em]
  \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\[0.5em]
  x_1^m &amp;amp; x_2^m &amp;amp; \dots  &amp;amp; x_n^m
\end{bmatrix} \qquad{}
&amp;amp; \vec θ = \begin{bmatrix} θ_0 \\ θ_1 \\ θ_2 \\ \vdots \\ θ_n \end{bmatrix}
&amp;amp; \vec y = \begin{bmatrix} y_0 \\ y_1 \\ \vdots \\ y_m \end{bmatrix}
\end{aligned}$$&lt;/div&gt;
&lt;p&gt;Let’s use &lt;code class="highlight"&gt;scikit-learn&lt;/code&gt; to generate a suitable dataset for us. Since we won’t have to do any of the computations by hand, let’s go wild with the number of features and samples. We also need a vector with our initial weights (all zeros).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sklearn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;make_regression&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# as many rows as X has columns, and 1 column&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;One important thing to note is that the dummy feature &lt;span class="math"&gt;\(x_0\)&lt;/span&gt; needs to be added to the data. Also, &lt;code class="highlight"&gt;scikit-learn&lt;/code&gt; generates a &lt;code class="highlight"&gt;y&lt;/code&gt; array that doesn’t have the proper dimensions of a vector for some reason.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hstack&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# padding for bias column&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# this just fixes a quirk of sklearn's output&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="math"&gt;$$ \begin{aligned} \textbf X =
\begin{bmatrix}
  \textcolor{red}1 &amp;amp; x_1^1 &amp;amp; x_2^1 &amp;amp; \dots &amp;amp; x_n^1 \\[0.5em]
  \textcolor{red}1 &amp;amp; x_1^2 &amp;amp; x_2^2 &amp;amp; \dots &amp;amp; x_n^2 \\[0.5em]
  \textcolor{red}\vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\[0.5em]
  \textcolor{red}1 &amp;amp; x_1^m &amp;amp; x_2^m &amp;amp; \dots &amp;amp; x_n^m
\end{bmatrix} \qquad{}
&amp;amp; \vec θ = \begin{bmatrix} θ_0 \\ θ_1 \\ θ_2 \\ \vdots \\ θ_n \end{bmatrix}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;The hypothesis function &lt;span class="math"&gt;\(h_θ(x^i)\)&lt;/span&gt; can now be written succinctly as the product of the “houses” matrix &lt;span class="math"&gt;\(\textbf X\)&lt;/span&gt; and the weights vector &lt;span class="math"&gt;\(\vec θ\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned} \textbf X\vec θ &amp;amp;= \begin{bmatrix}
  \textcolor{teal}{x_0^1} &amp;amp; \textcolor{teal}{x_1^1} &amp;amp; \textcolor{teal}{x_2^1} &amp;amp; \dots &amp;amp; \textcolor{teal}{x_n^1} \\[0.5em]
  \textcolor{teal}{x_0^2} &amp;amp; \textcolor{teal}{x_1^2} &amp;amp; \textcolor{teal}{x_2^2} &amp;amp; \dots &amp;amp; \textcolor{teal}{x_n^2} \\[0.5em]
  \textcolor{teal}\vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\[0.5em]
  \textcolor{teal}{x_0^m} &amp;amp; \textcolor{teal}{x_1^m} &amp;amp; \textcolor{teal}{x_2^m} &amp;amp; \dots &amp;amp; \textcolor{teal}{x_n^m}
\end{bmatrix} \begin{bmatrix} \textcolor{magenta}{θ_0} \\ \textcolor{magenta}{θ_1} \\ \textcolor{magenta}{θ_2} \\ \vdots \\ \textcolor{magenta}{θ_n} \end{bmatrix} \\
&amp;amp;= \begin{bmatrix}
  \textcolor{magenta}{θ_0}\textcolor{teal}{x_0^1} &amp;amp; \textcolor{magenta}{θ_1}\textcolor{teal}{x_1^1} &amp;amp; \textcolor{magenta}{θ_2}\textcolor{teal}{x_2^1} &amp;amp; \dots &amp;amp; \textcolor{magenta}{θ_n}\textcolor{teal}{x_n^1} \\[0.5em]
  \textcolor{magenta}{θ_0}\textcolor{teal}{x_0^2} &amp;amp; \textcolor{magenta}{θ_1}\textcolor{teal}{x_1^2} &amp;amp; \textcolor{magenta}{θ_2}\textcolor{teal}{x_2^2} &amp;amp; \dots &amp;amp; \textcolor{magenta}{n_2}\textcolor{teal}{x_n^2} \\[0.5em]
  \vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\[0.5em]
  \textcolor{magenta}{θ_0}\textcolor{teal}{x_0^m} &amp;amp; \textcolor{magenta}{θ_1}\textcolor{teal}{x_1^m} &amp;amp; \textcolor{magenta}{θ_2}\textcolor{teal}{x_2^m} &amp;amp; \dots &amp;amp; \textcolor{magenta}{θ_n}\textcolor{teal}{x_n^m}
\end{bmatrix} \end{aligned}
$$&lt;/div&gt;
&lt;p&gt;Here is the generalized form of linear regression before and after vectorization, followed by the vectorized NumPy version.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Notice how the non-vectorized version inherently refers to only one sample at a time, with the superscript &lt;span class="math"&gt;\(i\)&lt;/span&gt;. This implies the equation is true for each &lt;span class="math"&gt;\(i\)&lt;/span&gt;, but the vectorized version automatically includes every sample at the same time without us even having to know how many there are. So let’s use the plural &lt;code class="highlight"&gt;hypotheses&lt;/code&gt; to name the result.&lt;/li&gt;
&lt;li&gt;Look at how simple the math expression and the code become! (Of course, it does rely on a sufficient understanding of matrix multiplication.)&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
h_θ(x^i) &amp;amp;= \textcolor{magenta}{θ_0}\textcolor{teal}{x_0^i} + \textcolor{magenta}{θ_1}\textcolor{teal}{x_1^i} + \cdots + \textcolor{magenta}{θ_n}\textcolor{teal}{x_n^i} \\
h_θ(\textbf X) &amp;amp;= \textbf X\vec θ
\end{aligned} $$&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;hypotheses&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;theta&lt;/span&gt; &lt;span class="c1"&gt;# @ is short for matrix multiplication&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="vectorizing-the-cost-function-so-fresh-so-clean"&gt;Vectorizing the cost function: So fresh, so clean&lt;/h2&gt;
&lt;p&gt;This makes it easy to express the error as the difference between the hypothesis and the actual value:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\textrm{error} &amp;amp;= \hat{Y}_i - Y_i \\
&amp;amp;= h_θ(x^i) - y_i \\
\vec e &amp;amp;= \textbf X\vec θ - \vec y
\end{aligned} $$&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hypotheses&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Recall that the cost function involves the sum of squared errors. In linear algebra, summation can be expressed as the product of a transposed vector of ones and a vector with the values to be summed, which struck me as a very clever manipulation.&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\vec o = \begin{bmatrix} 1 \\ 1 \\ \vdots \\ 1 \end{bmatrix}
&amp;amp; \quad{} \vec e = \begin{bmatrix} e_1 \\ e_2 \\ \vdots \\ e_m \end{bmatrix}
= \begin{bmatrix} h_θ(x^1) - y_1 \\ h_θ(x^2) - y_2 \\ \vdots \\ h_θ(x^m) - y_m \end{bmatrix}
\end{aligned} $$&lt;/div&gt;
&lt;div class="math"&gt;$$
\begin{aligned}
\vec o^T\vec e &amp;amp;= \begin{bmatrix} 1 &amp;amp; 1 &amp;amp; \cdots &amp;amp; 1 \end{bmatrix} \begin{bmatrix} e_1 \\ e_2 \\ \vdots \\ e_m \end{bmatrix} \\
&amp;amp;= \textcolor{lightgray}1 \cdot e_1 + \textcolor{lightgray}1 \cdot e_2 + \cdots + \textcolor{lightgray}1 \cdot e_m = \sum_{i=1}^m e_i
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;The cost function then becomes:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
J(θ) &amp;amp;= \frac{1}{2m}\sum_{i=1}^m \Big[h_θ(x^i) - Y_i\Big]^2 \\
&amp;amp;= \frac{1}{2m}\sum_{i=1}^m {(e_i)}^2 \\
&amp;amp;= \frac{1}{2m} \vec o^T \vec e^2
\end{aligned} $$&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;num_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;o&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;num_samples&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that the NumPy function &lt;code class="highlight"&gt;np.square(z)&lt;/code&gt; is faster than &lt;code class="highlight"&gt;z ** 2&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;rando&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;500000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="c1"&gt;# just a random big dataset for testing&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rando&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mf"&gt;1.2&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="err"&gt;±&lt;/span&gt; &lt;span class="mf"&gt;7.99&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt; &lt;span class="err"&gt;±&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="n"&gt;runs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="n"&gt;each&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="n"&gt;rando&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="mf"&gt;1.19&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="err"&gt;±&lt;/span&gt; &lt;span class="mf"&gt;7.01&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt; &lt;span class="err"&gt;±&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="n"&gt;runs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="n"&gt;each&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and &lt;code class="highlight"&gt;o.T @ np.square(z))&lt;/code&gt; (that is, &lt;span class="math"&gt;\(\vec o^T\textbf Z^2\)&lt;/span&gt;)  blows &lt;code class="highlight"&gt;sum(z ** 2)&lt;/code&gt; (that is, &lt;span class="math"&gt;\(\sum_{i=1}^m (z_i)^2\)&lt;/span&gt;) out of the water:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rando&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mf"&gt;1.36&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="err"&gt;±&lt;/span&gt; &lt;span class="mf"&gt;16.3&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt; &lt;span class="err"&gt;±&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="n"&gt;runs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="n"&gt;each&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rando&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="mf"&gt;1.37&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="err"&gt;±&lt;/span&gt; &lt;span class="mf"&gt;12.1&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt; &lt;span class="err"&gt;±&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="n"&gt;runs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="n"&gt;each&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;rando&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="c1"&gt;# because rando has more than 1 column&lt;/span&gt;
&lt;span class="mf"&gt;25.1&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="err"&gt;±&lt;/span&gt; &lt;span class="mi"&gt;603&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt; &lt;span class="err"&gt;±&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="n"&gt;runs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="n"&gt;each&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;At this point, it’s helpful to turn our cost function into a Python function that takes &lt;span class="math"&gt;\(\textbf X, \vec y, \vec θ\)&lt;/span&gt; as its inputs. This will make it easier to evaluate our model later.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;num_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;o&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;num_samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
    &lt;span class="n"&gt;cost_array&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;num_samples&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# 1x1 matrix&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;cost_array&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;# plain number&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="vectorizing-the-gradient-ninja-mode-on-overdrive"&gt;Vectorizing the gradient: Ninja mode on overdrive&lt;/h2&gt;
&lt;p&gt;On to the gradient. This is where linear algebra really kicks this thing into high gear.&lt;/p&gt;
&lt;p&gt;(This is also where I get to show off my LaTeX chops.)&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\nabla J = \frac{\partial J(θ)}{\partial θ_j} &amp;amp;= \Bigg\{\frac{\partial J(θ)}{\partial θ_0}, \frac{\partial J(θ)}{\partial θ_1}, \cdots, \frac{\partial J(θ)}{\partial θ_n}\Bigg\} \\
&amp;amp;= \frac{1}{m} \sum_{i=1}^m \Big[h_θ(x^i) - Y_i\Big]^2 \cdot x_j^i \qquad{} \textrm{for } 0 \leq j \leq n \\
&amp;amp;= \frac{1}{m} \sum_{i=1}^m {(e_i)}^2 x_j^i \qquad{}\qquad{}\qquad{}\qquad{}\qquad{}  " \\
&amp;amp;= \frac{1}{m} \sum_{i=1}^m x_j^i {(e_i)}^2 \qquad{}\qquad{}\qquad{}\qquad{}\qquad{}  " \\
&amp;amp;= \Bigg\{ \textcolor{teal}{
  \frac{1}{m} \sum_{i=1}^m x_0^i {(e_i)}^2, \frac{1}{m} \sum_{i=1}^m x_1^i {(e_i)}^2, \cdots, \frac{1}{m} \sum_{i=1}^m x_n^i {(e_i)}^2
  }\Bigg\}
\end{aligned} $$&lt;/div&gt;
&lt;p&gt;Transposing &lt;span class="math"&gt;\(\textbf X\)&lt;/span&gt; and squaring &lt;span class="math"&gt;\(\vec e\)&lt;/span&gt; gives us:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{aligned}
\textbf X^T = \begin{bmatrix}
  x_0^1 &amp;amp; x_0^2 &amp;amp; \dots &amp;amp; x_0^m \\[0.5em]
  x_1^1 &amp;amp; x_1^2 &amp;amp; \dots &amp;amp; x_1^m \\[0.5em]
  \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\[0.5em]
  x_n^1 &amp;amp; x_n^2 &amp;amp; \dots  &amp;amp; x_n^m
\end{bmatrix} &amp;amp; \quad{} \vec e^2 = \begin{bmatrix} {(e_1)}^2 \\[0.5em] {(e_2)}^2 \\[0.5em] \vdots \\[0.5em] {(e_m)}^2 \end{bmatrix}
\end{aligned} $$&lt;/div&gt;
&lt;div class="math"&gt;$$ \textbf X^T \vec e^2 = \begin{bmatrix}
  x_0^1 {(e_1)}^2 + x_0^2 {(e_2)}^2 + x_0^3 {(e_3)}^2 + \cdots + x_0^m {(e_m)}^2 \\[0.5em]
  x_1^1 {(e_1)}^2 + x_1^2 {(e_2)}^2 + x_1^3 {(e_3)}^2 + \cdots + x_1^m {(e_m)}^2 \\[0.5em]
  \vdots \\[0.5em]
  x_n^1 {(e_1)}^2 + x_n^2 {(e_2)}^2 + x_n^3 {(e_3)}^2 + \cdots + x_n^m {(e_m)}^2
\end{bmatrix} = \begin{bmatrix}
  \sum_{i=1}^m x_0^i{(e_1)}^2 \\[0.5em]
  \sum_{i=1}^m x_1^i{(e_1)}^2 \\[0.5em]
  \vdots \\[0.5em]
  \sum_{i=1}^m x_n^i{(e_1)}^2 \\
\end{bmatrix} $$&lt;/div&gt;
&lt;p&gt;Notice how multiplying this result by &lt;span class="math"&gt;\(\frac{1}{m}\)&lt;/span&gt; gives us a vector containing the same values highlighted above in teal.&lt;/p&gt;
&lt;div class="math"&gt;$$ \frac{1}{m} \textbf X^T \vec e^2 = \frac{1}{m} \begin{bmatrix}
  \sum_{i=1}^m x_0^i{(e_1)}^2 \\[0.5em]
  \sum_{i=1}^m x_1^i{(e_1)}^2 \\[0.5em]
  \vdots \\[0.5em]
  \sum_{i=1}^m x_n^i{(e_1)}^2 \\
\end{bmatrix} = \begin{bmatrix}
  \textcolor{teal}{ \frac{1}{m} \sum_{i=1}^m x_0^i{(e_1)}^2 } \\[0.5em]
  \textcolor{teal}{ \frac{1}{m} \sum_{i=1}^m x_1^i{(e_1)}^2 } \\[0.5em]
  \textcolor{teal}{ \vdots } \\[0.5em]
  \textcolor{teal}{ \frac{1}{m} \sum_{i=1}^m x_n^i{(e_1)}^2 } \\
\end{bmatrix} = \begin{bmatrix}
  \frac{\partial J(θ)}{\partial θ_0} \\[0.5em]
  \frac{\partial J(θ)}{\partial θ_1} \\[0.5em]
  \vdots \\[0.5em]
  \frac{\partial J(θ)}{\partial θ_n}
\end{bmatrix} $$&lt;/div&gt;
&lt;p&gt;Astonishingly, that gigantic mess can be expressed as&lt;/p&gt;
&lt;div class="math"&gt;$$ \nabla J = \frac{1}{m} \textbf X^T \vec e^2 $$&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;num_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;gradient&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;num_samples&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Finally&lt;/em&gt;, we can work out the last function, the gradient descent function:&lt;/p&gt;
&lt;div class="math"&gt;$$ \begin{gathered} \vec θ := \vec θ - α\frac{1}{m} \textbf X^T \vec e^2 \\
\textrm{repeat until convergence} \end{gathered} $$&lt;/div&gt;
&lt;p&gt;Hey, where’d that &lt;span class="math"&gt;\(α\)&lt;/span&gt; come from? That’s the &lt;strong&gt;learning rate&lt;/strong&gt;, a small number that adjusts the size of each training step. Too large and you jump right over the minimum; too small and you never reach the minimum.&lt;/p&gt;
&lt;p&gt;For now, let’s choose an arbitrary value for &lt;span class="math"&gt;\(α\)&lt;/span&gt; and disregard the whole bit about convergence. If we wanted to perform stochastic gradient descent with 100 steps, this is how we’d do it:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.01&lt;/span&gt;
    &lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
    &lt;span class="n"&gt;num_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;step_distance&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;num_samples&lt;/span&gt;
    &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;step_distance&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Let’s refactor this as a function &lt;code class="highlight"&gt;train_lr_model&lt;/code&gt; that takes &lt;span class="math"&gt;\(\textbf X, \vec y\)&lt;/span&gt;, and the number of steps (training epochs) as its inputs, and outputs the weights &lt;span class="math"&gt;\(\vec θ\)&lt;/span&gt;. Along the way, let’s have it tell us the cost. If all goes well, we should see that number approach zero as training progresses.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;train_lr_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;num_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
        &lt;span class="n"&gt;step_distance&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;num_samples&lt;/span&gt;
        &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;step_distance&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="c1"&gt;# dot products are single values, but NumPy returns them as 1x1 matrices&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;

&lt;span class="n"&gt;weights_300_epochs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_lr_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;300&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now, we can predict the output for a random set of feature values.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;

&lt;span class="n"&gt;mystery_input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;mystery_input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hstack&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;mystery_input&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# dummy feature&lt;/span&gt;
&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mystery_input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights_300_epochs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I like to geek out on math notation and wrote this function to generate LaTeX for the equation of the model:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;expand_model_latex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;terms&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"{round(w[0], 2)}x_{i}"&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"$$ h_θ(x) &lt;/span&gt;&lt;span class="se"&gt;\a&lt;/span&gt;&lt;span class="s2"&gt;pprox {' + '.join(terms)} $$"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="math"&gt;$$ h_θ(x) \approx -2.36x_0 + 63.26x_1 + 61.15x_2 + 88.99x_3 + 0.82x_4 + 58.95x_5 $$&lt;/div&gt;
&lt;p&gt;We’re not done with linear regression, but let’s recap so that this post can end.&lt;/p&gt;
&lt;h2 id="summary-so-far"&gt;Summary so far&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align="center"&gt;Broke&lt;/th&gt;
&lt;th align="center"&gt;Woke&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Linear regression model&lt;/td&gt;
&lt;td align="center"&gt;
&lt;div class="math"&gt;$$h_θ(x) = θ_0x_0 + θ_1x_1 + \cdots + θ_nx_n$$&lt;/div&gt;
&lt;/td&gt;
&lt;td align="center"&gt;
&lt;div class="math"&gt;$$h_θ(\textbf X) = \textbf X\vec θ$$&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Cost function&lt;/td&gt;
&lt;td align="center"&gt;
&lt;div class="math"&gt;$$J(θ) = \frac{1}{2m}\sum_{i=1}^m{\Big[h_θ(x^i) - y_i\Big]}^2$$&lt;/div&gt;
&lt;/td&gt;
&lt;td align="center"&gt;
&lt;div class="math"&gt;$$ \begin{gathered} \vec e = h_θ{\textbf X} - \vec y \\ J(θ) = \frac{1}{2m}\vec o^T\vec e^2 \end{gathered} $$&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Gradient of cost function&lt;/td&gt;
&lt;td align="center"&gt;
&lt;div class="math"&gt;$$ \frac{\partial J(θ)}{\partial θ_j} = \frac{1}{m}\sum_{i=1}^m\Big[h_θ(x^i) - y_i\Big]x_j^i $$&lt;/div&gt;
&lt;/td&gt;
&lt;td align="center"&gt;
&lt;div class="math"&gt;$$ \nabla J = \frac{1}{m}\textbf X^T\vec e $$&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Gradient descent function&lt;/td&gt;
&lt;td align="center"&gt;
&lt;div class="math"&gt;$$ θ_j := θ_j - α\frac{\partial J(θ)}{\partial θ_j} $$&lt;/div&gt;
&lt;/td&gt;
&lt;td align="center"&gt;
&lt;div class="math"&gt;$$ \vec θ := \vec θ - α\nabla J $$&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Such complex math can be applied to a linear regression model trained in some 20 lines of Python!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt;

&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sklearn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;make_regression&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hstack&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# padding for bias column&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# this just fixes a quirk of sklearn's output&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;num_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;o&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;num_samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
    &lt;span class="n"&gt;cost_array&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;num_samples&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;cost_array&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;train_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;num_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
        &lt;span class="n"&gt;step_distance&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;num_samples&lt;/span&gt;
        &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;step_distance&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Completed {epochs} epochs of training."&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Final cost: {cost(X, y, weights)}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="comparison-of-performance"&gt;Comparison of performance&lt;/h2&gt;
&lt;p&gt;This is a contrived comparison, but it helps to illustrate very clearly the point of jumping through all of these mathematical hoops.&lt;/p&gt;
&lt;p&gt;On the 500-sample, 5-feature dataset we’ve been using, the vectorized gradient descent function runs over &lt;strong&gt;7,000 times faster&lt;/strong&gt; than the terrible, monstrous, don’t-say-I-didn’t-warn-you procedural version from the beginning of this post.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="n"&gt;train_lr_model_procedurally&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.00001&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mf"&gt;14.2&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="err"&gt;±&lt;/span&gt; &lt;span class="mi"&gt;609&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt; &lt;span class="err"&gt;±&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="n"&gt;runs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="n"&gt;each&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="n"&gt;train_lr_model_vectorizedly&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.00001&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mf"&gt;2.28&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="err"&gt;±&lt;/span&gt; &lt;span class="mf"&gt;64.9&lt;/span&gt; &lt;span class="err"&gt;µ&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt; &lt;span class="err"&gt;±&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="n"&gt;runs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="n"&gt;loops&lt;/span&gt; &lt;span class="n"&gt;each&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id="remaining-questions-for-future-posts-links-will-be-included-upon-publication"&gt;Remaining questions for future posts (links will be included upon publication)&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Are there any other simple techniques to speed this up? (Mean normalization)&lt;/li&gt;
&lt;li&gt;&lt;a href="squarest-root-in-babylon"&gt;Are there any complex techniques to speed this up? (Automatic differentiation)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="from-zero-to-ero"&gt;How do we know when we’ve reached convergence? (Epsilon)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;How can &lt;em&gt;linear&lt;/em&gt; (as opposed to &lt;em&gt;logistic&lt;/em&gt;) regression be applied to language tasks? (General backpropagation of neural networks)&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="references"&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=fNk_zzaMoSs&amp;amp;list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab"&gt;The Essence of Linear Algebra&lt;/a&gt; (video series), Grant Sanderson&lt;/li&gt;
&lt;li&gt;&lt;a href="https://towardsdatascience.com/linear-regression-using-python-b136c91bf0a2"&gt;Linear Regression using Python&lt;/a&gt;, Animesh Agarwal&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.ritchieng.com/multi-variable-linear-regression/"&gt;Linear Regression with Multiple Variables&lt;/a&gt;, Ritchie Ng&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/@lachlanmiller_52885/understanding-and-calculating-the-cost-function-for-linear-regression-39b8a3519fcb"&gt;Understanding and Calculating the Cost Function for Linear Regression&lt;/a&gt;, Lachlan Miller&lt;/li&gt;
&lt;li&gt;&lt;a href="http://anwarruff.com/the-linear-regression-cost-function-in-matrix-form/"&gt;The Linear Regression Cost Function in Matrix Form&lt;/a&gt;, Anwar Ruff&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/differentiating-vector-valued-functions/a/multivariable-chain-rule-simple-version"&gt;Multivariable chain rule, simple version&lt;/a&gt;, Khan Academy&lt;/li&gt;
&lt;/ul&gt;</content><category term="koan"></category><category term="multivariable calculus"></category><category term="stochastic gradient descent"></category><category term="linear algebra"></category></entry></feed>