<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="description" content="If you thought 1 + ϵ = 1 was weird, wait till you see what ϵ² equates to." />

    <meta name="twitter:card" content="summary" />
    <meta name="twitter:site" content="@tabidots" />
    <meta name="twitter:creator" content="@tabidots" />
    <meta name="twitter:title" content="The squarest root in Babylon and automatic differentiation" />
    <meta name="twitter:description" content="If you thought 1 + ϵ = 1 was weird, wait till you see what ϵ² equates to." />
    <meta name="twitter:image:src" content="../../images/selfportrait_small.png" />
    <meta name="twitter:domain" content="judosaltgenius.com" />

    <meta property="og:title" content="The squarest root in Babylon and automatic differentiation" />
    <meta property="og:type" content="article" />
    <meta property="og:description" content="If you thought 1 + ϵ = 1 was weird, wait till you see what ϵ² equates to." />
    <meta property="og:image" content="../../images/selfportrait_small.png" />
    <meta property="og:site_name" content="judosaltgenius.com" />
    <meta property="og:url" content="../../2019/01/squarest-root-in-babylon" />

        <link rel="alternate"  href="http://tabidots.github.io/feeds/all.atom.xml" type="application/atom+xml" title="Judo Salt Genius Full Atom Feed"/>

        <title>The squarest root in Babylon and automatic differentiation - Judo Salt Genius</title>


    <!-- KaTeX -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0-beta1/katex.min.css" integrity="sha384-VEnyslhHLHiYPca9KFkBB3CMeslnM9CzwjxsEbZTeA21JBm7tdLwKoZmCt3cZTYD" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0-beta1/katex.min.js" integrity="sha384-O4hpKqcplNCe+jLuBVEXC10Rn1QEqAmX98lKAIFBEDxZI0a+6Z2w2n8AEtQbR4CD" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0-beta1/contrib/auto-render.min.js" integrity="sha384-IiI65aU9ZYub2MY9zhtKd1H2ps7xxf+eb2YFG9lX6uRqpXCvBTOidPRCXCrQ++Uc" crossorigin="anonymous"></script>

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.1.0/css/font-awesome.min.css" />
    <link rel="stylesheet" href="../../theme/css/pure.css?v=0.1.0" />
      <!-- CSS specified by the user -->


      <link href="../../assets/mystyle.css" type="text/css" rel="stylesheet" />
    <link rel="stylesheet" href="../../theme/css/pygments.css" />

    <!-- for pelican_dynamic plugin -->
    <!-- end pelican_dynamic -->

</head>

<body>
<div class="pure-g-r" id="layout">
    <div class="sidebar sidebar-article pure-u">
        <header class="header-article">
                    <a href="../../author/justin-douglas" title="See posts by Justin Douglas">
                        <img class="avatar" alt="Justin Douglas" src="https://www.gravatar.com/avatar/74f13134596b2ed04a497936e3fdfd33?s=140">
                    </a>
                <h2 class="article-info">Justin Douglas</h2>



                <p class="article-date">Tue 22 January 2019</p>

                <a class="header-article-home" href="/">&larr;Home</a>
        </header>
    </div>
    <div class="pure-u">
        <div class="content">
            <section class="post">
                <header class="post-header">
                    <h1>The squarest root in Babylon and automatic&nbsp;differentiation</h1>
                </header>
            </section>

                <nav class="toc">
                <div class="toc">
<ul>
<li><a href="#same-same-but-different">Same same but different</a></li>
<li><a href="#coding-with-i">Cod\(i\)ng with \(i\)?</a></li>
<li><a href="#dual-numbers">Dual numbers</a></li>
<li><a href="#diy-automatic-differentiation"><span class="caps">DIY</span> automatic differentiation</a><ul>
<li><a href="#the-squarest-root-in-babylon">The squarest root in Babylon</a></li>
<li><a href="#getting-classy">Getting classy</a></li>
<li><a href="#ready-for-liftoff">Ready for liftoff</a></li>
<li><a href="#automatic-symbolic-differentiation">Automatic symbolic differentiation?</a></li>
</ul>
</li>
<li><a href="#automatic-differentiation">Automatic differentiation</a><ul>
<li><a href="#out-of-the-box-solutions">Out-of-the-box solutions</a></li>
<li><a href="#epsilon-in-the-cost-function">\(\epsilon\) in the cost function</a></li>
<li><a href="#making-the-loopless-loop-mathless-too">Making the loopless loop mathless, too?</a></li>
</ul>
</li>
<li><a href="#summary">Summary</a></li>
<li><a href="#references">References</a></li>
</ul>
</div>
                </nav>

            
<p>In my previous post on <a href="/2019/01/from-zero-to-ero"><span class="math">\(\epsilon\)</span> (epsilon)</a>, I wrote about this statement:</p>
<div class="math">$$ 1 + \epsilon = 1 $$</div>
<p>which seemed like it came from a planet that had fallen out of orbit or something. Well, try this one on for size:</p>
<div class="math">$$ \epsilon^2 = 0 $$</div>
<p>Another math koan! <span class="math">\(\epsilon\)</span> is still a stand-in for the same concept here—an infinitesimal value—but its function is a little different. This post will be about <strong>dual numbers</strong> and what you can do with them.</p>
<p>But first, let’s start with another devilishly complex (har har) number: <span class="math">\(i\)</span>.</p>
<h1 id="same-same-but-different">Same same but different</h1>
<p>You might remember imaginary and complex numbers from high school trigonometry. There is a number <span class="math">\(i\)</span> such that</p>
<div class="math">$$ i^2 = -1 $$</div>
<p>which really tempts you to find the value of just plain <span class="math">\(i\)</span>. Since it doesn’t really exist, we just have to treat it like an <span class="math">\(x\)</span>: <span class="math">\(2 + 3i\)</span> (a complex number), etc.</p>
<p>But the kicker is that the point of <span class="math">\(i\)</span> is not its value but <em>what it lets us do</em>. The point is that this property of <span class="math">\(i\)</span> makes it possible for us to reason about rotation around a circle, because its sign changes as you keep multiplying it by itself.</p>
<blockquote>
<p>I may or may not have learned that last point in high school, but if you’re anything like me, it is helpful to have a refresher that is more lucid and engaging than any high school math class: <a href="https://www.youtube.com/watch?v=spUNpyF58BY">3blue1brown</a> / <a href="https://betterexplained.com/articles/a-visual-intuitive-guide-to-imaginary-numbers/">BetterExplained</a> / <a href="https://www.youtube.com/watch?v=65wYmy8Pf-Y">Welch Labs</a></p>
</blockquote>
<h1 id="coding-with-i">Cod<span class="math">\(i\)</span>ng with <span class="math">\(i\)</span>?</h1>
<p>While we’re on the subject of complex numbers, let’s play with them a bit. I was a bit surprised to discover that built-in <code class="highlight">complex</code> data types are not rare among modern programming languages. It’s not a surprise that Julia has them natively, but so do R, Python, and even Ruby. (Sadly, Clojure does not.)</p>
<p>Of course, there is some variation in coolness of implementation:</p>
<div class="superfences-tabs">
<input checked="checked" id="__tab_1_0" name="__tabs_1" type="radio"/>
<label for="__tab_1_0">Julia</label>
<div class="superfences-content"><div class="highlight"><pre><span></span><span class="c"># You can use `im` to implicitly denote the imaginary part of a complex number</span>
<span class="c"># Not much different than typing LaTeX. Pretty slick!</span>
<span class="n">z</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">+</span> <span class="mi">4</span><span class="nb">im</span>
<span class="n">typeof</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>                     <span class="c"># Complex{Int64}</span>
<span class="mi">2</span><span class="n">z</span>                            <span class="c"># 6 + 8im</span>
<span class="mi">1</span><span class="nb">im</span> <span class="o">^</span> <span class="mi">2</span>                       <span class="c"># -1 + 0im. Don't need to declare 0 real part</span>
<span class="p">(</span><span class="mi">3</span> <span class="o">+</span> <span class="mi">4</span><span class="nb">im</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">3</span><span class="nb">im</span><span class="p">)</span>         <span class="c"># 5 + 7im</span>
<span class="mi">1</span><span class="nb">im</span> <span class="o">-</span> <span class="mi">1</span><span class="nb">im</span>                     <span class="c"># 0 + 0im</span>
<span class="p">(</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="nb">im</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">3</span> <span class="o">+</span> <span class="mi">1</span><span class="nb">im</span><span class="p">)</span>         <span class="c"># 5 + 5im</span>
</pre></div></div>
<input id="__tab_1_1" name="__tabs_1" type="radio"/>
<label for="__tab_1_1">Python</label>
<div class="superfences-content"><div class="highlight"><pre><span></span><span class="c1"># Python follows the electrical engineering convention of using j for i</span>
<span class="c1"># because i means current in that field (pun intended)</span>
<span class="n">z</span> <span class="o">=</span> <span class="nb">complex</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>             <span class="c1"># (3+4j)</span>
<span class="nb">type</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>                       <span class="c1"># complex</span>
<span class="mi">2</span> <span class="o">*</span> <span class="n">z</span>                         <span class="c1"># (6+8j)</span>
<span class="nb">complex</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>            <span class="c1"># (-1+0j)</span>
<span class="nb">complex</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span> <span class="o">+</span> <span class="nb">complex</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="c1"># (5+7j)</span>
<span class="nb">complex</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="nb">complex</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># 0j. interesting output</span>
<span class="nb">complex</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="nb">complex</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># (5+5j)</span>
</pre></div></div>
<input id="__tab_1_2" name="__tabs_1" type="radio"/>
<label for="__tab_1_2">R</label>
<div class="superfences-content"><div class="highlight"><pre><span></span><span class="c1"># Syntax is a bit cumbersome</span>
<span class="n">z</span> <span class="o">&lt;-</span> <span class="nf">complex</span><span class="p">(</span><span class="n">real</span> <span class="o">=</span> <span class="m">3</span><span class="p">,</span> <span class="n">imaginary</span> <span class="o">=</span> <span class="m">4</span><span class="p">)</span>    <span class="c1"># 3 + 4i</span>
<span class="nf">typeof</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>                                <span class="c1"># complex</span>
<span class="nf">complex</span><span class="p">(</span><span class="n">real</span> <span class="o">=</span> <span class="m">0</span><span class="p">,</span> <span class="n">imaginary</span> <span class="o">=</span> <span class="m">1</span><span class="p">)</span> <span class="o">**</span> <span class="m">2</span>    <span class="c1"># -1 + 0i</span>
<span class="nf">complex</span><span class="p">(</span><span class="n">real</span> <span class="o">=</span> <span class="m">3</span><span class="p">,</span> <span class="n">imaginary</span> <span class="o">=</span> <span class="m">4</span><span class="p">)</span> <span class="o">+</span> <span class="nf">complex</span><span class="p">(</span><span class="n">real</span> <span class="o">=</span> <span class="m">2</span><span class="p">,</span> <span class="n">imaginary</span> <span class="o">=</span> <span class="m">3</span><span class="p">)</span> <span class="c1"># 5 + 7i</span>

<span class="c1"># Sorry R, but I can't be bothered to type so much</span>
</pre></div></div>
</div>
<p>Okay, that was fun. Now let’s return to <span class="math">\(\epsilon\)</span>.</p>
<h1 id="dual-numbers">Dual numbers</h1>
<p>Dual numbers are pretty similar to complex numbers, except with <span class="math">\(\epsilon\)</span> instead of <span class="math">\(i\)</span>. <span class="math">\(2 + 3\epsilon\)</span> is a dual number, for example.</p>
<p>We could say that it still represents an infinitesimal here, a value so small that when you square it, it is effectively zero. Thus,</p>
<div class="math">$$ \epsilon^2 = 0 $$</div>
<p>But as with <span class="math">\(i\)</span>, the significance of <span class="math">\(\epsilon\)</span> is not in the exact value, but rather the mathematical play that it opens up for us. Watch what happens to this unsuspecting parabola:</p>
<div class="math">$$ \begin{aligned}
f(x) &amp;= x^2 \\
f(x + \epsilon) &amp;= (x + \epsilon)^2 \\
&amp;= x^2 + 2x\epsilon + \epsilon^2 \\
&amp;= x^2 + 2x\epsilon + \cancel{0}
\end{aligned} $$</div>
<p>We can rewrite this further, since our original function has reappeared in the result:</p>
<div class="math">$$ f(x + \epsilon) = f(x) + 2x\epsilon $$</div>
<p>And what is <span class="math">\(2x\)</span> but the <strong>derivative</strong> of <span class="math">\(x^2\)</span>? 🤔</p>
<div class="math">$$ f(x + \epsilon) \overset{?}{=} f(x) + f'(x)\epsilon $$</div>
<p>Just to make sure this isn’t a one-off, let’s try it with a more complex polynomial, and scale the <span class="math">\(\epsilon\)</span> component:</p>
<div class="math">$$ \begin{aligned}
f(x) &amp;= 2x^3 + 5x - 7 \\
f(x + \textcolor{magenta}{2} \epsilon) &amp;= 2(x + \textcolor{magenta}{2} \epsilon)^3 + 5(x + \textcolor{magenta}{2} \epsilon) - 7 \\
&amp;= 2(x^3 + 6x^2\epsilon + 12x\epsilon^2 + 8\epsilon^3) + 5(x + 2\epsilon) - 7 \\
&amp;= \textcolor{teal}{2x^3} + \textcolor{orange}{12x^2\epsilon} + \textcolor{lightgray}{24x\epsilon^2} + \textcolor{orange}{16\epsilon^3} + \textcolor{teal}{5x} + \textcolor{orange}{10\epsilon} - \textcolor{teal}{7} \\
&amp;= \textcolor{teal}{2x^3 + 5x - 7} + \textcolor{magenta}{2} \textcolor{orange}{(6x^2 + 5 } \textcolor{lightgray}{+ 8\epsilon^2}\textcolor{orange}{)\epsilon} \\
&amp;= \textcolor{teal}{f(x)} + \textcolor{magenta}{2} \textcolor{orange}{f'(x) \epsilon}
\end{aligned} $$</div>
<p>Indeed, we still obtain the derivative of our original function, multiplied by the dual component of our input. 😮 This means</p>
<div class="math">$$ f(a + b \epsilon) = f(a) + bf'(a)\epsilon $$</div>
<p>In other words, we found the output and a local derivative in one go—automagically!—without having to find the derivative by hand first (that would be <em>symbolic differentiation</em>, i.e., through manipulating symbols).</p>
<p>It should be possibly to exploit this property of <span class="math">\(\epsilon\)</span> with functions whose derivatives are not so straightforward to find.</p>
<p>Well, technically, you could also approximate the derivative with <em>finite differences</em>:</p>
<p><img alt="derivative animation" src="../../images/derivative_animation.gif" title="source: https://sites.google.com/a/student.ashcoll.school.nz/bcashcoll/13-mac/differentiation-as-3-6-91578"/></p>
<p>But this is tedious at best and still not perfectly accurate when done by hand, and prone to all sorts of errors when done by computer (truncation errors, rounding errors, etc.).</p>
<h1 id="diy-automatic-differentiation"><span class="caps">DIY</span> automatic differentiation</h1>
<p>This brings us to automatic differentiation, which is a <em>huge</em> topic in machine learning. There are libraries to do this, but it is important to understand how they work by implementing automatic differentiation from scratch.</p>
<p>One stumbling block, however, is that outside of machine learning, dual numbers are a pretty obscure piece of mathematics. No language comes with them built-in; you have to implement a class yourself.</p>
<h2 id="the-squarest-root-in-babylon">The squarest root in Babylon</h2>
<p>Before we build the class, let’s set a goalpost.</p>
<p><a href="https://www.youtube.com/watch?v=vAp6nUMrKYg">Alan Edelman’s demonstration of automatic differentiation in Julia</a> is pretty nifty, though I think it moves pretty fast for a newcomer to automatic differentiation. So let’s break down what he is trying to do.</p>
<p>He wants to find the derivative of <span class="math">\(\sqrt x\)</span>. With the same power rule we used for the polynomials above, that’s pretty trivial to do symbolically, right?</p>
<div class="math">$$ \begin{aligned}
f(x) = \sqrt x &amp;= x^{\frac{1}{2}} \\
\frac{df}{dx} = \frac{1}{2} x^{-\frac{1}{2}} &amp;= \frac{1}{2\sqrt x}
 \end{aligned} $$</div>
<p>Done. Blog post over!</p>
<p>🤦🏻</p>
<p>Okay, but let’s say we didn’t know that <span class="math">\(\sqrt x = x^{\frac{1}{2}}\)</span>. Now whatcha gonna do?</p>
<p>Apparently the Babylonians knew a way to approximate the square root.</p>
<div class="math">$$ \begin{gathered}
t := \frac{t + \frac{x}{t}}{2} \\
\textrm{Repeat until }t \textrm{ converges to } \sqrt x
\end{gathered} $$</div>
<p>The tutorial is of course intended to show off how well-suited Julia is to the overall task, but I’d say this preliminary work is a fun task for Clojure. Let <code class="highlight">n</code> denote the number of iterations.</p>
<div class="superfences-tabs">
<input checked="checked" id="__tab_2_0" name="__tabs_2" type="radio"/>
<label for="__tab_2_0">Clojure</label>
<div class="superfences-content"><div class="highlight"><pre><span></span><span class="p">(</span><span class="kd">defn </span><span class="nv">bab-sqrt</span> <span class="p">[</span><span class="nv">x</span> <span class="nv">n</span><span class="p">]</span>
  <span class="p">(</span><span class="k">loop </span><span class="p">[</span><span class="nv">t</span> <span class="mf">1.0</span> <span class="nv">acc</span> <span class="mi">0</span><span class="p">]</span>
    <span class="p">(</span><span class="k">if </span><span class="p">(</span><span class="nb">&gt;= </span><span class="nv">acc</span> <span class="nv">n</span><span class="p">)</span>
         <span class="nv">t</span>
        <span class="p">(</span><span class="nf">recur</span> <span class="p">(</span><span class="nb">-&gt; </span><span class="p">(</span><span class="nb">/ </span><span class="nv">x</span> <span class="nv">t</span><span class="p">)</span>
                   <span class="p">(</span><span class="nb">+ </span><span class="nv">t</span><span class="p">)</span>
                   <span class="p">(</span><span class="nb">/ </span><span class="mi">2</span><span class="p">))</span>
               <span class="p">(</span><span class="nb">inc </span><span class="nv">acc</span><span class="p">)))))</span>
<span class="p">(</span><span class="nf">bab-sqrt</span> <span class="mi">2</span> <span class="mi">5</span><span class="p">)</span>   <span class="c1">; 1.414213562373095</span>
<span class="p">(</span><span class="nf">Math/sqrt</span> <span class="mi">2</span><span class="p">)</span>    <span class="c1">; 1.4142135623730951</span>
</pre></div></div>
<input id="__tab_2_1" name="__tabs_2" type="radio"/>
<label for="__tab_2_1">Julia</label>
<div class="superfences-content"><div class="highlight"><pre><span></span><span class="c"># the original code from Alan Edelman's notebook</span>
<span class="k">function</span> <span class="n">Babylonian</span><span class="p">(</span><span class="n">x</span><span class="p">;</span> <span class="n">N</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
  <span class="n">t</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
  <span class="k">for</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">2</span><span class="o">:</span><span class="n">N</span><span class="p">;</span> <span class="n">t</span><span class="o">=</span><span class="p">(</span><span class="n">t</span> <span class="o">+</span> <span class="n">x</span><span class="o">/</span><span class="n">t</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>  <span class="k">end</span>    
  <span class="n">t</span>
<span class="k">end</span>
<span class="n">Babylonian</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>  <span class="c"># 1.414213562373095</span>
<span class="o">√</span><span class="mi">2</span>             <span class="c"># 1.4142135623730951</span>
</pre></div></div>
<input id="__tab_2_2" name="__tabs_2" type="radio"/>
<label for="__tab_2_2">Python</label>
<div class="superfences-content"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">bab_root</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">iters</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
  <span class="n">t</span> <span class="o">=</span> <span class="mi">1</span>
  <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iters</span><span class="p">):</span>
    <span class="n">t</span> <span class="o">=</span> <span class="p">(</span><span class="n">t</span> <span class="o">+</span> <span class="n">x</span> <span class="o">/</span> <span class="n">t</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
  <span class="k">return</span> <span class="n">t</span>
<span class="n">bab_root</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
</pre></div></div>
</div>
<p>That converged pretty quick! Not to mention, it’s more than an “approximation”—it’s practically indistinguishable to the true value after just five iterations.</p>
<p>Okay, so we have our function. Since we already know the derivative of <span class="math">\(f(x)\)</span> through symbolic differentiation, we can compute a true value for <span class="math">\(f'(x)\)</span> at any point <span class="math">\(x = a\)</span>, against which we can validate the result of automatically differentiating <span class="math">\(f(x)\)</span> at <span class="math">\(x = a\)</span>.</p>
<p>The first step to differentiate the Babylonian square root function at <span class="math">\(x = 2\)</span> <em>symbolically</em> using dual numbers would look like this:</p>
<div class="math">$$ \frac{t + \frac{2 + \epsilon}{t}}{2} $$</div>
<p>which should yield a satisfactorily precise result after 5 iterations.</p>
<p>We thus need to implement our class similarly to the imaginary number classes, so that something like <code class="highlight"><span class="n">bab_root</span><span class="p">(</span><span class="n">Dual</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span></code> will give us the derivative of <span class="math">\(f(x) = \sqrt x\)</span> at <span class="math">\(x = 5\)</span> <em>without having to explicitly write anything about</em> <span class="math">\(\frac{1}{2\sqrt 5}\)</span>.</p>
<h2 id="getting-classy">Getting classy</h2>
<p>The basic task here is to create a class that overloads the basic arithmetic operators so that dual numbers can be manipulated like normal numbers. In other words, extend the operators to follow the rules of dual number arithmetic (included below).</p>
<p>To be honest, defining classes is above my current level of Clojure skills, I’ve never overloaded operators in Python before, and I’m almost completely new to Julia. So I will adapt the Python code from <a href="http://eviatarbach.com/2013/05/13/dual-numbers-and-automatic-differentiation/">this post</a> and the Julia code from <a href="https://nbviewer.jupyter.org/github/alanedelman/YouTubeNotebooks/blob/master/Automatic%20Differentiation%20in%2010%20Minutes.ipynb">this notebook</a>, break it down and proceed from there.</p>
<p>The rules of dual number arithmetic are as follows. Addition and multiplication work just like with complex numbers or polynomials (<span class="caps">FOIL</span>):</p>
<div class="math">$$ \begin{aligned}
(a + b\epsilon) \pm (c + d\epsilon) &amp;= \textcolor{teal}{(a + c)} \pm \textcolor{orange}{(b + d)}\epsilon \\
(a + b\epsilon) (c + d\epsilon) &amp;= \textcolor{teal}{(ac)} + \textcolor{orange}{(bc + ad)}\epsilon
\end{aligned} $$</div>
<p>Division is not so obvious, but this is the rule (<a href="https://en.wikipedia.org/wiki/Dual_number#Division">from Wikipedia</a>):</p>
<div class="math">$$ \frac{a + b\epsilon}{c + d\epsilon} = \textcolor{teal}{\frac{a}{c}} + \textcolor{orange}{\frac{bc - ad}{c^2}} \epsilon $$</div>
<p>Our result should have the teal part as its real component and the orange part as its dual component. We can treat <span class="math">\(\epsilon\)</span> as merely a symbol to be printed when the value needs to be displayed for us humans to read.</p>
<p>The Python code looks really long, but don’t get intimidated; it’s mostly boilerplate.</p>
<div class="superfences-tabs">
<input checked="checked" id="__tab_3_0" name="__tabs_3" type="radio"/>
<label for="__tab_3_0">Python</label>
<div class="superfences-content"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Dual</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">real</span><span class="p">,</span> <span class="n">dual</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">real</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">real</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dual</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">dual</span><span class="p">)</span>

    <span class="c1"># Overload basic operators</span>
    <span class="c1"># Copying these to the "r" functions ensures that a mixed expression can be</span>
    <span class="c1"># computed regardless of the order of arguments (Real+Dual / Dual+Real)</span>
    <span class="k">def</span> <span class="fm">__add__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">Dual</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">Dual</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">real</span> <span class="o">+</span> <span class="n">other</span><span class="o">.</span><span class="n">real</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">dual</span> <span class="o">+</span> <span class="n">other</span><span class="o">.</span><span class="n">dual</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Dual</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">real</span> <span class="o">+</span> <span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dual</span><span class="p">)</span>
    <span class="fm">__radd__</span> <span class="o">=</span> <span class="fm">__add__</span>

    <span class="k">def</span> <span class="fm">__sub__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">Dual</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">Dual</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">real</span> <span class="o">-</span> <span class="n">other</span><span class="o">.</span><span class="n">real</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">dual</span> <span class="o">-</span> <span class="n">other</span><span class="o">.</span><span class="n">dual</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Dual</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">real</span> <span class="o">-</span> <span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dual</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__rsub__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">Dual</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="fm">__mul__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">Dual</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">Dual</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">real</span> <span class="o">*</span> <span class="n">other</span><span class="o">.</span><span class="n">real</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">real</span> <span class="o">*</span> <span class="n">other</span><span class="o">.</span><span class="n">dual</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dual</span> <span class="o">*</span> <span class="n">other</span><span class="o">.</span><span class="n">real</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Dual</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">real</span> <span class="o">*</span> <span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dual</span> <span class="o">*</span> <span class="n">other</span><span class="p">)</span>
    <span class="fm">__rmul__</span> <span class="o">=</span> <span class="fm">__mul__</span>

    <span class="k">def</span> <span class="fm">__truediv__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">Dual</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">Dual</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">real</span><span class="o">/</span><span class="n">other</span><span class="o">.</span><span class="n">real</span><span class="p">,</span>
                        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dual</span><span class="o">*</span><span class="n">other</span><span class="o">.</span><span class="n">real</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">real</span><span class="o">*</span><span class="n">other</span><span class="o">.</span><span class="n">dual</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">real</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">other</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="fm">__rtruediv__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">Dual</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="fm">__truediv__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__pow__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">Dual</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">real</span><span class="o">**</span><span class="n">other</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">dual</span> <span class="o">*</span> <span class="n">other</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">real</span><span class="o">**</span><span class="p">(</span><span class="n">other</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>

    <span class="c1"># For human-readable representation</span>
    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">repr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">real</span><span class="p">)</span> <span class="o">+</span> <span class="s1">' + '</span> <span class="o">+</span> <span class="nb">repr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dual</span><span class="p">)</span> <span class="o">+</span> <span class="s1">'ϵ'</span>
</pre></div></div>
<input id="__tab_3_1" name="__tabs_3" type="radio"/>
<label for="__tab_3_1">Julia</label>
<div class="superfences-content"><div class="highlight"><pre><span></span><span class="c"># taken from Alan's notebook</span>
<span class="k">import</span> <span class="n">Base</span><span class="o">:</span> <span class="o">+</span><span class="p">,</span> <span class="o">-</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="o">/</span><span class="p">,</span> <span class="n">convert</span><span class="p">,</span> <span class="n">promote_rule</span>

<span class="n">struct</span> <span class="n">D</span> <span class="o">&lt;:</span> <span class="kt">Number</span>  <span class="c"># D is a function-derivative pair</span>
    <span class="n">f</span><span class="o">::</span><span class="kt">Tuple</span><span class="p">{</span><span class="kt">Float64</span><span class="p">,</span><span class="kt">Float64</span><span class="p">}</span>
<span class="k">end</span>

<span class="c"># Overload basic operators</span>
<span class="o">+</span><span class="p">(</span><span class="n">x</span><span class="o">::</span><span class="n">D</span><span class="p">,</span> <span class="n">y</span><span class="o">::</span><span class="n">D</span><span class="p">)</span> <span class="o">=</span> <span class="n">D</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">f</span> <span class="o">.+</span> <span class="n">y</span><span class="o">.</span><span class="n">f</span><span class="p">)</span>
<span class="o">-</span><span class="p">(</span><span class="n">x</span><span class="o">::</span><span class="n">D</span><span class="p">,</span> <span class="n">y</span><span class="o">::</span><span class="n">D</span><span class="p">)</span> <span class="o">=</span> <span class="n">D</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">f</span> <span class="o">.-</span> <span class="n">y</span><span class="o">.</span><span class="n">f</span><span class="p">)</span>
<span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">::</span><span class="n">D</span><span class="p">,</span> <span class="n">y</span><span class="o">::</span><span class="n">D</span><span class="p">)</span> <span class="o">=</span> <span class="n">D</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">f</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">y</span><span class="o">.</span><span class="n">f</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">f</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="n">y</span><span class="o">.</span><span class="n">f</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">x</span><span class="o">.</span><span class="n">f</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">y</span><span class="o">.</span><span class="n">f</span><span class="p">[</span><span class="mi">2</span><span class="p">])))</span>
<span class="o">/</span><span class="p">(</span><span class="n">x</span><span class="o">::</span><span class="n">D</span><span class="p">,</span> <span class="n">y</span><span class="o">::</span><span class="n">D</span><span class="p">)</span> <span class="o">=</span> <span class="n">D</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">f</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="n">y</span><span class="o">.</span><span class="n">f</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">f</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">x</span><span class="o">.</span><span class="n">f</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">f</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">y</span><span class="o">.</span><span class="n">f</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">/</span><span class="n">y</span><span class="o">.</span><span class="n">f</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">^</span><span class="mi">2</span><span class="p">))</span>

<span class="c"># Convert(D, 3)</span>
<span class="n">convert</span><span class="p">(</span><span class="o">::</span><span class="kt">Type</span><span class="p">{</span><span class="n">D</span><span class="p">},</span> <span class="n">x</span><span class="o">::</span><span class="kt">Real</span><span class="p">)</span> <span class="o">=</span> <span class="n">D</span><span class="p">((</span><span class="n">x</span><span class="p">,</span><span class="n">zero</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
<span class="c"># Operations with a dual number and a real number return a dual value</span>
<span class="n">promote_rule</span><span class="p">(</span><span class="o">::</span><span class="kt">Type</span><span class="p">{</span><span class="n">D</span><span class="p">},</span> <span class="o">::</span><span class="kt">Type</span><span class="p">{</span><span class="o">&lt;:</span><span class="kt">Number</span><span class="p">})</span> <span class="o">=</span> <span class="n">D</span>
<span class="c"># For human-readable representation</span>
<span class="n">Base</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">io</span><span class="o">::</span><span class="kt">IO</span><span class="p">,</span><span class="n">x</span><span class="o">::</span><span class="n">D</span><span class="p">)</span> <span class="o">=</span> <span class="n">print</span><span class="p">(</span><span class="n">io</span><span class="p">,</span><span class="n">x</span><span class="o">.</span><span class="n">f</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="s">" + "</span><span class="p">,</span><span class="n">x</span><span class="o">.</span><span class="n">f</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span><span class="s">"ϵ"</span><span class="p">)</span>
</pre></div></div>
</div>
<p>I think it’s noteworthy how short the Julia code is, even beyond Alan’s use of single-letter variables, for accomplishing the same thing (with the exception of accepting <code class="highlight"><span class="n">D</span><span class="p">((</span><span class="n">x</span><span class="p">))</span></code> and returning <code class="highlight"><span class="n">D</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span></code>, which I’m sure is also possible). It’s almost like halfway between Python and Clojure! (And it almost makes Python look like Java 😆)</p>
<p>Let’s play around a bit.</p>
<div class="superfences-tabs">
<input checked="checked" id="__tab_4_0" name="__tabs_4" type="radio"/>
<label for="__tab_4_0">Python</label>
<div class="superfences-content"><div class="highlight"><pre><span></span><span class="c1"># Complete input</span>
<span class="n">Dual</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>                <span class="c1"># 3.0 + 5.0ϵ</span>
<span class="c1"># Real-only input</span>
<span class="n">Dual</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>                   <span class="c1"># 3.0 + 0.0ϵ</span>
<span class="c1"># Confirming the characteristic property of ϵ</span>
<span class="n">Dual</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>           <span class="c1"># 0.0 + 0.0ϵ</span>
<span class="c1"># Random arithmetic</span>
<span class="n">Dual</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="o">*</span> <span class="n">Dual</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>  <span class="c1"># 12.0 + 64.0ϵ</span>
<span class="n">Dual</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span>            <span class="c1"># 5.0 + 2.0ϵ</span>
<span class="mi">7</span> <span class="o">/</span> <span class="n">Dual</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>           <span class="c1"># 1.4 + -8.4ϵ  </span>
</pre></div></div>
<input id="__tab_4_1" name="__tabs_4" type="radio"/>
<label for="__tab_4_1">Julia</label>
<div class="superfences-content"><div class="highlight"><pre><span></span><span class="c"># Complete input</span>
<span class="n">D</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>                <span class="c"># 3.0 + 5.0ϵ</span>
<span class="c"># Convert real numbers to dual numbers</span>
<span class="n">convert</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="c"># Confirming the characteristic property of ϵ</span>
<span class="c"># Note that Julia doesn't require ^ to be explicitly defined!</span>
<span class="n">D</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="o">^</span> <span class="mi">2</span>           <span class="c"># 0.0 + 0.0ϵ</span>
<span class="c"># Random arithmetic</span>
<span class="n">D</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span> <span class="o">*</span> <span class="n">D</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>  <span class="c"># 12.0 + 64.0ϵ</span>
<span class="n">D</span><span class="p">((</span><span class="mi">7</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span> <span class="o">-</span> <span class="mi">2</span>            <span class="c"># 5.0 + 2.0ϵ</span>
<span class="mi">7</span> <span class="o">/</span> <span class="n">D</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span><span class="mi">30</span><span class="p">))</span>           <span class="c"># 1.4 + -8.4ϵ  </span>
</pre></div></div>
</div>
<h2 id="ready-for-liftoff">Ready for liftoff</h2>
<p>This makes it quite simple to do more sophisticated things with dual numbers, because our classes work with just the salient parts: the real and dual components. The <span class="math">\(+\)</span> and <span class="math">\(\epsilon\)</span> are just there for decoration.</p>
<p>What that means is when we input a <code class="highlight">Dual(my_real, 1)</code> into <code class="highlight">my_func(x)</code>, we get another <code class="highlight">Dual(dual, real)</code> back. The <code class="highlight">real</code> component of this <code class="highlight">Dual</code> result is the value of <code class="highlight">my_func(my_real)</code>. The <code class="highlight">dual</code> component of the result (which is just a <code class="highlight">float</code>, not another <code class="highlight">Dual</code>) is the derivative of <code class="highlight">my_func(x)</code> at <code class="highlight">my_real</code>.</p>
<p>The code is simpler than the explanation:</p>
<div class="superfences-tabs">
<input checked="checked" id="__tab_5_0" name="__tabs_5" type="radio"/>
<label for="__tab_5_0">Python</label>
<div class="superfences-content"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">auto_diff</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="n">Dual</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">1.</span><span class="p">))</span><span class="o">.</span><span class="n">dual</span>
</pre></div></div>
<input id="__tab_5_1" name="__tabs_5" type="radio"/>
<label for="__tab_5_1">Julia</label>
<div class="superfences-content"><div class="highlight"><pre><span></span><span class="k">function</span> <span class="n">AutoDiff</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">func</span><span class="p">(</span><span class="n">D</span><span class="p">((</span><span class="n">x</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span><span class="o">.</span><span class="n">f</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="k">end</span>
</pre></div></div>
</div>
<p>Let’s start with a softball. How about <span class="math">\(f'(2)\)</span> if <span class="math">\(f(x) = x^2\)</span>?</p>
<div class="superfences-tabs">
<input checked="checked" id="__tab_6_0" name="__tabs_6" type="radio"/>
<label for="__tab_6_0">Python</label>
<div class="superfences-content"><div class="highlight"><pre><span></span><span class="n">auto_diff</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>    <span class="c1"># 4.0</span>
</pre></div></div>
<input id="__tab_6_1" name="__tabs_6" type="radio"/>
<label for="__tab_6_1">Julia</label>
<div class="superfences-content"><div class="highlight"><pre><span></span><span class="n">AutoDiff</span><span class="p">(</span><span class="n">x</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">^</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</pre></div></div>
</div>
<p>Not bad! How about <span class="math">\(f'(10)\)</span> if <span class="math">\(f(x) = x^{\sqrt e} + x^{\sqrt \pi}\)</span>?</p>
<div class="superfences-tabs">
<input checked="checked" id="__tab_7_0" name="__tabs_7" type="radio"/>
<label for="__tab_7_0">Python</label>
<div class="superfences-content"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="n">auto_diff</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">**</span> <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">e</span><span class="p">))</span> <span class="o">+</span> <span class="n">x</span> <span class="o">**</span> <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">pi</span><span class="p">)),</span> <span class="mi">10</span><span class="p">)</span>
<span class="c1"># 17.839035180965308</span>
</pre></div></div>
</div>
<p>And how about <span class="math">\(f'(\pi)\)</span> if <span class="math">\(f(x)\)</span> is the Babylonian square root (<span class="math">\(\frac{t + \frac{x}{t}}{2}\)</span>)? The wild thing is that we can actually compute the derivative with more and more precision by increasing the number of iterations of the original function.</p>
<p>(Hmm, that sounds vaguely akin to gradient descent… 🤔)</p>
<p>Let’s modify <code class="highlight">auto_diff</code> to allow this, and then iteratively show more and more precise values for <span class="math">\(f(\pi)\)</span> and <span class="math">\(f'(\pi)\)</span>.</p>
<div class="superfences-tabs">
<input checked="checked" id="__tab_8_0" name="__tabs_8" type="radio"/>
<label for="__tab_8_0">Python</label>
<div class="superfences-content"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">auto_diff</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="n">Dual</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">1.</span><span class="p">),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">dual</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">):</span>
    <span class="n">func</span> <span class="o">=</span> <span class="n">bab_root</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">iters</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
    <span class="n">deriv</span> <span class="o">=</span> <span class="n">auto_diff</span><span class="p">(</span><span class="n">bab_root</span><span class="p">,</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">iters</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{func}, {deriv}"</span><span class="p">)</span>
</pre></div></div>
<input id="__tab_8_1" name="__tabs_8" type="radio"/>
<label for="__tab_8_1">Julia</label>
<div class="superfences-content"><div class="highlight"><pre><span></span><span class="k">function</span> <span class="n">AutoDiff</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">x</span><span class="p">;</span> <span class="n">kwargs</span><span class="o">...</span><span class="p">)</span>
    <span class="n">func</span><span class="p">(</span><span class="n">D</span><span class="p">((</span><span class="n">x</span><span class="p">,</span><span class="mi">1</span><span class="p">));</span> <span class="n">kwargs</span><span class="o">...</span><span class="p">)</span><span class="o">.</span><span class="n">f</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="k">end</span>

<span class="k">for</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="o">:</span><span class="mi">5</span>
    <span class="n">func</span> <span class="o">=</span> <span class="n">Babylonian</span><span class="p">(</span><span class="nb">π</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="n">i</span><span class="p">)</span>
    <span class="n">deriv</span> <span class="o">=</span> <span class="n">AutoDiff</span><span class="p">(</span><span class="n">Babylonian</span><span class="p">,</span> <span class="nb">π</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="n">i</span><span class="p">)</span>
    <span class="n">println</span><span class="p">(</span><span class="s">"</span><span class="si">$</span><span class="p">(</span><span class="n">func</span><span class="p">)</span><span class="s">, </span><span class="si">$</span><span class="p">(</span><span class="n">deriv</span><span class="p">)</span><span class="s">"</span><span class="p">)</span>
<span class="k">end</span>
</pre></div></div>
</div>
<p>What is impressive is that not only does this <em>work</em>, it’s also more manageable, computationally faster, and more accurate to take derivatives this way. I won’t bore you with the evidence (you can check other blogs for that) because I’m mostly interested in the math behind this.</p>
<p>Plus, I can already believe that this is a better way. The only thing is that it’s a black box; you can’t see the general derivative <span class="math">\(f'(x)\)</span>.</p>
<p>Or can you?</p>
<h2 id="automatic-symbolic-differentiation">Automatic symbolic differentiation?</h2>
<p>Thanks to Alan’s notebook, I discovered SymPy, which can generate properly typeset <span class="math">\(\LaTeX\)</span> <em>directly from your code</em> and manipulate variables like <span class="math">\(x\)</span> as symbols rather than values!</p>
<p>I tried to hack SymPy’s <code class="highlight">ImaginaryUnit</code> class to implement a symbolic version of dual numbers, but I was too unfamiliar with it to get any results (everything was coming back zero). So to demonstrate this, I’m going to jump ahead a bit and use Julia’s built-in <code class="highlight">diff</code> function.</p>
<div class="highlight"><pre><span></span><span class="c"># Pkg.add("SymPy")  # if you don't already have it</span>
<span class="k">using</span> <span class="n">SymPy</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">symbols</span><span class="p">(</span><span class="s">"x"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">1</span><span class="o">:</span><span class="mi">5</span>
    <span class="n">display</span><span class="p">(</span><span class="n">simplify</span><span class="p">(</span><span class="n">Babylonian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">N</span><span class="o">=</span><span class="n">k</span><span class="p">)))</span>
<span class="k">end</span>
<span class="k">for</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">1</span><span class="o">:</span><span class="mi">5</span>
    <span class="n">display</span><span class="p">(</span><span class="n">simplify</span><span class="p">(</span><span class="n">diff</span><span class="p">(</span><span class="n">simplify</span><span class="p">(</span><span class="n">Babylonian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">N</span><span class="o">=</span><span class="n">k</span><span class="p">)),</span><span class="n">x</span><span class="p">)))</span>
<span class="k">end</span>
</pre></div>
<p>Watch what happens as we do successive iterations of the function <code class="highlight">Babylonian</code>:</p>
<div class="math">$$ \begin{gathered}
\frac{x}{2} + \frac{1}{2} \\[0.8em]
\frac{x + \frac{\left(x + 1\right)^{2}}{4}}{x + 1} \\[1em]
\frac{x^{4} + 28 x^{3} + 70 x^{2} + 28 x + 1}{8 \left(x^{3} + 7 x^{2} + 7 x + 1\right)} \\[1em]
\frac{x^{8} + 120 x^{7} + 1820 x^{6} + 8008 x^{5} + 12870 x^{4} + 8008 x^{3} + 1820 x^{2} + 120 x + 1}{16 \left(x^{7} + 35 x^{6} + 273 x^{5} + 715 x^{4} + 715 x^{3} + 273 x^{2} + 35 x + 1\right)}
\end{gathered} $$</div>
<p>Watch what happens as we do successive iterations of its derivative:</p>
<div class="math">$$ \begin{gathered}
\frac{1}{2} \\[0.8em]
\frac{x^{2} + 2 x + 5}{4 \left(x^{2} + 2 x + 1\right)} \\[1em]
\frac{x^{6} + 14 x^{5} + 147 x^{4} + 340 x^{3} + 375 x^{2} + 126 x + 21}{8 \left(x^{6} + 14 x^{5} + 63 x^{4} + 100 x^{3} + 63 x^{2} + 14 x + 1\right)}
\end{gathered} $$</div>
<p>Once you go beyond the third iteration, the polynomial expression of the derivative of the Babylonian square root function explodes to a length that is way beyond any computer monitor (and I can’t get the <span class="math">\(\KaTeX\)</span> renderer to do line-wrapping), so you’ll have to be convinced by this.</p>
<p>It should be noted that this is <em>not</em> what the computer is doing in order to <code class="highlight">diff</code> our function, but it <em>is</em> what <em>we</em> would have to do by hand if</p>
<ul>
<li>We wanted an exact answer, but</li>
<li>Our <span class="math">\(f(x)\)</span> couldn’t be differentiated with simple rules like the power rule, and</li>
<li>Dual numbers didn’t exist.</li>
</ul>
<p>Imagine!</p>
<h1 id="automatic-differentiation">Automatic differentiation</h1>
<p>It’s showtime.</p>
<h2 id="out-of-the-box-solutions">Out-of-the-box solutions</h2>
<p>Earlier, I hinted at the relevance of automatic differentiation to gradient descent. Indeed, it is <em>hugely relevant</em> to gradient descent, and thus to machine learning more generally. It should come as no surprise, then, that major machine learning libraries like PyTorch and Google-backed TensorFlow leverage it heavily.</p>
<p>You can go <em>really</em> deep with this stuff, but for the purposes of this blog post (and where I’m at in my studies of all this), it’s enough just to get automatic differentiation working out of the box in Python (with <code class="highlight">Autograd</code>) and Julia (with <code class="highlight">ForwardDiff</code>).</p>
<div class="superfences-tabs">
<input checked="checked" id="__tab_9_0" name="__tabs_9" type="radio"/>
<label for="__tab_9_0">Python</label>
<div class="superfences-content"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">autograd.numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">autograd</span> <span class="kn">import</span> <span class="n">grad</span>

<span class="c1"># Our DIY version</span>
<span class="n">auto_diff</span><span class="p">(</span><span class="n">bab_root</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># 0.35355339059327373</span>

<span class="c1"># Autograd version</span>
<span class="n">dbab_root</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">bab_root</span><span class="p">)</span>
<span class="n">dbab_root</span><span class="p">(</span><span class="mf">2.</span><span class="p">)</span>           <span class="c1"># 0.35355339059327373</span>
</pre></div></div>
<input id="__tab_9_1" name="__tabs_9" type="radio"/>
<label for="__tab_9_1">Julia</label>
<div class="superfences-content"><div class="highlight"><pre><span></span><span class="c"># Pkg.add("ForwardDiff") # if you don't have it</span>
<span class="k">using</span> <span class="n">ForwardDiff</span>

<span class="c"># Our DIY version</span>
<span class="n">AutoDiff</span><span class="p">(</span><span class="n">Babylonian</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>                      <span class="c"># 0.3535533905932738</span>

<span class="c"># ForwardDiff version</span>
<span class="n">ForwardDiff</span><span class="o">.</span><span class="n">derivative</span><span class="p">(</span><span class="n">x</span> <span class="o">-&gt;</span> <span class="n">Babylonian</span><span class="p">(</span><span class="n">x</span><span class="p">;</span> <span class="n">N</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>  <span class="c"># 0.35355339059327373</span>
</pre></div></div>
</div>
<p>Cool! It works out of the box—no fiddling with making dual number classes. That’s been done for us (and done more comprehensively and faster too).</p>
<p>Now, we got <code class="highlight">grad</code> to auto-differentiate <code class="highlight">bab_root</code> for us, a function <span class="math">\(f(x)\)</span> that accepts a scalar and returns a scalar, <span class="math">\(f'(x)\)</span>.</p>
<h2 id="epsilon-in-the-cost-function"><span class="math">\(\epsilon\)</span> in the cost function</h2>
<p>Can <code class="highlight">grad</code> auto-gradiate(?) the cost function <span class="math">\(J(\theta)\)</span> of <a href="/from-zero-to-ero#convergence-threshold">our linear regression model from before</a>, finding multiple partial derivatives in one swoop?</p>
<p>Let’s first take a step back and think about what we’re actually doing here.</p>
<p>Our cost function <span class="math">\(J(\theta)\)</span> takes a vector of weights <span class="math">\(\theta\)</span>. The cost function returns a vector where each value indicates how “off” the model is due to each weight.</p>
<div class="math">$$ \begin{aligned}
J(θ) &amp;= \frac{1}{2m}\sum_{i=1}^m{\Big[h_θ(x^i) - y_i\Big]}^2 \\
&amp;= \frac{1}{2m} \Big[\vec o^T (h_θ{\textbf X} - \vec y)\Big]^2
\end{aligned} $$</div>
<p>In this case, there are 6 weights (5 features + the bias), so <span class="math">\(J(\theta)\)</span> has 6 components.</p>
<p>The partial derivatives of <span class="math">\(J(\theta)\)</span> takes the same vector of weights and return the gradient <span class="math">\(\nabla J\)</span>, which is a vector where each value indicates the “velocity” of each misestimation due to the corresponding weight. (Returning to the coffee mug analogy, the gradient tells us the slope in each dimension <span class="math">\(x, y, z\)</span> at our current point on the coffee mug.)</p>
<div class="math">$$ \frac{\partial J(θ)}{\partial θ_j} = \frac{1}{m}\sum_{i=1}^m\Big[h_θ(x^i) - y_i\Big]x_j^i $$</div>
<p>These “velocities” tell us how to change our weights so that we can get a little closer to the minimum of the function (convergence, or the bottom of the mug).</p>
<p>When we did this before, we still had to find the partial derivatives manually, even though we did use matrix operations to streamline it all a bit:</p>
<div class="math">$$
\nabla J = \begin{bmatrix}
  \frac{1}{m} \sum_{i=1}^m x_0^i{(e_1)}^2 \\[0.5em]
  \frac{1}{m} \sum_{i=1}^m x_1^i{(e_1)}^2 \\[0.5em]
  \vdots \\[0.5em]
  \frac{1}{m} \sum_{i=1}^m x_n^i{(e_1)}^2
\end{bmatrix} $$</div>
<p>What we are asking now is: Can we get the velocities straight from the cost function without explicitly doing any math to find partial derivatives?</p>
<p>That is, can we write code to do <span class="math">\(J(\theta + \epsilon)\)</span>?</p>
<div class="math">$$
\theta = \begin{bmatrix}
  \theta_0 \\ \theta_1 \\ \vdots \\ \theta_n
\end{bmatrix} \qquad
\theta + \epsilon = \begin{bmatrix}
  \theta_0 + \epsilon \\ \theta_1 + \epsilon \\ \vdots \\ \theta_n + \epsilon
\end{bmatrix}
$$</div>
<p>Spoiler alert: The answer is <em>yes</em>!</p>
<h2 id="making-the-loopless-loop-mathless-too">Making the loopless loop mathless, too?</h2>
<p>Let’s get our setup going again.</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sklearn.datasets</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">X</span><span class="p">))</span> <span class="c1"># padding for bias column</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="c1"># this just fixes a quirk of sklearn's output</span>
</pre></div>
<p>After much trial and error, it seems to me that <code class="highlight">grad</code> can only take one argument. Mathematically, this makes sense.</p>
<p>This will require re-working the code a little bit, since I originally wrote it in a way that was more modular but also required more variables (Clojure thinking pattern, perhaps?).</p>
<p>Also, I learned that <code class="highlight">numpy</code> has a built-in <code class="highlight">mean()</code> method, which makes it possible to simplify the cost function by quite a bit (eliminating the need for the <code class="highlight">ones</code> vector and the <code class="highlight">num_samples</code> variables), and make it very readable.</p>
<p>I suppose that since we’re doing automatic differentiation, we don’t need the <code class="highlight">cost</code> value to be divided by 2, since the original purpose of that was to make the symbolic differentiation easier.</p>
<div class="highlight"><pre><span></span><span class="hll"><span class="k">def</span> <span class="nf">cost</span><span class="p">(</span><span class="n">weights</span><span class="p">):</span>
</span>    <span class="n">errors</span> <span class="o">=</span> <span class="n">X</span> <span class="err">@</span> <span class="n">weights</span> <span class="o">-</span> <span class="n">y</span>
<span class="hll">    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">errors</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span>
<span class="n">dummy_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">cost</span><span class="p">(</span><span class="n">dummy_weights</span><span class="p">)</span>     <span class="c1"># a big number. I got 7177.83591830956</span>
</pre></div>
<p>To take this to the next level, just <em>one line</em> is needed!</p>
<div class="highlight"><pre><span></span><span class="n">dcost</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>  <span class="c1"># returns a new function</span>
<span class="n">dcost</span><span class="p">(</span><span class="n">dummy_weights</span><span class="p">)</span>
<span class="c1"># Returns a vector of values for each weight. I got this:</span>
<span class="c1"># array([[  7.68455105],</span>
<span class="c1">#        [-70.49488731],</span>
<span class="c1">#        [-77.80611382],</span>
<span class="c1">#        [-40.00725071],</span>
<span class="c1">#        [  5.90183055],</span>
<span class="c1">#        [ -3.48617932]])</span>
</pre></div>
<p>Amazing! Now we should be able to rewrite the <code class="highlight">train_model</code> function a bit.</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">last_cost</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">epochs</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># just to know the value; not critical for training</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">epochs</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="hll">        <span class="n">weights</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dcost</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
</span><span class="hll">        <span class="n">this_cost</span> <span class="o">=</span> <span class="n">cost</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
</span>        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">this_cost</span> <span class="o">-</span> <span class="n">last_cost</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">epsilon</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="n">last_cost</span> <span class="o">=</span> <span class="n">this_cost</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Completed {epochs} epochs of training."</span><span class="p">)</span>
<span class="hll">    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Final cost: {cost(weights)}"</span><span class="p">)</span>
</span>    <span class="k">return</span> <span class="n">weights</span>

<span class="n">train_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="c1"># Completed 699 epochs of training.</span>
<span class="c1"># Final cost: 0.06114217689306121</span>
<span class="c1"># array([[-0.09259437],</span>
<span class="c1">#        [81.0788861 ],</span>
<span class="c1">#        [88.26630974],</span>
<span class="c1">#        [43.93549829],</span>
<span class="c1">#        [ 4.96655198],</span>
<span class="c1">#        [ 2.08424121]])</span>
</pre></div>
<p>🔥🔥🔥</p>
<p>And that’s it for this post. Stay tuned for more!</p>
<h1 id="summary">Summary</h1>
<div class="highlight"><pre><span></span><span class="hll"><span class="kn">import</span> <span class="nn">autograd.numpy</span> <span class="kn">as</span> <span class="nn">np</span> <span class="c1"># use instead of normal numpy</span>
</span><span class="hll"><span class="kn">from</span> <span class="nn">autograd</span> <span class="kn">import</span> <span class="n">grad</span>
</span><span class="kn">import</span> <span class="nn">sklearn.datasets</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">X</span><span class="p">))</span> <span class="c1"># padding for bias column</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="c1"># this just fixes a quirk of sklearn's output</span>

<span class="hll"><span class="k">def</span> <span class="nf">cost</span><span class="p">(</span><span class="n">weights</span><span class="p">):</span>
</span>    <span class="n">errors</span> <span class="o">=</span> <span class="n">X</span> <span class="err">@</span> <span class="n">weights</span> <span class="o">-</span> <span class="n">y</span>
<span class="hll">    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">errors</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span>
<span class="n">dcost</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>  <span class="c1"># returns a new function</span>

<span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">last_cost</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">epochs</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># just to know the value; not critical for training</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">epochs</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="hll">        <span class="n">weights</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dcost</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
</span><span class="hll">        <span class="n">this_cost</span> <span class="o">=</span> <span class="n">cost</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
</span>        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">this_cost</span> <span class="o">-</span> <span class="n">last_cost</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">epsilon</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="n">last_cost</span> <span class="o">=</span> <span class="n">this_cost</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Completed {epochs} epochs of training."</span><span class="p">)</span>
<span class="hll">    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Final cost: {cost(weights)}"</span><span class="p">)</span>
</span>    <span class="k">return</span> <span class="n">weights</span>

<span class="n">train_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
<h1 id="references">References</h1>
<ul>
<li>Automatic differentiation in 10 minutes with Julia (<a href="https://www.youtube.com/watch?v=vAp6nUMrKYg">video</a> / <a href="https://nbviewer.jupyter.org/github/alanedelman/YouTubeNotebooks/blob/master/Automatic%20Differentiation%20in%2010%20Minutes.ipynb">notebook</a>), Alan Edelman</li>
<li>Automatic differentiation in Ruby (<a href="https://www.youtube.com/watch?v=TI7mtWB4WiA">video</a> / <a href="https://github.com/tomstuart/dual_number">code</a>), Tom Stuart</li>
<li><a href="http://eviatarbach.com/2013/05/13/dual-numbers-and-automatic-differentiation/">Dual numbers and automatic differentiation</a>, Eviatar Bach</li>
<li><a href="https://github.com/HIPS/autograd/blob/master/docs/tutorial.md">Autograd tutorial</a>, Autograd docs</li>
</ul>

            <p class="post-footer">
                // filed
under                    <a class="post-category" href="../../tag/dual-numbers">dual numbers</a>
                    <a class="post-category" href="../../tag/automatic-differentiation">automatic differentiation</a>
                    <a class="post-category" href="../../tag/machine-learning">machine learning</a>
                in <a class="post-category" href="../../category/math-programming">Math, Programming</a>&nbsp;&nbsp;&nbsp;

                <span style="display:inline-block;">
                // share on <a href="https://twitter.com/share?text=%22The%20squarest%20root%20in%20Babylon%20and%20automatic%C2%A0differentiation%3A%20If%20you%20thought%201%20%2B%20%CF%B5%20%3D%201%20was%20weird%2C%20wait%20till%20you%20see%20what%20%CF%B5%C2%B2%20equates%C2%A0to.%22&amp;hashtags=dualnumbers%2Cautomaticdifferentiation%2Cmachinelearning" target="_blank">
                    <i class="fa fa-twitter fa-lg"></i> Twitter
                </a>
                </span>
            </p>
            <div class="hr"></div>


            <a href="#" class="go-top">Go Top</a>
<footer class="footer">
    <p>&copy; Justin Douglas  2019. Published with <a href="https://github.com/getpelican/pelican">Pelican</a>.<br />This work is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</p>
</footer>        </div>
    </div>
</div>
    <script>
        renderMathInElement(document.body);
    </script>

			<!-- Script specified by the user -->
			<script type="text/javascript"  src="../../assets/tweaks.js"></script>

    <!-- for pelican_dynamic plugin -->



</body>
</html>