<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="description" content="Getting stumped by some basic probability questions led me down a rabbit hole whereupon I stumbled across Bayes’ theorem." />

    <meta name="twitter:card" content="summary" />
    <meta name="twitter:site" content="@tabidots" />
    <meta name="twitter:creator" content="@tabidots" />
    <meta name="twitter:title" content="Monty, Monte, and… Bayes: Statistics and probability" />
    <meta name="twitter:description" content="Getting stumped by some basic probability questions led me down a rabbit hole whereupon I stumbled across Bayes’ theorem." />
    <meta name="twitter:image:src" content="../../images/phja_den_view.JPG" />
    <meta name="twitter:domain" content="svenkreiss.com" />

    <meta property="og:title" content="Monty, Monte, and… Bayes: Statistics and probability" />
    <meta property="og:type" content="article" />
    <meta property="og:description" content="Getting stumped by some basic probability questions led me down a rabbit hole whereupon I stumbled across Bayes’ theorem." />
    <meta property="og:image" content="../../images/phja_den_view.JPG" />
    <meta property="og:site_name" content="judosaltgenius.com" />
    <meta property="og:url" content="../../2019/01/monty-hall-beginner.html" />

        <link rel="alternate"  href="http://tabidots.github.io/feeds/all.atom.xml" type="application/atom+xml" title="Judo Salt Genius Full Atom Feed"/>

        <title>Monty, Monte, and… Bayes: Statistics and probability - Judo Salt Genius</title>


    <!-- KaTeX -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0-beta1/katex.min.css" integrity="sha384-VEnyslhHLHiYPca9KFkBB3CMeslnM9CzwjxsEbZTeA21JBm7tdLwKoZmCt3cZTYD" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0-beta1/katex.min.js" integrity="sha384-O4hpKqcplNCe+jLuBVEXC10Rn1QEqAmX98lKAIFBEDxZI0a+6Z2w2n8AEtQbR4CD" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0-beta1/contrib/auto-render.min.js" integrity="sha384-IiI65aU9ZYub2MY9zhtKd1H2ps7xxf+eb2YFG9lX6uRqpXCvBTOidPRCXCrQ++Uc" crossorigin="anonymous"></script>

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.1.0/css/font-awesome.min.css" />
    <link rel="stylesheet" href="../../theme/css/pure.css?v=0.1.0" />
      <!-- CSS specified by the user -->


      <link href="../../assets/mystyle.css" type="text/css" rel="stylesheet" />
    <link rel="stylesheet" href="../../theme/css/pygments.css" />

    <!-- for pelican_dynamic plugin -->
    <!-- end pelican_dynamic -->

</head>

<body>
<div class="pure-g-r" id="layout">
    <div class="sidebar sidebar-article pure-u">
        <header class="header-article">
                    <a href="../../author/justin-douglas" title="See posts by Justin Douglas">
                        <img class="avatar" alt="Justin Douglas" src="https://www.gravatar.com/avatar/74f13134596b2ed04a497936e3fdfd33?s=140">
                    </a>
                <h2 class="article-info">Justin Douglas</h2>



                <p class="article-date">Sat 12 January 2019</p>

                <a class="header-article-home" href="/">&larr;Home</a>
        </header>
    </div>
    <div class="pure-u">
        <div class="content">
            <section class="post">
                <header class="post-header">
                    <h1>Monty, Monte, and&#8230; Bayes: Statistics and&nbsp;probability</h1>
                </header>
            </section>

                <nav class="toc">
                <div class="toc">
<ul>
<li><a href="#the-monty-hall-problem">The Monty Hall problem</a></li>
<li><a href="#statistical-approach">Statistical approach</a></li>
<li><a href="#probabilistic-approach">Probabilistic approach</a></li>
<li><a href="#where-do-we-go-from-here">Where do we go from here?</a></li>
<li><a href="#references">References</a></li>
</ul>
</div>
                </nav>

            
<p>I thought I had familiarized myself enough with the basic workings of linear algebra after Week 1 that I thought Rachel Thomas’ (<a href="www.fast.ai">fast.ai</a>)’s <a href="https://www.youtube.com/watch?v=8iGzBMboA0I&amp;index=2&amp;list=PLtmWHNX-gukIc92m1K0P6bIOnZb-mg0hY&amp;t=0s">Linear algebra for coders</a> course would be a good way to deepen my knowledge by applying these newly learned concepts in Python.</p>
<p>But embarrassingly, even the first warmup problem was beyond me. It required the use of a Markov matrix, which is the application of linear algebra to probability. Then I realized I had no background in probability, so I tried Brilliant’s <a href="https://brilliant.org/courses/probability/introduction-to-probability/">Intro to Probability</a>, whereupon I roundly botched a bunch of basic probability questions.</p>
<p>I found it really odd that I had just learned these mathematical techniques (basic linear algebra and multivariable calculus) to solve problems in a new way, yet while these probability problems <em>could</em> be solved computationally, they are meant to be solved “intuitively.” Of course, that seems like a cruel joke, since their counterintuitive solutions make such problems seem more like Zen koans.</p>
<h1 id="the-monty-hall-problem">The Monty Hall problem</h1>
<p>Take, for example, the <a href="https://en.wikipedia.org/wiki/Monty_Hall_problem">Monty Hall problem</a>:</p>
<blockquote>
<p>Suppose you’re on a game show, and you’re given the choice of three doors: Behind one door is a car; behind the others, goats.</p>
<p>You pick a door, say No. 1, and the host, who knows what’s behind the doors, opens another door, say No. 3, which has a goat. He then says to you, “Do you want to pick door No. 2?”</p>
<p>Is it to your advantage to switch your choice?</p>
</blockquote>
<p><strong>Spoiler alert</strong>: The answer is that you <em>do</em> switch, because you would then have a <span class="math">\(\frac{2}{3}\)</span> probability of choosing the car.</p>
<p>Wait, what? How does a single door go from having a <span class="math">\(\frac{1}{3}\)</span> chance that the car is behind it to a <span class="math">\(\frac{2}{3}\)</span> chance? It seemed to me that you would now have a 50/50 chance, since there were two doors left.</p>
<p>People tend to explain the rationale for the solution by increasing the number of doors to 100, and the number of doors revealed to 98. But this didn’t change anything for me; you still ended up with 2 doors, and thus a 50/50 chance.</p>
<p>No number of doors, visual explanation, or animation seemed to help me understand it. Finally, I managed to find a <a href="https://www.reddit.com/r/explainlikeimfive/comments/58cdw3/eli5_the_monty_hall_problem/d8zanoq">comment</a> in an old <a href="https://www.reddit.com/r/explainlikeimfive"><span class="caps">ELI5</span></a> thread that made it click for me:</p>
<blockquote>
<p>As simply as possible: Don’t think of it as three doors. Think of it as your door, and Monty’s doors. The odds that you picked the right door are 1 in 3, and the odds that you didn’t are 2 in 3, right?</p>
<p>When Monty gets rid of one bad choice, he doesn’t change the odds that your door is right - it’s still 1 in 3. That means he’s also not changing the odds that you aren’t right - it’s still 2 in 3.</p>
<p>Therefore you’re not picking one door - you’re picking two doors at the same time and getting the best possible outcome. If either of Monty’s doors was right, you win; If both of Monty’s doors were bad, you lose.</p>
</blockquote>
<p>Explained this way, it then makes sense that there would only be a 50/50 chance if you had two doors <em>to begin with</em>. Or, if you had fallen into “the probability trap of treating non-random information as if it were random,” as it has been described <a href="https://sites.google.com/site/psmartinsite/Home/bridge-articles/the-monty-hall-trap">elsewhere</a>.</p>
<h1 id="statistical-approach">Statistical approach</h1>
<p>Let’s first try to simulate the game in Python. I’ll skip over explaining what’s going on in the code here, as it’s pretty elementary.</p>
<p>I just added perpetual loops to avoid the problem of bad input (if you were going to get other people to play, for example).</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>

<span class="k">def</span> <span class="nf">monty_hall</span><span class="p">():</span>
    <span class="n">doors</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"a"</span><span class="p">,</span><span class="s2">"b"</span><span class="p">,</span><span class="s2">"c"</span><span class="p">]</span>
    <span class="n">car</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">doors</span><span class="p">)</span>

    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">first_choice</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s2">"Choose a door (a/b/c): "</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">first_choice</span> <span class="ow">in</span> <span class="n">doors</span><span class="p">:</span>
            <span class="k">break</span>

    <span class="k">for</span> <span class="n">door</span> <span class="ow">in</span> <span class="n">doors</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">door</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">car</span> <span class="ow">and</span> <span class="n">door</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">first_choice</span><span class="p">:</span>
            <span class="n">monty_opens</span> <span class="o">=</span> <span class="n">door</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">action</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="n">f</span><span class="s2">"Monty opens door {monty_opens}; do you switch? (y/n) "</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">action</span> <span class="o">==</span> <span class="s2">"y"</span><span class="p">:</span> <span class="c1"># switch doors</span>
            <span class="n">final_choice</span> <span class="o">=</span> <span class="p">[</span><span class="n">door</span> <span class="k">for</span> <span class="n">door</span> <span class="ow">in</span> <span class="n">doors</span> <span class="k">if</span> <span class="n">door</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">first_choice</span> <span class="ow">and</span> <span class="n">door</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">monty_opens</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">break</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="s2">"n"</span><span class="p">:</span>
            <span class="n">final_choice</span> <span class="o">=</span> <span class="n">first_choice</span>
            <span class="k">break</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">continue</span>

    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Your final choice is door {final_choice}."</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">final_choice</span> <span class="o">==</span> <span class="n">car</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"You win! The car is behind door {car}."</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"You lose. The car was behind door {car}."</span><span class="p">)</span>
</pre></div>
<p>Next, let’s automate the process so that the computer decides randomly whether or not to switch, and returns us the information we need to analyze the outcomes (<em>stay/switch</em> and <em>win/lose</em>).</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">monty_hall</span><span class="p">():</span>
    <span class="n">doors</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"a"</span><span class="p">,</span><span class="s2">"b"</span><span class="p">,</span><span class="s2">"c"</span><span class="p">]</span>
    <span class="n">car</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">doors</span><span class="p">)</span>
    <span class="n">first_choice</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">doors</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">door</span> <span class="ow">in</span> <span class="n">doors</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">door</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">car</span> <span class="ow">and</span> <span class="n">door</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">first_choice</span><span class="p">:</span>
            <span class="n">monty_opens</span> <span class="o">=</span> <span class="n">door</span>

    <span class="n">switch_doors</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="bp">True</span><span class="p">,</span> <span class="bp">False</span><span class="p">])</span>
    <span class="n">final_choice</span> <span class="o">=</span> <span class="p">[</span><span class="n">door</span> <span class="k">for</span> <span class="n">door</span> <span class="ow">in</span> <span class="n">doors</span> <span class="k">if</span> <span class="n">door</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">first_choice</span> <span class="ow">and</span> <span class="n">door</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">monty_opens</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">switch_doors</span> <span class="k">else</span> <span class="n">first_choice</span>
    <span class="n">result</span> <span class="o">=</span> <span class="bp">True</span> <span class="k">if</span> <span class="n">final_choice</span> <span class="o">==</span> <span class="n">car</span> <span class="k">else</span> <span class="bp">False</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">"switch_doors"</span><span class="p">:</span> <span class="n">switch_doors</span><span class="p">,</span> <span class="s2">"result"</span><span class="p">:</span> <span class="n">result</span><span class="p">}</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">18</span><span class="p">]:</span> <span class="n">monty_hall</span><span class="p">()</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">18</span><span class="p">]:</span> <span class="p">{</span><span class="s1">'switch_doors'</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span> <span class="s1">'result'</span><span class="p">:</span> <span class="bp">False</span><span class="p">}</span>
</pre></div>
<p>Just as we can get the computer to flip a million coins for us, we can also get it to confront the Monty Hall problem a million times (if we want). This is called a <strong>Monte Carlo simulation</strong>. I was already familiar with this concept, but to offer a quick summary here, it basically leverages the <strong>law of large numbers</strong>: If you perform the same experiment enough times, the real result eventually converges on the theoretical result.</p>
<p>So let’s code it with a simple loop, tallying the results in two lists, and taking advantage of the truthiness of booleans in Python to quickly analyze the results:</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">monte_monty</span><span class="p">(</span><span class="n">times</span><span class="p">):</span>
    <span class="n">switch</span><span class="p">,</span> <span class="n">stay</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">times</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">monty_hall</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">x</span><span class="p">[</span><span class="s2">"switch_doors"</span><span class="p">]:</span>
            <span class="n">switch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s2">"result"</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">stay</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s2">"result"</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">switch</span><span class="p">:</span> <span class="c1"># avoid division by zero errors if you do 1 or 2 trials</span>
        <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Switching won {sum(switch)} out of {len(switch)} times; probability of {round(sum(switch)/len(switch) * 100, 2)}%."</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">stay</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Staying won {sum(stay)} out of {len(stay)} times; probability of {round(sum(stay)/len(stay) * 100, 2)}%."</span><span class="p">)</span>
</pre></div>
<p>To reiterate the explanation above, <em>if you perform the same experiment enough times, the real result eventually converges on the theoretical result.</em> Watch what happens with just 25 simulations:</p>
<div class="highlight"><pre><span></span><span class="n">In</span> <span class="p">[</span><span class="mi">20</span><span class="p">]:</span> <span class="n">monte_monty</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span>
<span class="n">Switching</span> <span class="n">won</span> <span class="mi">7</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">12</span> <span class="n">times</span><span class="p">;</span> <span class="n">probability</span> <span class="n">of</span> <span class="mf">58.33</span><span class="o">%.</span>
<span class="n">Staying</span> <span class="n">won</span> <span class="mi">4</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">13</span> <span class="n">times</span><span class="p">;</span> <span class="n">probability</span> <span class="n">of</span> <span class="mf">30.77</span><span class="o">%.</span>
</pre></div>
<p>It is already clear after just 25 simulations that the probability of switching is significantly greater than that of staying. Let’s keep going.</p>
<div class="highlight"><pre><span></span><span class="n">In</span> <span class="p">[</span><span class="mi">21</span><span class="p">]:</span> <span class="n">monte_monty</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
<span class="n">Switching</span> <span class="n">won</span> <span class="mi">18</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">29</span> <span class="n">times</span><span class="p">;</span> <span class="n">probability</span> <span class="n">of</span> <span class="mf">62.07</span><span class="o">%.</span>
<span class="n">Staying</span> <span class="n">won</span> <span class="mi">7</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">21</span> <span class="n">times</span><span class="p">;</span> <span class="n">probability</span> <span class="n">of</span> <span class="mf">33.33</span><span class="o">%.</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">22</span><span class="p">]:</span> <span class="n">monte_monty</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">Switching</span> <span class="n">won</span> <span class="mi">32</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">51</span> <span class="n">times</span><span class="p">;</span> <span class="n">probability</span> <span class="n">of</span> <span class="mf">62.75</span><span class="o">%.</span>
<span class="n">Staying</span> <span class="n">won</span> <span class="mi">16</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">49</span> <span class="n">times</span><span class="p">;</span> <span class="n">probability</span> <span class="n">of</span> <span class="mf">32.65</span><span class="o">%.</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">23</span><span class="p">]:</span> <span class="n">monte_monty</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">Switching</span> <span class="n">won</span> <span class="mi">330</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">496</span> <span class="n">times</span><span class="p">;</span> <span class="n">probability</span> <span class="n">of</span> <span class="mf">66.53</span><span class="o">%.</span>
<span class="n">Staying</span> <span class="n">won</span> <span class="mi">169</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">504</span> <span class="n">times</span><span class="p">;</span> <span class="n">probability</span> <span class="n">of</span> <span class="mf">33.53</span><span class="o">%.</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">24</span><span class="p">]:</span> <span class="n">monte_monty</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
<span class="n">Switching</span> <span class="n">won</span> <span class="mi">3376</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">5053</span> <span class="n">times</span><span class="p">;</span> <span class="n">probability</span> <span class="n">of</span> <span class="mf">66.81</span><span class="o">%.</span>
<span class="n">Staying</span> <span class="n">won</span> <span class="mi">1675</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">4947</span> <span class="n">times</span><span class="p">;</span> <span class="n">probability</span> <span class="n">of</span> <span class="mf">33.86</span><span class="o">%.</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">25</span><span class="p">]:</span> <span class="n">monte_monty</span><span class="p">(</span><span class="mi">100000</span><span class="p">)</span>
<span class="n">Switching</span> <span class="n">won</span> <span class="mi">33289</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">49759</span> <span class="n">times</span><span class="p">;</span> <span class="n">probability</span> <span class="n">of</span> <span class="mf">66.9</span><span class="o">%.</span>
<span class="n">Staying</span> <span class="n">won</span> <span class="mi">16789</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">50241</span> <span class="n">times</span><span class="p">;</span> <span class="n">probability</span> <span class="n">of</span> <span class="mf">33.42</span><span class="o">%.</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">26</span><span class="p">]:</span> <span class="n">monte_monty</span><span class="p">(</span><span class="mi">1000000</span><span class="p">)</span>
<span class="n">Switching</span> <span class="n">won</span> <span class="mi">333204</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">500463</span> <span class="n">times</span><span class="p">;</span> <span class="n">probability</span> <span class="n">of</span> <span class="mf">66.58</span><span class="o">%.</span>
<span class="n">Staying</span> <span class="n">won</span> <span class="mi">166298</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">499537</span> <span class="n">times</span><span class="p">;</span> <span class="n">probability</span> <span class="n">of</span> <span class="mf">33.29</span><span class="o">%.</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">27</span><span class="p">]:</span> <span class="n">monte_monty</span><span class="p">(</span><span class="mi">10000000</span><span class="p">)</span>
<span class="n">Switching</span> <span class="n">won</span> <span class="mi">3331217</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">4998552</span> <span class="n">times</span><span class="p">;</span> <span class="n">probability</span> <span class="n">of</span> <span class="mf">66.64</span><span class="o">%.</span>
<span class="n">Staying</span> <span class="n">won</span> <span class="mi">1666441</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">5001448</span> <span class="n">times</span><span class="p">;</span> <span class="n">probability</span> <span class="n">of</span> <span class="mf">33.32</span><span class="o">%.</span>
</pre></div>
<p>After 1000 runs, we pretty much obtain the theoretical probability of <span class="math">\(\frac{2}{3}\)</span> chance of a winning switch and <span class="math">\(\frac{1}{3}\)</span> chance of a winning stay, and after 10 million runs, we come within a hair’s breadth of it.</p>
<p>In this way, the Monte Carlo method is not that different from stochastic gradient descent.</p>
<h1 id="probabilistic-approach">Probabilistic approach</h1>
<p>There is another, less brute-force, more theoretical way of working out this answer using <strong>Bayesian inference</strong>.</p>
<p>Let’s rephrase the problem. Instead of focusing on the probability of a certain action (<em>stay/switch</em>) winning, we’ll examine the probability of a car being behind door <span class="math">\(x\)</span> after Monty opens door <span class="math">\(y\)</span>, or in the language of <strong>conditional probability</strong>, <em>given</em> that Monty opens door <span class="math">\(y\)</span>. That is,</p>
<div class="math">$$ P(\textrm{car}_x | \textrm{Monty}_y) $$</div>
<p>Let’s start with the <em>unconditional</em> probability (i.e., before the game starts) of the car being behind each of the doors, <span class="math">\(P(\textrm{car}_x)\)</span>. There are three doors and one car, so</p>
<div class="math">$$ \begin{gathered} P(\textrm{car}_x) = \tfrac{1}{3} \\
\therefore P(\textrm{car}_a) = P(\textrm{car}_b) = P(\textrm{car}_c) = \tfrac{1}{3} \end{gathered} $$</div>
<p>Next, let’s determine the <em>unconditional</em> probabilities (i.e., before the game starts) of Monty choosing each of the doors. Since he cannot choose the door you will have chosen, that leaves him with two doors:</p>
<div class="math">$$ \begin{gathered} P(\textrm{Monty}_x) = \tfrac{1}{2} \\
\therefore P(\textrm{Monty}_a) = P(\textrm{Monty}_b) = P(\textrm{Monty}_c) = \tfrac{1}{2} \end{gathered} $$</div>
<p>Now that we have our building blocks, let’s plug in what we can into the theorem:</p>
<div class="math">$$ P(H|E) = \frac{P(E|H) P(H)}{P(E)} $$</div>
<p>where <span class="math">\(H\)</span> is the hypothesis we’re interested in and <span class="math">\(E\)</span> is the plot-twist, game-changing event.</p>
<p>Let’s assume our first choice is door A. If we want to know the probability of the car being behind door A after Monty opens door C (i.e., we win by staying), we can fill in what we know:</p>
<div class="math">$$ \begin{aligned} P(\textrm{car}_a|\textrm{Monty}_c) &amp;= \frac{P(\textrm{Monty}_c|\textrm{car}_a) P(\textrm{car}_a)}{P(\textrm{Monty}_c)} \\
&amp;= \frac{P(\textrm{Monty}_c|\textrm{car}_a) \cdot \tfrac{1}{3} }{\tfrac{1}{2}} \end{aligned} $$</div>
<p>which leaves one last probability to calculate, <span class="math">\(P(\textrm{Monty}_c|\textrm{car}_a)\)</span>. That is the probability that Monty will open door C if the car is behind door A.</p>
<p>Monty can’t choose your door (A) or the door with the car (also A), leaving him two choices. He is therefore equally likely to choose door B or C, which means that <span class="math">\(P(\textrm{Monty}_c|\textrm{car}_a) = \tfrac{1}{2}\)</span>.</p>
<div class="math">$$ P(\textrm{car}_a|\textrm{Monty}_c) = \frac{P(\textrm{Monty}_c|\textrm{car}_a) P(\textrm{car}_a)}{P(\textrm{Monty}_c)} = \frac{\tfrac{1}{2} \cdot \tfrac{1}{3} }{\tfrac{1}{2}} = \frac{1}{3} $$</div>
<p>Though the theorem is quite convoluted, this answer agrees with our intuition and the Monte Carlo results.</p>
<p>What about the probability that we win by switching (i.e., the probability that the car is behind door B after Monty opens door C)?</p>
<div class="math">$$ \begin{aligned} P(\textrm{car}_b|\textrm{Monty}_c) &amp;= \frac{P(\textrm{Monty}_c|\textrm{car}_b) P(\textrm{car}_b)}{P(\textrm{Monty}_c)} \\
&amp;= \frac{P(\textrm{Monty}_c|\textrm{car}_b) \cdot \tfrac{1}{3} }{\tfrac{1}{2}} \end{aligned} $$</div>
<p>In the case of <span class="math">\(P(\textrm{Monty}_c|\textrm{car}_b)\)</span>, we have chosen door A and the car is behind door B. Monty knows this, and he also can’t choose the door you’ve chosen, door A.</p>
<p>His <em>only</em> choice, then, is to choose door C, and therefore <span class="math">\(P(\textrm{Monty}_c|\textrm{car}_b) = 1\)</span>.</p>
<div class="math">$$ P(\textrm{car}_b|\textrm{Monty}_c) = \frac{P(\textrm{Monty}_c|\textrm{car}_b) P(\textrm{car}_b)}{P(\textrm{Monty}_c)} = \frac{1 \cdot \tfrac{1}{3} }{\tfrac{1}{2}} = \frac{2}{3} $$</div>
<p>Again, the theorem agrees with the Monte Carlo results, although whether or not it also agrees with your intuition is a different question!</p>
<h1 id="where-do-we-go-from-here">Where do we go from here?</h1>
<p>I know that the Monte Carlo method can be used to make predictions about the movements of the stock market. However, I’m totally new to probability theory, so I’m not yet sure where to go after Bayes’ theorem. I’ll update this section once I find out and post about more generalized and sophisticated ways to apply Monte Carlo and Bayes’ theorem. Stay tuned!</p>
<h1 id="references">References</h1>
<ul>
<li><a href="https://datant.wordpress.com/2017/01/16/the-monty-hall-problem-and-3-ways-to-solve-it/">The Monty Hall problem and 3 ways to solve it</a>, Anthony O’Farrell</li>
<li><a href="https://www.countbayesie.com/blog/2015/2/18/bayes-theorem-with-lego">Bayes’ Theorem with Lego</a>, Will Kurt</li>
<li><a href="https://sc5.io/posts/how-to-solve-the-monty-hall-problem-using-bayesian-inference/#gref">How to solve the Monty Hall problem using Bayesian inference</a>, Max Pagels</li>
</ul>

            <p class="post-footer">
                // filed
under                    <a class="post-category" href="../../tag/monte-carlo">Monte Carlo</a>
                    <a class="post-category" href="../../tag/bayesian-inference">Bayesian inference</a>
                in <a class="post-category" href="../../category/probability">Probability</a>&nbsp;&nbsp;&nbsp;

                <span style="display:inline-block;">
                // share on <a href="https://twitter.com/share?text=%22Monty%2C%20Monte%2C%20and%E2%80%A6%20Bayes%3A%20Statistics%20and%C2%A0probability%3A%20Getting%20stumped%20by%20some%20basic%20probability%20questions%20led%20me%20down%20a%20rabbit%20hole%20whereupon%20I%20stumbled%20across%20Bayes%E2%80%99%C2%A0theorem.%22&amp;hashtags=MonteCarlo%2CBayesianinference" target="_blank">
                    <i class="fa fa-twitter fa-lg"></i> Twitter
                </a>
                </span>
            </p>
            <div class="hr"></div>


            <a href="#" class="go-top">Go Top</a>
<footer class="footer">
    <p>&copy; Justin Douglas  2019. Published with <a href="https://github.com/getpelican/pelican">Pelican</a>.<br />This work is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</p>
</footer>        </div>
    </div>
</div>
    <script>
        renderMathInElement(document.body);
    </script>

			<!-- Script specified by the user -->
			<script type="text/javascript"  src="../../assets/tweaks.js"></script>

    <!-- for pelican_dynamic plugin -->



</body>
</html>